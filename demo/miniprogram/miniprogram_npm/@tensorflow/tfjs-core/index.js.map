{"version":3,"sources":["index.js","engine.js","environment.js","profiler.js","util.js","tape.js","tensor.js","tensor_format.js","tensor_util.js","types.js","flags.js","device_util.js","backends/webgl/backend_webgl.js","backends/webgl/flags_webgl.js","backends/webgl/webgl_util.js","backends/webgl/canvas_util.js","globals.js","log.js","ops/array_ops_util.js","ops/axis_util.js","ops/concat_util.js","ops/gather_nd_util.js","ops/reduce_util.js","ops/scatter_nd_util.js","ops/segment_util.js","ops/slice_util.js","ops/softmax.js","gradients.js","tensor_util_env.js","ops/operation.js","ops/tensor_ops.js","ops/complex_ops.js","backends/backend.js","backends/backend_util.js","ops/broadcast_util.js","ops/conv_util.js","backends/complex_util.js","backends/non_max_suppression_impl.js","backends/split_shared.js","backends/topk_impl.js","backends/where_impl.js","ops/array_ops.js","ops/concat_split.js","ops/rand.js","backends/webgl/addn_gpu.js","backends/webgl/addn_packed_gpu.js","backends/webgl/argminmax_gpu.js","backends/webgl/argminmax_packed_gpu.js","backends/packing_util.js","backends/webgl/shader_compiler.js","backends/webgl/glsl_version.js","backends/webgl/shader_compiler_util.js","backends/webgl/avg_pool_backprop_gpu.js","backends/webgl/batchnorm_gpu.js","backends/webgl/batchnorm_packed_gpu.js","backends/webgl/binaryop_complex_gpu.js","backends/webgl/binaryop_gpu.js","backends/webgl/binaryop_packed_gpu.js","backends/webgl/clip_gpu.js","backends/webgl/clip_packed_gpu.js","backends/webgl/complex_abs_gpu.js","backends/webgl/concat_gpu.js","backends/webgl/concat_packed_gpu.js","backends/webgl/conv_backprop_gpu.js","backends/webgl/conv_backprop_gpu_depthwise.js","backends/webgl/conv_gpu.js","backends/webgl/conv_gpu_depthwise.js","backends/webgl/conv_packed_gpu_depthwise.js","backends/webgl/crop_and_resize_gpu.js","backends/webgl/cumsum_gpu.js","backends/webgl/depth_to_space_gpu.js","backends/webgl/encode_float_gpu.js","backends/webgl/fft_gpu.js","backends/webgl/fill_gpu.js","backends/webgl/from_pixels_gpu.js","backends/webgl/gather_gpu.js","backends/webgl/gather_nd_gpu.js","backends/webgl/gpgpu_context.js","backends/webgl/gpgpu_util.js","backends/webgl/tex_util.js","backends/webgl/gpgpu_math.js","backends/webgl/im2col_packed_gpu.js","backends/webgl/lrn_gpu.js","backends/webgl/lrn_grad_gpu.js","backends/webgl/lrn_packed_gpu.js","backends/webgl/max_pool_backprop_gpu.js","backends/webgl/mulmat_packed_gpu.js","backends/webgl/multinomial_gpu.js","backends/webgl/onehot_gpu.js","backends/webgl/pack_gpu.js","backends/webgl/pad_gpu.js","backends/webgl/pad_packed_gpu.js","backends/webgl/pool_gpu.js","backends/webgl/reduce_gpu.js","backends/webgl/reshape_packed_gpu.js","backends/webgl/resize_bilinear_backprop_gpu.js","backends/webgl/resize_bilinear_gpu.js","backends/webgl/resize_bilinear_packed_gpu.js","backends/webgl/resize_nearest_neighbor_backprop_gpu.js","backends/webgl/resize_nearest_neighbor_gpu.js","backends/webgl/reverse_gpu.js","backends/webgl/reverse_packed_gpu.js","backends/webgl/scatter_gpu.js","backends/webgl/segment_gpu.js","backends/webgl/select_gpu.js","backends/webgl/slice_gpu.js","backends/webgl/slice_packed_gpu.js","backends/webgl/strided_slice_gpu.js","backends/webgl/texture_manager.js","backends/webgl/tile_gpu.js","backends/webgl/transpose_gpu.js","backends/webgl/transpose_packed_gpu.js","backends/webgl/unaryop_gpu.js","ops/erf_util.js","ops/selu_util.js","backends/webgl/unaryop_packed_gpu.js","backends/webgl/unpack_gpu.js","backends/cpu/backend_cpu.js","ops/ops.js","ops/batchnorm.js","ops/unary_ops.js","ops/conv.js","ops/matmul.js","ops/reverse.js","ops/pool.js","ops/slice.js","ops/reduction_ops.js","ops/compare.js","ops/binary_ops.js","ops/relu_ops.js","ops/logical_ops.js","ops/transpose.js","ops/lrn.js","ops/norm.js","ops/segment_ops.js","ops/lstm.js","ops/moving_average.js","ops/strided_slice.js","ops/topk.js","ops/scatter_nd.js","ops/spectral_ops.js","ops/sparse_to_dense.js","ops/sparse_to_dense_util.js","ops/gather_nd.js","ops/dropout.js","ops/signal_ops.js","ops/loss_ops.js","ops/linalg_ops.js","ops/image_ops.js","ops/fused_ops.js","platforms/platform_browser.js","platforms/platform_node.js","io/io.js","io/indexed_db.js","io/io_utils.js","io/types.js","io/model_management.js","io/router_registry.js","io/local_storage.js","io/browser_files.js","io/http.js","io/weights_loader.js","io/progress.js","io/passthrough.js","math.js","ops/confusion_matrix.js","ops/browser.js","serialization.js","test_util.js","version.js","webgl.js","optimizers/adadelta_optimizer.js","optimizers/optimizer.js","optimizers/adagrad_optimizer.js","optimizers/adam_optimizer.js","optimizers/adamax_optimizer.js","optimizers/momentum_optimizer.js","optimizers/sgd_optimizer.js","optimizers/rmsprop_optimizer.js","train.js","optimizers/optimizer_constructors.js","browser_util.js"],"names":[],"mappings":";;;;;;;AAAA;AACA;AACA;ACFA,ADGA;ACFA,ADGA;ACFA,ADGA;ACFA,ACHA,AFMA;ACFA,ACHA,AFMA;ACFA,ACHA,AFMA;ACFA,ACHA,AFMA,AGTA;AFOA,ACHA,AFMA,AGTA;AFOA,ACHA,AFMA,AGTA;AFOA,ACHA,AFMA,AGTA,ACHA;AHUA,ACHA,AFMA,AGTA,ACHA;AHUA,ACHA,AFMA,AGTA,ACHA;AHUA,ACHA,AFMA,AGTA,AENA,ADGA;AHUA,ACHA,AFMA,AGTA,AENA,ADGA;AHUA,ACHA,AFMA,AGTA,AENA,ADGA;AHUA,ACHA,AFMA,AGTA,AENA,ACHA,AFMA;AHUA,ACHA,AFMA,AGTA,AENA,ACHA,AFMA;AHUA,ACHA,AFMA,AGTA,AENA,ACHA,AFMA;AHUA,ACHA,AFMA,AGTA,AENA,ACHA,ACHA,AHSA;AHUA,ACHA,AFMA,AGTA,AENA,ACHA,ACHA,AHSA;AHUA,ACHA,AFMA,AGTA,AENA,ACHA,ACHA,AHSA;AHUA,ACHA,AFMA,AGTA,AENA,ACHA,ACHA,ACHA,AJYA;AHUA,ACHA,AFMA,AGTA,AENA,ACHA,ACHA,ACHA,AJYA;AHUA,ACHA,AFMA,AGTA,AENA,ACHA,ACHA,ACHA,AJYA;AHUA,ACHA,AFMA,AGTA,AENA,ACHA,ACHA,ACHA,ACHA,ALeA;AHUA,ACHA,AFMA,AGTA,AENA,ACHA,ACHA,ACHA,ACHA,ALeA;AHUA,ACHA,AFMA,AGTA,AENA,ACHA,ACHA,ACHA,ACHA,ALeA;AHUA,ACHA,AQxBA,AV8BA,AGTA,AENA,ACHA,ACHA,ACHA,ACHA,ALeA;AHUA,ACHA,AQxBA,AV8BA,AGTA,AENA,ACHA,ACHA,ACHA,ACHA,ALeA;AHUA,ACHA,AQxBA,AV8BA,AGTA,AENA,ACHA,ACHA,ACHA,ACHA,ALeA;AOpBA,AV8BA,ACHA,AQxBA,AV8BA,AGTA,AENA,ACHA,ACHA,ACHA,ACHA,ALeA;AOpBA,AV8BA,ACHA,AQxBA,AV8BA,AGTA,AENA,ACHA,ACHA,ACHA,ACHA,ALeA;AOpBA,AV8BA,ACHA,AQxBA,AV8BA,AGTA,AENA,ACHA,ACHA,ACHA,ACHA,ALeA;AQvBA,ADGA,AV8BA,ACHA,AQxBA,AV8BA,AGTA,AENA,ACHA,ACHA,ACHA,ACHA,ALeA;AQvBA,ADGA,AV8BA,ACHA,AQxBA,AV8BA,AGTA,AENA,ACHA,ACHA,ACHA,ACHA,ALeA;AQvBA,ADGA,AV8BA,ACHA,AQxBA,AV8BA,AGTA,AENA,ACHA,ACHA,ACHA,ACHA,ALeA;AQvBA,ACHA,AFMA,AV8BA,ACHA,AQxBA,AV8BA,AGTA,AENA,ACHA,ACHA,ACHA,ACHA,ALeA;AQvBA,ACHA,AFMA,AV8BA,ACHA,AQxBA,AV8BA,AGTA,AENA,ACHA,ACHA,ACHA,ACHA,ALeA;AQvBA,ACHA,AFMA,AV8BA,ACHA,AQxBA,AV8BA,AGTA,AENA,ACHA,ACHA,ACHA,ACHA,ALeA;AQvBA,ACHA,ACHA,AHSA,AV8BA,ACHA,AQxBA,AV8BA,AGTA,AENA,ACHA,ACHA,ACHA,ACHA,ALeA;AQvBA,ACHA,ACHA,AHSA,AV8BA,ACHA,AQxBA,AV8BA,AGTA,AENA,ACHA,ACHA,ACHA,ACHA,ALeA;AQvBA,ACHA,ACHA,AHSA,AV8BA,ACHA,AQxBA,AV8BA,AGTA,AENA,ACHA,ACHA,ACHA,ACHA,ALeA;AQvBA,AGTA,AFMA,ACHA,AHSA,AV8BA,ACHA,AQxBA,AV8BA,AGTA,AENA,ACHA,ACHA,ACHA,ACHA,ALeA;AQvBA,AGTA,AFMA,ACHA,AHSA,AV8BA,ACHA,AQxBA,AV8BA,AGTA,AENA,ACHA,ACHA,ACHA,ACHA,ALeA;AQvBA,AGTA,AFMA,ACHA,AHSA,AV8BA,ACHA,AQxBA,AV8BA,AGTA,AENA,ACHA,ACHA,ACHA,ACHA,ALeA;AQvBA,AGTA,AFMA,ACHA,AHSA,AV8BA,ACHA,AQxBA,AMlBA,AhBgDA,AGTA,AENA,ACHA,ACHA,ACHA,ACHA,ALeA;AQvBA,AGTA,AFMA,ACHA,AHSA,AV8BA,ACHA,AQxBA,AMlBA,AhBgDA,AGTA,AENA,ACHA,ACHA,ACHA,ACHA,ALeA;AQvBA,AGTA,AFMA,ACHA,AHSA,AV8BA,ACHA,AQxBA,AMlBA,AhBgDA,AGTA,AENA,ACHA,ACHA,ACHA,ACHA,ALeA;AQvBA,AGTA,AFMA,ACHA,AHSA,AV8BA,ACHA,AQxBA,AMlBA,AhBgDA,AiBnDA,Ad0CA,AENA,ACHA,ACHA,ACHA,ACHA,ALeA;AQvBA,AGTA,AFMA,ACHA,AHSA,AV8BA,ACHA,AQxBA,AMlBA,AhBgDA,AiBnDA,Ad0CA,AENA,ACHA,ACHA,ACHA,ACHA,ALeA;AQvBA,AGTA,AFMA,ACHA,AHSA,AV8BA,ACHA,AQxBA,AMlBA,AhBgDA,AiBnDA,Ad0CA,AENA,ACHA,ACHA,ACHA,ACHA,ALeA;AQvBA,AGTA,AFMA,ACHA,AHSA,AV8BA,ACHA,AQxBA,AMlBA,AhBgDA,AiBnDA,ACHA,Af6CA,AENA,ACHA,ACHA,ACHA,ACHA,ALeA;AQvBA,AGTA,AFMA,ACHA,AHSA,AV8BA,ACHA,AQxBA,AMlBA,AhBgDA,AiBnDA,ACHA,Af6CA,AENA,ACHA,ACHA,ACHA,ACHA,ALeA;AQvBA,AGTA,AFMA,ACHA,AHSA,AV8BA,ACHA,AQxBA,AMlBA,AhBgDA,AiBnDA,ACHA,Af6CA,AENA,ACHA,ACHA,ACHA,ACHA,ALeA;AQvBA,AGTA,AFMA,ACHA,AHSA,AV8BA,ACHA,AQxBA,AMlBA,AhBgDA,AiBnDA,ACHA,ACHA,AhBgDA,AENA,ACHA,ACHA,ACHA,ACHA,ALeA;AQvBA,AGTA,AFMA,ACHA,AHSA,AV8BA,ACHA,AQxBA,AMlBA,AhBgDA,AiBnDA,ACHA,ACHA,AhBgDA,AENA,ACHA,ACHA,ACHA,ACHA,ALeA;AQvBA,AGTA,AFMA,ACHA,AHSA,AV8BA,ACHA,AQxBA,AMlBA,AhBgDA,AiBnDA,ACHA,ACHA,AhBgDA,AENA,ACHA,ACHA,ACHA,ACHA,ALeA;AQvBA,AGTA,AFMA,ACHA,AHSA,AV8BA,ACHA,AQxBA,AMlBA,AhBgDA,AiBnDA,ACHA,ACHA,ACHA,AjBmDA,AENA,ACHA,ACHA,ACHA,ACHA,ALeA;AQvBA,AGTA,AFMA,ACHA,AHSA,AV8BA,ACHA,AQxBA,AMlBA,AhBgDA,AiBnDA,ACHA,ACHA,ACHA,AjBmDA,AENA,ACHA,ACHA,ACHA,ACHA,ALeA;AQvBA,AGTA,AFMA,ACHA,AHSA,AV8BA,ACHA,AQxBA,AMlBA,AhBgDA,AiBnDA,ACHA,ACHA,ACHA,AjBmDA,AENA,ACHA,ACHA,ACHA,ACHA,ALeA;AQvBA,AGTA,AFMA,ACHA,AHSA,AV8BA,ACHA,AQxBA,AMlBA,AhBgDA,AiBnDA,ACHA,ACHA,ACHA,ACHA,AlBsDA,AENA,ACHA,ACHA,ACHA,ACHA,ALeA;AQvBA,AGTA,AFMA,ACHA,AHSA,AV8BA,ACHA,AQxBA,AMlBA,AhBgDA,AiBnDA,ACHA,ACHA,ACHA,ACHA,AlBsDA,AENA,ACHA,ACHA,ACHA,ACHA,ALeA;AQvBA,AGTA,AFMA,ACHA,AHSA,AV8BA,ACHA,AQxBA,AMlBA,AhBgDA,AiBnDA,ACHA,ACHA,ACHA,ACHA,AlBsDA,AENA,ACHA,ACHA,ACHA,ACHA,ALeA;AQvBA,AGTA,AFMA,ACHA,AHSA,AV8BA,ACHA,AQxBA,AMlBA,AhBgDA,AiBnDA,ACHA,ACHA,ACHA,ACHA,ACHA,AnByDA,AENA,ACHA,ACHA,ACHA,ACHA,ALeA;AQvBA,AGTA,AFMA,ACHA,AbuCA,ACHA,AQxBA,AMlBA,AhBgDA,AiBnDA,ACHA,ACHA,ACHA,ACHA,ACHA,AnByDA,AENA,ACHA,ACHA,ACHA,ACHA,ALeA;AQvBA,AGTA,AFMA,ACHA,AbuCA,ACHA,AQxBA,AMlBA,AhBgDA,AiBnDA,ACHA,ACHA,ACHA,ACHA,ACHA,AnByDA,AENA,ACHA,ACHA,ACHA,ACHA,ALeA;AQvBA,AGTA,AFMA,ACHA,AbuCA,ACHA,AQxBA,AMlBA,AhBgDA,AiBnDA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ApB4DA,AENA,ACHA,ACHA,ACHA,ACHA,ALeA;AQvBA,AGTA,AFMA,ACHA,AbuCA,ACHA,AQxBA,AMlBA,AhBgDA,AiBnDA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ApB4DA,AENA,ACHA,ACHA,ACHA,ACHA,ALeA;AQvBA,AGTA,AFMA,ACHA,AbuCA,ACHA,AQxBA,AMlBA,AhBgDA,AiBnDA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ApB4DA,AENA,ACHA,ACHA,ACHA,ACHA,ALeA;AQvBA,AGTA,AFMA,ACHA,AbuCA,ACHA,AQxBA,AMlBA,AhBgDA,AiBnDA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ArB+DA,AENA,ACHA,ACHA,ACHA,ACHA,ALeA;AQvBA,AGTA,AFMA,ACHA,AbuCA,ACHA,AQxBA,AMlBA,AhBgDA,AiBnDA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ArB+DA,AENA,ACHA,ACHA,ACHA,ACHA,ALeA;AQvBA,AGTA,AFMA,ACHA,AbuCA,ACHA,AQxBA,AMlBA,AhBgDA,AiBnDA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ArB+DA,AENA,ACHA,ACHA,ACHA,ACHA,ALeA;AQvBA,AGTA,AFMA,ACHA,AbuCA,ACHA,AQxBA,AMlBA,AhBgDA,AiBnDA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ApB4DA,ACHA,ACHA,ACHA,ACHA,ALeA;AQvBA,AGTA,AFMA,ACHA,AbuCA,ACHA,AQxBA,AMlBA,AhBgDA,AiBnDA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ApB4DA,ACHA,ACHA,ACHA,ACHA,ALeA;AQvBA,AGTA,AFMA,ACHA,AbuCA,ACHA,AQxBA,AMlBA,AhBgDA,AiBnDA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ApB4DA,ACHA,ACHA,ACHA,ACHA,ALeA;AQvBA,AGTA,AFMA,ACHA,AbuCA,ACHA,AQxBA,AMlBA,AhBgDA,AiBnDA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ArB+DA,ACHA,ACHA,ACHA,ACHA,ALeA;AQvBA,AGTA,AFMA,ACHA,AbuCA,ACHA,AQxBA,AMlBA,AhBgDA,AiBnDA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ArB+DA,ACHA,ACHA,ACHA,ACHA,ALeA;AQvBA,AGTA,AFMA,ACHA,AbuCA,ACHA,AQxBA,AMlBA,AhBgDA,AiBnDA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ArB+DA,ACHA,ACHA,ACHA,ACHA,ALeA;AQvBA,AGTA,AFMA,ACHA,AbuCA,ACHA,AQxBA,AMlBA,AWjCA,A3BiFA,AiBnDA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ArB+DA,ACHA,ACHA,ACHA,ACHA,ALeA;AQvBA,AGTA,AFMA,ACHA,AbuCA,ACHA,AQxBA,AMlBA,AWjCA,A3BiFA,AiBnDA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ArB+DA,ACHA,ACHA,ACHA,ACHA,ALeA;AQvBA,AGTA,AFMA,ACHA,AbuCA,ACHA,AQxBA,AMlBA,AWjCA,A3BiFA,AiBnDA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ArB+DA,ACHA,ACHA,ACHA,ACHA,ALeA;AQvBA,AGTA,AFMA,ACHA,AbuCA,ACHA,AQxBA,AMlBA,AWjCA,A3BiFA,AiBnDA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ArB+DA,ACHA,ACHA,ACHA,AoB5DA,AnByDA,ALeA;AQvBA,AGTA,AFMA,ACHA,AbuCA,ACHA,AQxBA,AMlBA,AWjCA,A3BiFA,AiBnDA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ArB+DA,ACHA,ACHA,ACHA,AoB5DA,AnByDA,ALeA;AQvBA,AGTA,AFMA,ACHA,AbuCA,ACHA,Ac1CA,AWjCA,A3BiFA,AiBnDA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ArB+DA,ACHA,ACHA,ACHA,AoB5DA,AnByDA,ALeA;AQvBA,AGTA,AFMA,ACHA,AbuCA,ACHA,Ac1CA,AWjCA,A3BiFA,AiBnDA,ACHA,ACHA,ACHA,ACHA,AQxBA,APqBA,ACHA,ACHA,ACHA,ACHA,ArB+DA,ACHA,ACHA,ACHA,AoB5DA,AnByDA,ALeA;AQvBA,AGTA,AFMA,ACHA,AbuCA,ACHA,Ac1CA,AWjCA,A3BiFA,AiBnDA,ACHA,ACHA,ACHA,ACHA,AQxBA,APqBA,ACHA,ACHA,ACHA,ACHA,ArB+DA,ACHA,ACHA,ACHA,AoB5DA,AnByDA,ALeA;AQvBA,AGTA,AFMA,ACHA,AbuCA,ACHA,Ac1CA,AWjCA,A3BiFA,AiBnDA,ACHA,ACHA,ACHA,ACHA,AQxBA,APqBA,ACHA,ACHA,ACHA,ACHA,ArB+DA,ACHA,ACHA,ACHA,AoB5DA,AnByDA,ALeA;AQvBA,AGTA,AFMA,ACHA,AbuCA,ACHA,Ac1CA,AWjCA,A3BiFA,AiBnDA,ACHA,ACHA,ACHA,ACHA,AQxBA,APqBA,ACHA,ACHA,ACHA,ACHA,AIZA,AzB2EA,ACHA,ACHA,ACHA,AoB5DA,AnByDA,ALeA;AQvBA,AGTA,AFMA,ACHA,AbuCA,ACHA,Ac1CA,AWjCA,A3BiFA,AkBtDA,ACHA,ACHA,ACHA,AQxBA,APqBA,ACHA,ACHA,ACHA,ACHA,AIZA,AzB2EA,ACHA,ACHA,ACHA,AoB5DA,AnByDA,ALeA;AQvBA,AGTA,AFMA,ACHA,AbuCA,ACHA,Ac1CA,AWjCA,A3BiFA,AkBtDA,ACHA,ACHA,ACHA,AQxBA,APqBA,ACHA,ACHA,ACHA,ACHA,AIZA,AzB2EA,ACHA,ACHA,ACHA,AoB5DA,AnByDA,ALeA;AQvBA,AGTA,AFMA,ACHA,AbuCA,ACHA,Ac1CA,AWjCA,A3BiFA,AkBtDA,ACHA,AYpCA,AXiCA,ACHA,AQxBA,APqBA,ACHA,ACHA,ACHA,ACHA,AIZA,AzB2EA,ACHA,ACHA,ACHA,AoB5DA,AnByDA,ALeA;AQvBA,AGTA,AFMA,ACHA,AbuCA,ACHA,Ac1CA,AWjCA,A3BiFA,AkBtDA,ACHA,AYpCA,AXiCA,ACHA,AQxBA,APqBA,ACHA,ACHA,ACHA,ACHA,AIZA,AzB2EA,ACHA,ACHA,ACHA,AoB5DA,AnByDA,ALeA;AQvBA,AGTA,AFMA,ACHA,AbuCA,ACHA,Ac1CA,AWjCA,A3BiFA,AkBtDA,ACHA,AYpCA,AXiCA,ACHA,AQxBA,APqBA,ACHA,ACHA,ACHA,ACHA,AIZA,AzB2EA,ACHA,ACHA,ACHA,AoB5DA,AnByDA,ALeA;A4BnFA,ApB4DA,AGTA,AFMA,ACHA,AbuCA,ACHA,Ac1CA,AWjCA,A3BiFA,AkBtDA,ACHA,AYpCA,AXiCA,ACHA,AQxBA,APqBA,ACHA,ACHA,ACHA,ACHA,AIZA,AzB2EA,ACHA,ACHA,ACHA,AoB5DA,AnByDA,ALeA;A4BnFA,ApB4DA,AGTA,AFMA,ACHA,AbuCA,ACHA,Ac1CA,AWjCA,A3BiFA,AkBtDA,ACHA,AYpCA,AXiCA,ACHA,AQxBA,APqBA,ACHA,ACHA,ACHA,ACHA,AIZA,AzB2EA,ACHA,ACHA,ACHA,AoB5DA,AnByDA,ALeA;A4BnFA,ApB4DA,AGTA,AFMA,ACHA,AbuCA,ACHA,Ac1CA,AWjCA,A3BiFA,AkBtDA,ACHA,AYpCA,AXiCA,ACHA,AQxBA,ANkBA,ACHA,ACHA,ACHA,AIZA,AzB2EA,ACHA,ACHA,ACHA,AoB5DA,AnByDA,ALeA;A4BnFA,ACHA,ArB+DA,AGTA,AFMA,ACHA,AbuCA,ACHA,Ac1CA,AWjCA,A3BiFA,AkBtDA,ACHA,AYpCA,AXiCA,ACHA,AQxBA,ANkBA,ACHA,ACHA,ACHA,AIZA,AzB2EA,ACHA,ACHA,ACHA,AoB5DA,AnByDA,ALeA;A4BnFA,ACHA,ArB+DA,AGTA,AFMA,ACHA,AbuCA,ACHA,Ac1CA,AWjCA,A3BiFA,AkBtDA,ACHA,AYpCA,AXiCA,ACHA,AQxBA,ANkBA,ACHA,ACHA,ACHA,AIZA,AzB2EA,ACHA,ACHA,ACHA,AoB5DA,AnByDA,ALeA;A4BnFA,ACHA,ArB+DA,AGTA,AFMA,ACHA,AbuCA,ACHA,Ac1CA,AWjCA,A3BiFA,AkBtDA,ACHA,AYpCA,AXiCA,ACHA,AQxBA,ANkBA,ACHA,ACHA,ACHA,AIZA,AzB2EA,ACHA,ACHA,ACHA,AoB5DA,AnByDA,ALeA;A4BnFA,ACHA,ArB+DA,AGTA,AFMA,ACHA,AbuCA,ACHA,Ac1CA,AWjCA,A3BiFA,AkBtDA,ACHA,Ae7CA,AHSA,AXiCA,ACHA,AQxBA,ANkBA,ACHA,ACHA,ACHA,AIZA,AzB2EA,ACHA,ACHA,ACHA,AoB5DA,AnByDA,ALeA;A4BnFA,ACHA,ArB+DA,AGTA,AFMA,ACHA,AbuCA,ACHA,Ac1CA,AWjCA,A3BiFA,AkBtDA,ACHA,Ae7CA,AHSA,AXiCA,ACHA,AQxBA,ANkBA,ACHA,ACHA,ACHA,AIZA,AzB2EA,ACHA,ACHA,ACHA,AoB5DA,AnByDA,ALeA;A4BnFA,ACHA,ArB+DA,AGTA,AFMA,ACHA,AbuCA,ACHA,Ac1CA,AWjCA,A3BiFA,AkBtDA,ACHA,Ae7CA,AHSA,AXiCA,ACHA,AQxBA,ANkBA,ACHA,ACHA,ACHA,AIZA,AzB2EA,ACHA,ACHA,ACHA,AoB5DA,AnByDA,ALeA;A4BnFA,ACHA,ArB+DA,AGTA,AFMA,ACHA,AbuCA,ACHA,Ac1CA,AWjCA,AT2BA,ACHA,Ae7CA,AHSA,AXiCA,Ae7CA,Ad0CA,AQxBA,ANkBA,ACHA,ACHA,ACHA,AIZA,AzB2EA,ACHA,ACHA,ACHA,AoB5DA,AnByDA,ALeA;A4BnFA,ACHA,ArB+DA,AGTA,AFMA,ACHA,AbuCA,ACHA,Ac1CA,AWjCA,AT2BA,ACHA,Ae7CA,AHSA,AXiCA,Ae7CA,Ad0CA,AQxBA,ANkBA,ACHA,ACHA,ACHA,AIZA,AzB2EA,ACHA,ACHA,ACHA,AoB5DA,AnByDA,ALeA;A4BnFA,ACHA,ArB+DA,AGTA,AFMA,ACHA,AbuCA,ACHA,Ac1CA,AWjCA,AT2BA,ACHA,Ae7CA,AHSA,AIZA,Ad0CA,AQxBA,ANkBA,ACHA,ACHA,ACHA,AIZA,AzB2EA,ACHA,ACHA,ACHA,AoB5DA,AxBwEA;A4BnFA,ACHA,AGTA,AxBwEA,AGTA,AFMA,ACHA,AbuCA,ACHA,Ac1CA,AWjCA,AT2BA,ACHA,Ae7CA,AHSA,AIZA,Ad0CA,AQxBA,ANkBA,ACHA,ACHA,ACHA,AIZA,AzB2EA,ACHA,ACHA,ACHA,AoB5DA,AxBwEA;A4BnFA,ACHA,AGTA,AxBwEA,AGTA,AFMA,ACHA,AbuCA,ACHA,Ac1CA,AWjCA,AT2BA,ACHA,Ae7CA,AHSA,AIZA,Ad0CA,AQxBA,ANkBA,ACHA,ACHA,ACHA,AIZA,AzB2EA,ACHA,ACHA,ACHA,AoB5DA,AxBwEA;A4BnFA,ACHA,AGTA,AxBwEA,AGTA,AFMA,ACHA,AbuCA,ACHA,Ac1CA,AWjCA,AT2BA,ACHA,Ae7CA,AHSA,AIZA,Ad0CA,AQxBA,ANkBA,ACHA,ACHA,ACHA,AIZA,AzB2EA,ACHA,ACHA,ACHA,AoB5DA,AxBwEA;A4BnFA,ACHA,AGTA,ACHA,AzB2EA,AGTA,AFMA,ACHA,AbuCA,ACHA,Ac1CA,AWjCA,AT2BA,ACHA,Ae7CA,AHSA,AIZA,Ad0CA,AQxBA,ANkBA,ACHA,ACHA,ACHA,AIZA,AzB2EA,ACHA,ACHA,ACHA,AoB5DA,AxBwEA;A4BnFA,ACHA,AGTA,ACHA,AzB2EA,AGTA,AFMA,ACHA,AbuCA,ACHA,Ac1CA,AWjCA,AT2BA,ACHA,Ae7CA,AHSA,AIZA,Ad0CA,AQxBA,ANkBA,ACHA,ACHA,ACHA,AIZA,AzB2EA,ACHA,ACHA,AqB/DA,AxBwEA;A4BnFA,ACHA,AGTA,ACHA,AzB2EA,AGTA,AFMA,ACHA,AbuCA,ACHA,Ac1CA,AWjCA,AT2BA,ACHA,Ae7CA,AHSA,AIZA,Ad0CA,AQxBA,ANkBA,ACHA,ACHA,ACHA,AIZA,AzB2EA,ACHA,ACHA,AqB/DA,AxBwEA;A4BnFA,ACHA,AGTA,ACHA,ACHA,A1B8EA,ACHA,ACHA,AbuCA,ACHA,Ac1CA,AWjCA,AT2BA,ACHA,Ae7CA,AHSA,AIZA,Ad0CA,AQxBA,ANkBA,ACHA,ACHA,ACHA,AIZA,AzB2EA,ACHA,ACHA,AqB/DA,AxBwEA;A4BnFA,ACHA,AGTA,ACHA,ACHA,A1B8EA,ACHA,ACHA,AbuCA,ACHA,Ac1CA,AWjCA,AT2BA,ACHA,Ae7CA,AHSA,AIZA,Ad0CA,AQxBA,ANkBA,ACHA,ACHA,ACHA,AIZA,AzB2EA,ACHA,ACHA,AqB/DA,AxBwEA;A4BnFA,ACHA,AGTA,ACHA,ACHA,A1B8EA,ACHA,ACHA,AbuCA,ACHA,Ac1CA,AWjCA,AT2BA,ACHA,Ae7CA,AHSA,AIZA,ANkBA,ANkBA,ACHA,ACHA,ACHA,AIZA,AzB2EA,ACHA,ACHA,AqB/DA,AxBwEA;A4BnFA,ACHA,AGTA,ACHA,ACHA,ACHA,A3BiFA,ACHA,ACHA,AbuCA,ACHA,Ac1CA,AWjCA,AT2BA,ACHA,Ae7CA,AHSA,AIZA,ANkBA,ANkBA,ACHA,ACHA,ACHA,AIZA,AzB2EA,ACHA,ACHA,AqB/DA,AxBwEA;A4BnFA,ACHA,AGTA,ACHA,ACHA,ACHA,A3BiFA,ACHA,ACHA,AbuCA,ACHA,Ac1CA,AWjCA,AT2BA,ACHA,Ae7CA,AHSA,AIZA,ANkBA,ANkBA,ACHA,ACHA,ACHA,AIZA,AzB2EA,ACHA,ACHA,AqB/DA,AxBwEA;A4BnFA,ACHA,AGTA,ACHA,ACHA,ACHA,A3BiFA,ACHA,ACHA,AbuCA,ACHA,Ac1CA,AWjCA,AT2BA,ACHA,Ae7CA,AHSA,AIZA,ANkBA,ANkBA,ACHA,ACHA,ACHA,AIZA,AzB2EA,ACHA,ACHA,AqB/DA,AxBwEA;A4BnFA,ACHA,AGTA,ACHA,ACHA,ACHA,A3BiFA,ACHA,ACHA,A0B9EA,AvCqHA,ACHA,Ac1CA,AWjCA,AT2BA,ACHA,Ae7CA,AHSA,AIZA,ANkBA,ANkBA,ACHA,ACHA,ACHA,AIZA,AzB2EA,ACHA,ACHA,AqB/DA,AxBwEA;A4BnFA,ACHA,AGTA,ACHA,ACHA,ACHA,A3BiFA,ACHA,ACHA,A0B9EA,AvCqHA,ACHA,Ac1CA,AWjCA,AT2BA,ACHA,Ae7CA,AHSA,AIZA,ANkBA,ANkBA,ACHA,ACHA,ACHA,AIZA,AzB2EA,ACHA,ACHA,AqB/DA,AxBwEA;A4BnFA,ACHA,AGTA,ACHA,ACHA,ACHA,A3BiFA,ACHA,ACHA,A0B9EA,AvCqHA,ACHA,Ac1CA,AWjCA,AT2BA,ACHA,Ae7CA,AHSA,AIZA,ANkBA,ANkBA,ACHA,ACHA,ACHA,AIZA,AzB2EA,ACHA,ACHA,AqB/DA,AxBwEA;A4BnFA,ACHA,AGTA,ACHA,ACHA,ACHA,A3BiFA,ACHA,ACHA,A0B9EA,AvCqHA,ACHA,Ac1CA,AWjCA,Ac1CA,AvBqEA,ACHA,Ae7CA,AHSA,AIZA,ANkBA,ANkBA,ACHA,ACHA,ACHA,AIZA,AzB2EA,ACHA,ACHA,AqB/DA,AxBwEA;A4BnFA,ACHA,AGTA,ACHA,ACHA,ACHA,A3BiFA,ACHA,ACHA,A0B9EA,AvCqHA,ACHA,Ac1CA,AWjCA,Ac1CA,AvBqEA,ACHA,Ae7CA,AHSA,AIZA,ANkBA,ANkBA,ACHA,ACHA,ACHA,AIZA,AzB2EA,ACHA,ACHA,AqB/DA,AxBwEA;A4BnFA,ACHA,AGTA,ACHA,ACHA,ACHA,A3BiFA,ACHA,ACHA,A0B9EA,AvCqHA,ACHA,Ac1CA,AWjCA,Ac1CA,AvBqEA,ACHA,Ae7CA,AHSA,AIZA,ANkBA,ANkBA,ACHA,ACHA,ACHA,AIZA,AzB2EA,ACHA,ACHA,AqB/DA,AxBwEA;A4BnFA,ACHA,AGTA,ACHA,ACHA,ACHA,A3BiFA,ACHA,ACHA,A0B9EA,AvCqHA,ACHA,Ac1CA,AWjCA,Ac1CA,AvBqEA,ACHA,Ae7CA,AHSA,AWjCA,APqBA,ANkBA,ANkBA,ACHA,ACHA,ACHA,AIZA,AzB2EA,ACHA,ACHA,AqB/DA,AxBwEA;A4BnFA,ACHA,AGTA,ACHA,ACHA,ACHA,A3BiFA,ACHA,ACHA,A0B9EA,AvCqHA,ACHA,Ac1CA,AWjCA,Ac1CA,AvBqEA,ACHA,Ae7CA,AHSA,AWjCA,APqBA,ANkBA,ANkBA,ACHA,ACHA,ACHA,AIZA,AzB2EA,ACHA,ACHA,AqB/DA,AxBwEA;A4BnFA,ACHA,AGTA,ACHA,ACHA,ACHA,A3BiFA,ACHA,ACHA,A0B9EA,AvCqHA,ACHA,Ac1CA,AWjCA,Ac1CA,AvBqEA,ACHA,Ae7CA,AHSA,AWjCA,APqBA,ANkBA,ANkBA,ACHA,ACHA,ACHA,AIZA,AzB2EA,ACHA,ACHA,AqB/DA,AxBwEA;A4BnFA,ACHA,AGTA,ACHA,ACHA,ACHA,A3BiFA,ACHA,ACHA,A0B9EA,AvCqHA,ACHA,Ac1CA,AWjCA,Ac1CA,AvBqEA,ACHA,Ae7CA,AHSA,AWjCA,APqBA,ANkBA,Ac1CA,ApB4DA,ACHA,ACHA,ACHA,AIZA,AzB2EA,ACHA,ACHA,AqB/DA,AxBwEA;A4BnFA,ACHA,AGTA,ACHA,ACHA,ACHA,A3BiFA,ACHA,ACHA,A0B9EA,AvCqHA,ACHA,Ac1CA,AWjCA,Ac1CA,AvBqEA,ACHA,Ae7CA,AHSA,AWjCA,APqBA,ANkBA,Ac1CA,ApB4DA,ACHA,ACHA,ACHA,AIZA,AzB2EA,ACHA,ACHA,AqB/DA,AxBwEA;A4BnFA,ACHA,AGTA,ACHA,ACHA,ACHA,A3BiFA,ACHA,ACHA,A0B9EA,AvCqHA,ACHA,Ac1CA,AWjCA,Ac1CA,AvBqEA,ACHA,Ae7CA,AHSA,AWjCA,APqBA,ANkBA,Ac1CA,ApB4DA,ACHA,ACHA,ACHA,AIZA,AzB2EA,ACHA,ACHA,AqB/DA,AxBwEA;A4BnFA,ACHA,AGTA,ACHA,ACHA,ACHA,AKfA,AhCgGA,ACHA,ACHA,A0B9EA,AvCqHA,ACHA,Ac1CA,AWjCA,Ac1CA,AvBqEA,ACHA,Ae7CA,AHSA,AWjCA,APqBA,ANkBA,Ac1CA,ApB4DA,ACHA,ACHA,ACHA,AIZA,AzB2EA,ACHA,ACHA,AqB/DA,AxBwEA;A4BnFA,ACHA,AGTA,ACHA,ACHA,ACHA,AKfA,AhCgGA,ACHA,ACHA,A0B9EA,AvCqHA,ACHA,Ac1CA,AWjCA,Ac1CA,AvBqEA,ACHA,Ae7CA,AHSA,AWjCA,APqBA,ANkBA,Ac1CA,ApB4DA,ACHA,ACHA,ACHA,AIZA,AzB2EA,ACHA,ACHA,AqB/DA,AxBwEA;A4BnFA,ACHA,AGTA,ACHA,ACHA,ACHA,AKfA,AhCgGA,ACHA,ACHA,A0B9EA,AvCqHA,ACHA,Ac1CA,AWjCA,Ac1CA,AvBqEA,ACHA,Ae7CA,AHSA,AWjCA,APqBA,ANkBA,Ac1CA,ApB4DA,ACHA,ACHA,ACHA,AIZA,AzB2EA,ACHA,ACHA,AqB/DA,AxBwEA;A4BnFA,ACHA,AGTA,ACHA,ACHA,ACHA,AKfA,ACHA,AjCmGA,ACHA,ACHA,A0B9EA,AvCqHA,ACHA,Ac1CA,AWjCA,Ac1CA,AvBqEA,ACHA,Ae7CA,AHSA,AWjCA,APqBA,ANkBA,Ac1CA,ApB4DA,ACHA,ACHA,ACHA,AIZA,AzB2EA,ACHA,ACHA,AqB/DA,AxBwEA;A4BnFA,ACHA,AGTA,ACHA,ACHA,ACHA,AKfA,ACHA,AjCmGA,ACHA,ACHA,A0B9EA,AvCqHA,ACHA,Ac1CA,AWjCA,Ac1CA,AvBqEA,ACHA,Ae7CA,AHSA,AWjCA,APqBA,ANkBA,Ac1CA,ApB4DA,ACHA,ACHA,ACHA,AIZA,AzB2EA,ACHA,ACHA,AqB/DA,AxBwEA;A4BnFA,ACHA,AGTA,ACHA,ACHA,ACHA,AKfA,ACHA,AjCmGA,ACHA,ACHA,A0B9EA,AvCqHA,ACHA,Ac1CA,AWjCA,Ac1CA,AvBqEA,ACHA,Ae7CA,AHSA,AWjCA,APqBA,ANkBA,Ac1CA,ApB4DA,ACHA,ACHA,ACHA,AIZA,AzB2EA,ACHA,ACHA,AqB/DA,AxBwEA;A4BnFA,ACHA,AGTA,ACHA,ACHA,ACHA,AKfA,ACHA,ACHA,AlCsGA,ACHA,ACHA,A0B9EA,AvCqHA,ACHA,Ac1CA,AWjCA,Ac1CA,AvBqEA,ACHA,Ae7CA,AHSA,AWjCA,APqBA,ANkBA,Ac1CA,ApB4DA,ACHA,ACHA,ACHA,AIZA,AzB2EA,ACHA,ACHA,AqB/DA,AxBwEA;A4BnFA,ACHA,AGTA,ACHA,ACHA,ACHA,AKfA,ACHA,ACHA,AlCsGA,ACHA,ACHA,A0B9EA,AvCqHA,ACHA,Ac1CA,AWjCA,Ac1CA,AvBqEA,ACHA,Ae7CA,AHSA,AWjCA,APqBA,ANkBA,Ac1CA,ApB4DA,ACHA,ACHA,ACHA,AIZA,AzB2EA,ACHA,ACHA,AqB/DA,AxBwEA;A4BnFA,ACHA,AGTA,ACHA,ACHA,ACHA,AKfA,ACHA,ACHA,AlCsGA,ACHA,ACHA,A0B9EA,AvCqHA,ACHA,Ac1CA,AWjCA,Ac1CA,AvBqEA,ACHA,Ae7CA,AHSA,AWjCA,APqBA,ANkBA,Ac1CA,ApB4DA,ACHA,ACHA,ACHA,AIZA,AzB2EA,ACHA,ACHA,AqB/DA,AxBwEA;A4BnFA,ACHA,AGTA,ACHA,ACHA,ACHA,AKfA,ACHA,ACHA,ACHA,AnCyGA,ACHA,ACHA,A0B9EA,AvCqHA,ACHA,Ac1CA,AWjCA,Ac1CA,AvBqEA,ACHA,Ae7CA,AHSA,AWjCA,APqBA,ANkBA,Ac1CA,ApB4DA,ACHA,ACHA,ACHA,AIZA,AzB2EA,ACHA,ACHA,AqB/DA,AxBwEA;A4BnFA,ACHA,AGTA,ACHA,ACHA,ACHA,AKfA,ACHA,ACHA,ACHA,AnCyGA,ACHA,ACHA,A0B9EA,AvCqHA,ACHA,Ac1CA,AWjCA,Ac1CA,AvBqEA,ACHA,Ae7CA,AHSA,AWjCA,APqBA,ANkBA,Ac1CA,ApB4DA,ACHA,ACHA,ACHA,AIZA,AzB2EA,ACHA,ACHA,AqB/DA,AxBwEA;A4BnFA,ACHA,AGTA,ACHA,ACHA,ACHA,AKfA,ACHA,ACHA,ACHA,AnCyGA,ACHA,ACHA,A0B9EA,AvCqHA,ACHA,Ac1CA,AWjCA,Ac1CA,AvBqEA,ACHA,Ae7CA,AHSA,AWjCA,APqBA,ANkBA,Ac1CA,ApB4DA,ACHA,ACHA,ACHA,AIZA,AzB2EA,ACHA,ACHA,AqB/DA,AxBwEA;A4BnFA,ACHA,AGTA,ACHA,AWjCA,AV8BA,ACHA,AKfA,ACHA,ACHA,ACHA,AnCyGA,ACHA,ACHA,A0B9EA,AvCqHA,ACHA,Ac1CA,AWjCA,Ac1CA,AvBqEA,ACHA,Ae7CA,AHSA,AWjCA,APqBA,ANkBA,Ac1CA,ApB4DA,ACHA,ACHA,ACHA,AIZA,AzB2EA,ACHA,ACHA,AqB/DA,AxBwEA;A4BnFA,ACHA,AGTA,ACHA,AWjCA,AT2BA,AKfA,ACHA,ACHA,ACHA,AnCyGA,ACHA,ACHA,A0B9EA,AvCqHA,ACHA,Ac1CA,AWjCA,Ac1CA,AvBqEA,ACHA,Ae7CA,AHSA,AWjCA,APqBA,ANkBA,Ac1CA,ApB4DA,ACHA,ACHA,ACHA,AIZA,AzB2EA,ACHA,ACHA,AqB/DA,AxBwEA;A4BnFA,ACHA,AGTA,ACHA,AWjCA,AT2BA,AKfA,ACHA,ACHA,ACHA,AnCyGA,ACHA,ACHA,A0B9EA,AvCqHA,ACHA,Ac1CA,AWjCA,Ac1CA,AvBqEA,ACHA,Ae7CA,AHSA,AWjCA,APqBA,ANkBA,Ac1CA,ApB4DA,ACHA,ACHA,ACHA,AIZA,AzB2EA,ACHA,ACHA,AqB/DA,AxBwEA;A4BnFA,ACHA,AGTA,ACHA,AWjCA,AT2BA,AKfA,ACHA,ACHA,ACHA,AnCyGA,ACHA,AoC5GA,AnCyGA,A0B9EA,AvCqHA,ACHA,Ac1CA,AWjCA,Ac1CA,AvBqEA,ACHA,Ae7CA,AHSA,AWjCA,APqBA,ANkBA,Ac1CA,ApB4DA,AENA,ACHA,AIZA,AzB2EA,ACHA,ACHA,AqB/DA,AxBwEA;A4BnFA,ACHA,AGTA,ACHA,AWjCA,AT2BA,AKfA,ACHA,ACHA,ACHA,AnCyGA,ACHA,AoC5GA,AnCyGA,A0B9EA,AvCqHA,ACHA,Ac1CA,AWjCA,Ac1CA,AvBqEA,ACHA,Ae7CA,AHSA,AWjCA,APqBA,ANkBA,Ac1CA,ApB4DA,AENA,ACHA,AIZA,AzB2EA,ACHA,ACHA,AqB/DA,AxBwEA;A4BnFA,ACHA,AGTA,ACHA,AWjCA,AT2BA,AKfA,ACHA,ACHA,ACHA,AnCyGA,AqC/GA,AnCyGA,A0B9EA,AvCqHA,ACHA,Ac1CA,AWjCA,Ac1CA,AvBqEA,ACHA,Ae7CA,AHSA,AWjCA,APqBA,ANkBA,Ac1CA,ApB4DA,AENA,ACHA,AIZA,AzB2EA,ACHA,ACHA,AqB/DA,AxBwEA;A4BnFA,ACHA,AGTA,ACHA,AWjCA,AT2BA,AKfA,ACHA,ACHA,ACHA,AnCyGA,AsClHA,ADGA,AnCyGA,A0B9EA,AvCqHA,ACHA,Ac1CA,AWjCA,Ac1CA,AvBqEA,ACHA,Ae7CA,AHSA,AWjCA,APqBA,AQxBA,ApB4DA,AENA,ACHA,AIZA,AzB2EA,ACHA,ACHA,AqB/DA,AxBwEA;A4BnFA,ACHA,AGTA,ACHA,AWjCA,AT2BA,AKfA,ACHA,ACHA,ACHA,AnCyGA,AsClHA,ADGA,AnCyGA,A0B9EA,AvCqHA,ACHA,Ac1CA,AWjCA,Ac1CA,AvBqEA,ACHA,Ae7CA,AHSA,AWjCA,APqBA,AQxBA,ApB4DA,AENA,ACHA,AIZA,AzB2EA,ACHA,ACHA,AqB/DA,AxBwEA;A4BnFA,ACHA,AGTA,ACHA,AWjCA,AT2BA,AKfA,ACHA,ACHA,ACHA,AnCyGA,AsClHA,ADGA,AnCyGA,A0B9EA,AvCqHA,ACHA,Ac1CA,AWjCA,Ac1CA,AvBqEA,ACHA,Ae7CA,AHSA,AWjCA,APqBA,AQxBA,ApB4DA,AENA,ACHA,AIZA,AzB2EA,ACHA,ACHA,AqB/DA,AxBwEA;A4BnFA,ACHA,AGTA,ACHA,AWjCA,AT2BA,AKfA,ACHA,ACHA,ACHA,AnCyGA,AsClHA,ADGA,AENA,ArC+GA,A0B9EA,AvCqHA,ACHA,Ac1CA,AWjCA,Ac1CA,AvBqEA,ACHA,Ae7CA,AHSA,AWjCA,APqBA,AQxBA,ApB4DA,AENA,ACHA,AIZA,AzB2EA,ACHA,ACHA,AqB/DA,AxBwEA;A4BnFA,ACHA,AGTA,ACHA,AWjCA,AT2BA,AKfA,ACHA,ACHA,ACHA,AnCyGA,AsClHA,ADGA,AENA,ArC+GA,A0B9EA,AvCqHA,ACHA,Ac1CA,AWjCA,Ac1CA,AvBqEA,ACHA,Ae7CA,AHSA,AWjCA,APqBA,AQxBA,ApB4DA,AENA,ACHA,AIZA,AzB2EA,ACHA,ACHA,AqB/DA,AxBwEA;A4BnFA,ACHA,AGTA,ACHA,AWjCA,AT2BA,AKfA,ACHA,ACHA,ACHA,AnCyGA,AsClHA,ADGA,AENA,ArC+GA,A0B9EA,AvCqHA,ACHA,Ac1CA,AWjCA,Ac1CA,AvBqEA,ACHA,Ae7CA,AHSA,AWjCA,APqBA,AQxBA,ApB4DA,AENA,ACHA,AIZA,AzB2EA,ACHA,ACHA,AqB/DA,AxBwEA;A4BnFA,ACHA,AGTA,ACHA,AWjCA,AT2BA,AKfA,ACHA,ACHA,ACHA,AKfA,AxCwHA,AsClHA,ADGA,AENA,ArC+GA,A0B9EA,AvCqHA,ACHA,Ac1CA,AWjCA,Ac1CA,AvBqEA,ACHA,Ae7CA,AHSA,AWjCA,APqBA,AQxBA,ApB4DA,AENA,ACHA,AIZA,AzB2EA,ACHA,ACHA,AqB/DA,AxBwEA;A4BnFA,ACHA,AGTA,ACHA,AWjCA,AT2BA,AKfA,ACHA,ACHA,ACHA,AKfA,AxCwHA,AsClHA,ADGA,AENA,ArC+GA,A0B9EA,AvCqHA,ACHA,Ac1CA,AWjCA,Ac1CA,AvBqEA,ACHA,Ae7CA,AHSA,AWjCA,APqBA,AQxBA,ApB4DA,AENA,ACHA,AIZA,AzB2EA,ACHA,ACHA,AqB/DA,AxBwEA;A4BnFA,ACHA,AGTA,ACHA,AWjCA,AT2BA,AKfA,ACHA,ACHA,ACHA,AKfA,AxCwHA,AsClHA,ADGA,AENA,ArC+GA,AbuCA,ACHA,Ac1CA,AWjCA,Ac1CA,AvBqEA,ACHA,Ae7CA,AHSA,AWjCA,APqBA,AQxBA,ApB4DA,AENA,ACHA,AIZA,AzB2EA,ACHA,ACHA,AqB/DA,AxBwEA;A4BnFA,ACHA,AGTA,ACHA,AWjCA,AT2BA,AKfA,ACHA,ACHA,ACHA,AKfA,AxCwHA,AyC3HA,AHSA,ADGA,AENA,ArC+GA,AbuCA,ACHA,Ac1CA,AWjCA,Ac1CA,AvBqEA,ACHA,Ae7CA,AHSA,AWjCA,APqBA,AQxBA,ApB4DA,AENA,ACHA,AIZA,AzB2EA,ACHA,ACHA,AqB/DA,AxBwEA;A4BnFA,ACHA,AGTA,ACHA,AWjCA,AT2BA,AKfA,ACHA,ACHA,ACHA,AKfA,AxCwHA,AyC3HA,AHSA,ADGA,AENA,ArC+GA,AbuCA,ACHA,Ac1CA,AWjCA,Ac1CA,AvBqEA,ACHA,Ae7CA,AHSA,AWjCA,APqBA,AQxBA,ApB4DA,AENA,ACHA,AIZA,AzB2EA,ACHA,ACHA,AqB/DA,AxBwEA;A4BnFA,ACHA,AGTA,ACHA,AWjCA,AT2BA,AKfA,ACHA,ACHA,ACHA,AKfA,AxCwHA,AyC3HA,AHSA,ADGA,AENA,ArC+GA,AbuCA,ACHA,Ac1CA,AWjCA,Ac1CA,AvBqEA,ACHA,Ae7CA,AHSA,AWjCA,APqBA,AQxBA,ApB4DA,AENA,ACHA,AIZA,AzB2EA,ACHA,ACHA,AqB/DA,AxBwEA;A4BnFA,ACHA,AGTA,ACHA,AWjCA,AT2BA,AKfA,ACHA,ACHA,ACHA,AKfA,AxCwHA,AyC3HA,ACHA,AJYA,ADGA,AENA,ArC+GA,AbuCA,ACHA,Ac1CA,AWjCA,Ac1CA,AvBqEA,AgBhDA,AHSA,AWjCA,APqBA,AQxBA,ApB4DA,AENA,ACHA,AIZA,AzB2EA,ACHA,ACHA,AqB/DA,AxBwEA;A4BnFA,ACHA,AGTA,ACHA,AWjCA,AT2BA,AKfA,ACHA,ACHA,ACHA,AKfA,AxCwHA,AyC3HA,ACHA,AJYA,ADGA,AENA,ArC+GA,AbuCA,ACHA,Ac1CA,AWjCA,Ac1CA,AvBqEA,AgBhDA,AHSA,AWjCA,APqBA,AQxBA,ApB4DA,AENA,ACHA,AIZA,AzB2EA,ACHA,ACHA,AqB/DA,AxBwEA;A4BnFA,ACHA,AGTA,ACHA,AWjCA,AT2BA,AKfA,ACHA,ACHA,ACHA,AKfA,AxCwHA,AyC3HA,ACHA,AJYA,ADGA,AENA,ArC+GA,AbuCA,ACHA,Ac1CA,AWjCA,Ac1CA,AvBqEA,AgBhDA,AHSA,AWjCA,APqBA,AQxBA,ApB4DA,AENA,ACHA,AIZA,AzB2EA,ACHA,ACHA,AqB/DA,AxBwEA;A4BnFA,ACHA,AGTA,ACHA,AWjCA,AT2BA,AKfA,ACHA,ACHA,ACHA,AKfA,AxCwHA,AyC3HA,ACHA,ACHA,ALeA,ADGA,AENA,ArC+GA,AbuCA,ACHA,Ac1CA,AWjCA,Ac1CA,AvBqEA,AgBhDA,AHSA,AWjCA,APqBA,AQxBA,ApB4DA,AENA,ACHA,AIZA,AzB2EA,ACHA,ACHA,AqB/DA,AxBwEA;A4BnFA,ACHA,AGTA,ACHA,AWjCA,AT2BA,AKfA,ACHA,ACHA,ACHA,AKfA,AxCwHA,AyC3HA,ACHA,ACHA,ALeA,ADGA,AENA,ArC+GA,AbuCA,ACHA,Ac1CA,AWjCA,Ac1CA,AvBqEA,AgBhDA,AHSA,AWjCA,APqBA,AQxBA,ApB4DA,AENA,ACHA,AIZA,AzB2EA,ACHA,ACHA,AqB/DA,AxBwEA;A4BnFA,ACHA,AGTA,ACHA,AWjCA,AT2BA,AKfA,ACHA,ACHA,ACHA,AKfA,AxCwHA,AyC3HA,ACHA,ACHA,ALeA,ADGA,AENA,ArC+GA,AbuCA,ACHA,Ac1CA,AWjCA,Ac1CA,AvBqEA,AgBhDA,AHSA,AWjCA,APqBA,AQxBA,ApB4DA,AENA,ACHA,AIZA,AzB2EA,ACHA,ACHA,AqB/DA,AxBwEA;A4BnFA,ACHA,AGTA,ACHA,AWjCA,AT2BA,AKfA,ACHA,ACHA,ACHA,AKfA,AxCwHA,AyC3HA,ACHA,ACHA,ACHA,ANkBA,ADGA,AENA,ArC+GA,AbuCA,ACHA,Ac1CA,AWjCA,Ac1CA,AvBqEA,AgBhDA,AHSA,AWjCA,APqBA,AQxBA,ApB4DA,AENA,ACHA,AIZA,AzB2EA,ACHA,ACHA,AqB/DA,AxBwEA;A4BnFA,ACHA,AGTA,ACHA,AWjCA,AT2BA,AKfA,ACHA,ACHA,ACHA,AKfA,AxCwHA,AyC3HA,ACHA,ACHA,ACHA,ANkBA,ADGA,AENA,ArC+GA,AbuCA,ACHA,Ac1CA,AWjCA,Ac1CA,AvBqEA,AgBhDA,AHSA,AWjCA,APqBA,AQxBA,ApB4DA,AENA,ACHA,AIZA,AzB2EA,ACHA,ACHA,AqB/DA,AxBwEA;A4BnFA,ACHA,AGTA,ACHA,AWjCA,AT2BA,AMlBA,ACHA,ACHA,AKfA,AxCwHA,AyC3HA,ACHA,ACHA,ACHA,ANkBA,ADGA,AENA,ArC+GA,AbuCA,Ae7CA,AWjCA,Ac1CA,AvBqEA,AgBhDA,AHSA,AWjCA,APqBA,AQxBA,AlBsDA,ACHA,AIZA,AzB2EA,ACHA,ACHA,AqB/DA,AxBwEA;A4BnFA,ACHA,AGTA,ACHA,AWjCA,AHSA,ACHA,ACHA,AKfA,AxCwHA,AyC3HA,ACHA,ACHA,ACHA,ACHA,APqBA,ADGA,AENA,ArC+GA,AbuCA,Ae7CA,AWjCA,Ac1CA,AvBqEA,AgBhDA,AHSA,AWjCA,APqBA,AQxBA,AlBsDA,ACHA,AIZA,AzB2EA,ACHA,ACHA,AqB/DA,AxBwEA;A4BnFA,ACHA,AGTA,ACHA,AWjCA,AHSA,ACHA,ACHA,AKfA,AxCwHA,AyC3HA,ACHA,ACHA,ACHA,ACHA,APqBA,ADGA,AENA,ArC+GA,AbuCA,Ae7CA,AWjCA,Ac1CA,AvBqEA,AgBhDA,AHSA,AWjCA,APqBA,AQxBA,AlBsDA,ACHA,AIZA,AzB2EA,ACHA,ACHA,AqB/DA,AxBwEA;A4BnFA,ACHA,AGTA,ACHA,AWjCA,AHSA,ACHA,ACHA,AKfA,AxCwHA,AyC3HA,ACHA,ACHA,ACHA,ACHA,APqBA,ADGA,AENA,ArC+GA,AbuCA,Ae7CA,AWjCA,Ac1CA,AvBqEA,AgBhDA,AHSA,AWjCA,APqBA,AQxBA,AlBsDA,ACHA,AIZA,AzB2EA,ACHA,ACHA,AqB/DA,AxBwEA;A4BnFA,ACHA,AGTA,ACHA,AWjCA,AFMA,ACHA,AKfA,AxCwHA,AyC3HA,ACHA,ACHA,ACHA,ACHA,ACHA,ARwBA,ADGA,AENA,ArC+GA,AbuCA,Ae7CA,AWjCA,Ac1CA,AvBqEA,AgBhDA,AHSA,AWjCA,APqBA,AQxBA,AlBsDA,ACHA,AIZA,AzB2EA,ACHA,ACHA,AqB/DA,AxBwEA;A4BnFA,ACHA,AGTA,ACHA,AWjCA,AFMA,ACHA,AKfA,AxCwHA,AyC3HA,ACHA,ACHA,ACHA,ACHA,ACHA,ARwBA,ADGA,AENA,ArC+GA,AbuCA,Ae7CA,AWjCA,Ac1CA,AvBqEA,AgBhDA,AHSA,AWjCA,APqBA,AQxBA,AlBsDA,ACHA,AIZA,AzB2EA,ACHA,ACHA,AqB/DA,AxBwEA;A4BnFA,ACHA,AGTA,ACHA,AWjCA,AFMA,ACHA,AKfA,AxCwHA,AyC3HA,ACHA,ACHA,ACHA,ACHA,ACHA,ARwBA,ADGA,AENA,ArC+GA,AbuCA,Ae7CA,AWjCA,Ac1CA,AvBqEA,AgBhDA,AHSA,AWjCA,APqBA,AQxBA,AlBsDA,ACHA,AIZA,AzB2EA,ACHA,ACHA,AqB/DA,AxBwEA;A4BnFA,ACHA,AGTA,ACHA,AWjCA,ADGA,AKfA,AxCwHA,AyC3HA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,AT2BA,ADGA,AENA,ArC+GA,AbuCA,Ae7CA,AWjCA,Ac1CA,AvBqEA,AgBhDA,AHSA,AWjCA,APqBA,AQxBA,AlBsDA,ACHA,AIZA,AzB2EA,ACHA,ACHA,AqB/DA,AxBwEA;A4BnFA,ACHA,AGTA,ACHA,AWjCA,ADGA,AKfA,AxCwHA,AyC3HA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,AT2BA,ADGA,AENA,ArC+GA,AbuCA,Ae7CA,AWjCA,Ac1CA,AvBqEA,AgBhDA,AHSA,AWjCA,APqBA,AQxBA,AlBsDA,ACHA,AIZA,AzB2EA,ACHA,ACHA,AqB/DA,AxBwEA;A4BnFA,ACHA,AGTA,ACHA,AWjCA,ADGA,AKfA,AxCwHA,AyC3HA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,AT2BA,ADGA,AENA,ArC+GA,AbuCA,Ae7CA,AWjCA,Ac1CA,AvBqEA,AgBhDA,AHSA,AWjCA,APqBA,AQxBA,AlBsDA,ACHA,AIZA,AzB2EA,ACHA,ACHA,AqB/DA,AxBwEA;A4BnFA,ACHA,AGTA,ACHA,AWjCA,ADGA,AKfA,AxCwHA,AyC3HA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,AV8BA,ADGA,AENA,ArC+GA,AbuCA,Ae7CA,AWjCA,Ac1CA,AvBqEA,AgBhDA,AQxBA,APqBA,AQxBA,AlBsDA,ACHA,AIZA,AxBwEA,ACHA,AqB/DA,AxBwEA;A4BnFA,ACHA,AGTA,ACHA,AWjCA,ADGA,AKfA,AxCwHA,AyC3HA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,AV8BA,ADGA,AENA,ArC+GA,AbuCA,Ae7CA,AWjCA,Ac1CA,AvBqEA,AgBhDA,AQxBA,APqBA,AQxBA,AlBsDA,ACHA,AIZA,AxBwEA,ACHA,AqB/DA,AxBwEA;A4BnFA,AIZA,ACHA,AWjCA,ADGA,AKfA,AxCwHA,AyC3HA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,AV8BA,ADGA,AENA,ArC+GA,AbuCA,Ae7CA,AWjCA,Ac1CA,AvBqEA,AgBhDA,AQxBA,APqBA,AQxBA,AlBsDA,ACHA,AIZA,AxBwEA,ACHA,AqB/DA,AxBwEA;A4BnFA,AIZA,ACHA,AWjCA,ADGA,AKfA,AxCwHA,AyC3HA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,AXiCA,ADGA,AENA,ArC+GA,AbuCA,Ae7CA,AWjCA,Ac1CA,AvBqEA,AgBhDA,AQxBA,APqBA,AQxBA,AlBsDA,ACHA,AIZA,AxBwEA,ACHA,AqB/DA,AxBwEA;A4BnFA,AIZA,ACHA,AWjCA,ADGA,AKfA,AxCwHA,AyC3HA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,AXiCA,ADGA,AENA,ArC+GA,AbuCA,Ae7CA,AWjCA,Ac1CA,AvBqEA,AgBhDA,AQxBA,APqBA,AQxBA,AlBsDA,ACHA,AIZA,AxBwEA,AsBlEA,AxBwEA;A4BnFA,AIZA,ACHA,AWjCA,ADGA,AKfA,AxCwHA,AyC3HA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,AXiCA,ADGA,AENA,ArC+GA,AbuCA,Ae7CA,AWjCA,Ac1CA,AvBqEA,AgBhDA,AQxBA,APqBA,AQxBA,AlBsDA,ACHA,AIZA,AxBwEA,AsBlEA,AxBwEA;A4BnFA,AIZA,ACHA,AWjCA,ADGA,AKfA,AxCwHA,AyC3HA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,AZoCA,ADGA,AENA,ArC+GA,AbuCA,Ae7CA,AWjCA,Ac1CA,AvBqEA,AgBhDA,AQxBA,APqBA,AQxBA,AlBsDA,ACHA,AIZA,AxBwEA,AsBlEA,AxBwEA;A4BnFA,AIZA,AYpCA,ADGA,AKfA,AxCwHA,AyC3HA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,AZoCA,ADGA,AENA,ArC+GA,AbuCA,Ae7CA,AWjCA,Ac1CA,AvBqEA,AgBhDA,AQxBA,APqBA,AQxBA,AlBsDA,ACHA,AIZA,AxBwEA,AsBlEA,AxBwEA;A4BnFA,AIZA,AWjCA,AKfA,AxCwHA,AyC3HA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,AZoCA,ADGA,AENA,ArC+GA,AbuCA,Ae7CA,AWjCA,Ac1CA,AvBqEA,AgBhDA,AQxBA,APqBA,AQxBA,AlBsDA,ACHA,AIZA,AxBwEA,AsBlEA,AxBwEA;A4BnFA,AIZA,AWjCA,AKfA,AxCwHA,AyC3HA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,AbuCA,ADGA,AENA,ArC+GA,AbuCA,Ae7CA,AWjCA,Ac1CA,AvBqEA,AgBhDA,AQxBA,APqBA,AQxBA,AlBsDA,ACHA,AIZA,AxBwEA,AsBlEA,AxBwEA;A4BnFA,AIZA,AWjCA,AKfA,AxCwHA,AyC3HA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,AbuCA,ADGA,AENA,ArC+GA,AbuCA,Ae7CA,AWjCA,Ac1CA,AvBqEA,AgBhDA,AQxBA,APqBA,AQxBA,AlBsDA,ACHA,AIZA,AxBwEA,AsBlEA,AxBwEA;A4BnFA,AIZA,AWjCA,AKfA,AxCwHA,AyC3HA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,AbuCA,ADGA,AENA,ArC+GA,AbuCA,Ae7CA,AWjCA,Ac1CA,AvBqEA,AwBxEA,APqBA,AQxBA,AlBsDA,ACHA,AIZA,AxBwEA,AsBlEA,AxBwEA;A4BnFA,AIZA,AWjCA,AKfA,AxCwHA,AyC3HA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,Ad0CA,ADGA,AENA,ArC+GA,AbuCA,Ae7CA,AWjCA,Ac1CA,AvBqEA,AwBxEA,APqBA,AQxBA,AlBsDA,ACHA,AIZA,AxBwEA,AFMA;A4BnFA,AIZA,AWjCA,AKfA,AxCwHA,AyC3HA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,Ad0CA,ADGA,AENA,ArC+GA,AbuCA,Ae7CA,AWjCA,Ac1CA,AvBqEA,AwBxEA,APqBA,AQxBA,AlBsDA,ACHA,AIZA,AxBwEA,AFMA;A4BnFA,AIZA,AWjCA,AKfA,AxCwHA,AyC3HA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,Ad0CA,ADGA,AENA,ArC+GA,AbuCA,Ae7CA,AWjCA,Ac1CA,AvBqEA,AwBxEA,APqBA,AQxBA,AlBsDA,ACHA,AIZA,AxBwEA,AFMA;A4BnFA,AIZA,AWjCA,AnCyGA,AyC3HA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,Af6CA,ADGA,AENA,ArC+GA,AbuCA,Ae7CA,AWjCA,Ac1CA,AvBqEA,AwBxEA,APqBA,AQxBA,AlBsDA,AKfA,AxBwEA,AFMA;A4BnFA,AIZA,AWjCA,AnCyGA,AyC3HA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,Af6CA,ADGA,AENA,ArC+GA,AbuCA,Ae7CA,AWjCA,Ac1CA,AvBqEA,AwBxEA,APqBA,AQxBA,AlBsDA,AKfA,AxBwEA,AFMA;A4BnFA,AIZA,AWjCA,AnCyGA,AyC3HA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,Af6CA,ADGA,AENA,ArC+GA,AbuCA,Ae7CA,AWjCA,Ac1CA,AvBqEA,AwBxEA,APqBA,AQxBA,AlBsDA,AKfA,AxBwEA,AFMA;A4BnFA,AIZA,AWjCA,AnCyGA,AyC3HA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,AhBgDA,ADGA,AENA,ArC+GA,AbuCA,Ae7CA,AWjCA,Ac1CA,AvBqEA,AwBxEA,APqBA,AQxBA,AlBsDA,AKfA,AxBwEA,AFMA;A4BnFA,AIZA,AWjCA,AnCyGA,AyC3HA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,AhBgDA,ADGA,AENA,ArC+GA,AbuCA,Ae7CA,AWjCA,Ac1CA,AvBqEA,AwBxEA,APqBA,AQxBA,AlBsDA,AKfA,AxBwEA,AFMA;A4BnFA,AIZA,AWjCA,AnCyGA,AyC3HA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,AhBgDA,ADGA,AENA,ArC+GA,AbuCA,Ae7CA,AWjCA,Ac1CA,AvBqEA,AwBxEA,APqBA,AQxBA,AlBsDA,AKfA,AxBwEA,AFMA;A4BnFA,AIZA,AWjCA,AnCyGA,AyC3HA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,AjBmDA,ADGA,AENA,ArC+GA,AbuCA,Ae7CA,AWjCA,Ac1CA,AvBqEA,AwBxEA,APqBA,AQxBA,AlBsDA,AKfA,AxBwEA,AFMA;A4BnFA,AIZA,AWjCA,AnCyGA,AyC3HA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,AjBmDA,ADGA,AENA,ArC+GA,AbuCA,Ae7CA,AWjCA,Ac1CA,AvBqEA,AwBxEA,APqBA,AQxBA,AlBsDA,AKfA,AxBwEA,AFMA;A4BnFA,AIZA,AWjCA,AnCyGA,A0C9HA,AENA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,AjBmDA,ADGA,AENA,ArC+GA,AbuCA,Ae7CA,AWjCA,Ac1CA,AvBqEA,AwBxEA,APqBA,AQxBA,AlBsDA,AKfA,AxBwEA,AFMA;A4BnFA,AIZA,AWjCA,AnCyGA,A0C9HA,AENA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,AlBsDA,ADGA,AENA,ArC+GA,AbuCA,Ae7CA,AWjCA,Ac1CA,AvBqEA,AwBxEA,APqBA,AQxBA,AlBsDA,AKfA,AxBwEA,AFMA;A4BnFA,AIZA,AWjCA,AnCyGA,A0C9HA,AENA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,AlBsDA,ADGA,AENA,ArC+GA,AbuCA,Ae7CA,AWjCA,Ac1CA,AvBqEA,AwBxEA,APqBA,AQxBA,AlBsDA,AKfA,AxBwEA,AFMA;A4BnFA,AIZA,AWjCA,AnCyGA,A4CpIA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,AlBsDA,ADGA,AENA,ArC+GA,AbuCA,Ae7CA,AWjCA,Ac1CA,AvBqEA,AwBxEA,APqBA,AQxBA,AlBsDA,AKfA,AxBwEA,AFMA;A4BnFA,AIZA,AWjCA,AnCyGA,A4CpIA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,AnByDA,ADGA,AENA,ArC+GA,AbuCA,Ae7CA,AWjCA,Ac1CA,AvBqEA,AwBxEA,APqBA,AQxBA,AlBsDA,AKfA,AxBwEA,AFMA;A4BnFA,AIZA,AWjCA,AnCyGA,A4CpIA,ACHA,ACHA,ACHA,AENA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,AnByDA,ADGA,AENA,ArC+GA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,AQxBA,AlBsDA,AKfA,AxBwEA,AFMA;A4BnFA,AIZA,AxBwEA,A4CpIA,ACHA,ACHA,ACHA,AENA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,AnByDA,ADGA,AENA,ArC+GA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,AQxBA,AlBsDA,AKfA,AxBwEA,AFMA;A4BnFA,AIZA,AxBwEA,A4CpIA,ACHA,ACHA,ACHA,AENA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ApB4DA,ADGA,AENA,ArC+GA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,AQxBA,AlBsDA,AKfA,AxBwEA,AFMA;A4BnFA,AIZA,AxBwEA,A4CpIA,ACHA,ACHA,ACHA,AENA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ApB4DA,ADGA,AENA,ArC+GA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,AQxBA,AlBsDA,AKfA,AxBwEA,AFMA;A4BnFA,AIZA,AxBwEA,A4CpIA,ACHA,ACHA,ACHA,AENA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ApB4DA,ADGA,AENA,ArC+GA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,AQxBA,AlBsDA,AKfA,AxBwEA,AFMA;A4BnFA,AIZA,AxBwEA,A4CpIA,ACHA,AENA,AENA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ArB+DA,ADGA,AENA,ArC+GA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,AQxBA,AlBsDA,AKfA,AxBwEA,AFMA;A4BnFA,AIZA,AxBwEA,A4CpIA,ACHA,AENA,AENA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ArB+DA,ADGA,AENA,ArC+GA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,AQxBA,AlBsDA,AKfA,AxBwEA,AFMA;A4BnFA,AIZA,AxBwEA,A4CpIA,ACHA,AENA,AENA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ArB+DA,ADGA,AENA,ArC+GA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,AQxBA,AlBsDA,AKfA,AxBwEA,AFMA;A4BnFA,AIZA,AxBwEA,A4CpIA,ACHA,AENA,AENA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,AtBkEA,ADGA,AENA,ArC+GA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,AQxBA,AlBsDA,AKfA,AxBwEA,AFMA;A4BnFA,AIZA,AxBwEA,A4CpIA,ACHA,AIZA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,AtBkEA,ADGA,AENA,ArC+GA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,AQxBA,AlBsDA,AKfA,AxBwEA,AFMA;A4BnFA,AIZA,AxBwEA,A4CpIA,ACHA,AIZA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,AtBkEA,ADGA,AENA,ArC+GA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,AQxBA,AlBsDA,AKfA,AxBwEA,AFMA;A4BnFA,AIZA,AxBwEA,A4CpIA,ACHA,AIZA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,AxBwEA,AENA,ArC+GA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,AQxBA,AlBsDA,AKfA,AxBwEA,AFMA;A4BnFA,AIZA,AxBwEA,A4CpIA,ACHA,AIZA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,AxBwEA,AENA,ArC+GA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,AQxBA,AlBsDA,AKfA,AxBwEA,AFMA;A4BnFA,AIZA,AxBwEA,A4CpIA,ACHA,AIZA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,AxBwEA,AENA,ArC+GA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,AQxBA,AlBsDA,AKfA,AxBwEA,AFMA;A4BnFA,AIZA,AxBwEA,A4CpIA,ACHA,AIZA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,AzB2EA,AENA,ArC+GA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,AQxBA,AlBsDA,AKfA,AxBwEA,AFMA;A4BnFA,AIZA,AxBwEA,A4CpIA,ACHA,AIZA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,AzB2EA,AENA,ArC+GA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,AQxBA,AlBsDA,AKfA,AxBwEA,AFMA;A4BnFA,AIZA,AxBwEA,A4CpIA,ACHA,AIZA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,AzB2EA,AENA,ArC+GA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,AQxBA,AlBsDA,AKfA,AxBwEA,AFMA;A4BnFA,AIZA,AxBwEA,A4CpIA,ACHA,AIZA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,A1B8EA,AENA,ArC+GA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,AQxBA,AlBsDA,AKfA,AxBwEA,AFMA;A4BnFA,AIZA,AxBwEA,A6CvIA,AIZA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,A1B8EA,AENA,ArC+GA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,AQxBA,AlBsDA,AKfA,AxBwEA,AFMA;A4BnFA,AIZA,AxBwEA,A6CvIA,AIZA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,A1B8EA,AnCyGA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,AQxBA,AlBsDA,AKfA,AxBwEA,AFMA;A4BnFA,AIZA,AxBwEA,A6CvIA,AKfA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,A3BiFA,AnCyGA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,AQxBA,AlBsDA,AKfA,AxBwEA,AFMA;A4BnFA,AIZA,AxBwEA,A6CvIA,AKfA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,A3BiFA,AnCyGA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,AQxBA,AlBsDA,AKfA,AxBwEA,AFMA;A4BnFA,AIZA,AxBwEA,A6CvIA,AKfA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,A3BiFA,AnCyGA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,AQxBA,AlBsDA,AKfA,AxBwEA,AFMA;A4BnFA,AIZA,AxBwEA,A6CvIA,AKfA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,A5BoFA,AnCyGA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,AQxBA,AlBsDA,AKfA,AxBwEA,AFMA;A4BnFA,AIZA,AxBwEA,A6CvIA,AKfA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,A5BoFA,AnCyGA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,AQxBA,AlBsDA,AKfA,AxBwEA,AFMA;A4BnFA,AIZA,AxBwEA,A6CvIA,AKfA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,A5BoFA,AnCyGA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,AQxBA,AlBsDA,AKfA,AxBwEA,AFMA;A4BnFA,AIZA,AxBwEA,A6CvIA,AKfA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,A7BuFA,AnCyGA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,AQxBA,AlBsDA,AKfA,AxBwEA,AFMA;A4BnFA,AIZA,AxBwEA,A6CvIA,AKfA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,A7BuFA,AnCyGA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,AQxBA,AlBsDA,AKfA,AxBwEA,AFMA;A4BnFA,AIZA,AxBwEA,A6CvIA,AKfA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,A7BuFA,AnCyGA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,AV8BA,AKfA,AxBwEA,AFMA;A4BnFA,AIZA,AxBwEA,A6CvIA,AKfA,ACHA,ACHA,ACHA,AENA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,A7BuFA,A8B1FA,AjEmMA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,AV8BA,AKfA,AxBwEA,AFMA;A4BnFA,AIZA,AxBwEA,A6CvIA,AKfA,ACHA,ACHA,ACHA,AENA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,A7BuFA,A8B1FA,AjEmMA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,AV8BA,AKfA,AxBwEA,AFMA;A4BnFA,AIZA,AxBwEA,A6CvIA,AKfA,ACHA,ACHA,ACHA,AENA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,A7BuFA,A8B1FA,AjEmMA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,AV8BA,AKfA,AxBwEA,AFMA;A4BnFA,AIZA,AxBwEA,A6CvIA,AMlBA,ACHA,ACHA,AENA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,AGTA,AFMA,A7BuFA,A8B1FA,AjEmMA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,AV8BA,AKfA,AxBwEA,AFMA;A4BnFA,AIZA,AxBwEA,A6CvIA,AMlBA,AENA,AENA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,AGTA,AFMA,A7BuFA,A8B1FA,AjEmMA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,AV8BA,AKfA,AxBwEA,AFMA;A4BnFA,AIZA,AxBwEA,A6CvIA,AMlBA,AENA,AENA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,AGTA,AFMA,A7BuFA,A8B1FA,AjEmMA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,AV8BA,AKfA,AxBwEA,AFMA;A4BnFA,AIZA,AxBwEA,A6CvIA,AMlBA,AENA,AENA,ACHA,ACHA,ACHA,AENA,ACHA,ACHA,ACHA,ACHA,ACHA,AGTA,AFMA,AGTA,AhCgGA,A8B1FA,AjEmMA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,AV8BA,AKfA,AxBwEA,AFMA;A4BnFA,AIZA,AxBwEA,A6CvIA,AMlBA,AENA,AENA,ACHA,ACHA,ACHA,AENA,ACHA,ACHA,ACHA,ACHA,ACHA,AGTA,AFMA,AGTA,AhCgGA,A8B1FA,AjEmMA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,AV8BA,AKfA,AxBwEA,AFMA;A4BnFA,AIZA,AxBwEA,A6CvIA,AMlBA,AENA,AENA,ACHA,ACHA,ACHA,AENA,ACHA,ACHA,ACHA,ACHA,ACHA,AGTA,AFMA,AGTA,AhCgGA,A8B1FA,AjEmMA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,ALeA,AxBwEA,AFMA;A4BnFA,AIZA,AxBwEA,A6CvIA,AMlBA,AENA,AENA,ACHA,ACHA,ACHA,AENA,ACHA,ACHA,ACHA,AENA,AGTA,AFMA,AGTA,ACHA,AjCmGA,A8B1FA,AjEmMA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,ALeA,AxBwEA,AFMA;A4BnFA,AIZA,AxBwEA,A6CvIA,AMlBA,AENA,AENA,ACHA,ACHA,ACHA,AENA,ACHA,ACHA,ACHA,AENA,AGTA,AFMA,AGTA,ACHA,AjCmGA,A8B1FA,AjEmMA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,ALeA,AxBwEA,AFMA;A4BnFA,AIZA,AxBwEA,A6CvIA,AMlBA,AENA,AENA,ACHA,ACHA,ACHA,AENA,ACHA,ACHA,ACHA,AENA,AGTA,AFMA,AGTA,ACHA,AjCmGA,A8B1FA,AjEmMA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,ALeA,AxBwEA,AFMA;A4BnFA,AIZA,AxBwEA,A6CvIA,AMlBA,AENA,AENA,ACHA,ACHA,ACHA,AENA,ACHA,ACHA,ACHA,AENA,AGTA,AFMA,AGTA,ACHA,ACHA,AlCsGA,A8B1FA,AjEmMA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,ALeA,AxBwEA,AFMA;A4BnFA,AIZA,AxBwEA,AmDzJA,AENA,AENA,ACHA,ACHA,ACHA,AENA,ACHA,ACHA,ACHA,AENA,AGTA,AFMA,AGTA,ACHA,ACHA,AlCsGA,A8B1FA,AjEmMA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,ALeA,AxBwEA,AFMA;A4BnFA,AIZA,AxBwEA,AmDzJA,AENA,AENA,ACHA,ACHA,ACHA,AGTA,ACHA,ACHA,AENA,AGTA,AFMA,AGTA,ACHA,ACHA,AlCsGA,A8B1FA,AjEmMA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,ALeA,AxBwEA,AFMA;A4BnFA,AIZA,AxBwEA,AmDzJA,AENA,AENA,ACHA,ACHA,ACHA,AGTA,ACHA,ACHA,AENA,AGTA,AFMA,AGTA,ACHA,ACHA,ACHA,AnCyGA,A8B1FA,AjEmMA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,ALeA,AxBwEA,AFMA;A4BnFA,AIZA,AxBwEA,AmDzJA,AENA,AENA,ACHA,ACHA,ACHA,AGTA,AENA,AENA,AGTA,AFMA,AGTA,ACHA,ACHA,ACHA,AnCyGA,A8B1FA,AjEmMA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,ALeA,AxBwEA,AFMA;A4BnFA,ApB4DA,AmDzJA,AENA,AENA,ACHA,ACHA,ACHA,AGTA,AENA,AENA,AGTA,AFMA,AGTA,ACHA,ACHA,ACHA,AnCyGA,A8B1FA,AjEmMA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,ALeA,AxBwEA,AFMA;A4BnFA,ApB4DA,AmDzJA,AENA,AENA,ACHA,ACHA,ACHA,AGTA,AENA,AENA,AGTA,AFMA,AGTA,ACHA,ACHA,ACHA,ACHA,ApC4GA,A8B1FA,AjEmMA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,ALeA,AxBwEA,AFMA;A4BnFA,ApB4DA,AmDzJA,AIZA,ACHA,ACHA,ACHA,AGTA,AENA,AENA,AGTA,AFMA,AGTA,ACHA,ACHA,ACHA,ACHA,ApC4GA,A8B1FA,AjEmMA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,ALeA,AxBwEA,AFMA;A4BnFA,ApB4DA,AmDzJA,AIZA,ACHA,ACHA,ACHA,AKfA,AENA,AGTA,AFMA,AGTA,ACHA,ACHA,ACHA,ACHA,ApC4GA,A8B1FA,AjEmMA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,ALeA,AxBwEA,AFMA;A4BnFA,ApB4DA,AmDzJA,AIZA,ACHA,ACHA,ACHA,AKfA,AENA,AGTA,AFMA,AGTA,ACHA,ACHA,ACHA,ACHA,ACHA,ArC+GA,A8B1FA,AjEmMA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,ALeA,AxBwEA,AFMA;A4BnFA,ApB4DA,AmDzJA,AIZA,ACHA,ACHA,ACHA,AKfA,AENA,AGTA,AFMA,AGTA,ACHA,ACHA,ACHA,ACHA,ACHA,ArC+GA,A8B1FA,AjEmMA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,ALeA,AxBwEA,AFMA;A4BnFA,ApB4DA,AmDzJA,AIZA,ACHA,ACHA,ACHA,AKfA,AENA,AGTA,AFMA,AGTA,ACHA,ACHA,ACHA,ACHA,ACHA,ArC+GA,A8B1FA,AjEmMA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,ALeA,AxBwEA,AFMA;A4BnFA,ApB4DA,AmDzJA,AIZA,ACHA,ACHA,ACHA,AKfA,AENA,AGTA,AFMA,AGTA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,AtCkHA,A8B1FA,AjEmMA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,ALeA,AxBwEA,AFMA;A4BnFA,ApB4DA,AmDzJA,AIZA,ACHA,ACHA,ACHA,AKfA,AENA,AGTA,AFMA,AGTA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,AtCkHA,A8B1FA,AjEmMA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,ALeA,AxBwEA,AFMA;A4BnFA,ApB4DA,AmDzJA,AIZA,AENA,ACHA,AKfA,AENA,AGTA,AFMA,AGTA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,AtCkHA,A8B1FA,AjEmMA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,ALeA,AxBwEA,AFMA;A4BnFA,ApB4DA,AmDzJA,AIZA,AENA,ACHA,AKfA,AENA,AGTA,AFMA,AGTA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,AvCqHA,A8B1FA,AjEmMA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,ALeA,AxBwEA,AFMA;A4BnFA,ApB4DA,AmDzJA,AIZA,AENA,ACHA,AKfA,AENA,AGTA,AFMA,AGTA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,AvCqHA,A8B1FA,AjEmMA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,ALeA,AxBwEA,AFMA;A4BnFA,ApB4DA,AmDzJA,AIZA,AENA,ACHA,AKfA,AENA,AGTA,AFMA,AGTA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,AvCqHA,A8B1FA,AjEmMA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,ALeA,AxBwEA,AFMA;A4BnFA,ApB4DA,AmDzJA,AIZA,AENA,ACHA,AKfA,AENA,AGTA,AFMA,AGTA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,AxCwHA,A8B1FA,AjEmMA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,ALeA,AxBwEA,AFMA;A4BnFA,ApB4DA,AmDzJA,AIZA,AENA,ACHA,AKfA,AENA,AGTA,AFMA,AGTA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,AxCwHA,A8B1FA,AjEmMA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,ALeA,AxBwEA,AFMA;A4BnFA,ApB4DA,AuDrKA,AENA,ACHA,AKfA,AENA,AGTA,AFMA,AGTA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,AxCwHA,A8B1FA,AjEmMA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,ALeA,AxBwEA,AFMA;A4BnFA,ApB4DA,AuDrKA,AENA,ACHA,AKfA,AENA,AGTA,AFMA,AGTA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,AzC2HA,A8B1FA,AjEmMA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,ALeA,AxBwEA,AFMA;A4BnFA,ApB4DA,AuDrKA,AENA,ACHA,AKfA,AENA,AGTA,AFMA,AGTA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,AzC2HA,A8B1FA,AjEmMA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,ALeA,AxBwEA,AFMA;A4BnFA,ApB4DA,AuDrKA,AENA,ACHA,AKfA,AENA,AGTA,AFMA,AGTA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,AzC2HA,A8B1FA,AjEmMA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,ALeA,AxBwEA,AFMA;A4BnFA,ApB4DA,AuDrKA,AGTA,AKfA,AENA,AGTA,AFMA,AGTA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,A1C8HA,A8B1FA,AjEmMA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,ALeA,AxBwEA,AFMA;A4BnFA,ApB4DA,AuDrKA,AGTA,AKfA,AENA,AGTA,AFMA,AGTA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,A1C8HA,A8B1FA,AjEmMA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,ALeA,AxBwEA,AFMA;A4BnFA,ApB4DA,AuDrKA,AGTA,AKfA,AENA,AGTA,AFMA,AGTA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,A1C8HA,A8B1FA,AjEmMA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,ALeA,AxBwEA,AFMA;A4BnFA,ApB4DA,AuDrKA,AGTA,AKfA,AENA,AGTA,AFMA,AGTA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,A3CiIA,A8B1FA,AjEmMA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,ALeA,AxBwEA,AFMA;A4BnFA,ApB4DA,AuDrKA,AGTA,AKfA,AENA,AGTA,AFMA,AIZA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,A3CiIA,A8B1FA,AjEmMA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,ALeA,AxBwEA,AFMA;A4BnFA,ApB4DA,AuDrKA,AGTA,AKfA,AENA,AGTA,AFMA,AIZA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,A3CiIA,A8B1FA,AjEmMA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,ALeA,AxBwEA,AFMA;A4BnFA,ApB4DA,AuDrKA,AGTA,AOrBA,AGTA,AFMA,AIZA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,A5CoIA,A8B1FA,AjEmMA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,ALeA,AxBwEA,AFMA;A4BnFA,ApB4DA,AuDrKA,AGTA,AOrBA,AGTA,AFMA,AIZA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,A5CoIA,A8B1FA,AjEmMA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,ALeA,AxBwEA,AFMA;A4BnFA,ApB4DA,AuDrKA,AU9BA,AGTA,AFMA,AIZA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,A5CoIA,A8B1FA,AjEmMA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,ALeA,AxBwEA,AFMA;A4BnFA,ApB4DA,AuDrKA,AU9BA,AGTA,AFMA,AIZA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,A7CuIA,A8B1FA,AjEmMA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,ALeA,AxBwEA,AFMA;A4BnFA,ApB4DA,AuDrKA,AU9BA,AGTA,AFMA,AIZA,AENA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,A7CuIA,A8B1FA,AjEmMA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,ALeA,AxBwEA,AFMA;A4BnFA,ApB4DA,AuDrKA,AU9BA,AGTA,AFMA,AIZA,AENA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,A7CuIA,A8B1FA,AjEmMA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,ALeA,AxBwEA,AFMA;A4BnFA,ApB4DA,AuDrKA,AU9BA,AGTA,AFMA,AIZA,AENA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,A9C0IA,A8B1FA,AjEmMA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,ALeA,AxBwEA,AFMA;A4BnFA,ApB4DA,AuDrKA,AU9BA,AGTA,AFMA,AIZA,AENA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,A9C0IA,A8B1FA,AjEmMA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,ALeA,AxBwEA,AFMA;A4BnFA,ApB4DA,AuDrKA,AU9BA,AGTA,AFMA,AIZA,AENA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,A9C0IA,A8B1FA,AjEmMA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,ALeA,AxBwEA,AFMA;A4BnFA,ApB4DA,AuDrKA,AU9BA,AGTA,AFMA,AIZA,AENA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,A/C6IA,A8B1FA,AjEmMA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,ALeA,AxBwEA,AFMA;A4BnFA,ApB4DA,AuDrKA,AU9BA,AGTA,AFMA,AIZA,AENA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,A/C6IA,A8B1FA,AjEmMA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,ALeA,AxBwEA,AFMA;A4BnFA,ApB4DA,AuDrKA,AU9BA,AGTA,AFMA,AIZA,AENA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,A/C6IA,A8B1FA,AjEmMA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,ALeA,AxBwEA,AFMA;A4BnFA,ApB4DA,AuDrKA,AU9BA,AGTA,AFMA,AIZA,AENA,AENA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,AhDgJA,A8B1FA,AjEmMA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,ALeA,AxBwEA,AFMA;A4BnFA,ApB4DA,AuDrKA,AU9BA,AGTA,AFMA,AMlBA,AENA,ACHA,AENA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,AhDgJA,A8B1FA,AjEmMA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,ALeA,AxBwEA,AFMA;A4BnFA,ApB4DA,AuDrKA,AU9BA,AGTA,AFMA,AMlBA,AENA,ACHA,AENA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,AhDgJA,A8B1FA,AjEmMA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,ALeA,AxBwEA,AFMA;A4BnFA,ApB4DA,AuDrKA,AU9BA,AGTA,AFMA,AMlBA,AENA,ACHA,AENA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,AjDmJA,A8B1FA,AjEmMA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,ALeA,AxBwEA,AFMA;A4BnFA,ApB4DA,AuDrKA,AU9BA,AGTA,AFMA,AMlBA,AENA,ACHA,AENA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,AjDmJA,A8B1FA,AjEmMA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,ALeA,AxBwEA,AFMA;A4BnFA,ApB4DA,AuDrKA,AU9BA,AGTA,AFMA,AMlBA,AENA,ACHA,AENA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,AjDmJA,A8B1FA,AjEmMA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,ALeA,AxBwEA,AFMA;A4BnFA,ApB4DA,AuDrKA,AU9BA,AGTA,AFMA,AMlBA,AENA,ACHA,AENA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,AlDsJA,A8B1FA,AjEmMA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,ALeA,AxBwEA,AFMA;A4BnFA,ApB4DA,AuDrKA,AU9BA,AGTA,AFMA,AMlBA,AENA,AGTA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,AlDsJA,A8B1FA,AjEmMA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,ALeA,AxBwEA,AFMA;A4BnFA,ApB4DA,AuDrKA,AU9BA,AGTA,AFMA,AQxBA,AGTA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,AlDsJA,A8B1FA,AjEmMA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,ALeA,AxBwEA,AFMA;A4BnFA,ApB4DA,AuDrKA,AU9BA,AGTA,AFMA,AQxBA,AGTA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,AnDyJA,A8B1FA,AjEmMA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,ALeA,AxBwEA,AFMA;A4BnFA,ApB4DA,AuDrKA,AU9BA,AGTA,AFMA,AQxBA,AGTA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,AnDyJA,A8B1FA,AjEmMA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,ALeA,AxBwEA,AFMA;A4BnFA,ApB4DA,AuDrKA,AU9BA,AGTA,AFMA,AQxBA,AGTA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,AnDyJA,A8B1FA,AjEmMA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,ALeA,AxBwEA,AFMA;A4BnFA,ApB4DA,AuDrKA,AU9BA,AGTA,AFMA,AQxBA,AGTA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ApD4JA,A8B1FA,AjEmMA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,ALeA,AxBwEA,AFMA;A4BnFA,ApB4DA,AuDrKA,AU9BA,AGTA,AFMA,AQxBA,AGTA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ApD4JA,A8B1FA,AjEmMA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,ALeA,AxBwEA,AFMA;A4BnFA,ApB4DA,AuDrKA,AU9BA,AGTA,AFMA,AQxBA,AGTA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ApD4JA,A8B1FA,AjEmMA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,ALeA,AxBwEA,AFMA;A4BnFA,ApB4DA,AuDrKA,AU9BA,AGTA,AFMA,AWjCA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ArD+JA,A8B1FA,AjEmMA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,ALeA,AxBwEA,AFMA;A4BnFA,ApB4DA,AuDrKA,AU9BA,AGTA,AFMA,AWjCA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ArD+JA,A8B1FA,AjEmMA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,ALeA,AxBwEA,AFMA;A4BnFA,ApB4DA,AuDrKA,AU9BA,AGTA,AFMA,AWjCA,AENA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ArD+JA,A8B1FA,AjEmMA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,ALeA,AxBwEA,AFMA;A4BnFA,ApB4DA,AuDrKA,AU9BA,AGTA,AFMA,AWjCA,AENA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,AtDkKA,A8B1FA,AjEmMA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,ALeA,AxBwEA,AFMA;A4BnFA,ApB4DA,AuDrKA,AU9BA,AGTA,AFMA,AWjCA,AENA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,AtDkKA,A8B1FA,AjEmMA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,ALeA,AxBwEA,AFMA;A4BnFA,ApB4DA,AuDrKA,AU9BA,AGTA,AFMA,AWjCA,AENA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,AtDkKA,A8B1FA,AjEmMA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,ALeA,AxBwEA,AFMA;A4BnFA,ApB4DA,AuDrKA,AU9BA,AGTA,AFMA,AWjCA,AENA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,AvDqKA,A8B1FA,AjEmMA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,ALeA,AxBwEA,AFMA;A4BnFA,ApB4DA,AuDrKA,AU9BA,AGTA,AFMA,AWjCA,AENA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,AvDqKA,A8B1FA,AjEmMA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,ALeA,AxBwEA,AFMA;A4BnFA,ApB4DA,AuDrKA,AU9BA,AGTA,AFMA,AWjCA,AENA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,AvDqKA,A8B1FA,AjEmMA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,ALeA,AxBwEA,AFMA;A4BnFA,ApB4DA,AuDrKA,AU9BA,AGTA,AFMA,AWjCA,AENA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,AvDqKA,AwDxKA,A1B8EA,AjEmMA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,ALeA,AxBwEA,AFMA;A4BnFA,ApB4DA,AuDrKA,AU9BA,AGTA,AFMA,AWjCA,AENA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,AvDqKA,AwDxKA,A1B8EA,AjEmMA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,ALeA,AxBwEA,AFMA;A4BnFA,ApB4DA,AuDrKA,AU9BA,AGTA,AFMA,AWjCA,AENA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,AvDqKA,AwDxKA,A1B8EA,AjEmMA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,ALeA,AxBwEA,AFMA;A4BnFA,ApB4DA,AuDrKA,AU9BA,AGTA,AFMA,AWjCA,AENA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,AvDqKA,AwDxKA,ACHA,A3BiFA,AjEmMA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,ALeA,AxBwEA,AFMA;A4BnFA,ApB4DA,AuDrKA,AU9BA,AGTA,AFMA,AWjCA,AENA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,AvDqKA,AwDxKA,ACHA,A3BiFA,AjEmMA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,ALeA,AxBwEA,AFMA;A4BnFA,ApB4DA,AuDrKA,AU9BA,AGTA,AFMA,AWjCA,AENA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,AvDqKA,AwDxKA,ACHA,A3BiFA,AjEmMA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,ALeA,AxBwEA,AFMA;A4BnFA,ApB4DA,AuDrKA,AU9BA,AGTA,AFMA,AWjCA,AENA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,AvDqKA,AwDxKA,ACHA,ACHA,A5BoFA,AjEmMA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,ALeA,AxBwEA,AFMA;A4BnFA,ApB4DA,AuDrKA,AU9BA,AGTA,AFMA,AWjCA,AENA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,AvDqKA,AwDxKA,ACHA,ACHA,A5BoFA,AjEmMA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,ALeA,AxBwEA,AFMA;A4BnFA,ApB4DA,AuDrKA,AU9BA,AGTA,AFMA,AWjCA,AENA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,AvDqKA,AwDxKA,ACHA,ACHA,A5BoFA,AjEmMA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,ALeA,AxBwEA,AFMA;A4BnFA,ApB4DA,AuDrKA,AU9BA,AGTA,AFMA,AWjCA,AENA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,AvDqKA,AwDxKA,ACHA,ACHA,A5BoFA,A6BvFA,A9F0RA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,ALeA,AxBwEA,AFMA;A4BnFA,ApB4DA,AuDrKA,AU9BA,AGTA,AFMA,AWjCA,AENA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,AvDqKA,AwDxKA,ACHA,ACHA,A5BoFA,A6BvFA,A9F0RA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,ALeA,AxBwEA,AFMA;A4BnFA,ApB4DA,AuDrKA,AU9BA,AGTA,AFMA,AWjCA,AENA,ACHA,ACHA,ACHA,ACHA,AENA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,AvDqKA,AwDxKA,ACHA,ACHA,A5BoFA,A6BvFA,A9F0RA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,ALeA,AxBwEA,AFMA;A4BnFA,ApB4DA,AuDrKA,AU9BA,AGTA,AFMA,AWjCA,AENA,ACHA,ACHA,ACHA,ACHA,AENA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,AvDqKA,AwDxKA,ACHA,ACHA,A5BoFA,A6BvFA,ACHA,A/F6RA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,ALeA,AxBwEA,AFMA;A4BnFA,ApB4DA,AuDrKA,AU9BA,AGTA,AFMA,AWjCA,AGTA,ACHA,ACHA,ACHA,AENA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,AvDqKA,AwDxKA,ACHA,ACHA,A5BoFA,A6BvFA,ACHA,A/F6RA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,ALeA,AxBwEA,AFMA;A4BnFA,ApB4DA,AuDrKA,AU9BA,AGTA,AFMA,AWjCA,AGTA,ACHA,ACHA,ACHA,AENA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,AvDqKA,AwDxKA,ACHA,ACHA,A5BoFA,A6BvFA,ACHA,A/F6RA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,ALeA,AxBwEA,AFMA;A4BnFA,ApB4DA,AuDrKA,AU9BA,AGTA,AFMA,AWjCA,AGTA,ACHA,ACHA,ACHA,AGTA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,AvDqKA,AwDxKA,ACHA,ACHA,A5BoFA,A6BvFA,ACHA,ACHA,AhGgSA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,ALeA,AxBwEA,AFMA;A4BnFA,ApB4DA,AuDrKA,AU9BA,AGTA,AFMA,AWjCA,AGTA,ACHA,ACHA,ACHA,AGTA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,AvDqKA,AwDxKA,ACHA,ACHA,A5BoFA,A6BvFA,ACHA,ACHA,AhGgSA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,ALeA,AxBwEA,AFMA;A4BnFA,ApB4DA,AuDrKA,AU9BA,AGTA,AFMA,AWjCA,AGTA,ACHA,AENA,AGTA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,AvDqKA,AwDxKA,ACHA,ACHA,A5BoFA,A6BvFA,ACHA,ACHA,AhGgSA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,ALeA,AxBwEA,AFMA;A4BnFA,ApB4DA,AuDrKA,AU9BA,AGTA,AFMA,AWjCA,AGTA,ACHA,AENA,AGTA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,AvDqKA,AwDxKA,ACHA,ACHA,A5BoFA,A6BvFA,ACHA,ACHA,ACHA,AjGmSA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,ALeA,AxBwEA,AFMA;A4BnFA,ApB4DA,AuDrKA,AU9BA,AGTA,AFMA,AWjCA,AGTA,ACHA,AENA,AGTA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,AvDqKA,AwDxKA,ACHA,ACHA,A5BoFA,A6BvFA,ACHA,ACHA,ACHA,AjGmSA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,ALeA,AxBwEA,AFMA;A4BnFA,ApB4DA,AuDrKA,AU9BA,AGTA,AFMA,AWjCA,AGTA,ACHA,AKfA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,AvDqKA,AwDxKA,ACHA,ACHA,A5BoFA,A6BvFA,ACHA,ACHA,ACHA,AjGmSA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,ALeA,AxBwEA,AFMA;A4BnFA,ApB4DA,AuDrKA,AU9BA,AGTA,AFMA,AWjCA,AIZA,AKfA,ACHA,ACHA,ACHA,ACHA,ACHA,ACHA,AvDqKA,AwDxKA,ACHA,ACHA,A5BoFA,A6BvFA,ACHA,ACHA,ACHA,ACHA,AlGsSA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,ALeA,AxBwEA,AFMA;A4BnFA,ApB4DA,AuDrKA,AU9BA,AGTA,AFMA,AWjCA,AIZA,AKfA,AENA,ACHA,ACHA,ACHA,ACHA,AvDqKA,AwDxKA,ACHA,ACHA,A5BoFA,A6BvFA,ACHA,ACHA,ACHA,ACHA,AlGsSA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,ALeA,AxBwEA,AFMA;A4BnFA,ApB4DA,AuDrKA,AU9BA,AGTA,AFMA,AWjCA,AIZA,AKfA,AENA,ACHA,ACHA,ACHA,ACHA,AvDqKA,AwDxKA,ACHA,ACHA,A5BoFA,A6BvFA,ACHA,ACHA,ACHA,ACHA,AlGsSA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,ALeA,AxBwEA,AFMA;A4BnFA,ApB4DA,AiEnMA,AGTA,AFMA,AWjCA,AIZA,AKfA,AENA,ACHA,ACHA,ACHA,ACHA,AvDqKA,AwDxKA,ACHA,ACHA,A5BoFA,A6BvFA,ACHA,ACHA,ACHA,ACHA,AlGsSA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,A8E1OA,AnFyPA,AxBwEA,AFMA;A4BnFA,ApB4DA,AiEnMA,AGTA,AFMA,AWjCA,AIZA,AKfA,AENA,ACHA,ACHA,ACHA,ACHA,AvDqKA,AwDxKA,ACHA,ACHA,A5BoFA,A6BvFA,ACHA,ACHA,ACHA,ACHA,AlGsSA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,A8E1OA,AnFyPA,AxBwEA,AFMA;A4BnFA,ApB4DA,AiEnMA,AGTA,AFMA,AWjCA,AIZA,AKfA,AENA,ACHA,ACHA,ACHA,ACHA,AvDqKA,AwDxKA,ACHA,ACHA,A5BoFA,A6BvFA,ACHA,ACHA,ACHA,ACHA,AlGsSA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,A8E1OA,AnFyPA,AxBwEA,AFMA;A4BnFA,ApB4DA,AiEnMA,AGTA,AFMA,AWjCA,AIZA,AKfA,AENA,ACHA,ACHA,ACHA,ACHA,AvDqKA,AwDxKA,ACHA,ACHA,A5BoFA,A6BvFA,ACHA,ACHA,ACHA,ACHA,AlGsSA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,A8E1OA,ACHA,ApF4PA,AxBwEA,AFMA;A4BnFA,ApB4DA,AiEnMA,AGTA,AFMA,AWjCA,AIZA,AKfA,AENA,ACHA,ACHA,ACHA,ACHA,AvDqKA,AwDxKA,ACHA,ACHA,A5BoFA,A6BvFA,ACHA,ACHA,ACHA,ACHA,AlGsSA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,A8E1OA,ACHA,ApF4PA,AxBwEA,AFMA;A4BnFA,ApB4DA,AiEnMA,AGTA,AFMA,AWjCA,AIZA,AOrBA,ACHA,ACHA,ACHA,ACHA,AvDqKA,AwDxKA,ACHA,ACHA,A5BoFA,A6BvFA,ACHA,ACHA,ACHA,ACHA,AlGsSA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,A8E1OA,ACHA,ApF4PA,AxBwEA,AFMA;A4BnFA,ApB4DA,AiEnMA,AGTA,AFMA,AWjCA,AIZA,AQxBA,ACHA,ACHA,ACHA,AvDqKA,AwDxKA,ACHA,ACHA,A5BoFA,A6BvFA,ACHA,ACHA,ACHA,ACHA,AGTA,ArG+SA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,A8E1OA,ACHA,ApF4PA,AxBwEA,AFMA;A4BnFA,ApB4DA,AiEnMA,AGTA,AFMA,AWjCA,AIZA,AQxBA,ACHA,ACHA,ACHA,AvDqKA,AwDxKA,ACHA,ACHA,A5BoFA,A6BvFA,ACHA,ACHA,ACHA,ACHA,AGTA,ArG+SA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,A8E1OA,ACHA,ApF4PA,AxBwEA,AFMA;A4BnFA,ApB4DA,AiEnMA,AGTA,AFMA,AWjCA,AIZA,AQxBA,ACHA,ACHA,ACHA,AvDqKA,AwDxKA,ACHA,ACHA,A5BoFA,A6BvFA,ACHA,ACHA,ACHA,ACHA,AGTA,ArG+SA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,A8E1OA,ACHA,ApF4PA,AxBwEA,AFMA;A4BnFA,ApB4DA,AiEnMA,AGTA,AFMA,AWjCA,AIZA,AQxBA,ACHA,ACHA,ACHA,AvDqKA,AwDxKA,ACHA,ACHA,A5BoFA,A6BvFA,ACHA,ACHA,ACHA,ACHA,AGTA,ACHA,AtGkTA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,A8E1OA,ACHA,ApF4PA,AxBwEA,AFMA;A4BnFA,ApB4DA,AiEnMA,AGTA,AFMA,AWjCA,AIZA,AQxBA,ACHA,ACHA,ACHA,AvDqKA,AwDxKA,ACHA,ACHA,A5BoFA,A6BvFA,ACHA,ACHA,ACHA,ACHA,AGTA,ACHA,AtGkTA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,A8E1OA,ACHA,ApF4PA,AxBwEA,AFMA;A4BnFA,ApB4DA,AiEnMA,AGTA,AFMA,AWjCA,AIZA,AQxBA,ACHA,ACHA,ACHA,AvDqKA,AwDxKA,ACHA,ACHA,A5BoFA,A6BvFA,ACHA,ACHA,ACHA,ACHA,AGTA,ACHA,AtGkTA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,A8E1OA,ACHA,ApF4PA,AxBwEA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,AGTA,AFMA,Ae7CA,AQxBA,ACHA,ACHA,ACHA,AvDqKA,AwDxKA,ACHA,ACHA,A5BoFA,A6BvFA,ACHA,ACHA,ACHA,ACHA,AGTA,ACHA,AtGkTA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,A8E1OA,ACHA,ApF4PA,AxBwEA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,AGTA,AFMA,Ae7CA,AQxBA,ACHA,ACHA,ACHA,AvDqKA,AwDxKA,ACHA,ACHA,A5BoFA,A6BvFA,ACHA,ACHA,ACHA,ACHA,AGTA,ACHA,AtGkTA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,A8E1OA,ACHA,ApF4PA,AxBwEA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,AGTA,AFMA,Ae7CA,AQxBA,ACHA,ACHA,ACHA,AvDqKA,AwDxKA,ACHA,ACHA,A5BoFA,A6BvFA,ACHA,ACHA,ACHA,ACHA,AGTA,ACHA,AtGkTA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,A8E1OA,ACHA,ApF4PA,AxBwEA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,AGTA,AFMA,Ae7CA,AQxBA,ACHA,ACHA,ACHA,AvDqKA,AwDxKA,ACHA,ACHA,A5BoFA,A6BvFA,ACHA,ACHA,ACHA,ACHA,AGTA,ACHA,AtGkTA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,A8E1OA,AKfA,AJYA,ApF4PA,AxBwEA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,AGTA,AFMA,Ae7CA,AQxBA,AGTA,AvDqKA,AwDxKA,ACHA,ACHA,A5BoFA,A6BvFA,ACHA,ACHA,ACHA,ACHA,AGTA,ACHA,AtGkTA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,A8E1OA,AKfA,AJYA,ApF4PA,AxBwEA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,AGTA,AFMA,Ae7CA,AQxBA,AGTA,AvDqKA,AwDxKA,ACHA,ACHA,A5BoFA,A6BvFA,ACHA,ACHA,ACHA,ACHA,AGTA,ACHA,AtGkTA,AbuCA,Ae7CA,AWjCA,Ac1CA,ACHA,APqBA,A8E1OA,AKfA,AJYA,ApF4PA,AxBwEA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,AGTA,AFMA,Ae7CA,AQxBA,AGTA,AvDqKA,AwDxKA,ACHA,ACHA,A5BoFA,A6BvFA,ACHA,ACHA,ACHA,ACHA,AGTA,ACHA,AtGkTA,AbuCA,Ae7CA,AWjCA,Ac1CA,A8E1OA,A7EuOA,APqBA,A8E1OA,AKfA,AJYA,ApF4PA,AxBwEA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,AGTA,AFMA,AuBrEA,AGTA,AvDqKA,AwDxKA,ACHA,ACHA,A5BoFA,A6BvFA,ACHA,ACHA,ACHA,ACHA,AGTA,ACHA,AtGkTA,AbuCA,Ae7CA,AWjCA,Ac1CA,A8E1OA,A7EuOA,APqBA,A8E1OA,AKfA,AJYA,ApF4PA,AxBwEA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,AGTA,AFMA,AuBrEA,AGTA,AvDqKA,AwDxKA,ACHA,ACHA,A5BoFA,A6BvFA,ACHA,ACHA,ACHA,ACHA,AGTA,ACHA,AtGkTA,AbuCA,Ae7CA,AWjCA,Ac1CA,A8E1OA,A7EuOA,APqBA,A8E1OA,AKfA,AJYA,ApF4PA,AxBwEA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,AGTA,AFMA,AuBrEA,AGTA,AvDqKA,AwDxKA,ACHA,ACHA,A5BoFA,A6BvFA,ACHA,ACHA,ACHA,ACHA,AGTA,ACHA,AtGkTA,AbuCA,Ae7CA,AWjCA,Ac1CA,A8E1OA,ApF4PA,A8E1OA,AKfA,AJYA,ApF4PA,A0F9QA,AlHsVA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,AGTA,AFMA,AuBrEA,AGTA,AvDqKA,AwDxKA,ACHA,ACHA,A5BoFA,A6BvFA,ACHA,ACHA,ACHA,ACHA,AGTA,ACHA,AtGkTA,AbuCA,Ae7CA,AWjCA,Ac1CA,A8E1OA,ApF4PA,A8E1OA,AKfA,AJYA,ApF4PA,A0F9QA,AlHsVA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,AGTA,AFMA,AuBrEA,AGTA,AvDqKA,AwDxKA,ACHA,ACHA,A5BoFA,A6BvFA,ACHA,ACHA,ACHA,ACHA,AGTA,ACHA,AtGkTA,AbuCA,Ae7CA,AWjCA,Ac1CA,A8E1OA,ApF4PA,A8E1OA,AKfA,AJYA,ApF4PA,A0F9QA,AlHsVA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,AGTA,AFMA,AuBrEA,AGTA,AvDqKA,AwDxKA,ACHA,ACHA,A5BoFA,A6BvFA,ACHA,ACHA,ACHA,ACHA,AGTA,ACHA,AtGkTA,AbuCA,Ae7CA,AWjCA,Ac1CA,A8E1OA,AENA,AtFkQA,A8E1OA,AKfA,AxFwQA,A0F9QA,AlHsVA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,AGTA,AFMA,AuBrEA,ApD4JA,AwDxKA,ACHA,ACHA,A5BoFA,A6BvFA,ACHA,ACHA,ACHA,ACHA,AGTA,ACHA,AtGkTA,AbuCA,Ae7CA,AWjCA,Ac1CA,A8E1OA,AENA,AtFkQA,AmFzPA,AxFwQA,A0F9QA,AlHsVA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,AGTA,AFMA,AuBrEA,ApD4JA,AwDxKA,ACHA,ACHA,A5BoFA,A6BvFA,ACHA,ACHA,ACHA,ACHA,AGTA,ACHA,AtGkTA,AbuCA,Ae7CA,AWjCA,Ac1CA,A8E1OA,AENA,AtFkQA,AmFzPA,AxFwQA,A0F9QA,AlHsVA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,AGTA,AFMA,AuBrEA,ApD4JA,AwDxKA,ACHA,ACHA,A5BoFA,A6BvFA,ACHA,ACHA,ACHA,ACHA,AGTA,ACHA,AtGkTA,AbuCA,Ae7CA,AWjCA,Ac1CA,A8E1OA,AENA,AtFkQA,AuFrQA,AJYA,AxFwQA,A0F9QA,AlHsVA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,AGTA,AFMA,AuBrEA,ApD4JA,AwDxKA,ACHA,ACHA,A5BoFA,A6BvFA,ACHA,ACHA,ACHA,ACHA,AGTA,ACHA,AtGkTA,AbuCA,Ae7CA,AWjCA,Ac1CA,A8E1OA,AENA,AtFkQA,AuFrQA,AJYA,AxFwQA,A0F9QA,AlHsVA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,AGTA,AFMA,AuBrEA,ApD4JA,AwDxKA,ACHA,ACHA,A5BoFA,A6BvFA,ACHA,ACHA,ACHA,ACHA,AGTA,ACHA,AtGkTA,AbuCA,Ae7CA,AWjCA,Ac1CA,A8E1OA,AENA,AtFkQA,AuFrQA,AJYA,AxFwQA,A0F9QA,AlHsVA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,AGTA,AFMA,AuBrEA,ApD4JA,AwDxKA,ACHA,ACHA,A5BoFA,A6BvFA,ACHA,ACHA,ACHA,ACHA,AGTA,ACHA,AtGkTA,AbuCA,Ae7CA,AWjCA,Ac1CA,A8E1OA,AENA,AtFkQA,AuFrQA,AJYA,AKfA,A7FuRA,A0F9QA,AlHsVA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,AGTA,AFMA,AuBrEA,ApD4JA,AwDxKA,ACHA,ACHA,A5BoFA,A6BvFA,ACHA,ACHA,ACHA,ACHA,AGTA,ACHA,AtGkTA,AbuCA,Ae7CA,AWjCA,Ac1CA,A8E1OA,AENA,AtFkQA,AuFrQA,AJYA,AKfA,A7FuRA,A0F9QA,AlHsVA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,AGTA,AFMA,AuBrEA,ApD4JA,AwDxKA,ACHA,ACHA,A5BoFA,A6BvFA,ACHA,ACHA,ACHA,ACHA,AGTA,ACHA,AtGkTA,AbuCA,Ae7CA,AWjCA,Ac1CA,A8E1OA,AENA,AtFkQA,AuFrQA,AJYA,AKfA,A7FuRA,A0F9QA,AlHsVA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,AGTA,AFMA,AuBrEA,ApD4JA,AwDxKA,ACHA,ACHA,A5BoFA,A6BvFA,ACHA,ACHA,ACHA,ACHA,AGTA,ACHA,AtGkTA,AbuCA,Ae7CA,AWjCA,Ac1CA,A8E1OA,AENA,AtFkQA,AuFrQA,AJYA,AMlBA,ADGA,A7FuRA,A0F9QA,AlHsVA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,AGTA,AFMA,AuBrEA,ApD4JA,AwDxKA,ACHA,ACHA,A5BoFA,A6BvFA,ACHA,ACHA,ACHA,ACHA,AGTA,ACHA,AtGkTA,AbuCA,Ae7CA,AWjCA,Ac1CA,A8E1OA,AENA,AtFkQA,AuFrQA,AJYA,AMlBA,ADGA,A7FuRA,A0F9QA,AlHsVA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,AGTA,AFMA,AuBrEA,ApD4JA,AwDxKA,ACHA,A3BiFA,A6BvFA,ACHA,ACHA,ACHA,ACHA,AGTA,ACHA,AtGkTA,AbuCA,Ae7CA,AWjCA,Ac1CA,A8E1OA,AENA,AtFkQA,AuFrQA,AJYA,AMlBA,ADGA,A7FuRA,A0F9QA,AlHsVA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,AGTA,AFMA,AuBrEA,ApD4JA,AwDxKA,ACHA,A3BiFA,A6BvFA,ACHA,ACHA,ACHA,ACHA,AGTA,ACHA,AtGkTA,AbuCA,Ae7CA,AWjCA,Ac1CA,A8E1OA,AENA,AtFkQA,AuFrQA,AJYA,AMlBA,ADGA,AENA,A/F6RA,A0F9QA,AlHsVA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,AGTA,AFMA,AuBrEA,ApD4JA,AwDxKA,ACHA,A3BiFA,A6BvFA,ACHA,ACHA,ACHA,ACHA,AGTA,ACHA,AtGkTA,AbuCA,Ae7CA,AWjCA,Ac1CA,A8E1OA,AENA,AtFkQA,AuFrQA,AJYA,AMlBA,ADGA,AENA,A/F6RA,A0F9QA,AlHsVA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,AGTA,AFMA,A7BuFA,AwDxKA,ACHA,A3BiFA,A6BvFA,ACHA,ACHA,ACHA,ACHA,AIZA,AtGkTA,AbuCA,Ae7CA,AWjCA,Ac1CA,A8E1OA,AENA,AtFkQA,AuFrQA,AJYA,AMlBA,ADGA,AENA,A/F6RA,A0F9QA,AlHsVA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,AGTA,AFMA,A7BuFA,AwDxKA,ACHA,A3BiFA,A6BvFA,AGTA,ACHA,AIZA,AtGkTA,AbuCA,Ae7CA,AWjCA,Ac1CA,A8E1OA,AENA,AtFkQA,AuFrQA,AJYA,AMlBA,AENA,AHSA,AENA,A/F6RA,A0F9QA,AlHsVA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,AGTA,AFMA,A7BuFA,AwDxKA,A1B8EA,A6BvFA,AGTA,ACHA,AIZA,AtGkTA,AbuCA,Ae7CA,AWjCA,Ac1CA,A8E1OA,AENA,AtFkQA,AuFrQA,AJYA,AMlBA,AENA,AHSA,AENA,A/F6RA,A0F9QA,AlHsVA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,AGTA,AFMA,A7BuFA,AwDxKA,A1B8EA,A6BvFA,AGTA,ACHA,AIZA,AtGkTA,AbuCA,Ae7CA,AWjCA,Ac1CA,A8E1OA,AENA,AtFkQA,AuFrQA,AJYA,AMlBA,AENA,AHSA,AENA,A/F6RA,A0F9QA,AlHsVA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,AGTA,AFMA,A7BuFA,AwDxKA,A1B8EA,A6BvFA,AIZA,AIZA,AtGkTA,AbuCA,Ae7CA,AWjCA,Ac1CA,A8E1OA,AQxBA,ANkBA,AtFkQA,AuFrQA,AJYA,AMlBA,AENA,AHSA,AENA,A/F6RA,A0F9QA,AlHsVA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,AGTA,AFMA,A7BuFA,AwDxKA,A1B8EA,A6BvFA,AIZA,AIZA,AtGkTA,AbuCA,Ae7CA,AWjCA,Ac1CA,A8E1OA,AQxBA,ANkBA,AtFkQA,AuFrQA,AJYA,AMlBA,AENA,AHSA,AENA,A/F6RA,A0F9QA,AlHsVA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,AGTA,AFMA,A7BuFA,A8B1FA,A6BvFA,AIZA,AIZA,AtGkTA,AbuCA,Ae7CA,AWjCA,Ac1CA,A8E1OA,AQxBA,ANkBA,AtFkQA,AuFrQA,AJYA,AMlBA,AENA,AHSA,AENA,A/F6RA,A0F9QA,AlHsVA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,AGTA,AFMA,A7BuFA,A8B1FA,A6BvFA,AIZA,AIZA,AtGkTA,AbuCA,Ae7CA,AWjCA,Ac1CA,A8E1OA,AS3BA,ADGA,ANkBA,AtFkQA,AuFrQA,AJYA,AMlBA,AENA,AHSA,AENA,A/F6RA,A0F9QA,AlHsVA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,AGTA,AFMA,A7BuFA,A8B1FA,A6BvFA,AIZA,AlGsSA,AbuCA,Ae7CA,AWjCA,Ac1CA,A8E1OA,AS3BA,ADGA,ANkBA,AtFkQA,AuFrQA,AJYA,AMlBA,AENA,AHSA,AENA,A/F6RA,A0F9QA,AlHsVA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,AGTA,AFMA,A7BuFA,A8B1FA,A6BvFA,AIZA,AlGsSA,AbuCA,Ae7CA,AWjCA,Ac1CA,A8E1OA,AS3BA,ADGA,ANkBA,AtFkQA,AuFrQA,AJYA,AMlBA,AENA,AHSA,AENA,A/F6RA,A0F9QA,AlHsVA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,AGTA,AFMA,A7BuFA,A8B1FA,A6BvFA,AIZA,AlGsSA,AbuCA,Ae7CA,AWjCA,Ac1CA,A8E1OA,AS3BA,ADGA,ANkBA,AtFkQA,AuFrQA,AJYA,AMlBA,AENA,AGTA,ANkBA,AENA,A/F6RA,A0F9QA,AlHsVA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,AGTA,AFMA,A7BuFA,A8B1FA,A6BvFA,AIZA,AlGsSA,AbuCA,Ae7CA,AWjCA,Ac1CA,A8E1OA,AS3BA,ADGA,ANkBA,AtFkQA,AuFrQA,AJYA,AMlBA,AENA,AGTA,ANkBA,AENA,A/F6RA,A0F9QA,AlHsVA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,AGTA,AFMA,A7BuFA,A8B1FA,A6BvFA,AIZA,AlGsSA,AbuCA,Ae7CA,AWjCA,Ac1CA,A8E1OA,AS3BA,ADGA,ANkBA,AtFkQA,AuFrQA,AJYA,AMlBA,AENA,AGTA,ANkBA,AENA,A/F6RA,A0F9QA,AlHsVA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,AGTA,AFMA,A7BuFA,A8B1FA,A6BvFA,AIZA,AlGsSA,AbuCA,Ae7CA,AWjCA,Ac1CA,A8E1OA,AS3BA,ADGA,ANkBA,AtFkQA,A+F7RA,ARwBA,AJYA,AMlBA,AENA,AGTA,ANkBA,AENA,A/F6RA,A0F9QA,AlHsVA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,AGTA,AFMA,A7BuFA,A8B1FA,A6BvFA,AIZA,AlGsSA,AbuCA,Ae7CA,AWjCA,Ac1CA,A8E1OA,AS3BA,ADGA,ANkBA,AtFkQA,A+F7RA,ARwBA,AJYA,AMlBA,AENA,AGTA,ANkBA,AENA,A/F6RA,A0F9QA,AlHsVA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,AGTA,AFMA,A7BuFA,A8B1FA,A6BvFA,AIZA,AlGsSA,AbuCA,Ae7CA,AWjCA,Ac1CA,A8E1OA,AS3BA,ADGA,ANkBA,AtFkQA,A+F7RA,ARwBA,AJYA,AMlBA,AENA,AGTA,ANkBA,AENA,A/F6RA,A0F9QA,AlHsVA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,AGTA,AFMA,A7BuFA,A8B1FA,A6BvFA,AIZA,AlGsSA,AbuCA,A0B9EA,Ac1CA,A8E1OA,AS3BA,ADGA,ANkBA,AtFkQA,A+F7RA,ARwBA,AJYA,AMlBA,AENA,AGTA,ANkBA,AENA,A/F6RA,AqG/SA,AXiCA,AlHsVA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,AGTA,AFMA,A7BuFA,A8B1FA,A6BvFA,AIZA,AlGsSA,AbuCA,A0B9EA,Ac1CA,A8E1OA,AS3BA,ADGA,ANkBA,AtFkQA,A+F7RA,ARwBA,AJYA,AMlBA,AENA,AGTA,ANkBA,AENA,A/F6RA,AqG/SA,AXiCA,AlHsVA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,AGTA,AFMA,A7BuFA,A8B1FA,A6BvFA,AIZA,AlGsSA,AbuCA,A0B9EA,Ac1CA,A8E1OA,AS3BA,ADGA,ANkBA,AtFkQA,A+F7RA,ARwBA,AJYA,AMlBA,AENA,AGTA,ANkBA,AENA,A/F6RA,AqG/SA,AXiCA,AlHsVA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,AGTA,AFMA,A7BuFA,A8B1FA,A6BvFA,AIZA,AlGsSA,AbuCA,A0B9EA,Ac1CA,A8E1OA,AS3BA,ADGA,ANkBA,AtFkQA,A+F7RA,AENA,AV8BA,AJYA,AMlBA,AENA,AGTA,ANkBA,AENA,A/F6RA,AqG/SA,AXiCA,AlHsVA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,AGTA,AFMA,A7BuFA,A8B1FA,A6BvFA,AIZA,AlGsSA,AbuCA,A0B9EA,Ac1CA,A8E1OA,AS3BA,ADGA,ANkBA,AtFkQA,A+F7RA,AENA,AV8BA,AJYA,AMlBA,AENA,AGTA,ANkBA,AENA,A/F6RA,AqG/SA,AXiCA,AlHsVA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,AGTA,AFMA,A7BuFA,A8B1FA,A6BvFA,AIZA,AlGsSA,AbuCA,A0B9EA,Ac1CA,A8E1OA,AS3BA,ADGA,ANkBA,AtFkQA,A+F7RA,AENA,AV8BA,AJYA,AMlBA,AENA,AGTA,ANkBA,AENA,A/F6RA,AqG/SA,AXiCA,AlHsVA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,AGTA,AFMA,A7BuFA,A8B1FA,A6BvFA,AIZA,AlGsSA,AbuCA,A0B9EA,Ac1CA,A8E1OA,AS3BA,ADGA,ANkBA,AtFkQA,A+F7RA,AENA,AV8BA,AWjCA,Af6CA,AMlBA,AENA,AGTA,ANkBA,AENA,A/F6RA,AqG/SA,AXiCA,AlHsVA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,AGTA,AFMA,A7BuFA,A8B1FA,A6BvFA,AIZA,AlGsSA,AbuCA,A0B9EA,Ac1CA,A8E1OA,AS3BA,ADGA,ANkBA,AS3BA,AENA,AV8BA,AWjCA,Af6CA,AMlBA,AENA,AGTA,ANkBA,AENA,A/F6RA,AqG/SA,AXiCA,AlHsVA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,AGTA,AFMA,A7BuFA,A8B1FA,A6BvFA,AIZA,AlGsSA,AbuCA,A0B9EA,Ac1CA,A8E1OA,AS3BA,ADGA,ANkBA,AS3BA,AENA,AV8BA,AWjCA,Af6CA,AMlBA,AENA,AGTA,ANkBA,AENA,A/F6RA,AqG/SA,AXiCA,AlHsVA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,AGTA,AFMA,A7BuFA,A8B1FA,A6BvFA,AIZA,AlGsSA,AbuCA,A0B9EA,Ac1CA,A8E1OA,AS3BA,ADGA,ANkBA,AS3BA,AENA,AV8BA,AWjCA,Af6CA,AMlBA,AENA,AGTA,ANkBA,AWjCA,AT2BA,A/F6RA,AqG/SA,AXiCA,AlHsVA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,AGTA,AFMA,A7BuFA,A8B1FA,A6BvFA,AIZA,AlGsSA,AbuCA,A0B9EA,Ac1CA,A8E1OA,AS3BA,ADGA,ANkBA,AS3BA,AENA,AV8BA,AWjCA,Af6CA,AMlBA,AENA,AGTA,ANkBA,AWjCA,AT2BA,A/F6RA,AqG/SA,AXiCA,AlHsVA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,AGTA,AFMA,A7BuFA,A8B1FA,A6BvFA,AIZA,AlGsSA,AbuCA,A0B9EA,Ac1CA,A8E1OA,AS3BA,ADGA,ANkBA,AS3BA,AENA,AV8BA,AWjCA,Af6CA,AMlBA,AENA,AGTA,ANkBA,AWjCA,AT2BA,A/F6RA,AqG/SA,AXiCA,AlHsVA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,AGTA,AFMA,A7BuFA,A8B1FA,A6BvFA,AIZA,AlGsSA,AbuCA,AwCxHA,A8E1OA,AS3BA,ADGA,ANkBA,AS3BA,AENA,AGTA,AbuCA,AWjCA,Af6CA,AMlBA,AENA,AGTA,ANkBA,AWjCA,AT2BA,A/F6RA,AqG/SA,AXiCA,AlHsVA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,AGTA,AFMA,A7BuFA,A8B1FA,A6BvFA,AIZA,AlGsSA,AbuCA,AwCxHA,A8E1OA,AS3BA,ADGA,ANkBA,AS3BA,AENA,AGTA,AbuCA,AWjCA,Af6CA,AMlBA,AENA,AGTA,ANkBA,AWjCA,AT2BA,A/F6RA,AqG/SA,AXiCA,AlHsVA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,AGTA,AFMA,A7BuFA,A8B1FA,A6BvFA,AIZA,AlGsSA,AbuCA,AwCxHA,A8E1OA,AS3BA,ADGA,ANkBA,AS3BA,AENA,AGTA,AbuCA,AWjCA,Af6CA,AMlBA,AENA,AGTA,ANkBA,AWjCA,AT2BA,A/F6RA,AqG/SA,AXiCA,AlHsVA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,AGTA,AFMA,A7BuFA,A8B1FA,A6BvFA,AIZA,AlGsSA,AbuCA,AwCxHA,A8E1OA,AS3BA,ADGA,ANkBA,AS3BA,AENA,AGTA,AbuCA,Ac1CA,AHSA,Af6CA,AMlBA,AENA,AGTA,ANkBA,AWjCA,AT2BA,A/F6RA,AqG/SA,AXiCA,AlHsVA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,AGTA,AFMA,A7BuFA,A8B1FA,A6BvFA,AIZA,AlGsSA,AbuCA,AwCxHA,A8E1OA,AS3BA,ADGA,ANkBA,AS3BA,AENA,AGTA,AbuCA,Ac1CA,AHSA,Af6CA,AMlBA,AENA,AGTA,ANkBA,AWjCA,AT2BA,A/F6RA,AqG/SA,AXiCA,AlHsVA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,AGTA,AFMA,A7BuFA,A8B1FA,A6BvFA,AIZA,AlGsSA,AbuCA,AwCxHA,A8E1OA,AS3BA,ADGA,ANkBA,AS3BA,AENA,AGTA,AbuCA,Ac1CA,AHSA,Af6CA,AMlBA,AENA,AGTA,ANkBA,AWjCA,AT2BA,A/F6RA,AqG/SA,AXiCA,AlHsVA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,AGTA,AFMA,A7BuFA,A8B1FA,A6BvFA,AIZA,AlGsSA,AbuCA,AwCxHA,A8E1OA,AS3BA,ADGA,ANkBA,AS3BA,AENA,AGTA,AbuCA,Ac1CA,AHSA,Af6CA,AMlBA,AENA,AGTA,ANkBA,AWjCA,AT2BA,AYpCA,A3GiUA,AqG/SA,AXiCA,AlHsVA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,ACHA,A7BuFA,A8B1FA,A6BvFA,AIZA,AlGsSA,AbuCA,AwCxHA,A8E1OA,AS3BA,ADGA,ANkBA,AS3BA,AENA,AGTA,AbuCA,Ac1CA,AHSA,Af6CA,AMlBA,AENA,AGTA,ANkBA,AWjCA,AT2BA,AYpCA,A3GiUA,AqG/SA,AXiCA,AlHsVA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,ACHA,A7BuFA,A8B1FA,A6BvFA,AIZA,AlGsSA,AbuCA,AwCxHA,A8E1OA,AS3BA,ADGA,ANkBA,AS3BA,AENA,AGTA,AbuCA,Ac1CA,AHSA,Af6CA,AMlBA,AENA,AGTA,ANkBA,AWjCA,AT2BA,AYpCA,A3GiUA,AqG/SA,AXiCA,AlHsVA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,ACHA,A7BuFA,A8B1FA,A6BvFA,AIZA,AlGsSA,AbuCA,AwCxHA,A8E1OA,AS3BA,ADGA,ANkBA,AS3BA,AENA,AGTA,AbuCA,Ac1CA,AHSA,Af6CA,AMlBA,AENA,AGTA,ANkBA,AWjCA,AT2BA,AYpCA,A3GiUA,A4GpUA,APqBA,AXiCA,AlHsVA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,ACHA,A7BuFA,A8B1FA,A6BvFA,AIZA,AlGsSA,AbuCA,AwCxHA,A8E1OA,AS3BA,ADGA,ANkBA,AS3BA,AENA,AGTA,AbuCA,Ac1CA,AHSA,Af6CA,AMlBA,AENA,AGTA,ANkBA,AWjCA,AT2BA,AYpCA,A3GiUA,A4GpUA,APqBA,AXiCA,AlHsVA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,ACHA,A7BuFA,A8B1FA,A6BvFA,AIZA,AlGsSA,AbuCA,AwCxHA,A8E1OA,AS3BA,ADGA,ANkBA,AS3BA,AENA,AGTA,AbuCA,Ac1CA,AHSA,Af6CA,AMlBA,AENA,AGTA,ANkBA,AWjCA,AT2BA,AYpCA,A3GiUA,A4GpUA,APqBA,AXiCA,AlHsVA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,ACHA,A7BuFA,A8B1FA,A6BvFA,AIZA,AlGsSA,AbuCA,AwCxHA,A8E1OA,AS3BA,ADGA,ANkBA,AS3BA,AENA,AGTA,AbuCA,Ac1CA,AHSA,Af6CA,AMlBA,AENA,AGTA,ANkBA,AgBhDA,ALeA,AT2BA,AYpCA,A3GiUA,A4GpUA,APqBA,AXiCA,AlHsVA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,ACHA,A7BuFA,A8B1FA,A6BvFA,AIZA,AlGsSA,AbuCA,AwCxHA,A8E1OA,AS3BA,ADGA,ANkBA,AS3BA,AENA,AGTA,AbuCA,Ac1CA,AHSA,Af6CA,AMlBA,AENA,AGTA,ANkBA,AgBhDA,ALeA,AT2BA,AYpCA,A3GiUA,A4GpUA,APqBA,AXiCA,AlHsVA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,ACHA,A7BuFA,A8B1FA,A6BvFA,AIZA,AlGsSA,AbuCA,AwCxHA,A8E1OA,AS3BA,ADGA,ANkBA,AS3BA,AENA,AGTA,AbuCA,Ac1CA,AHSA,Af6CA,AMlBA,AENA,AGTA,ANkBA,AgBhDA,ALeA,AT2BA,AYpCA,A3GiUA,A4GpUA,APqBA,AXiCA,AlHsVA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,ACHA,A7BuFA,A8B1FA,A6BvFA,AIZA,AlGsSA,AbuCA,AwCxHA,A8E1OA,AS3BA,ADGA,ANkBA,AS3BA,AENA,AGTA,AbuCA,Ac1CA,AHSA,Af6CA,AMlBA,AENA,AGTA,ANkBA,AgBhDA,ALeA,AT2BA,Ae7CA,AHSA,A3GiUA,A4GpUA,APqBA,AXiCA,AlHsVA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,ACHA,A7BuFA,A8B1FA,A6BvFA,AIZA,AlGsSA,AbuCA,AwCxHA,A8E1OA,AS3BA,ADGA,ANkBA,AS3BA,AENA,AGTA,AbuCA,Ac1CA,AHSA,Af6CA,AMlBA,AENA,AGTA,ANkBA,AgBhDA,ALeA,AT2BA,Ae7CA,AHSA,A3GiUA,A4GpUA,APqBA,AXiCA,AlHsVA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,ACHA,A7BuFA,A8B1FA,A6BvFA,AIZA,AlGsSA,AbuCA,AwCxHA,A8E1OA,AS3BA,ADGA,ANkBA,AS3BA,AENA,AGTA,AbuCA,Ac1CA,AHSA,AT2BA,AENA,AGTA,ANkBA,AgBhDA,ALeA,AT2BA,Ae7CA,AHSA,A3GiUA,A4GpUA,APqBA,AXiCA,AlHsVA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,ACHA,A7BuFA,A8B1FA,A6BvFA,AIZA,AlGsSA,AbuCA,AwCxHA,A8E1OA,AS3BA,ADGA,ANkBA,AS3BA,AENA,AGTA,AbuCA,Ac1CA,AHSA,AT2BA,AENA,AGTA,ANkBA,AgBhDA,ALeA,AT2BA,AgBhDA,ADGA,AHSA,A3GiUA,A4GpUA,APqBA,AXiCA,AlHsVA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,ACHA,A7BuFA,A8B1FA,A6BvFA,A9F0RA,AbuCA,AwCxHA,A8E1OA,AS3BA,ADGA,ANkBA,AS3BA,AENA,AGTA,AbuCA,Ac1CA,AHSA,AT2BA,AENA,AGTA,ANkBA,AgBhDA,ALeA,AT2BA,AgBhDA,ADGA,AHSA,A3GiUA,A4GpUA,APqBA,AXiCA,AlHsVA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,ACHA,A7BuFA,A8B1FA,A6BvFA,A9F0RA,AbuCA,AwCxHA,A8E1OA,AS3BA,ADGA,ANkBA,AS3BA,AENA,AGTA,AbuCA,Ac1CA,AHSA,AT2BA,AENA,AGTA,ANkBA,AgBhDA,ALeA,AT2BA,AgBhDA,ADGA,AHSA,A3GiUA,A4GpUA,APqBA,AXiCA,AlHsVA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,ACHA,A7BuFA,A8B1FA,A6BvFA,A9F0RA,AbuCA,AwCxHA,A8E1OA,AS3BA,ADGA,ANkBA,AS3BA,AENA,AGTA,AbuCA,Ac1CA,AHSA,AT2BA,AENA,AGTA,ANkBA,AgBhDA,ALeA,AT2BA,AgBhDA,ACHA,AFMA,AHSA,A3GiUA,A4GpUA,APqBA,AXiCA,AlHsVA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,ACHA,A7BuFA,A8B1FA,A6BvFA,A9F0RA,AbuCA,AwCxHA,A8E1OA,AS3BA,ADGA,ANkBA,AS3BA,AENA,AGTA,AbuCA,Ac1CA,AHSA,AT2BA,AENA,AGTA,ANkBA,AgBhDA,ALeA,AT2BA,AgBhDA,ACHA,AFMA,AHSA,A3GiUA,A4GpUA,APqBA,AXiCA,AlHsVA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,ACHA,A7BuFA,A8B1FA,A6BvFA,A9F0RA,AbuCA,AwCxHA,A8E1OA,AS3BA,ADGA,ANkBA,AS3BA,AENA,AGTA,AbuCA,Ac1CA,AHSA,AT2BA,AENA,AGTA,ANkBA,AgBhDA,ALeA,AT2BA,AgBhDA,ACHA,AFMA,AHSA,A3GiUA,A4GpUA,APqBA,AXiCA,AlHsVA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,ACHA,A7BuFA,A8B1FA,A6BvFA,A9F0RA,AbuCA,AwCxHA,A8E1OA,AS3BA,ADGA,ANkBA,AsBlEA,AbuCA,AENA,AGTA,AbuCA,Ac1CA,AHSA,AT2BA,AENA,AGTA,ANkBA,AgBhDA,ALeA,AT2BA,AgBhDA,ACHA,AFMA,AHSA,A3GiUA,A4GpUA,APqBA,AXiCA,AlHsVA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,ACHA,A7BuFA,A8B1FA,A6BvFA,A9F0RA,AbuCA,AwCxHA,A8E1OA,AS3BA,ADGA,ANkBA,AsBlEA,AbuCA,AENA,AGTA,AbuCA,Ac1CA,AHSA,AT2BA,AENA,AGTA,ANkBA,AgBhDA,ALeA,AT2BA,AgBhDA,ACHA,AFMA,AHSA,A3GiUA,A4GpUA,APqBA,AXiCA,AlHsVA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,ACHA,A7BuFA,A8B1FA,A6BvFA,A9F0RA,AbuCA,AwCxHA,A8E1OA,AS3BA,ADGA,ANkBA,AsBlEA,AbuCA,AENA,AGTA,AbuCA,Ac1CA,AHSA,AT2BA,AENA,AGTA,ANkBA,AgBhDA,ALeA,AT2BA,AgBhDA,ACHA,AFMA,AHSA,A3GiUA,A4GpUA,APqBA,AXiCA,AlHsVA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,ACHA,A7BuFA,A8B1FA,A6BvFA,A9F0RA,AbuCA,AwCxHA,A8E1OA,AS3BA,ADGA,ANkBA,AuBrEA,ADGA,AbuCA,AENA,AGTA,AbuCA,Ac1CA,AHSA,AT2BA,AENA,AGTA,ANkBA,AgBhDA,ALeA,AT2BA,AgBhDA,ACHA,AFMA,AHSA,A3GiUA,A4GpUA,APqBA,AXiCA,AlHsVA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,ACHA,A7BuFA,A8B1FA,A6BvFA,A9F0RA,AbuCA,AwCxHA,A8E1OA,AS3BA,ADGA,ANkBA,AuBrEA,ADGA,AbuCA,AENA,AGTA,AbuCA,Ac1CA,AHSA,AT2BA,AENA,AGTA,ANkBA,AgBhDA,ALeA,AT2BA,AgBhDA,ACHA,AFMA,AHSA,A3GiUA,A4GpUA,APqBA,AXiCA,AlHsVA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,ACHA,A7BuFA,A8B1FA,A6BvFA,A9F0RA,AbuCA,AwCxHA,A8E1OA,AS3BA,ADGA,ANkBA,AuBrEA,ADGA,AbuCA,AENA,AGTA,AbuCA,Ac1CA,AHSA,AT2BA,AENA,AGTA,ANkBA,AgBhDA,ALeA,AT2BA,AgBhDA,ACHA,AFMA,AHSA,A3GiUA,A4GpUA,APqBA,AXiCA,AlHsVA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,ACHA,A7BuFA,A8B1FA,A6BvFA,A9F0RA,AbuCA,AwCxHA,A8E1OA,AS3BA,ADGA,ANkBA,AuBrEA,ADGA,AbuCA,AENA,AGTA,AbuCA,Ac1CA,AHSA,AT2BA,AENA,AGTA,ANkBA,AgBhDA,ALeA,AWjCA,ApB4DA,AgBhDA,ACHA,AFMA,AHSA,A3GiUA,A4GpUA,APqBA,AXiCA,AlHsVA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,ACHA,A7BuFA,A8B1FA,A6BvFA,A9F0RA,AbuCA,AwCxHA,A8E1OA,AS3BA,ADGA,ANkBA,AuBrEA,ADGA,AbuCA,AENA,AGTA,AbuCA,Ac1CA,AHSA,AT2BA,AENA,AGTA,ANkBA,AgBhDA,ALeA,AWjCA,ApB4DA,AgBhDA,ACHA,AFMA,AHSA,A3GiUA,A4GpUA,APqBA,AXiCA,AlHsVA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,ACHA,A7BuFA,A8B1FA,A6BvFA,A9F0RA,AbuCA,AwCxHA,A8E1OA,AS3BA,ADGA,ANkBA,AuBrEA,ADGA,AbuCA,AENA,AGTA,AbuCA,Ac1CA,AHSA,AT2BA,AENA,AGTA,ANkBA,AgBhDA,ALeA,AWjCA,ApB4DA,AgBhDA,ACHA,AFMA,AHSA,A3GiUA,A4GpUA,APqBA,AXiCA,AlHsVA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,ACHA,A7BuFA,A8B1FA,A6BvFA,A9F0RA,AbuCA,AwCxHA,A8E1OA,AS3BA,ADGA,ANkBA,AuBrEA,ADGA,AbuCA,AgBhDA,Ad0CA,AGTA,AbuCA,Ac1CA,AHSA,AT2BA,AENA,AGTA,ANkBA,AgBhDA,ALeA,AWjCA,ApB4DA,AgBhDA,ACHA,AFMA,AHSA,A3GiUA,A4GpUA,APqBA,AXiCA,AlHsVA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,ACHA,A7BuFA,A8B1FA,A6BvFA,A9F0RA,AbuCA,AwCxHA,A8E1OA,AS3BA,ADGA,ANkBA,AuBrEA,ADGA,AbuCA,AgBhDA,Ad0CA,AGTA,AbuCA,Ac1CA,AHSA,AT2BA,AENA,AGTA,ANkBA,AgBhDA,ALeA,AWjCA,ApB4DA,AgBhDA,ACHA,AFMA,AHSA,A3GiUA,A4GpUA,APqBA,AXiCA,AlHsVA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,ACHA,A7BuFA,A8B1FA,A6BvFA,A9F0RA,AbuCA,AwCxHA,A8E1OA,AS3BA,ADGA,ANkBA,AuBrEA,ADGA,AbuCA,AgBhDA,Ad0CA,AGTA,AbuCA,Ac1CA,AHSA,AT2BA,AENA,AGTA,ANkBA,AgBhDA,ALeA,AWjCA,ApB4DA,AgBhDA,ACHA,AFMA,AHSA,A3GiUA,A4GpUA,APqBA,AXiCA,AlHsVA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,ACHA,A7BuFA,A8B1FA,A6BvFA,A9F0RA,AbuCA,AwCxHA,A8E1OA,AS3BA,ADGA,ANkBA,AuBrEA,ADGA,AIZA,AjBmDA,AgBhDA,Ad0CA,AGTA,AbuCA,Ac1CA,AHSA,AT2BA,AENA,AGTA,ANkBA,AgBhDA,ALeA,AWjCA,ApB4DA,AgBhDA,ACHA,AFMA,AHSA,A3GiUA,A4GpUA,APqBA,AXiCA,AlHsVA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,ACHA,A7BuFA,A8B1FA,A6BvFA,A9F0RA,AbuCA,AwCxHA,A8E1OA,AS3BA,ADGA,ANkBA,AuBrEA,ADGA,AIZA,AjBmDA,AgBhDA,Ad0CA,AGTA,AbuCA,Ac1CA,AHSA,AT2BA,AENA,AGTA,ANkBA,AgBhDA,ALeA,AWjCA,ApB4DA,AgBhDA,ACHA,AFMA,AHSA,A3GiUA,A4GpUA,APqBA,AXiCA,AlHsVA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,ACHA,A7BuFA,A8B1FA,A6BvFA,A9F0RA,AbuCA,AwCxHA,A8E1OA,AS3BA,ADGA,ANkBA,AuBrEA,ADGA,AIZA,AjBmDA,AgBhDA,Ad0CA,AGTA,AbuCA,Ac1CA,AHSA,AT2BA,AENA,AGTA,ANkBA,AgBhDA,ALeA,AWjCA,ApB4DA,AgBhDA,ACHA,AFMA,AHSA,A3GiUA,A4GpUA,APqBA,AXiCA,AlHsVA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,ACHA,A7BuFA,A8B1FA,A6BvFA,A9F0RA,AbuCA,AwCxHA,A8E1OA,AS3BA,ADGA,ANkBA,AuBrEA,ADGA,AKfA,ADGA,AjBmDA,AgBhDA,Ad0CA,AGTA,AbuCA,Ac1CA,AHSA,AT2BA,AENA,AGTA,ANkBA,AgBhDA,ALeA,AWjCA,ApB4DA,AgBhDA,ACHA,AFMA,AHSA,A3GiUA,A4GpUA,APqBA,AXiCA,AlHsVA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,ACHA,A7BuFA,A8B1FA,A6BvFA,A9F0RA,AbuCA,AwCxHA,A8E1OA,AS3BA,ADGA,ANkBA,AuBrEA,ADGA,AKfA,ADGA,AjBmDA,AgBhDA,Ad0CA,AGTA,AbuCA,Ac1CA,AHSA,AT2BA,AENA,AGTA,ANkBA,AgBhDA,ALeA,AWjCA,ApB4DA,AgBhDA,ACHA,AFMA,AHSA,A3GiUA,A4GpUA,APqBA,AXiCA,AlHsVA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,ACHA,A7BuFA,A8B1FA,A6BvFA,A9F0RA,AbuCA,AwCxHA,A8E1OA,AS3BA,ADGA,ANkBA,AuBrEA,ADGA,AKfA,ADGA,AjBmDA,AgBhDA,Ad0CA,AGTA,AbuCA,Ac1CA,AHSA,AT2BA,AENA,AGTA,ANkBA,AgBhDA,ALeA,AWjCA,ApB4DA,AgBhDA,ACHA,AFMA,AHSA,A3GiUA,A4GpUA,APqBA,AXiCA,AlHsVA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,ACHA,A7BuFA,A8B1FA,A6BvFA,A9F0RA,AbuCA,AwCxHA,A8E1OA,AS3BA,ADGA,ANkBA,AuBrEA,AKfA,ANkBA,AKfA,ADGA,AjBmDA,AgBhDA,Ad0CA,AGTA,AbuCA,Ac1CA,AHSA,AT2BA,AENA,AGTA,ANkBA,AgBhDA,ALeA,AWjCA,ApB4DA,AgBhDA,ACHA,AFMA,AHSA,A3GiUA,A4GpUA,APqBA,AXiCA,AlHsVA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,ACHA,A7BuFA,A8B1FA,A6BvFA,A9F0RA,AbuCA,AwCxHA,A8E1OA,AS3BA,ADGA,ANkBA,AuBrEA,AKfA,ANkBA,AKfA,ADGA,AjBmDA,AgBhDA,Ad0CA,AGTA,AbuCA,Ac1CA,AHSA,AT2BA,AENA,AGTA,ANkBA,AgBhDA,ALeA,AWjCA,ApB4DA,AgBhDA,ACHA,AFMA,AHSA,A3GiUA,A4GpUA,APqBA,AXiCA,AlHsVA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,ACHA,A7BuFA,A8B1FA,A6BvFA,A9F0RA,AbuCA,AwCxHA,A8E1OA,AS3BA,ADGA,ANkBA,AuBrEA,AKfA,ANkBA,AKfA,ADGA,AjBmDA,AgBhDA,Ad0CA,AGTA,AbuCA,Ac1CA,AHSA,AT2BA,AENA,AGTA,ANkBA,AgBhDA,ALeA,AWjCA,ApB4DA,AgBhDA,ACHA,AFMA,AHSA,A3GiUA,A4GpUA,APqBA,AXiCA,AlHsVA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,ACHA,A7BuFA,A8B1FA,A6BvFA,A9F0RA,AbuCA,AwCxHA,A8E1OA,AS3BA,ADGA,ANkBA,AuBrEA,AKfA,ANkBA,AKfA,ADGA,AjBmDA,AgBhDA,Ad0CA,AGTA,AbuCA,Ac1CA,AHSA,AT2BA,AENA,AGTA,ANkBA,AgBhDA,ALeA,AWjCA,ApB4DA,AgBhDA,ACHA,AFMA,AHSA,A3GiUA,A4GpUA,APqBA,AXiCA,A8B1FA,AhJgbA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,ACHA,A7BuFA,A8B1FA,A6BvFA,A9F0RA,AbuCA,AwCxHA,A8E1OA,AS3BA,ADGA,ANkBA,AuBrEA,AKfA,ANkBA,AKfA,ADGA,AjBmDA,AgBhDA,Ad0CA,AGTA,AbuCA,Ac1CA,AHSA,AT2BA,AENA,AGTA,ANkBA,AgBhDA,ALeA,AWjCA,ApB4DA,AgBhDA,ACHA,AFMA,AHSA,A3GiUA,A4GpUA,APqBA,AXiCA,A8B1FA,AhJgbA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,ACHA,A7BuFA,A8B1FA,A6BvFA,A9F0RA,AbuCA,AwCxHA,A8E1OA,AS3BA,ADGA,ANkBA,AuBrEA,AKfA,ANkBA,AKfA,ADGA,AjBmDA,AgBhDA,Ad0CA,AGTA,AbuCA,Ac1CA,AHSA,AT2BA,AENA,AGTA,ANkBA,AgBhDA,ALeA,AWjCA,ApB4DA,AgBhDA,ACHA,AFMA,AHSA,A3GiUA,A4GpUA,APqBA,AXiCA,A8B1FA,AhJgbA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,ACHA,A7BuFA,A8B1FA,A6BvFA,A9F0RA,AbuCA,AwCxHA,A8E1OA,AS3BA,ADGA,ANkBA,AuBrEA,AKfA,ANkBA,AKfA,ADGA,AjBmDA,AgBhDA,Ad0CA,AGTA,AbuCA,Ac1CA,AHSA,AT2BA,AENA,AGTA,ANkBA,AgBhDA,ALeA,AWjCA,ApB4DA,AgBhDA,ACHA,AFMA,AHSA,A3GiUA,A4GpUA,APqBA,AXiCA,A8B1FA,ACHA,AjJmbA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,ACHA,A7BuFA,A8B1FA,A6BvFA,A9F0RA,AbuCA,AwCxHA,A8E1OA,AS3BA,ADGA,ANkBA,AuBrEA,AKfA,ANkBA,AKfA,ADGA,AjBmDA,AgBhDA,Ad0CA,AGTA,AbuCA,Ac1CA,AHSA,AT2BA,AENA,AGTA,ANkBA,AgBhDA,ALeA,AWjCA,ApB4DA,AgBhDA,ACHA,AFMA,AHSA,A3GiUA,A4GpUA,APqBA,AXiCA,A8B1FA,ACHA,AjJmbA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,ACHA,A7BuFA,A8B1FA,A6BvFA,A9F0RA,AbuCA,AwCxHA,A8E1OA,AS3BA,ADGA,ANkBA,AuBrEA,AKfA,ANkBA,AKfA,ADGA,AjBmDA,AgBhDA,Ad0CA,AGTA,AbuCA,Ac1CA,AHSA,AT2BA,AENA,AGTA,ANkBA,AgBhDA,ALeA,AWjCA,ApB4DA,AgBhDA,ACHA,AFMA,AHSA,A3GiUA,A4GpUA,APqBA,AXiCA,A8B1FA,ACHA,AjJmbA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,ACHA,A7BuFA,A8B1FA,A6BvFA,A9F0RA,AbuCA,AuJrcA,A/G6UA,A8E1OA,AS3BA,ADGA,ANkBA,AuBrEA,AKfA,ANkBA,AKfA,ADGA,AjBmDA,AgBhDA,Ad0CA,AGTA,AbuCA,Ac1CA,AHSA,AT2BA,AENA,AGTA,ANkBA,AgBhDA,ALeA,AWjCA,ApB4DA,AgBhDA,ACHA,AFMA,AHSA,A3GiUA,A4GpUA,AlBsDA,A8B1FA,ACHA,AjJmbA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,ACHA,A7BuFA,A8B1FA,A6BvFA,A9F0RA,AbuCA,AuJrcA,A/G6UA,A8E1OA,AS3BA,ADGA,ANkBA,AuBrEA,AKfA,ANkBA,AKfA,ADGA,AjBmDA,AgBhDA,Ad0CA,AGTA,AbuCA,Ac1CA,AHSA,AT2BA,AENA,AGTA,ANkBA,AgBhDA,ALeA,AWjCA,ApB4DA,AgBhDA,ACHA,AFMA,AHSA,A3GiUA,A4GpUA,AlBsDA,A8B1FA,ACHA,AjJmbA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,ACHA,A7BuFA,A8B1FA,A6BvFA,A9F0RA,AbuCA,AuJrcA,A/G6UA,A8E1OA,AS3BA,ADGA,ANkBA,AuBrEA,AKfA,ANkBA,AKfA,ADGA,AjBmDA,AgBhDA,Ad0CA,AGTA,AbuCA,Ac1CA,AHSA,AT2BA,AENA,AGTA,ANkBA,AgBhDA,ALeA,AWjCA,ApB4DA,AgBhDA,ACHA,AFMA,AHSA,A3GiUA,A4GpUA,AlBsDA,A8B1FA,ACHA,AjJmbA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,ACHA,A7BuFA,A8B1FA,A6BvFA,A9F0RA,AbuCA,AwJxcA,ADGA,A/G6UA,A8E1OA,AS3BA,ADGA,ANkBA,AuBrEA,AKfA,ANkBA,AKfA,ADGA,AjBmDA,AgBhDA,Ad0CA,AGTA,AbuCA,Ac1CA,AHSA,AT2BA,AENA,AGTA,ANkBA,AgBhDA,ALeA,AWjCA,ApB4DA,AgBhDA,ACHA,AFMA,AHSA,A3GiUA,A4GpUA,AlBsDA,A8B1FA,ACHA,AjJmbA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,ACHA,A7BuFA,A8B1FA,A6BvFA,A9F0RA,AbuCA,AwJxcA,ADGA,A/G6UA,A8E1OA,AS3BA,ADGA,ANkBA,AuBrEA,AKfA,ANkBA,AKfA,ADGA,AjBmDA,AgBhDA,Ad0CA,AGTA,AbuCA,Ac1CA,AHSA,AT2BA,AENA,AGTA,ANkBA,AgBhDA,ALeA,AWjCA,ApB4DA,AgBhDA,ACHA,AFMA,AHSA,A3GiUA,A4GpUA,AlBsDA,A8B1FA,ACHA,AjJmbA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,ACHA,A7BuFA,A8B1FA,A6BvFA,A9F0RA,AbuCA,AwJxcA,ADGA,A/G6UA,A8E1OA,AS3BA,ADGA,ANkBA,AuBrEA,AKfA,ANkBA,AKfA,ADGA,AjBmDA,AgBhDA,Ad0CA,AGTA,AbuCA,Ac1CA,AHSA,AT2BA,AENA,AGTA,ANkBA,AgBhDA,ALeA,AWjCA,ApB4DA,AgBhDA,ACHA,AFMA,AHSA,A3GiUA,A4GpUA,AlBsDA,A8B1FA,ACHA,AjJmbA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,ACHA,A7BuFA,A8B1FA,A6BvFA,A9F0RA,AbuCA,AwJxcA,ADGA,AENA,AjHmVA,A8E1OA,AS3BA,ADGA,ANkBA,AuBrEA,AKfA,ANkBA,AKfA,ADGA,AjBmDA,AgBhDA,Ad0CA,AGTA,AbuCA,Ac1CA,AHSA,AT2BA,AENA,AGTA,ANkBA,AgBhDA,ALeA,AWjCA,ApB4DA,AgBhDA,ACHA,AFMA,AHSA,A3GiUA,A4GpUA,AlBsDA,A8B1FA,ACHA,AjJmbA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,ACHA,A7BuFA,A8B1FA,A6BvFA,A9F0RA,AbuCA,AwJxcA,ADGA,AENA,AjHmVA,A8E1OA,AS3BA,ADGA,ANkBA,AuBrEA,AKfA,ANkBA,AKfA,ADGA,AjBmDA,AgBhDA,Ad0CA,AGTA,AbuCA,Ac1CA,AHSA,AT2BA,AENA,AGTA,ANkBA,AgBhDA,ALeA,AWjCA,ApB4DA,AgBhDA,ACHA,AFMA,AHSA,A3GiUA,A4GpUA,AlBsDA,A8B1FA,ACHA,AjJmbA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,ACHA,A7BuFA,A8B1FA,A6BvFA,A9F0RA,AbuCA,AwJxcA,ADGA,AENA,AjHmVA,A8E1OA,AS3BA,ADGA,ANkBA,AuBrEA,AKfA,ANkBA,AKfA,ADGA,AjBmDA,AgBhDA,Ad0CA,AGTA,AbuCA,Ac1CA,AHSA,AT2BA,AENA,AGTA,ANkBA,AgBhDA,ALeA,AWjCA,ApB4DA,AgBhDA,ACHA,AFMA,AHSA,A3GiUA,A4GpUA,AlBsDA,A8B1FA,ACHA,AjJmbA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,ACHA,A7BuFA,A8B1FA,A6BvFA,A9F0RA,AbuCA,AwJxcA,ADGA,AENA,ACHA,AlHsVA,A8E1OA,AS3BA,ADGA,ANkBA,AuBrEA,AKfA,ANkBA,AKfA,ADGA,AjBmDA,AgBhDA,Ad0CA,AGTA,AbuCA,Ac1CA,AHSA,AT2BA,AENA,AGTA,ANkBA,AWjCA,AWjCA,ApB4DA,AgBhDA,ACHA,AFMA,AHSA,A3GiUA,A4GpUA,AlBsDA,A8B1FA,ACHA,AjJmbA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,ACHA,A7BuFA,A8B1FA,A6BvFA,A9F0RA,AbuCA,AwJxcA,ADGA,AENA,ACHA,AlHsVA,A8E1OA,AS3BA,ADGA,ANkBA,AuBrEA,AKfA,ANkBA,AKfA,ADGA,AjBmDA,AgBhDA,Ad0CA,AGTA,AbuCA,Ac1CA,AHSA,AT2BA,AENA,AGTA,ANkBA,AWjCA,AWjCA,ApB4DA,AgBhDA,ACHA,AFMA,AHSA,A3GiUA,A4GpUA,AlBsDA,A8B1FA,ACHA,AjJmbA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,ACHA,A7BuFA,A8B1FA,A6BvFA,A9F0RA,AbuCA,AwJxcA,ADGA,AENA,ACHA,AlHsVA,A8E1OA,AS3BA,ADGA,ANkBA,AuBrEA,AKfA,ANkBA,AKfA,ADGA,AjBmDA,AgBhDA,AXiCA,AbuCA,Ac1CA,AHSA,AT2BA,AENA,AGTA,ANkBA,AWjCA,AWjCA,ApB4DA,AgBhDA,ACHA,AFMA,AHSA,A3GiUA,A4GpUA,AlBsDA,A8B1FA,ACHA,AjJmbA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,ACHA,A7BuFA,A8B1FA,A6BvFA,A9F0RA,AbuCA,AwJxcA,ADGA,AENA,AENA,ADGA,AlHsVA,A8E1OA,AS3BA,ADGA,ANkBA,AuBrEA,AKfA,ANkBA,AKfA,ADGA,AjBmDA,AgBhDA,AXiCA,AbuCA,Ac1CA,AHSA,AT2BA,AENA,AGTA,ANkBA,AWjCA,AWjCA,ApB4DA,AgBhDA,ADGA,AHSA,A3GiUA,A4GpUA,AlBsDA,A8B1FA,ACHA,AjJmbA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,ACHA,A7BuFA,A8B1FA,A6BvFA,A9F0RA,AbuCA,AwJxcA,ADGA,AENA,AENA,ADGA,AlHsVA,A8E1OA,AS3BA,ADGA,ANkBA,AuBrEA,AKfA,ANkBA,AKfA,ADGA,AjBmDA,AgBhDA,AXiCA,AbuCA,Ac1CA,AHSA,AT2BA,AENA,AGTA,ANkBA,AWjCA,AWjCA,ApB4DA,AgBhDA,ADGA,AHSA,A3GiUA,A4GpUA,AlBsDA,A8B1FA,ACHA,AjJmbA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,ACHA,A7BuFA,A8B1FA,A6BvFA,A9F0RA,AbuCA,AwJxcA,ADGA,AENA,AENA,ADGA,AlHsVA,A8E1OA,AS3BA,ADGA,ANkBA,AuBrEA,AKfA,ANkBA,AKfA,ADGA,AjBmDA,AgBhDA,AXiCA,AbuCA,Ac1CA,AHSA,AT2BA,AENA,AGTA,ANkBA,AWjCA,AWjCA,ApB4DA,AgBhDA,ADGA,AHSA,A3GiUA,A4GpUA,AlBsDA,A8B1FA,ACHA,AjJmbA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,ACHA,A7BuFA,A8B1FA,A6BvFA,A9F0RA,AbuCA,AwJxcA,ADGA,AENA,AENA,ACHA,AFMA,AlHsVA,A8E1OA,AS3BA,ADGA,ANkBA,AuBrEA,AKfA,ANkBA,AKfA,ADGA,AjBmDA,AgBhDA,AXiCA,AbuCA,Ac1CA,AHSA,AT2BA,AENA,AGTA,ANkBA,AWjCA,AWjCA,ApB4DA,AgBhDA,ADGA,AHSA,A3GiUA,A4GpUA,AlBsDA,A8B1FA,ACHA,AjJmbA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,ACHA,A7BuFA,A8B1FA,A6BvFA,A9F0RA,AbuCA,AwJxcA,ADGA,AENA,AENA,ACHA,AFMA,AlHsVA,A8E1OA,AS3BA,ADGA,ANkBA,AuBrEA,AKfA,ANkBA,AKfA,ADGA,AjBmDA,AgBhDA,AXiCA,AbuCA,Ac1CA,AHSA,AT2BA,AENA,AGTA,ANkBA,AWjCA,AWjCA,ApB4DA,AgBhDA,ADGA,AHSA,A3GiUA,A4GpUA,AlBsDA,A8B1FA,ACHA,AjJmbA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,ACHA,A7BuFA,A8B1FA,A6BvFA,A9F0RA,AbuCA,AwJxcA,ADGA,AENA,AENA,ACHA,AFMA,AlHsVA,A8E1OA,AS3BA,ADGA,ANkBA,AuBrEA,AKfA,ANkBA,AKfA,ADGA,AjBmDA,AgBhDA,AXiCA,AbuCA,Ac1CA,AHSA,AT2BA,AENA,AGTA,ANkBA,AWjCA,AWjCA,ApB4DA,AgBhDA,ADGA,AHSA,A3GiUA,A4GpUA,AlBsDA,A8B1FA,ACHA,AjJmbA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,ACHA,A7BuFA,A8B1FA,A6BvFA,A9F0RA,AbuCA,AwJxcA,ADGA,AENA,AIZA,AFMA,ACHA,AFMA,AlHsVA,A8E1OA,AS3BA,ADGA,ANkBA,AuBrEA,AKfA,ANkBA,AKfA,ADGA,AjBmDA,AgBhDA,AXiCA,AbuCA,Ac1CA,AHSA,AT2BA,AENA,AGTA,ANkBA,AWjCA,AWjCA,ApB4DA,AgBhDA,ADGA,AHSA,A3GiUA,A4GpUA,AlBsDA,A8B1FA,ACHA,AjJmbA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,ACHA,A7BuFA,A8B1FA,A6BvFA,A9F0RA,AbuCA,AwJxcA,ADGA,AENA,AIZA,AFMA,ACHA,AFMA,AlHsVA,A8E1OA,AS3BA,ADGA,ANkBA,AuBrEA,AKfA,ANkBA,AKfA,ADGA,AjBmDA,AgBhDA,AXiCA,AbuCA,Ac1CA,AHSA,AT2BA,AENA,AGTA,ANkBA,AWjCA,AWjCA,ApB4DA,AgBhDA,ADGA,AHSA,A3GiUA,A0F9QA,A8B1FA,ACHA,AjJmbA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,ACHA,A7BuFA,A8B1FA,A6BvFA,A9F0RA,AbuCA,AwJxcA,ADGA,AENA,AIZA,AFMA,ACHA,AFMA,AlHsVA,A8E1OA,AS3BA,ADGA,ANkBA,AuBrEA,AKfA,ANkBA,AKfA,ADGA,AjBmDA,AgBhDA,AXiCA,AbuCA,Ac1CA,AHSA,AT2BA,AENA,AGTA,ANkBA,AWjCA,AWjCA,ApB4DA,AgBhDA,ADGA,AHSA,A3GiUA,A0F9QA,A8B1FA,ACHA,AjJmbA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,ACHA,A7BuFA,A8B1FA,A6BvFA,A9F0RA,AbuCA,A8J1dA,ANkBA,ADGA,AENA,AIZA,AFMA,ACHA,AFMA,AlHsVA,A8E1OA,AS3BA,ADGA,ANkBA,AuBrEA,AKfA,ANkBA,AKfA,ADGA,AjBmDA,AgBhDA,AXiCA,AbuCA,Ac1CA,AHSA,AT2BA,AENA,AGTA,ANkBA,AWjCA,AWjCA,ApB4DA,AgBhDA,ADGA,AHSA,A3GiUA,A0F9QA,A8B1FA,ACHA,AjJmbA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,ACHA,A7BuFA,A8B1FA,A6BvFA,A9F0RA,AbuCA,A8J1dA,ANkBA,ADGA,AENA,AIZA,AFMA,ACHA,AFMA,AlHsVA,A8E1OA,AS3BA,ADGA,ANkBA,AuBrEA,AKfA,ANkBA,AKfA,ADGA,AjBmDA,AgBhDA,AXiCA,AbuCA,AWjCA,AT2BA,AENA,AGTA,ANkBA,AWjCA,AWjCA,ApB4DA,AgBhDA,ADGA,AHSA,A3GiUA,A0F9QA,A8B1FA,ACHA,AjJmbA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,ACHA,A7BuFA,A8B1FA,AjEmMA,AbuCA,A8J1dA,ANkBA,ADGA,AENA,AIZA,AFMA,ACHA,AFMA,AlHsVA,A8E1OA,AS3BA,ADGA,ANkBA,AuBrEA,AKfA,ANkBA,AKfA,ADGA,AjBmDA,AgBhDA,AXiCA,AbuCA,AWjCA,AT2BA,AENA,AGTA,ANkBA,AWjCA,AWjCA,ApB4DA,AgBhDA,ADGA,AHSA,A3GiUA,A0F9QA,A8B1FA,ACHA,AjJmbA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,ACHA,A7BuFA,A8B1FA,AjEmMA,AbuCA,A8J1dA,ACHA,APqBA,ADGA,AENA,AIZA,AFMA,ACHA,AFMA,AlHsVA,A8E1OA,AS3BA,ADGA,ANkBA,AuBrEA,AKfA,ANkBA,AKfA,ADGA,AjBmDA,AgBhDA,AXiCA,AbuCA,AWjCA,AT2BA,AENA,AGTA,ANkBA,AWjCA,AWjCA,ApB4DA,AgBhDA,ADGA,AHSA,A3GiUA,A0F9QA,A8B1FA,ACHA,AjJmbA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,ACHA,A7BuFA,A8B1FA,AjEmMA,AbuCA,A8J1dA,ACHA,APqBA,ADGA,AENA,AIZA,AFMA,ACHA,AFMA,AlHsVA,A8E1OA,AS3BA,ADGA,ANkBA,AuBrEA,AKfA,ANkBA,AKfA,ADGA,AjBmDA,AgBhDA,AXiCA,AbuCA,AWjCA,AT2BA,AENA,AGTA,ANkBA,AWjCA,AWjCA,ApB4DA,AgBhDA,ADGA,AHSA,A3GiUA,A0F9QA,A8B1FA,ACHA,AjJmbA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,ACHA,A7BuFA,A8B1FA,AjEmMA,AbuCA,A8J1dA,ACHA,APqBA,ADGA,AENA,AIZA,AFMA,ACHA,AFMA,AlHsVA,A8E1OA,AS3BA,ADGA,ANkBA,AuBrEA,AKfA,ANkBA,AKfA,ADGA,AjBmDA,AgBhDA,AXiCA,AbuCA,AWjCA,AT2BA,AENA,AGTA,ANkBA,AWjCA,AWjCA,ApB4DA,AgBhDA,ADGA,AHSA,A3GiUA,A0F9QA,A+B7FA,AjJmbA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,ACHA,A7BuFA,A8B1FA,AjEmMA,AbuCA,A8J1dA,ACHA,APqBA,ADGA,AENA,AIZA,AFMA,ACHA,AFMA,AMlBA,AxHwWA,A8E1OA,AS3BA,ADGA,ANkBA,A4BpFA,ANkBA,AKfA,ADGA,AjBmDA,AgBhDA,AXiCA,AbuCA,AWjCA,AT2BA,AENA,AGTA,ANkBA,AWjCA,AWjCA,ApB4DA,AgBhDA,ADGA,AHSA,A3GiUA,A0F9QA,A+B7FA,AjJmbA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,ACHA,A7BuFA,AnCyGA,AbuCA,A8J1dA,ACHA,APqBA,ADGA,AENA,AIZA,AFMA,ACHA,AFMA,AMlBA,AxHwWA,A8E1OA,AS3BA,ADGA,ANkBA,A4BpFA,ANkBA,AKfA,ADGA,AjBmDA,AgBhDA,AXiCA,AbuCA,AWjCA,AT2BA,AENA,AGTA,ANkBA,AWjCA,AWjCA,ApB4DA,AgBhDA,ADGA,AHSA,A3GiUA,A0F9QA,A+B7FA,AjJmbA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,ACHA,A7BuFA,AnCyGA,AbuCA,A8J1dA,ACHA,APqBA,ADGA,AENA,AIZA,AFMA,ACHA,AFMA,AMlBA,AxHwWA,A8E1OA,AS3BA,ADGA,ANkBA,A4BpFA,ANkBA,AKfA,ADGA,AjBmDA,AgBhDA,AXiCA,AbuCA,AWjCA,AT2BA,AENA,AGTA,AKfA,AWjCA,ApB4DA,AgBhDA,ADGA,AHSA,A3GiUA,A0F9QA,A+B7FA,AjJmbA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,ACHA,A7BuFA,AnCyGA,AbuCA,A8J1dA,ACHA,APqBA,ADGA,AENA,AIZA,AFMA,AMlBA,ALeA,AFMA,AMlBA,AxHwWA,A8E1OA,AS3BA,ADGA,ANkBA,A4BpFA,ANkBA,AKfA,ADGA,AjBmDA,AgBhDA,AXiCA,AbuCA,AWjCA,AT2BA,AENA,AGTA,AKfA,AWjCA,ApB4DA,AgBhDA,ADGA,AHSA,A3GiUA,A0F9QA,A+B7FA,AjJmbA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,ACHA,A7BuFA,AnCyGA,AbuCA,A8J1dA,ACHA,APqBA,ADGA,AENA,AIZA,AFMA,AMlBA,ALeA,AFMA,AMlBA,AxHwWA,A8E1OA,AS3BA,ADGA,ANkBA,A4BpFA,ANkBA,AKfA,ADGA,AjBmDA,AgBhDA,AXiCA,AbuCA,AWjCA,AT2BA,AENA,AGTA,AKfA,AWjCA,ApB4DA,AgBhDA,ADGA,AHSA,A3GiUA,A0F9QA,A+B7FA,AjJmbA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,ACHA,A7BuFA,AnCyGA,AbuCA,A8J1dA,ACHA,APqBA,ADGA,AENA,AIZA,AFMA,AMlBA,ALeA,AFMA,AMlBA,AxHwWA,A8E1OA,AS3BA,ADGA,ANkBA,A4BpFA,ANkBA,AKfA,ADGA,AjBmDA,AgBhDA,AXiCA,AbuCA,AWjCA,AT2BA,AENA,AGTA,AKfA,AWjCA,ApB4DA,AgBhDA,ADGA,AHSA,A3GiUA,A0F9QA,A+B7FA,AjJmbA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,ACHA,A7BuFA,AnCyGA,AbuCA,A8J1dA,ACHA,APqBA,ADGA,AENA,AIZA,AFMA,AOrBA,ADGA,ALeA,AFMA,AMlBA,AxHwWA,A8E1OA,AS3BA,ADGA,ANkBA,A4BpFA,ANkBA,AKfA,ADGA,AjBmDA,AgBhDA,AXiCA,AbuCA,AWjCA,AT2BA,AENA,AGTA,AKfA,AWjCA,ApB4DA,AgBhDA,ADGA,A9G0UA,A0F9QA,A+B7FA,AjJmbA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,ACHA,A7BuFA,AnCyGA,AbuCA,A8J1dA,ACHA,APqBA,ADGA,AENA,AIZA,AFMA,AOrBA,ADGA,ALeA,AFMA,AMlBA,AxHwWA,A8E1OA,AS3BA,ADGA,ANkBA,A4BpFA,ANkBA,AKfA,ADGA,AjBmDA,AgBhDA,AXiCA,AbuCA,AWjCA,AT2BA,AENA,AGTA,AKfA,AWjCA,ApB4DA,AgBhDA,ADGA,A9G0UA,A0F9QA,A+B7FA,AjJmbA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,ACHA,A7BuFA,AnCyGA,AbuCA,A8J1dA,ACHA,APqBA,ADGA,AENA,AIZA,AFMA,AOrBA,ADGA,ALeA,AFMA,AMlBA,AxHwWA,A8E1OA,AS3BA,ADGA,ANkBA,A4BpFA,ANkBA,AKfA,ADGA,AjBmDA,AgBhDA,AXiCA,AbuCA,AWjCA,AT2BA,AENA,AGTA,AKfA,AWjCA,ApB4DA,AgBhDA,ADGA,A9G0UA,A0F9QA,A+B7FA,AjJmbA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,ACHA,A7BuFA,AnCyGA,AbuCA,A8J1dA,ACHA,APqBA,ADGA,AENA,AIZA,AFMA,AOrBA,ADGA,ALeA,AFMA,AMlBA,AGTA,A3HiXA,A8E1OA,AS3BA,ADGA,ANkBA,A4BpFA,ANkBA,AKfA,ADGA,AjBmDA,AgBhDA,AXiCA,AbuCA,AWjCA,AT2BA,AENA,AGTA,AKfA,AWjCA,ApB4DA,Ae7CA,A9G0UA,A0F9QA,A+B7FA,AjJmbA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,ACHA,A7BuFA,AnCyGA,AbuCA,A8J1dA,ACHA,APqBA,ADGA,AENA,AIZA,AFMA,AOrBA,ADGA,ALeA,AFMA,AMlBA,AGTA,A3HiXA,A8E1OA,AS3BA,ADGA,ANkBA,A4BpFA,ANkBA,AKfA,ADGA,AjBmDA,AgBhDA,AXiCA,AbuCA,AWjCA,AT2BA,AENA,AGTA,AKfA,AWjCA,ApB4DA,Ae7CA,A9G0UA,A0F9QA,A+B7FA,AjJmbA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,A5BoFA,AnCyGA,AbuCA,A8J1dA,ACHA,APqBA,ADGA,AENA,AIZA,AFMA,AOrBA,ADGA,ALeA,AFMA,AMlBA,AGTA,A3HiXA,A8E1OA,AS3BA,ADGA,ANkBA,A4BpFA,ADGA,ADGA,AjBmDA,AgBhDA,AXiCA,AbuCA,AWjCA,AT2BA,AENA,AGTA,AKfA,AWjCA,ApB4DA,Ae7CA,A9G0UA,A0F9QA,A+B7FA,AjJmbA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,A5BoFA,AnCyGA,AbuCA,A8J1dA,ACHA,APqBA,ADGA,AENA,AIZA,AFMA,AOrBA,ADGA,ALeA,AIZA,AGTA,A3HiXA,A8E1OA,AS3BA,ADGA,AsClHA,A5CoIA,A4BpFA,ADGA,ADGA,AjBmDA,AgBhDA,AXiCA,AbuCA,AWjCA,AT2BA,AENA,AGTA,AKfA,AWjCA,ApB4DA,Ae7CA,A9G0UA,A0F9QA,A+B7FA,AjJmbA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,A5BoFA,AnCyGA,AbuCA,A8J1dA,ACHA,APqBA,ADGA,AENA,AIZA,AFMA,AOrBA,ADGA,ALeA,AIZA,AGTA,A3HiXA,A8E1OA,AS3BA,ADGA,AsClHA,A5CoIA,A4BpFA,ADGA,ADGA,AjBmDA,AgBhDA,AXiCA,AbuCA,AWjCA,AT2BA,AENA,AGTA,AKfA,AWjCA,ApB4DA,Ae7CA,A9G0UA,A0F9QA,AlHsVA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,A5BoFA,AnCyGA,AbuCA,A8J1dA,ACHA,APqBA,ADGA,AENA,AIZA,AFMA,AOrBA,ADGA,ALeA,AIZA,AGTA,A3HiXA,A8E1OA,AS3BA,ADGA,AsClHA,A5CoIA,A4BpFA,ADGA,ADGA,AjBmDA,AgBhDA,AXiCA,AbuCA,AWjCA,AT2BA,AENA,AGTA,AKfA,AWjCA,ApB4DA,Ae7CA,A9G0UA,A0F9QA,AlHsVA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,A5BoFA,AnCyGA,AbuCA,A8J1dA,ACHA,APqBA,ADGA,AENA,AIZA,AFMA,AOrBA,ADGA,ALeA,AIZA,AGTA,A3HiXA,A8E1OA,AS3BA,AsClHA,AvCqHA,AsClHA,A5CoIA,A4BpFA,ADGA,ADGA,AjBmDA,AgBhDA,AXiCA,AbuCA,AWjCA,AT2BA,AENA,AGTA,AKfA,AWjCA,ApB4DA,Ae7CA,A9G0UA,A0F9QA,AlHsVA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,A5BoFA,AnCyGA,AbuCA,A8J1dA,ACHA,APqBA,ADGA,AENA,AIZA,AFMA,AOrBA,ADGA,ALeA,AIZA,AGTA,A3HiXA,A8E1OA,AS3BA,AsClHA,AvCqHA,AsClHA,A5CoIA,A4BpFA,ADGA,ADGA,AjBmDA,AgBhDA,AXiCA,AbuCA,AWjCA,AT2BA,AENA,AGTA,AKfA,AWjCA,ApB4DA,Ae7CA,A9G0UA,A0F9QA,AlHsVA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,A5BoFA,AnCyGA,AbuCA,A8J1dA,ACHA,APqBA,ADGA,AENA,AIZA,AFMA,AOrBA,ADGA,ALeA,AIZA,AGTA,A3HiXA,A8E1OA,AS3BA,AsClHA,AvCqHA,AsClHA,A5CoIA,A4BpFA,ADGA,ADGA,AjBmDA,AgBhDA,AxBwEA,AWjCA,AT2BA,AENA,AGTA,AKfA,AWjCA,ApB4DA,Ae7CA,A9G0UA,A0F9QA,AlHsVA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,A5BoFA,AnCyGA,AbuCA,A8J1dA,ACHA,APqBA,ADGA,AENA,AIZA,AFMA,AOrBA,ADGA,ALeA,AIZA,AGTA,A3HiXA,A8E1OA,AS3BA,AsClHA,AvCqHA,AsClHA,A5CoIA,A4BpFA,ADGA,ADGA,AjBmDA,AgBhDA,AxBwEA,AWjCA,AT2BA,AENA,AGTA,AKfA,AWjCA,ApB4DA,Ae7CA,A9G0UA,A0F9QA,A+C7IA,AjKmeA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,A5BoFA,AnCyGA,AbuCA,A8J1dA,ACHA,APqBA,ADGA,AENA,AIZA,AFMA,AOrBA,ADGA,ALeA,AIZA,AGTA,A3HiXA,A8E1OA,AS3BA,AsClHA,AvCqHA,AsClHA,A5CoIA,A4BpFA,ADGA,ADGA,AjBmDA,AgBhDA,AxBwEA,AWjCA,AT2BA,AENA,AGTA,AKfA,AWjCA,ApB4DA,Ae7CA,A9G0UA,A0F9QA,A+C7IA,AjKmeA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,A5BoFA,AnCyGA,AbuCA,A8J1dA,ACHA,APqBA,ADGA,AENA,AIZA,AFMA,AOrBA,ADGA,ALeA,AIZA,AGTA,A3HiXA,A8E1OA,AS3BA,AsClHA,AvCqHA,AsClHA,A5CoIA,A4BpFA,ADGA,ADGA,AjBmDA,AgBhDA,AxBwEA,AWjCA,AT2BA,AENA,AGTA,AKfA,AWjCA,ApB4DA,Ae7CA,A9G0UA,A0F9QA,A+C7IA,AjKmeA,AFMA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,A5BoFA,AnCyGA,AbuCA,A8J1dA,ACHA,APqBA,ADGA,AENA,AIZA,AFMA,AOrBA,ADGA,ALeA,AIZA,AGTA,A3HiXA,A8E1OA,AS3BA,AsClHA,AvCqHA,AsClHA,A5CoIA,A4BpFA,ADGA,ADGA,AjBmDA,AgBhDA,AxBwEA,AWjCA,AT2BA,AENA,AGTA,AKfA,AWjCA,ApB4DA,Ae7CA,A9G0UA,A0F9QA,A+C7IA,AjKmeA,AkKteA,ApK4eA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,A5BoFA,AnCyGA,AbuCA,A8J1dA,ACHA,APqBA,ADGA,AENA,AIZA,AFMA,AOrBA,ADGA,ALeA,AIZA,AGTA,A3HiXA,A8E1OA,AS3BA,AsClHA,AvCqHA,AsClHA,A5CoIA,A4BpFA,ADGA,ADGA,AjBmDA,AgBhDA,AxBwEA,AWjCA,AT2BA,AENA,AGTA,AKfA,AWjCA,ApB4DA,Ae7CA,A9G0UA,A0F9QA,A+C7IA,AjKmeA,AkKteA,ApK4eA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,A5BoFA,AnCyGA,AbuCA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AOrBA,ADGA,ALeA,AIZA,AGTA,A3HiXA,A8E1OA,AS3BA,AsClHA,AvCqHA,AsClHA,A5CoIA,A4BpFA,ADGA,ADGA,AjBmDA,AgBhDA,AxBwEA,AWjCA,AT2BA,AENA,AGTA,AKfA,AWjCA,ApB4DA,Ae7CA,A9G0UA,A0F9QA,A+C7IA,AjKmeA,AkKteA,ApK4eA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,A5BoFA,AnCyGA,AbuCA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AOrBA,ADGA,ALeA,AIZA,AGTA,A3HiXA,A8E1OA,AS3BA,AsClHA,AvCqHA,AsClHA,A5CoIA,A4BpFA,ADGA,ADGA,AjBmDA,AgBhDA,AxBwEA,AWjCA,AT2BA,AENA,AGTA,AKfA,AWjCA,ApB4DA,Ae7CA,A9G0UA,A0F9QA,A+C7IA,AjKmeA,AkKteA,ApK4eA,AqK/eA;AzI4ZA,AqF/PA,AzG2TA,AiEnMA,A5BoFA,AnCyGA,AbuCA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AOrBA,ADGA,ALeA,AIZA,AGTA,A3HiXA,A8E1OA,AS3BA,AsClHA,AvCqHA,AsClHA,A5CoIA,A4BpFA,ADGA,ADGA,AjBmDA,AgBhDA,AxBwEA,AWjCA,AT2BA,AENA,AGTA,AKfA,AWjCA,ApB4DA,Ae7CA,A9G0UA,A0F9QA,A+C7IA,AjKmeA,AkKteA,ApK4eA,AqK/eA;AzI4ZA,AqF/PA,AzG2TA,AiEnMA,A5BoFA,AnCyGA,AbuCA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AOrBA,ADGA,ALeA,AIZA,AGTA,A3HiXA,A8E1OA,AS3BA,AsClHA,AvCqHA,AsClHA,A5CoIA,A4BpFA,ADGA,ADGA,AjBmDA,AgBhDA,AxBwEA,AWjCA,AT2BA,AENA,AGTA,AKfA,AWjCA,ApB4DA,Ae7CA,A9G0UA,A0F9QA,A+C7IA,AjKmeA,AkKteA,ApK4eA,AqK/eA;AzI4ZA,AqF/PA,AzG2TA,AiEnMA,A5BoFA,AnCyGA,AbuCA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AOrBA,ADGA,ALeA,AIZA,AGTA,A3HiXA,A8E1OA,AS3BA,AsClHA,AvCqHA,AsClHA,A5CoIA,A4BpFA,ADGA,ADGA,AjBmDA,AgBhDA,AxBwEA,AWjCA,AT2BA,AENA,AGTA,AKfA,AWjCA,ApB4DA,Ae7CA,A9G0UA,A0F9QA,A+C7IA,AjKmeA,AkKteA,ApK4eA,AqK/eA,ACHA;A1I+ZA,AqF/PA,AzG2TA,AiEnMA,A5BoFA,AnCyGA,AbuCA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AOrBA,ADGA,ALeA,AIZA,AGTA,A3HiXA,A8E1OA,AS3BA,AsClHA,AvCqHA,AsClHA,A5CoIA,A4BpFA,ADGA,ADGA,AjBmDA,AgBhDA,AxBwEA,AWjCA,AT2BA,AENA,AGTA,AKfA,AWjCA,ApB4DA,Ae7CA,A9G0UA,A0F9QA,A+C7IA,AjKmeA,AkKteA,ApK4eA,AqK/eA,ACHA;A1I+ZA,AqF/PA,AzG2TA,AiEnMA,A5BoFA,AnCyGA,AbuCA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AOrBA,ADGA,ALeA,AIZA,AGTA,A3HiXA,A8E1OA,AS3BA,AsClHA,AvCqHA,AsClHA,A5CoIA,A4BpFA,ADGA,ADGA,AjBmDA,AgBhDA,AxBwEA,AWjCA,AT2BA,AENA,AGTA,AKfA,AWjCA,ApB4DA,Ae7CA,A9G0UA,A0F9QA,A+C7IA,AjKmeA,AkKteA,ApK4eA,AqK/eA,ACHA;A1I+ZA,AqF/PA,AzG2TA,AiEnMA,A5BoFA,AnCyGA,AbuCA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AOrBA,ADGA,ALeA,AIZA,AGTA,A3HiXA,A8E1OA,AS3BA,AsClHA,AvCqHA,AsClHA,A5CoIA,A4BpFA,ADGA,ADGA,AjBmDA,AgBhDA,AxBwEA,AWjCA,AT2BA,AENA,AGTA,AKfA,AWjCA,ApB4DA,Ae7CA,A9G0UA,A0F9QA,AmDzJA,AJYA,AjKmeA,AkKteA,ApK4eA,AqK/eA,ACHA;A1I+ZA,AqF/PA,AzG2TA,AiEnMA,A5BoFA,AnCyGA,AbuCA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AOrBA,ADGA,ALeA,AIZA,AGTA,A3HiXA,A8E1OA,AS3BA,AsClHA,AvCqHA,AsClHA,A5CoIA,A4BpFA,ADGA,ADGA,AjBmDA,AgBhDA,AxBwEA,AWjCA,AT2BA,AENA,AGTA,AKfA,AWjCA,ApB4DA,Ae7CA,A9G0UA,A0F9QA,AmDzJA,AJYA,AjKmeA,AkKteA,ApK4eA,AsKlfA;A1I+ZA,AqF/PA,AzG2TA,AiEnMA,A5BoFA,AnCyGA,AbuCA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AOrBA,ADGA,ALeA,AIZA,AGTA,A3HiXA,A8E1OA,AS3BA,AsClHA,AvCqHA,AsClHA,A5CoIA,A4BpFA,ADGA,ADGA,AjBmDA,AgBhDA,AxBwEA,AWjCA,AT2BA,AENA,AGTA,AKfA,AWjCA,ApB4DA,Ae7CA,A9G0UA,A0F9QA,AmDzJA,AJYA,AjKmeA,AkKteA,ApK4eA,AsKlfA;A1I+ZA,AqF/PA,AzG2TA,AiEnMA,A5BoFA,AnCyGA,AbuCA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AOrBA,ADGA,ALeA,AIZA,AxHwWA,A8E1OA,AS3BA,AsClHA,AvCqHA,AsClHA,A5CoIA,A4BpFA,ADGA,ADGA,AjBmDA,AgBhDA,AxBwEA,AWjCA,AT2BA,AENA,AGTA,AKfA,AWjCA,ApB4DA,Ae7CA,A9G0UA,A0F9QA,AmDzJA,ACHA,ALeA,AjKmeA,AkKteA,ApK4eA,AsKlfA;A1I+ZA,AqF/PA,AzG2TA,AiEnMA,A5BoFA,AnCyGA,AbuCA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AOrBA,ADGA,ALeA,AIZA,AxHwWA,A8E1OA,AS3BA,AsClHA,AvCqHA,AsClHA,A5CoIA,A4BpFA,ADGA,ADGA,AjBmDA,AgBhDA,AxBwEA,AWjCA,AT2BA,AENA,AGTA,AKfA,AWjCA,ApB4DA,Ae7CA,A9G0UA,A0F9QA,AmDzJA,ACHA,ALeA,AjKmeA,AkKteA,ApK4eA,AsKlfA;A1I+ZA,AqF/PA,AzG2TA,AiEnMA,A5BoFA,AnCyGA,AbuCA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AOrBA,ADGA,ALeA,AIZA,AxHwWA,A8E1OA,AS3BA,AsClHA,AvCqHA,AsClHA,A5CoIA,A4BpFA,ADGA,ADGA,AjBmDA,AgBhDA,AxBwEA,AWjCA,AT2BA,AENA,AGTA,AKfA,AWjCA,ApB4DA,Ae7CA,A9G0UA,A0F9QA,AmDzJA,ACHA,ALeA,AjKmeA,AkKteA,ApK4eA,AsKlfA;A1I+ZA,AqF/PA,AzG2TA,AiEnMA,A5BoFA,AnCyGA,AbuCA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AOrBA,ADGA,ALeA,AIZA,AxHwWA,A8E1OA,AS3BA,AsClHA,AvCqHA,AsClHA,A5CoIA,A4BpFA,ADGA,ADGA,AjBmDA,AgBhDA,AxBwEA,AWjCA,AT2BA,AENA,AGTA,AKfA,AWjCA,ApB4DA,Ae7CA,A9G0UA,A0F9QA,AmDzJA,AENA,ADGA,ALeA,AjKmeA,AkKteA,ApK4eA,AsKlfA;A1I+ZA,AqF/PA,AzG2TA,AiEnMA,A5BoFA,AnCyGA,AbuCA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AOrBA,ADGA,ALeA,AIZA,AxHwWA,A8E1OA,AS3BA,AsClHA,AvCqHA,AsClHA,A5CoIA,A4BpFA,ADGA,ADGA,AjBmDA,AgBhDA,AxBwEA,AENA,AENA,AGTA,AKfA,AWjCA,ApB4DA,Ae7CA,A9G0UA,A0F9QA,AmDzJA,AENA,ADGA,ALeA,AjKmeA,AkKteA,ApK4eA,AsKlfA;A1I+ZA,AqF/PA,AzG2TA,AiEnMA,A5BoFA,AnCyGA,AbuCA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AOrBA,ADGA,ALeA,AIZA,AxHwWA,A8E1OA,AS3BA,AsClHA,AvCqHA,AsClHA,A5CoIA,A4BpFA,ADGA,ADGA,AjBmDA,AgBhDA,AxBwEA,AENA,AENA,AGTA,AKfA,AWjCA,ApB4DA,Ae7CA,A9G0UA,A0F9QA,AmDzJA,AENA,ADGA,ALeA,AjKmeA,AkKteA,ApK4eA,AsKlfA;A1I+ZA,AqF/PA,AzG2TA,AiEnMA,A5BoFA,AnCyGA,AbuCA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AOrBA,ADGA,ALeA,AIZA,AxHwWA,A8E1OA,AS3BA,AsClHA,AvCqHA,AsClHA,A5CoIA,A4BpFA,ADGA,ADGA,AjBmDA,AgBhDA,AxBwEA,AENA,AENA,AGTA,AKfA,AWjCA,ApB4DA,Ae7CA,A9G0UA,A0F9QA,AmDzJA,AENA,ACHA,AFMA,ALeA,AjKmeA,AkKteA,ApK4eA,AsKlfA;A1I+ZA,AqF/PA,AzG2TA,AiEnMA,A5BoFA,AnCyGA,AbuCA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AOrBA,ADGA,ALeA,AIZA,AxHwWA,A8E1OA,AS3BA,AsClHA,AvCqHA,AsClHA,A5CoIA,A4BpFA,ADGA,ADGA,AjBmDA,AgBhDA,AxBwEA,AENA,AENA,AGTA,AKfA,AWjCA,ApB4DA,Ae7CA,A9G0UA,A0F9QA,AmDzJA,AENA,ACHA,AFMA,ALeA,AjKmeA,AkKteA,ApK4eA,AsKlfA;A1I+ZA,AqF/PA,AzG2TA,AiEnMA,A5BoFA,AnCyGA,AbuCA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AOrBA,ADGA,ALeA,AIZA,AxHwWA,A8E1OA,AS3BA,AsClHA,AvCqHA,AsClHA,A5CoIA,A4BpFA,ADGA,ADGA,AjBmDA,AgBhDA,AxBwEA,AENA,AENA,AGTA,AKfA,AWjCA,ApB4DA,Ae7CA,A9G0UA,A0F9QA,AmDzJA,AENA,ACHA,AFMA,ALeA,AjKmeA,AkKteA,ApK4eA,AsKlfA;A1I+ZA,AqF/PA,AzG2TA,AiEnMA,A5BoFA,AnCyGA,AbuCA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AOrBA,ADGA,ALeA,AIZA,AxHwWA,A8E1OA,AS3BA,AsClHA,AvCqHA,AsClHA,A5CoIA,A4BpFA,ADGA,ADGA,AjBmDA,AgBhDA,AxBwEA,AENA,AENA,AGTA,AKfA,AWjCA,ApB4DA,Ae7CA,A9G0UA,A0F9QA,AmDzJA,AENA,ACHA,ACHA,AHSA,ALeA,AjKmeA,AkKteA,ApK4eA,AsKlfA;A1I+ZA,AqF/PA,AzG2TA,AiEnMA,A5BoFA,AnCyGA,AbuCA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AOrBA,ADGA,ALeA,AIZA,AxHwWA,A8E1OA,AS3BA,AsClHA,AvCqHA,AsClHA,A5CoIA,A4BpFA,ADGA,ADGA,AjBmDA,AgBhDA,AxBwEA,AENA,AENA,AGTA,AKfA,AWjCA,ApB4DA,Ae7CA,A9G0UA,A0F9QA,AmDzJA,AENA,ACHA,ACHA,AHSA,ALeA,AjKmeA,AkKteA,ApK4eA,AsKlfA;A1I+ZA,AqF/PA,AzG2TA,AiEnMA,A5BoFA,AnCyGA,AbuCA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AOrBA,ADGA,ALeA,AIZA,AxHwWA,A8E1OA,AS3BA,AsClHA,AvCqHA,AsClHA,A5CoIA,A4BpFA,ADGA,ADGA,AjBmDA,AgBhDA,AxBwEA,AENA,AENA,AGTA,AKfA,AWjCA,ApB4DA,Ae7CA,A9G0UA,A0F9QA,AmDzJA,AENA,ACHA,ACHA,AHSA,ALeA,AjKmeA,AkKteA,ApK4eA,AsKlfA;A1I+ZA,AqF/PA,AzG2TA,AiEnMA,A5BoFA,AnCyGA,AbuCA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AOrBA,ADGA,ALeA,AIZA,AxHwWA,A8E1OA,AS3BA,AsClHA,AvCqHA,AsClHA,A5CoIA,A4BpFA,ADGA,ADGA,AjBmDA,AgBhDA,AxBwEA,AENA,AENA,AGTA,AKfA,AWjCA,ApB4DA,Ae7CA,A9G0UA,A0F9QA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,ALeA,AjKmeA,AkKteA,ApK4eA,AsKlfA;A1I+ZA,AqF/PA,AzG2TA,AiEnMA,A5BoFA,AnCyGA,AbuCA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AOrBA,ADGA,ALeA,AIZA,AxHwWA,A8E1OA,AS3BA,AsClHA,AvCqHA,AsClHA,A5CoIA,A4BpFA,ADGA,ADGA,AjBmDA,AgBhDA,AtBkEA,AENA,AGTA,AKfA,AWjCA,ApB4DA,Ae7CA,A9G0UA,A0F9QA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,ALeA,AjKmeA,AkKteA,ApK4eA,AsKlfA;A1I+ZA,AqF/PA,AzG2TA,AiEnMA,A5BoFA,AnCyGA,AbuCA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AOrBA,ADGA,ALeA,AIZA,AxHwWA,A8E1OA,AS3BA,AsClHA,AvCqHA,AsClHA,A5CoIA,A4BpFA,ADGA,ADGA,AjBmDA,AgBhDA,AtBkEA,AENA,AGTA,AKfA,AWjCA,ApB4DA,Ae7CA,A9G0UA,A0F9QA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,ALeA,AjKmeA,AkKteA,ApK4eA,AsKlfA;A1I+ZA,AqF/PA,AzG2TA,AiEnMA,A5BoFA,AnCyGA,AbuCA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AOrBA,ADGA,ALeA,AIZA,AxHwWA,A8E1OA,AS3BA,AsClHA,AvCqHA,AsClHA,A5CoIA,A4BpFA,ADGA,ADGA,AjBmDA,AgBhDA,AtBkEA,AENA,AGTA,AKfA,AWjCA,ApB4DA,Ae7CA,A9G0UA,A0F9QA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AKfA,AV8BA,AjKmeA,AkKteA,ApK4eA,AsKlfA;A1I+ZA,AqF/PA,AzG2TA,AiEnMA,A5BoFA,AnCyGA,AbuCA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AOrBA,ADGA,ALeA,AIZA,AxHwWA,A8E1OA,AS3BA,AsClHA,AvCqHA,AsClHA,A5CoIA,A4BpFA,ADGA,ADGA,AjBmDA,AgBhDA,AtBkEA,AENA,AGTA,AKfA,AWjCA,ApB4DA,Ae7CA,A9G0UA,A0F9QA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AKfA,AV8BA,AjKmeA,AkKteA,ApK4eA,AsKlfA;A1I+ZA,AqF/PA,AzG2TA,AiEnMA,A5BoFA,AnCyGA,AbuCA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AOrBA,ADGA,ALeA,AIZA,AxHwWA,A8E1OA,AS3BA,AsClHA,AvCqHA,AsClHA,A5CoIA,A4BpFA,ADGA,ADGA,AjBmDA,AgBhDA,AtBkEA,AENA,AGTA,AKfA,AWjCA,ApB4DA,Ae7CA,A9G0UA,A0F9QA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AKfA,AV8BA,AjKmeA,AkKteA,ApK4eA,AsKlfA;A1I+ZA,AqF/PA,AzG2TA,AiEnMA,A5BoFA,AnCyGA,AbuCA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AOrBA,ADGA,ALeA,AIZA,AxHwWA,A8E1OA,AS3BA,AsClHA,AvCqHA,AsClHA,A5CoIA,A4BpFA,ADGA,ADGA,AjBmDA,AgBhDA,AtBkEA,AENA,AGTA,AKfA,AWjCA,ApB4DA,Ae7CA,A9G0UA,A0F9QA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AMlBA,ADGA,AV8BA,AjKmeA,AkKteA,ApK4eA,AsKlfA;A1I+ZA,AqF/PA,AzG2TA,AiEnMA,A5BoFA,AnCyGA,AbuCA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AOrBA,ADGA,ALeA,AIZA,AxHwWA,A8E1OA,AS3BA,AsClHA,AvCqHA,AsClHA,A5CoIA,A4BpFA,ADGA,ADGA,AjBmDA,AgBhDA,AtBkEA,AENA,AGTA,AKfA,AMlBA,A9G0UA,A0F9QA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AMlBA,ADGA,AV8BA,AjKmeA,AkKteA,ApK4eA,AsKlfA;A1I+ZA,AqF/PA,AzG2TA,AiEnMA,A5BoFA,AnCyGA,AbuCA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AOrBA,ADGA,ALeA,AIZA,AxHwWA,A8E1OA,AS3BA,AsClHA,AvCqHA,AsClHA,A5CoIA,A4BpFA,ADGA,ADGA,AjBmDA,AgBhDA,AtBkEA,AENA,AGTA,AKfA,AMlBA,A9G0UA,A0F9QA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AMlBA,ADGA,AV8BA,AjKmeA,AkKteA,ApK4eA,AsKlfA;A1I+ZA,AqF/PA,AzG2TA,AiEnMA,A5BoFA,AnCyGA,AbuCA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AOrBA,ADGA,ALeA,AIZA,AxHwWA,A8E1OA,AS3BA,AsClHA,AvCqHA,AsClHA,A5CoIA,A4BpFA,ADGA,ADGA,AjBmDA,AgBhDA,AtBkEA,AENA,AGTA,AKfA,AMlBA,A9G0UA,A0F9QA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AMlBA,ADGA,AV8BA,AjKmeA,AkKteA,AWjCA,A/K6gBA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,A5BoFA,AnCyGA,AbuCA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AOrBA,ADGA,ALeA,AIZA,AxHwWA,A8E1OA,AS3BA,AsClHA,AvCqHA,AsClHA,A5CoIA,A4BpFA,ADGA,ADGA,AjBmDA,AgBhDA,AtBkEA,AENA,AGTA,AKfA,AMlBA,A9G0UA,A0F9QA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AMlBA,ADGA,AV8BA,AjKmeA,AkKteA,AWjCA,A/K6gBA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,A5BoFA,AnCyGA,AbuCA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AOrBA,ADGA,ALeA,AIZA,AxHwWA,A8E1OA,AS3BA,AsClHA,AvCqHA,AsClHA,A5CoIA,A4BpFA,ADGA,ADGA,AjBmDA,AgBhDA,AtBkEA,AENA,AGTA,AKfA,AMlBA,A9G0UA,A0F9QA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AMlBA,ADGA,AV8BA,AjKmeA,AkKteA,AWjCA,A/K6gBA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,A5BoFA,AnCyGA,AbuCA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AOrBA,ADGA,ALeA,AIZA,AxHwWA,A8E1OA,AS3BA,AsClHA,AvCqHA,AsClHA,A5CoIA,A4BpFA,ADGA,ADGA,AjBmDA,AgBhDA,AtBkEA,AENA,AGTA,AKfA,AMlBA,A9G0UA,A0F9QA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AQxBA,AFMA,ADGA,AV8BA,AjKmeA,AkKteA,AWjCA,A/K6gBA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,A5BoFA,AnCyGA,AbuCA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AOrBA,ADGA,ALeA,AIZA,AxHwWA,A8E1OA,AS3BA,AsClHA,AvCqHA,AsClHA,A5CoIA,A4BpFA,ADGA,ADGA,AjBmDA,AgBhDA,AtBkEA,AENA,AGTA,AKfA,AMlBA,A9G0UA,A0F9QA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AQxBA,AFMA,ADGA,AV8BA,AjKmeA,AkKteA,AWjCA,A/K6gBA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,A5BoFA,AnCyGA,AbuCA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AOrBA,ADGA,ALeA,AIZA,AxHwWA,A8E1OA,AS3BA,AsClHA,AvCqHA,AsClHA,A5CoIA,A4BpFA,ADGA,ADGA,AjBmDA,AgBhDA,AtBkEA,AENA,AGTA,AKfA,AMlBA,A9G0UA,A0F9QA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AQxBA,AFMA,ADGA,AV8BA,AjKmeA,AkKteA,AWjCA,A/K6gBA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,A5BoFA,AnCyGA,AuKrfA,ApL4hBA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AOrBA,ADGA,ALeA,AIZA,AxHwWA,A8E1OA,AS3BA,AsClHA,AvCqHA,AsClHA,A5CoIA,A4BpFA,ADGA,ADGA,AjBmDA,AgBhDA,AtBkEA,AENA,AGTA,AKfA,AMlBA,A9G0UA,A0F9QA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AQxBA,AFMA,ADGA,AV8BA,AjKmeA,AkKteA,AWjCA,A/K6gBA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,A5BoFA,AnCyGA,AuKrfA,ApL4hBA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AOrBA,ADGA,ALeA,AIZA,AxHwWA,A8E1OA,AS3BA,AsClHA,AvCqHA,AsClHA,A5CoIA,A4BpFA,ADGA,ADGA,AjBmDA,AgBhDA,AtBkEA,AENA,AGTA,AKfA,AMlBA,A9G0UA,A0F9QA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AQxBA,AFMA,ADGA,AV8BA,AjKmeA,AkKteA,AWjCA,A/K6gBA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,A5BoFA,AnCyGA,AuKrfA,ApL4hBA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AOrBA,ANkBA,AIZA,AxHwWA,A8E1OA,AS3BA,AsClHA,AvCqHA,AsClHA,A5CoIA,A4BpFA,ADGA,ADGA,AjBmDA,AgBhDA,AtBkEA,AENA,AGTA,AKfA,AMlBA,A9G0UA,A0F9QA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AQxBA,AFMA,ADGA,AV8BA,AjKmeA,AkKteA,AWjCA,A/K6gBA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,A5BoFA,AnCyGA,AuKrfA,ApL4hBA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AOrBA,ANkBA,AIZA,AxHwWA,A8E1OA,AS3BA,AsClHA,AvCqHA,AsClHA,A5CoIA,A4BpFA,ADGA,ADGA,AjBmDA,AgBhDA,AtBkEA,AENA,AGTA,AKfA,AMlBA,A9G0UA,A0F9QA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AQxBA,AFMA,ADGA,AV8BA,AjKmeA,AkKteA,AWjCA,A/K6gBA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,A5BoFA,AnCyGA,AuKrfA,ApL4hBA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AOrBA,ANkBA,AIZA,AxHwWA,A8E1OA,AS3BA,AsClHA,AvCqHA,AsClHA,A5CoIA,A4BpFA,ADGA,ADGA,AjBmDA,AgBhDA,AtBkEA,AENA,AGTA,AKfA,AMlBA,A9G0UA,A0F9QA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AQxBA,AFMA,ADGA,AV8BA,AjKmeA,AkKteA,AWjCA,A/K6gBA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,A5BoFA,AnCyGA,AuKrfA,ApL4hBA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AOrBA,ANkBA,AIZA,AxHwWA,A8E1OA,AS3BA,AsClHA,AvCqHA,AsClHA,A5CoIA,A4BpFA,ADGA,ADGA,AjBmDA,AgBhDA,AtBkEA,AENA,AGTA,AKfA,AMlBA,A9G0UA,A0F9QA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AQxBA,AFMA,ADGA,AV8BA,AjKmeA,AkKteA,AWjCA,A/K6gBA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,A5BoFA,AnCyGA,AuKrfA,ApL4hBA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AOrBA,ANkBA,AIZA,AxHwWA,A8E1OA,AS3BA,AsClHA,AvCqHA,AsClHA,A5CoIA,A4BpFA,ADGA,ADGA,AjBmDA,AgBhDA,AtBkEA,AENA,AGTA,AKfA,AMlBA,A9G0UA,A0F9QA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AQxBA,AFMA,ADGA,AV8BA,AjKmeA,AkKteA,AWjCA,A/K6gBA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,A5BoFA,AnCyGA,AuKrfA,ApL4hBA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AOrBA,ANkBA,AIZA,AxHwWA,A8E1OA,AS3BA,AsClHA,AvCqHA,AsClHA,A5CoIA,A4BpFA,ADGA,ADGA,AjBmDA,AgBhDA,AtBkEA,AENA,AGTA,AKfA,AMlBA,A9G0UA,A0F9QA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AQxBA,AFMA,ADGA,AV8BA,AjKmeA,AkKteA,AWjCA,A/K6gBA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,A5BoFA,AnCyGA,AuKrfA,ApL4hBA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AOrBA,ANkBA,AIZA,AxHwWA,A8E1OA,AS3BA,AsClHA,AvCqHA,AsClHA,A5CoIA,A4BpFA,ADGA,ADGA,AjBmDA,AgBhDA,AtBkEA,AENA,AGTA,AKfA,AMlBA,A9G0UA,A0F9QA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AQxBA,AFMA,ADGA,AV8BA,AjKmeA,AkKteA,AWjCA,A/K6gBA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,A5BoFA,AnCyGA,AuKrfA,ApL4hBA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AOrBA,ANkBA,AIZA,AxHwWA,A8E1OA,AS3BA,AsClHA,AvCqHA,AsClHA,A5CoIA,A4BpFA,ADGA,ADGA,AjBmDA,AgBhDA,AtBkEA,AENA,AGTA,AKfA,AMlBA,A9G0UA,A0F9QA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AQxBA,AFMA,ADGA,AV8BA,AjKmeA,AkKteA,AWjCA,A/K6gBA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,A5BoFA,AoI5YA,ApL4hBA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AOrBA,ANkBA,AIZA,AxHwWA,A8E1OA,AS3BA,AsClHA,AvCqHA,AsClHA,A5CoIA,A4BpFA,ADGA,ADGA,AjBmDA,AgBhDA,AtBkEA,AENA,AGTA,AKfA,AMlBA,A9G0UA,A0F9QA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AQxBA,AFMA,ADGA,AV8BA,AjKmeA,AkKteA,AWjCA,A/K6gBA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,A5BoFA,AoI5YA,ApL4hBA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AOrBA,ANkBA,AIZA,AxHwWA,A8E1OA,AS3BA,AsClHA,AvCqHA,AsClHA,A5CoIA,A4BpFA,ADGA,ADGA,AjBmDA,AgBhDA,AtBkEA,AENA,AGTA,AKfA,AMlBA,A9G0UA,A0F9QA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AQxBA,AFMA,ADGA,AV8BA,AjKmeA,AkKteA,AWjCA,A/K6gBA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,A5BoFA,AoI5YA,ApL4hBA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AOrBA,ANkBA,AIZA,AxHwWA,A8E1OA,AS3BA,AsClHA,AvCqHA,AsClHA,A5CoIA,A4BpFA,ADGA,ADGA,AjBmDA,AgBhDA,AtBkEA,AENA,AGTA,AWjCA,A9G0UA,A0F9QA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AQxBA,AFMA,ADGA,AV8BA,AjKmeA,AkKteA,AWjCA,A/K6gBA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,A5BoFA,AoI5YA,ApL4hBA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AOrBA,ANkBA,AIZA,AxHwWA,A8E1OA,AS3BA,AsClHA,AvCqHA,AsClHA,A5CoIA,A4BpFA,ADGA,ADGA,AjBmDA,AgBhDA,AtBkEA,AENA,AGTA,AWjCA,A9G0UA,A0F9QA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AQxBA,AFMA,ADGA,AV8BA,AjKmeA,AkKteA,AWjCA,A/K6gBA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,A5BoFA,AoI5YA,ApL4hBA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AOrBA,ANkBA,AIZA,AxHwWA,A8E1OA,AS3BA,AsClHA,AvCqHA,AsClHA,A5CoIA,A4BpFA,ADGA,ADGA,AjBmDA,AgBhDA,AtBkEA,AENA,AGTA,AWjCA,A9G0UA,A0F9QA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AQxBA,AFMA,ADGA,AV8BA,AjKmeA,AkKteA,AWjCA,A/K6gBA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,A5BoFA,AoI5YA,ApL4hBA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AOrBA,ANkBA,AIZA,AxHwWA,A8E1OA,AS3BA,AsClHA,AvCqHA,AsClHA,A5CoIA,A4BpFA,ADGA,ADGA,AjBmDA,AgBhDA,AtBkEA,AENA,AGTA,AWjCA,A9G0UA,A0F9QA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AQxBA,AFMA,ADGA,AV8BA,AjKmeA,AkKteA,AWjCA,A/K6gBA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,A5BoFA,AoI5YA,ApL4hBA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AOrBA,ANkBA,AIZA,AxHwWA,A8E1OA,AS3BA,AsClHA,AvCqHA,AsClHA,A5CoIA,A4BpFA,ADGA,ADGA,AjBmDA,AgBhDA,AtBkEA,AENA,AGTA,AWjCA,A9G0UA,A0F9QA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AQxBA,AFMA,ADGA,AV8BA,AjKmeA,AkKteA,AWjCA,A/K6gBA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,A5BoFA,AoI5YA,ApL4hBA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AOrBA,ANkBA,AIZA,AxHwWA,A8E1OA,AS3BA,AsClHA,AvCqHA,AsClHA,A5CoIA,A4BpFA,ADGA,ADGA,AjBmDA,AgBhDA,AtBkEA,AENA,AGTA,AWjCA,A9G0UA,A0F9QA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AQxBA,AFMA,ADGA,AV8BA,AjKmeA,AkKteA,AWjCA,A/K6gBA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,A5BoFA,AoI5YA,ApL4hBA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AOrBA,ANkBA,AIZA,AxHwWA,A8E1OA,AS3BA,AsClHA,AvCqHA,AsClHA,A5CoIA,A4BpFA,ADGA,ADGA,AjBmDA,AgBhDA,AtBkEA,AENA,AGTA,AWjCA,A9G0UA,A0F9QA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AQxBA,AFMA,ADGA,AV8BA,AjKmeA,AkKteA,AWjCA,A/K6gBA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,A5BoFA,AoI5YA,ApL4hBA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AOrBA,ANkBA,AIZA,AxHwWA,A8E1OA,AS3BA,AsClHA,AvCqHA,AsClHA,A5CoIA,A4BpFA,ADGA,ADGA,AjBmDA,AgBhDA,AtBkEA,AENA,AGTA,AWjCA,A9G0UA,A0F9QA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AQxBA,AFMA,ADGA,AV8BA,AjKmeA,AkKteA,AWjCA,A/K6gBA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,A5BoFA,AoI5YA,ApL4hBA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AOrBA,ANkBA,AIZA,AxHwWA,A8E1OA,AS3BA,AsClHA,AvCqHA,AsClHA,A5CoIA,A4BpFA,ADGA,ADGA,AjBmDA,AgBhDA,AtBkEA,AENA,AGTA,AWjCA,A9G0UA,A0F9QA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AQxBA,AFMA,ADGA,AV8BA,AjKmeA,AkKteA,AWjCA,A/K6gBA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,A5BoFA,AoI5YA,ApL4hBA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AOrBA,ANkBA,AIZA,AxHwWA,A8E1OA,AS3BA,AsClHA,AvCqHA,AsClHA,A5CoIA,A4BpFA,ADGA,ADGA,AjBmDA,AgBhDA,AtBkEA,AENA,AGTA,AWjCA,A9G0UA,A0F9QA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AQxBA,AFMA,ADGA,AV8BA,AjKmeA,AkKteA,AWjCA,A/K6gBA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,A5BoFA,AoI5YA,ApL4hBA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AOrBA,ANkBA,AIZA,AxHwWA,A8E1OA,AS3BA,AsClHA,AvCqHA,AsClHA,A5CoIA,A4BpFA,ADGA,ADGA,AjBmDA,AgBhDA,AtBkEA,AENA,Ac1CA,A9G0UA,A0F9QA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AQxBA,AFMA,ADGA,AV8BA,AjKmeA,AkKteA,AWjCA,A/K6gBA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,A5BoFA,AoI5YA,ApL4hBA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AOrBA,ANkBA,AIZA,AxHwWA,A8E1OA,AS3BA,AsClHA,AvCqHA,AsClHA,A5CoIA,A4BpFA,ADGA,ADGA,AjBmDA,AgBhDA,AtBkEA,AENA,Ac1CA,A9G0UA,A0F9QA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AQxBA,AFMA,ADGA,AV8BA,AjKmeA,AkKteA,AWjCA,A/K6gBA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,A5BoFA,AoI5YA,ApL4hBA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AOrBA,ANkBA,AIZA,AxHwWA,A8E1OA,AS3BA,AsClHA,AvCqHA,ANkBA,A4BpFA,ADGA,ADGA,AjBmDA,AgBhDA,AtBkEA,AENA,Ac1CA,A9G0UA,A0F9QA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AQxBA,AFMA,ADGA,AV8BA,AjKmeA,AkKteA,AWjCA,A/K6gBA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,A5BoFA,AoI5YA,ApL4hBA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AOrBA,ANkBA,AIZA,AxHwWA,A8E1OA,AS3BA,AsClHA,AvCqHA,ANkBA,A4BpFA,ADGA,ADGA,AjBmDA,AgBhDA,AtBkEA,AENA,Ac1CA,A9G0UA,A0F9QA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AQxBA,AFMA,ADGA,AV8BA,AjKmeA,AkKteA,AWjCA,A/K6gBA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,A5BoFA,AoI5YA,ApL4hBA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AOrBA,ANkBA,AIZA,AxHwWA,A8E1OA,AS3BA,AsClHA,AvCqHA,ANkBA,A4BpFA,ADGA,ADGA,AjBmDA,AgBhDA,AtBkEA,AENA,Ac1CA,A9G0UA,A0F9QA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AQxBA,AFMA,ADGA,AV8BA,AjKmeA,AkKteA,AWjCA,A/K6gBA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,A5BoFA,AoI5YA,ApL4hBA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AOrBA,AFMA,AxHwWA,A8E1OA,AS3BA,AsClHA,AvCqHA,ANkBA,A4BpFA,ADGA,ADGA,AjBmDA,AgBhDA,AtBkEA,AENA,Ac1CA,A9G0UA,A0F9QA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AQxBA,AFMA,ADGA,AV8BA,AjKmeA,AkKteA,AWjCA,A/K6gBA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,A5BoFA,AoI5YA,ApL4hBA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AOrBA,AFMA,AxHwWA,A8E1OA,AS3BA,AsClHA,AvCqHA,ANkBA,A4BpFA,ADGA,ADGA,AjBmDA,AgBhDA,AtBkEA,AENA,Ac1CA,A9G0UA,A0F9QA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AQxBA,AFMA,ADGA,AV8BA,AjKmeA,AkKteA,AWjCA,A/K6gBA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,A5BoFA,AoI5YA,ApL4hBA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AOrBA,AFMA,AxHwWA,A8E1OA,AS3BA,AsClHA,AvCqHA,ANkBA,A4BpFA,ADGA,ADGA,AjBmDA,AgBhDA,AtBkEA,AENA,Ac1CA,A9G0UA,A0F9QA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AQxBA,AFMA,ADGA,AV8BA,AjKmeA,AkKteA,AWjCA,A/K6gBA;A4BnFA,AqF/PA,AzG2TA,AiEnMA,A5BoFA,AoI5YA,ApL4hBA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AOrBA,AFMA,AxHwWA,A8E1OA,AS3BA,AsClHA,AvCqHA,ANkBA,A4BpFA,ADGA,ADGA,AjBmDA,AgBhDA,AtBkEA,AENA,Ac1CA,A9G0UA,A0F9QA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AQxBA,AFMA,ADGA,AV8BA,AjKmeA,AkKteA,AWjCA,A/K6gBA;AiHlVA,AzG2TA,AiEnMA,A5BoFA,AoI5YA,ApL4hBA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AOrBA,AFMA,AxHwWA,A8E1OA,AS3BA,AsClHA,AvCqHA,ANkBA,A4BpFA,ADGA,ADGA,AjBmDA,AgBhDA,AtBkEA,AENA,Ac1CA,A9G0UA,A0F9QA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AQxBA,AFMA,ADGA,AV8BA,AjKmeA,AkKteA,AWjCA,A/K6gBA;AiHlVA,AzG2TA,AiEnMA,A5BoFA,AoI5YA,ApL4hBA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AOrBA,AFMA,AxHwWA,A8E1OA,AS3BA,AsClHA,AvCqHA,ANkBA,A4BpFA,ADGA,ADGA,AjBmDA,AgBhDA,AtBkEA,AENA,Ac1CA,A9G0UA,A0F9QA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AQxBA,AFMA,ADGA,AV8BA,AjKmeA,AkKteA,AWjCA,A/K6gBA;AiHlVA,AzG2TA,AiEnMA,A5BoFA,AoI5YA,ApL4hBA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AOrBA,AFMA,AxHwWA,A8E1OA,AS3BA,AsClHA,AvCqHA,ANkBA,A4BpFA,ADGA,ADGA,AjBmDA,AgBhDA,AtBkEA,AENA,Ac1CA,A9G0UA,A0F9QA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AQxBA,AFMA,ADGA,AV8BA,AjKmeA,AkKteA,AWjCA,A/K6gBA;AiHlVA,AzG2TA,AiEnMA,A5BoFA,AoI5YA,ApL4hBA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AOrBA,AFMA,AxHwWA,A8E1OA,AS3BA,AsClHA,AvCqHA,ANkBA,A4BpFA,ADGA,ADGA,AjBmDA,AgBhDA,AtBkEA,AENA,Ac1CA,A9G0UA,A0F9QA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AQxBA,AFMA,ADGA,AV8BA,AjKmeA,AkKteA,ApK4eA;AiHlVA,AzG2TA,AiEnMA,A5BoFA,AoI5YA,ApL4hBA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AOrBA,AFMA,AxHwWA,A8E1OA,AS3BA,AsClHA,AvCqHA,ANkBA,A4BpFA,ADGA,ADGA,AjBmDA,AgBhDA,AtBkEA,AENA,Ac1CA,A9G0UA,A0F9QA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AQxBA,AFMA,ADGA,AV8BA,AjKmeA,AkKteA,ApK4eA;AiHlVA,AzG2TA,AiEnMA,A5BoFA,AoI5YA,ApL4hBA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AOrBA,AFMA,AxHwWA,A8E1OA,AS3BA,AsClHA,AvCqHA,ANkBA,A4BpFA,ADGA,ADGA,AjBmDA,AgBhDA,AtBkEA,AENA,Ac1CA,A9G0UA,A0F9QA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AQxBA,AFMA,ADGA,AV8BA,AjKmeA,AkKteA,ApK4eA;AiHlVA,AzG2TA,AiEnMA,A5BoFA,AoI5YA,ApL4hBA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AOrBA,AFMA,AxHwWA,A8E1OA,AS3BA,AsClHA,AvCqHA,ANkBA,A4BpFA,ADGA,ADGA,AjBmDA,AgBhDA,AtBkEA,AENA,Ac1CA,A9G0UA,A0F9QA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AQxBA,AFMA,ADGA,AV8BA,AjKmeA,AkKteA,ApK4eA;AiHlVA,AzG2TA,AiEnMA,A5BoFA,AoI5YA,ApL4hBA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AOrBA,AFMA,AxHwWA,A8E1OA,AS3BA,AsClHA,AvCqHA,ANkBA,A4BpFA,ADGA,ADGA,AjBmDA,AgBhDA,AtBkEA,AENA,Ac1CA,A9G0UA,A0F9QA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AQxBA,AFMA,ADGA,AV8BA,AjKmeA,AkKteA,ApK4eA;AiHlVA,AzG2TA,AiEnMA,A5BoFA,AoI5YA,ApL4hBA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AOrBA,AFMA,AxHwWA,A8E1OA,AS3BA,AsClHA,AvCqHA,ANkBA,A4BpFA,ADGA,ADGA,AjBmDA,AgBhDA,AtBkEA,AENA,AhGgSA,A0F9QA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AQxBA,AFMA,ADGA,AV8BA,AjKmeA,AkKteA,ApK4eA;AiHlVA,AzG2TA,AiEnMA,A5BoFA,AoI5YA,ApL4hBA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AOrBA,AFMA,AxHwWA,A8E1OA,AS3BA,AsClHA,AvCqHA,ANkBA,A4BpFA,ADGA,ADGA,AjBmDA,AgBhDA,AtBkEA,AENA,AhGgSA,A0F9QA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AQxBA,AFMA,ADGA,AV8BA,AjKmeA,AkKteA,ApK4eA;AiHlVA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AOrBA,AFMA,AxHwWA,A8E1OA,AS3BA,AsClHA,AvCqHA,ANkBA,A4BpFA,ADGA,ADGA,AjBmDA,AgBhDA,AtBkEA,AENA,AhGgSA,A0F9QA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AQxBA,AFMA,ADGA,AV8BA,AjKmeA,AkKteA,ApK4eA;AiHlVA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AOrBA,AFMA,AxHwWA,A8E1OA,AS3BA,AsClHA,AvCqHA,ANkBA,A4BpFA,ADGA,ADGA,AjBmDA,AgBhDA,AtBkEA,AENA,AhGgSA,A0F9QA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AQxBA,AFMA,ADGA,AV8BA,AjKmeA,AkKteA,ApK4eA;AiHlVA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AOrBA,AFMA,AxHwWA,A8E1OA,AS3BA,AsClHA,AvCqHA,ANkBA,A4BpFA,ADGA,ADGA,AjBmDA,AgBhDA,AtBkEA,AENA,AhGgSA,A0F9QA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AQxBA,AFMA,ADGA,AV8BA,AjKmeA,AkKteA,ApK4eA;AiHlVA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AOrBA,AFMA,AxHwWA,A8E1OA,AS3BA,AsClHA,AvCqHA,ANkBA,A4BpFA,ADGA,ADGA,AjBmDA,AgBhDA,AtBkEA,AENA,AhGgSA,A0F9QA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AQxBA,AFMA,ADGA,AV8BA,AjKmeA,AkKteA,ApK4eA;AiHlVA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AOrBA,AFMA,AxHwWA,A8E1OA,AS3BA,AsClHA,AvCqHA,ANkBA,A4BpFA,ADGA,ADGA,AjBmDA,AgBhDA,AtBkEA,AENA,AhGgSA,A0F9QA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AQxBA,AFMA,ADGA,AV8BA,AjKmeA,AkKteA,ApK4eA;AiHlVA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AOrBA,AFMA,AxHwWA,A8E1OA,AS3BA,AsClHA,AvCqHA,ANkBA,A4BpFA,ADGA,ADGA,AjBmDA,AgBhDA,AtBkEA,AENA,AhGgSA,A0F9QA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AQxBA,AFMA,ADGA,AV8BA,AjKmeA,AkKteA,ApK4eA;AiHlVA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AOrBA,AFMA,AxHwWA,A8E1OA,AS3BA,AsClHA,AvCqHA,ANkBA,A4BpFA,ADGA,ADGA,AjBmDA,AgBhDA,AtBkEA,AENA,AhGgSA,A0F9QA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AQxBA,AFMA,ADGA,AV8BA,AjKmeA,AkKteA,ApK4eA;AiHlVA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AOrBA,AFMA,AxHwWA,A8E1OA,AS3BA,AsClHA,AvCqHA,ANkBA,A4BpFA,ADGA,ADGA,AjBmDA,AgBhDA,AtBkEA,AENA,AhGgSA,A0F9QA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AQxBA,AFMA,ADGA,AV8BA,AjKmeA,AkKteA,ApK4eA;AiHlVA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AOrBA,AFMA,AxHwWA,A8E1OA,AS3BA,AsClHA,AvCqHA,ANkBA,A4BpFA,ADGA,ADGA,AjBmDA,AgBhDA,AtBkEA,AENA,AhGgSA,A0F9QA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AQxBA,AFMA,ADGA,AV8BA,AjKmeA,AkKteA,ApK4eA;AiHlVA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AOrBA,AFMA,AxHwWA,A8E1OA,AS3BA,AsClHA,AvCqHA,ANkBA,A4BpFA,ADGA,ADGA,AjBmDA,AgBhDA,AtBkEA,AENA,AhGgSA,A0F9QA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AQxBA,AFMA,ADGA,AV8BA,AjKmeA,AkKteA,ApK4eA;AiHlVA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AOrBA,AFMA,AxHwWA,A8E1OA,AS3BA,AsClHA,AvCqHA,ANkBA,A4BpFA,ADGA,ADGA,AjBmDA,AgBhDA,AtBkEA,AENA,ANkBA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AQxBA,AFMA,ADGA,AV8BA,AjKmeA,AkKteA,ApK4eA;AiHlVA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AOrBA,AFMA,AxHwWA,A8E1OA,AS3BA,AsClHA,AvCqHA,ANkBA,A2BjFA,ADGA,AjBmDA,AgBhDA,AtBkEA,AENA,ANkBA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AQxBA,AFMA,ADGA,AV8BA,AjKmeA,AkKteA,ApK4eA;AiHlVA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AOrBA,AFMA,AxHwWA,A8E1OA,AS3BA,AsClHA,AvCqHA,ANkBA,A2BjFA,ADGA,AjBmDA,AgBhDA,AtBkEA,AENA,ANkBA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AQxBA,AFMA,ADGA,AV8BA,AjKmeA,AkKteA,ApK4eA;AiHlVA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AOrBA,AFMA,AxHwWA,A8E1OA,AS3BA,AsClHA,AvCqHA,ANkBA,A2BjFA,ADGA,AjBmDA,AgBhDA,AtBkEA,AENA,ANkBA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AQxBA,AFMA,ADGA,AV8BA,AjKmeA,AkKteA,ApK4eA;AiHlVA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AOrBA,AFMA,AxHwWA,A8E1OA,AS3BA,AsClHA,AvCqHA,ANkBA,A2BjFA,ADGA,AjBmDA,AgBhDA,AtBkEA,AENA,ANkBA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AQxBA,AFMA,ADGA,AV8BA,AjKmeA,AkKteA,ApK4eA;AiHlVA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AOrBA,AFMA,AxHwWA,A8E1OA,AS3BA,AsClHA,AvCqHA,ANkBA,A2BjFA,ADGA,AjBmDA,AgBhDA,AtBkEA,AENA,ANkBA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AQxBA,AFMA,ADGA,AV8BA,AjKmeA,AkKteA,ApK4eA;AiHlVA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AOrBA,AFMA,AxHwWA,A8E1OA,AS3BA,AsClHA,AvCqHA,ANkBA,A2BjFA,ADGA,AjBmDA,AgBhDA,AtBkEA,AENA,ANkBA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AQxBA,AFMA,ADGA,AV8BA,AjKmeA,AkKteA,ApK4eA;AiHlVA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AOrBA,AFMA,AxHwWA,A8E1OA,AS3BA,AsClHA,AvCqHA,ANkBA,A2BjFA,ADGA,AjBmDA,AgBhDA,AtBkEA,AENA,ANkBA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AQxBA,AFMA,ADGA,AV8BA,AjKmeA,AkKteA,ApK4eA;AiHlVA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AOrBA,AFMA,AxHwWA,A8E1OA,AS3BA,AsClHA,AvCqHA,ANkBA,A2BjFA,ADGA,AjBmDA,AgBhDA,AtBkEA,AENA,ANkBA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AQxBA,AFMA,ADGA,AV8BA,AjKmeA,AkKteA,ApK4eA;AiHlVA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AOrBA,AFMA,AxHwWA,A8E1OA,AS3BA,AsClHA,AvCqHA,ANkBA,A2BjFA,ADGA,AjBmDA,AgBhDA,AtBkEA,AENA,ANkBA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AQxBA,AFMA,ADGA,AV8BA,AjKmeA,AkKteA,ApK4eA;AiHlVA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AOrBA,AFMA,AxHwWA,A8E1OA,AS3BA,AsClHA,AvCqHA,ANkBA,A2BjFA,ADGA,AjBmDA,AgBhDA,AtBkEA,AENA,ANkBA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AQxBA,AFMA,ADGA,AV8BA,AjKmeA,AkKteA,ApK4eA;AiHlVA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AOrBA,AFMA,AxHwWA,A8E1OA,AS3BA,AsClHA,AvCqHA,ANkBA,A2BjFA,ADGA,AjBmDA,AgBhDA,AtBkEA,AENA,ANkBA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AQxBA,AFMA,ADGA,AV8BA,AjKmeA,AkKteA,ApK4eA;AiHlVA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AOrBA,AFMA,AxHwWA,A8E1OA,AS3BA,AsClHA,AvCqHA,ANkBA,A2BjFA,ADGA,AjBmDA,AgBhDA,AtBkEA,AENA,ANkBA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AQxBA,AFMA,ADGA,AV8BA,AjKmeA,AkKteA,ApK4eA;AiHlVA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AOrBA,AFMA,AxHwWA,A8E1OA,AS3BA,AsClHA,AvCqHA,ANkBA,A2BjFA,ADGA,AjBmDA,AgBhDA,AtBkEA,AENA,ANkBA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AQxBA,AFMA,ADGA,AV8BA,AjKmeA,AkKteA,ApK4eA;AiHlVA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AOrBA,AFMA,AxHwWA,A8E1OA,AS3BA,AsClHA,AvCqHA,ANkBA,A2BjFA,ADGA,AjBmDA,AgBhDA,AtBkEA,AENA,ANkBA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AQxBA,AFMA,ADGA,AV8BA,AjKmeA,AkKteA,ApK4eA;AiHlVA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AOrBA,AFMA,AxHwWA,A8E1OA,AS3BA,AsClHA,AvCqHA,ANkBA,A2BjFA,ADGA,AjBmDA,AgBhDA,AtBkEA,AENA,ANkBA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AQxBA,AFMA,ADGA,AV8BA,AjKmeA,AkKteA,ApK4eA;AiHlVA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AOrBA,AFMA,AxHwWA,A8E1OA,AS3BA,AsClHA,AvCqHA,ANkBA,A2BjFA,ADGA,AjBmDA,AgBhDA,AtBkEA,AENA,ANkBA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AQxBA,AFMA,ADGA,AV8BA,AjKmeA,AkKteA,ApK4eA;AiHlVA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AOrBA,AFMA,AxHwWA,A8E1OA,AS3BA,AsClHA,AvCqHA,ANkBA,A2BjFA,ADGA,AjBmDA,AgBhDA,AtBkEA,AENA,ANkBA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AQxBA,AFMA,ADGA,AV8BA,AjKmeA,AkKteA,ApK4eA;AiHlVA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AOrBA,AFMA,AxHwWA,A8E1OA,AS3BA,AsClHA,AvCqHA,ANkBA,A2BjFA,ADGA,AjBmDA,AgBhDA,AtBkEA,AENA,ANkBA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AQxBA,AFMA,ADGA,AV8BA,AjKmeA,AkKteA,ApK4eA;AiHlVA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AOrBA,AFMA,AxHwWA,A8E1OA,AS3BA,AsClHA,AvCqHA,ANkBA,A2BjFA,ADGA,AjBmDA,AgBhDA,AtBkEA,AENA,ANkBA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AQxBA,AFMA,ADGA,AV8BA,AjKmeA,AkKteA,ApK4eA;AiHlVA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AOrBA,AFMA,AxHwWA,A8E1OA,AS3BA,AsClHA,AvCqHA,ANkBA,A2BjFA,ADGA,AjBmDA,AgBhDA,AtBkEA,AENA,ANkBA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AQxBA,AFMA,ADGA,AV8BA,AjKmeA,AkKteA,ApK4eA;AiHlVA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AOrBA,AFMA,AxHwWA,A8E1OA,AS3BA,AsClHA,AvCqHA,ANkBA,A2BjFA,ADGA,AjBmDA,AgBhDA,AtBkEA,AENA,ANkBA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AQxBA,AFMA,ADGA,AV8BA,AjKmeA,AkKteA,ApK4eA;AiHlVA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AOrBA,AFMA,AxHwWA,A8E1OA,AS3BA,AsClHA,AvCqHA,ANkBA,A2BjFA,ADGA,AjBmDA,AgBhDA,AtBkEA,AENA,ANkBA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AQxBA,AFMA,ADGA,AV8BA,AjKmeA,AkKteA,ApK4eA;AiHlVA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AOrBA,AFMA,AxHwWA,A8E1OA,AS3BA,AsClHA,AvCqHA,ANkBA,A2BjFA,ADGA,AjBmDA,AgBhDA,AtBkEA,AENA,ANkBA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AQxBA,AFMA,ADGA,AV8BA,AjKmeA,AkKteA,ApK4eA;AiHlVA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AOrBA,AFMA,AxHwWA,A8E1OA,AS3BA,AsClHA,AvCqHA,ANkBA,A2BjFA,ADGA,AjBmDA,AgBhDA,AtBkEA,AENA,ANkBA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AQxBA,AFMA,ADGA,AV8BA,AjKmeA,AkKteA,ApK4eA;AiHlVA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AOrBA,AFMA,AxHwWA,A8E1OA,AS3BA,AsClHA,AvCqHA,ANkBA,A2BjFA,ADGA,AjBmDA,AgBhDA,AtBkEA,AENA,ANkBA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AQxBA,AFMA,ADGA,AV8BA,AjKmeA,AkKteA,ApK4eA;AiHlVA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AOrBA,AFMA,AxHwWA,A8E1OA,AS3BA,AsClHA,AvCqHA,ANkBA,A2BjFA,ADGA,ADGA,AtBkEA,AENA,ANkBA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AQxBA,AFMA,ADGA,AV8BA,AjKmeA,AkKteA,ApK4eA;AiHlVA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AOrBA,AFMA,AxHwWA,A8E1OA,AS3BA,AsClHA,AvCqHA,ANkBA,A2BjFA,ADGA,ADGA,AtBkEA,AENA,ANkBA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AQxBA,AFMA,ADGA,AV8BA,AjKmeA,AkKteA,ApK4eA;AiHlVA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AOrBA,AFMA,AxHwWA,A8E1OA,AS3BA,AsClHA,AvCqHA,ANkBA,A2BjFA,ADGA,ADGA,AtBkEA,AENA,ANkBA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AQxBA,AFMA,ADGA,AV8BA,AjKmeA,AkKteA,ApK4eA;AiHlVA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AOrBA,AFMA,AxHwWA,A8E1OA,AS3BA,AsClHA,AvCqHA,ANkBA,A2BjFA,ADGA,ADGA,AtBkEA,AENA,ANkBA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AQxBA,AFMA,ADGA,A3KigBA,AkKteA,ApK4eA;AiHlVA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AOrBA,AFMA,AxHwWA,A8E1OA,AS3BA,AsClHA,AvCqHA,ANkBA,A2BjFA,ADGA,ADGA,AtBkEA,AENA,ANkBA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AQxBA,AFMA,ADGA,A3KigBA,AkKteA,ApK4eA;AiHlVA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AOrBA,AFMA,AxHwWA,A8E1OA,AS3BA,AsClHA,AvCqHA,ANkBA,A2BjFA,ADGA,ADGA,AtBkEA,AENA,ANkBA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AQxBA,AFMA,ADGA,A3KigBA,AkKteA,ApK4eA;AiHlVA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AOrBA,AFMA,AxHwWA,A8E1OA,AS3BA,AsClHA,AvCqHA,ANkBA,A2BjFA,ADGA,ADGA,AtBkEA,AENA,ANkBA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AQxBA,AFMA,ADGA,A3KigBA,AkKteA,ApK4eA;AiHlVA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AOrBA,AFMA,AxHwWA,A8E1OA,AS3BA,AsClHA,A7CuIA,A2BjFA,ADGA,ADGA,AtBkEA,AENA,ANkBA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AQxBA,AFMA,ADGA,A3KigBA,AkKteA,ApK4eA;AiHlVA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AOrBA,AFMA,AxHwWA,A8E1OA,AS3BA,AsClHA,A7CuIA,A2BjFA,ADGA,ADGA,AtBkEA,AENA,ANkBA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AQxBA,AFMA,ADGA,A3KigBA,AkKteA,ApK4eA;AiHlVA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AOrBA,AFMA,AxHwWA,A8E1OA,AS3BA,AsClHA,A7CuIA,A2BjFA,ADGA,ADGA,AtBkEA,AENA,ANkBA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AQxBA,AFMA,ADGA,A3KigBA,AkKteA,ApK4eA;AiHlVA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AOrBA,AFMA,AxHwWA,A8E1OA,AS3BA,AsClHA,A7CuIA,A2BjFA,ADGA,ADGA,AtBkEA,AENA,ANkBA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AQxBA,AFMA,ADGA,A3KigBA,AkKteA,ApK4eA;AiHlVA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AOrBA,AFMA,AxHwWA,A8E1OA,AS3BA,AsClHA,A7CuIA,A2BjFA,ADGA,ADGA,AtBkEA,AENA,ANkBA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AQxBA,AFMA,ADGA,A3KigBA,AFMA;AiHlVA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AOrBA,AFMA,AxHwWA,A8E1OA,AS3BA,AsClHA,A7CuIA,A2BjFA,ADGA,ADGA,AtBkEA,AENA,ANkBA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AQxBA,AFMA,ADGA,A3KigBA,AFMA;AiHlVA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AOrBA,AFMA,AxHwWA,A8E1OA,AS3BA,AsClHA,A7CuIA,A2BjFA,ADGA,ADGA,AtBkEA,AENA,ANkBA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AQxBA,AFMA,ADGA,A3KigBA,AFMA;AiHlVA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AOrBA,AFMA,AxHwWA,A8E1OA,AS3BA,AsClHA,A7CuIA,A2BjFA,ADGA,ADGA,AtBkEA,AENA,ANkBA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AQxBA,AFMA,ADGA,A3KigBA,AFMA;AiHlVA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AOrBA,AFMA,AxHwWA,A8E1OA,AS3BA,AsClHA,A7CuIA,A2BjFA,ADGA,ADGA,AtBkEA,AENA,ANkBA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AQxBA,AFMA,ADGA,A3KigBA,AFMA;AiHlVA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AKfA,AxHwWA,A8E1OA,AS3BA,AsClHA,A7CuIA,A2BjFA,ADGA,ADGA,AtBkEA,AENA,ANkBA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AQxBA,AFMA,ADGA,A3KigBA,AFMA;AiHlVA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AKfA,AxHwWA,A8E1OA,AS3BA,AsClHA,A7CuIA,A2BjFA,ADGA,ADGA,AtBkEA,AENA,ANkBA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AQxBA,AFMA,ADGA,A3KigBA,AFMA;AiHlVA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AKfA,AxHwWA,A8E1OA,AS3BA,AsClHA,A7CuIA,A2BjFA,ADGA,ADGA,AtBkEA,AENA,ANkBA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AQxBA,AFMA,ADGA,A3KigBA,AFMA;AiHlVA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AKfA,AxHwWA,A8E1OA,AS3BA,AsClHA,A7CuIA,A2BjFA,ADGA,ADGA,AtBkEA,AENA,ANkBA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AQxBA,AFMA,ADGA,A3KigBA,AFMA;AiHlVA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AKfA,AxHwWA,A8E1OA,AS3BA,AsClHA,A7CuIA,A2BjFA,ADGA,ADGA,AtBkEA,AENA,ANkBA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AQxBA,AFMA,ADGA,A3KigBA,AFMA;AiHlVA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AKfA,AxHwWA,A8E1OA,AS3BA,AsClHA,A7CuIA,A2BjFA,ADGA,ADGA,AtBkEA,AENA,ANkBA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AQxBA,AFMA,ADGA,A3KigBA,AFMA;AiHlVA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AKfA,AxHwWA,A8E1OA,AS3BA,AsClHA,A7CuIA,A2BjFA,ADGA,ADGA,AtBkEA,AENA,ANkBA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AQxBA,AFMA,ADGA,A3KigBA,AFMA;AiHlVA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AKfA,AxHwWA,A8E1OA,AS3BA,AsClHA,A7CuIA,A2BjFA,ADGA,ADGA,AtBkEA,AENA,ANkBA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AQxBA,AFMA,ADGA,A3KigBA,AFMA;AiHlVA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AKfA,AxHwWA,A8E1OA,AS3BA,AsClHA,A7CuIA,A2BjFA,ADGA,ADGA,AtBkEA,AENA,ANkBA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AQxBA,AFMA,ADGA,A3KigBA,AFMA;AiHlVA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AKfA,AxHwWA,A8E1OA,AS3BA,AsClHA,A7CuIA,A2BjFA,ADGA,ADGA,AtBkEA,AENA,ANkBA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AQxBA,AFMA,ADGA,A3KigBA,AFMA;AiHlVA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AKfA,AxHwWA,A8E1OA,AS3BA,AsClHA,A7CuIA,A2BjFA,ADGA,ADGA,AtBkEA,AENA,ANkBA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AQxBA,AFMA,ADGA,A3KigBA,AFMA;AiHlVA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AKfA,AxHwWA,A8E1OA,AS3BA,AsClHA,A7CuIA,A2BjFA,ADGA,ADGA,AtBkEA,AENA,ANkBA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AQxBA,AFMA,ADGA,A3KigBA,AFMA;AiHlVA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AKfA,AxHwWA,A8E1OA,AS3BA,AsClHA,A7CuIA,A2BjFA,ADGA,ADGA,AtBkEA,AENA,ANkBA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AQxBA,AFMA,ADGA,A3KigBA,AFMA;AiHlVA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AKfA,AxHwWA,A8E1OA,AS3BA,AsClHA,A7CuIA,A2BjFA,ADGA,ADGA,AtBkEA,AENA,ANkBA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AQxBA,AFMA,ADGA,A3KigBA,AFMA;AiHlVA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AKfA,AxHwWA,A8E1OA,AS3BA,AsClHA,A7CuIA,A2BjFA,ADGA,ADGA,AtBkEA,AENA,ANkBA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AQxBA,AFMA,ADGA,A3KigBA,AFMA;AiHlVA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AKfA,AxHwWA,A8E1OA,AS3BA,AsClHA,A7CuIA,A2BjFA,ADGA,ADGA,AtBkEA,AENA,ANkBA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AQxBA,AFMA,ADGA,A3KigBA,AFMA;AiHlVA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AKfA,AxHwWA,A8E1OA,AS3BA,AsClHA,A7CuIA,A2BjFA,ADGA,ADGA,AtBkEA,AENA,ANkBA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AQxBA,AFMA,ADGA,A3KigBA,AFMA;AiHlVA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AKfA,AxHwWA,A8E1OA,AS3BA,AsClHA,A7CuIA,A2BjFA,ADGA,ADGA,AtBkEA,AENA,ANkBA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AQxBA,AFMA,ADGA,A3KigBA,AFMA;AiHlVA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AKfA,AxHwWA,A8E1OA,AS3BA,AsClHA,A7CuIA,A2BjFA,ADGA,ADGA,AtBkEA,AENA,ANkBA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AQxBA,AFMA,ADGA,A3KigBA,AFMA;AiHlVA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AKfA,AxHwWA,A8E1OA,AS3BA,AsClHA,A7CuIA,A2BjFA,ADGA,ADGA,AtBkEA,AENA,ANkBA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AQxBA,AFMA,ADGA,A3KigBA,AFMA;AiHlVA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AKfA,AxHwWA,A8E1OA,AS3BA,AsClHA,A7CuIA,A2BjFA,ADGA,ADGA,AtBkEA,AENA,ANkBA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AQxBA,AFMA,ADGA,A3KigBA,AFMA;AiHlVA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AKfA,AxHwWA,A8E1OA,AS3BA,AsClHA,A7CuIA,A2BjFA,ADGA,ADGA,AtBkEA,AENA,ANkBA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AQxBA,AFMA,ADGA,A3KigBA,AFMA;AiHlVA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AKfA,AxHwWA,A8E1OA,AS3BA,AsClHA,A7CuIA,A2BjFA,ADGA,ADGA,AtBkEA,AENA,ANkBA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AQxBA,AFMA,ADGA,A3KigBA,AFMA;AiHlVA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AKfA,AxHwWA,A8E1OA,AS3BA,AsClHA,A7CuIA,A2BjFA,ADGA,ADGA,AtBkEA,AENA,ANkBA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AQxBA,AFMA,ADGA,A3KigBA,AFMA;AiHlVA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AKfA,AxHwWA,A8E1OA,AS3BA,AsClHA,A7CuIA,A2BjFA,ADGA,ADGA,AtBkEA,AENA,ANkBA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AQxBA,AFMA,ADGA,A3KigBA,AFMA;AiHlVA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AKfA,AxHwWA,A8E1OA,AS3BA,AsClHA,A7CuIA,A2BjFA,ADGA,ADGA,AtBkEA,AENA,ANkBA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AQxBA,AFMA,ADGA,A3KigBA,AFMA;AiHlVA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AKfA,AxHwWA,A8E1OA,AS3BA,AsClHA,A7CuIA,A2BjFA,ADGA,ADGA,AtBkEA,AENA,ANkBA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AQxBA,AFMA,ADGA,A3KigBA,AFMA;AiHlVA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AKfA,AxHwWA,A8E1OA,AS3BA,AsClHA,A7CuIA,A2BjFA,ADGA,ADGA,AtBkEA,AENA,ANkBA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AQxBA,AFMA,ADGA,A3KigBA,AFMA;AiHlVA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AKfA,AxHwWA,A8E1OA,AS3BA,AsClHA,A7CuIA,A2BjFA,ADGA,ADGA,AtBkEA,AENA,ANkBA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AQxBA,AFMA,ADGA,A3KigBA,AFMA;AiHlVA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AKfA,AxHwWA,A8E1OA,AS3BA,AsClHA,A7CuIA,A2BjFA,ADGA,ADGA,AtBkEA,AENA,ANkBA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AQxBA,AFMA,ADGA,A3KigBA,AFMA;AiHlVA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AKfA,AxHwWA,A8E1OA,AS3BA,AsClHA,A7CuIA,A2BjFA,ADGA,ADGA,AtBkEA,AENA,ANkBA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AQxBA,AFMA,ADGA,A3KigBA,AFMA;AiHlVA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AKfA,AxHwWA,A8E1OA,AS3BA,AsClHA,A7CuIA,A2BjFA,ADGA,ADGA,AtBkEA,AENA,ANkBA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AQxBA,AFMA,ADGA,A3KigBA,AFMA;AiHlVA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AKfA,AxHwWA,A8E1OA,AS3BA,AsClHA,A7CuIA,A2BjFA,ADGA,ADGA,AtBkEA,AENA,ANkBA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AQxBA,AFMA,ADGA,A3KigBA,AFMA;AiHlVA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AKfA,AxHwWA,A8E1OA,AS3BA,AsClHA,A7CuIA,A2BjFA,ADGA,ADGA,AtBkEA,AENA,ANkBA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AQxBA,AFMA,ADGA,A3KigBA,AFMA;AiHlVA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AKfA,AxHwWA,A8E1OA,AS3BA,AsClHA,A7CuIA,A2BjFA,ADGA,ADGA,AtBkEA,AENA,ANkBA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AQxBA,AFMA,ADGA,A3KigBA,AFMA;AiHlVA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AKfA,AxHwWA,A8E1OA,AS3BA,AsClHA,A7CuIA,A2BjFA,ADGA,ADGA,AtBkEA,AENA,ANkBA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AQxBA,AFMA,ADGA,A3KigBA,AFMA;AiHlVA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AKfA,AxHwWA,A8E1OA,AS3BA,AsClHA,A7CuIA,A2BjFA,ADGA,ADGA,AtBkEA,AENA,ANkBA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AQxBA,AFMA,ADGA,A3KigBA,AFMA;AiHlVA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AKfA,AxHwWA,A8E1OA,AS3BA,AsClHA,A7CuIA,A2BjFA,ADGA,ADGA,AtBkEA,AENA,ANkBA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AQxBA,AFMA,ADGA,A3KigBA,AFMA;AiHlVA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AKfA,AxHwWA,A8E1OA,AS3BA,AsClHA,A7CuIA,A2BjFA,ADGA,ADGA,AtBkEA,AENA,ANkBA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AQxBA,AFMA,ADGA,A3KigBA,AFMA;AiHlVA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AKfA,AxHwWA,A8E1OA,AS3BA,AsClHA,A7CuIA,A2BjFA,ADGA,ADGA,AtBkEA,AENA,ANkBA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AQxBA,AFMA,ADGA,A3KigBA,AFMA;AiHlVA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AKfA,AxHwWA,A8E1OA,AS3BA,AsClHA,A7CuIA,A2BjFA,ADGA,ADGA,AtBkEA,AENA,ANkBA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AQxBA,AFMA,ADGA,A3KigBA,AFMA;AiHlVA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AKfA,AxHwWA,A8E1OA,AS3BA,AsClHA,A7CuIA,A2BjFA,ADGA,ADGA,AtBkEA,AENA,ANkBA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AQxBA,AFMA,ADGA,A3KigBA,AFMA;AiHlVA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AKfA,AxHwWA,A8E1OA,AS3BA,AsClHA,A7CuIA,A2BjFA,ADGA,ADGA,AtBkEA,AENA,ANkBA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AQxBA,AFMA,ADGA,A3KigBA,AFMA;AiHlVA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AKfA,AxHwWA,A8E1OA,AS3BA,AsClHA,A7CuIA,A2BjFA,ADGA,ADGA,AtBkEA,AENA,ANkBA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AQxBA,AFMA,ADGA,A3KigBA,AFMA;AiHlVA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AKfA,AxHwWA,A8E1OA,AS3BA,AsClHA,A7CuIA,A2BjFA,ADGA,ADGA,AtBkEA,AENA,ANkBA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AQxBA,AFMA,ADGA,A3KigBA,AFMA;AiHlVA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AKfA,AxHwWA,A8E1OA,AS3BA,AsClHA,A7CuIA,A2BjFA,ADGA,ADGA,AtBkEA,AENA,ANkBA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AQxBA,AFMA,ADGA,A3KigBA,AFMA;AiHlVA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AKfA,AxHwWA,A8E1OA,AS3BA,AsClHA,A7CuIA,A2BjFA,ADGA,ADGA,AtBkEA,AENA,ANkBA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AQxBA,AFMA,ADGA,A3KigBA,AFMA;AiHlVA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AKfA,AxHwWA,A8E1OA,AS3BA,AsClHA,A7CuIA,A2BjFA,ADGA,ADGA,AtBkEA,AENA,ANkBA,AmDzJA,AENA,ACHA,ACHA,ACHA,AJYA,AQxBA,AFMA,A5KogBA,AFMA;AiHlVA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AKfA,AxHwWA,A8E1OA,AS3BA,AsClHA,A7CuIA,A2BjFA,ADGA,ADGA,AtBkEA,AENA,ANkBA,AmDzJA,AGTA,ACHA,ACHA,AJYA,AQxBA,AFMA,A5KogBA,AFMA;AiHlVA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AKfA,AxHwWA,A8E1OA,AS3BA,AsClHA,A7CuIA,A2BjFA,ADGA,ADGA,AtBkEA,AENA,ANkBA,AmDzJA,AGTA,ACHA,ACHA,AJYA,AQxBA,AFMA,A5KogBA,AFMA;AiHlVA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AKfA,AxHwWA,A8E1OA,AS3BA,AsClHA,A7CuIA,A2BjFA,ADGA,ADGA,AtBkEA,AENA,ANkBA,AmDzJA,AGTA,ACHA,ACHA,AJYA,AQxBA,AFMA,A5KogBA,AFMA;AiHlVA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AKfA,AxHwWA,A8E1OA,AS3BA,AsClHA,A7CuIA,A2BjFA,ADGA,ADGA,AtBkEA,AENA,ANkBA,AmDzJA,AGTA,ACHA,ACHA,AJYA,AQxBA,AFMA,A5KogBA,AFMA;AiHlVA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AKfA,AxHwWA,A8E1OA,AS3BA,AsClHA,A7CuIA,A2BjFA,ADGA,ADGA,AtBkEA,AENA,ANkBA,AmDzJA,AGTA,ACHA,ACHA,AJYA,AQxBA,AFMA,A5KogBA,AFMA;AiHlVA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AKfA,AxHwWA,A8E1OA,AS3BA,AsClHA,A7CuIA,A2BjFA,ADGA,ADGA,AtBkEA,AENA,ANkBA,AmDzJA,AGTA,ACHA,ACHA,AJYA,AQxBA,AFMA,A5KogBA,AFMA;AiHlVA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AKfA,AxHwWA,A8E1OA,AS3BA,AsClHA,A7CuIA,A2BjFA,ADGA,ADGA,AtBkEA,AENA,ANkBA,AmDzJA,AGTA,ACHA,ACHA,AJYA,AQxBA,AFMA,A5KogBA;A+G5UA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AKfA,AxHwWA,A8E1OA,AS3BA,AsClHA,A7CuIA,A2BjFA,ADGA,ADGA,AtBkEA,AENA,ANkBA,AmDzJA,AGTA,ACHA,ACHA,AJYA,AQxBA,AFMA,A5KogBA;A+G5UA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AKfA,AxHwWA,A8E1OA,AS3BA,AsClHA,A7CuIA,A2BjFA,ADGA,ADGA,AtBkEA,AENA,ANkBA,AmDzJA,AGTA,ACHA,ACHA,AJYA,AQxBA,AFMA,A5KogBA;A+G5UA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AKfA,AxHwWA,A8E1OA,AS3BA,AsClHA,A7CuIA,A2BjFA,ADGA,ADGA,AtBkEA,AENA,ANkBA,AmDzJA,AGTA,ACHA,ACHA,AJYA,AQxBA,AFMA,A5KogBA;A+G5UA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AKfA,AxHwWA,A8E1OA,AS3BA,AsClHA,A7CuIA,A2BjFA,AFMA,AtBkEA,AENA,ANkBA,AmDzJA,AGTA,ACHA,ACHA,AJYA,AQxBA,AFMA,A5KogBA;A+G5UA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AKfA,AxHwWA,A8E1OA,AS3BA,AsClHA,A7CuIA,A2BjFA,AFMA,AtBkEA,AENA,ANkBA,AmDzJA,AGTA,ACHA,ACHA,AJYA,AQxBA,AFMA,A5KogBA;A+G5UA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AKfA,AxHwWA,A8E1OA,AS3BA,APqBA,A2BjFA,AFMA,AtBkEA,AENA,ANkBA,AmDzJA,AGTA,ACHA,ACHA,AJYA,AQxBA,AFMA,A5KogBA;A+G5UA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AKfA,AxHwWA,A8E1OA,AS3BA,APqBA,A2BjFA,AFMA,AtBkEA,AENA,ANkBA,AmDzJA,AGTA,ACHA,ACHA,AJYA,AQxBA,AFMA,A5KogBA;A+G5UA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AKfA,AxHwWA,A8E1OA,AS3BA,APqBA,A2BjFA,AFMA,AtBkEA,AENA,ANkBA,AmDzJA,AGTA,ACHA,ACHA,AJYA,AQxBA,AFMA,A5KogBA;A+G5UA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AKfA,AxHwWA,AuFrQA,APqBA,A2BjFA,AFMA,AtBkEA,AENA,ANkBA,AmDzJA,AGTA,ACHA,ACHA,AJYA,AQxBA,AFMA,A5KogBA;A+G5UA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AKfA,AxHwWA,AuFrQA,APqBA,A2BjFA,AFMA,AtBkEA,AENA,ANkBA,AmDzJA,AGTA,ACHA,ACHA,AJYA,AQxBA,AFMA,A5KogBA;A+G5UA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AKfA,AxHwWA,AuFrQA,APqBA,A2BjFA,AFMA,AtBkEA,AENA,ANkBA,AmDzJA,AGTA,ACHA,ACHA,AJYA,AQxBA,AFMA,A5KogBA;A+G5UA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AKfA,AxHwWA,AuFrQA,APqBA,A2BjFA,AFMA,AtBkEA,AENA,ANkBA,AmDzJA,AGTA,ACHA,ACHA,AJYA,AQxBA,AFMA,A5KogBA;A+G5UA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AKfA,AxHwWA,AuFrQA,APqBA,A2BjFA,AFMA,AtBkEA,AENA,ANkBA,AmDzJA,AGTA,ACHA,ACHA,AJYA,AQxBA,AFMA,A5KogBA;A+G5UA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AKfA,AxHwWA,AuFrQA,APqBA,A2BjFA,AFMA,AtBkEA,AENA,ANkBA,AmDzJA,AGTA,ACHA,ACHA,AJYA,AQxBA,AFMA,A5KogBA;A+G5UA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AKfA,AxHwWA,AuFrQA,APqBA,A2BjFA,AFMA,AtBkEA,AENA,ANkBA,AmDzJA,AGTA,ACHA,ACHA,AJYA,AQxBA,AFMA,A5KogBA;A+G5UA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AKfA,AxHwWA,AuFrQA,APqBA,A2BjFA,AFMA,AtBkEA,AENA,ANkBA,AsDlKA,ACHA,ACHA,AJYA,AQxBA,AFMA,A5KogBA;A+G5UA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AKfA,AxHwWA,AuFrQA,APqBA,A2BjFA,AFMA,AtBkEA,AENA,ANkBA,AsDlKA,ACHA,ACHA,AJYA,AQxBA,AFMA,A5KogBA;A+G5UA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AKfA,AxHwWA,AuFrQA,APqBA,A2BjFA,AFMA,AtBkEA,AENA,ANkBA,AsDlKA,ACHA,AHSA,AQxBA,AFMA,A5KogBA;A+G5UA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AKfA,AxHwWA,AuFrQA,APqBA,A2BjFA,AFMA,AtBkEA,AENA,ANkBA,AsDlKA,AFMA,AQxBA,AFMA,A5KogBA;A+G5UA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AKfA,AxHwWA,AuFrQA,APqBA,A2BjFA,AFMA,AtBkEA,AENA,ANkBA,AsDlKA,AFMA,AQxBA,AFMA,A5KogBA;A+G5UA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AKfA,AxHwWA,AuFrQA,APqBA,A2BjFA,AFMA,AtBkEA,AENA,ANkBA,AsDlKA,AFMA,AQxBA,AFMA,A5KogBA;A+G5UA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AKfA,AxHwWA,AuFrQA,APqBA,A2BjFA,AFMA,AtBkEA,AENA,ANkBA,AsDlKA,AFMA,AQxBA,AFMA,A5KogBA;A+G5UA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AKfA,AxHwWA,AuFrQA,APqBA,A2BjFA,AFMA,AtBkEA,AENA,ANkBA,AsDlKA,AFMA,AQxBA,AFMA,A5KogBA;A+G5UA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AKfA,AxHwWA,AuFrQA,APqBA,A2BjFA,AFMA,AtBkEA,AENA,ANkBA,AsDlKA,AFMA,AQxBA,AFMA,A5KogBA;A+G5UA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AKfA,AxHwWA,AuFrQA,APqBA,A2BjFA,AFMA,AtBkEA,AENA,ANkBA,AsDlKA,AFMA,AQxBA,AFMA,A5KogBA;A+G5UA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AKfA,AxHwWA,AuFrQA,APqBA,A2BjFA,AFMA,AtBkEA,AENA,ANkBA,AsDlKA,AFMA,AQxBA,AFMA,A5KogBA;A+G5UA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AKfA,AxHwWA,AuFrQA,APqBA,A2BjFA,AFMA,AtBkEA,AENA,ANkBA,AsDlKA,AFMA,AQxBA,AFMA,A5KogBA;A+G5UA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AKfA,AxHwWA,AuFrQA,APqBA,A2BjFA,AFMA,AtBkEA,AENA,ANkBA,AsDlKA,AFMA,AQxBA,AFMA,A5KogBA;A+G5UA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AKfA,AxHwWA,AuFrQA,APqBA,A2BjFA,AFMA,AtBkEA,AENA,ANkBA,AsDlKA,AFMA,AQxBA,AFMA,A5KogBA;A+G5UA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AKfA,AxHwWA,AuFrQA,APqBA,A2BjFA,AFMA,AtBkEA,AENA,ANkBA,AsDlKA,AFMA,AQxBA,AFMA,A5KogBA;A+G5UA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AKfA,AxHwWA,AuFrQA,APqBA,A2BjFA,AFMA,AtBkEA,AENA,ANkBA,AsDlKA,AFMA,AQxBA,AFMA,A5KogBA;A+G5UA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AKfA,AxHwWA,AuFrQA,APqBA,AyB3EA,AtBkEA,AENA,ANkBA,AsDlKA,AFMA,AQxBA,AFMA,A5KogBA;A+G5UA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AKfA,AxHwWA,AuFrQA,APqBA,AyB3EA,AtBkEA,AENA,ANkBA,AsDlKA,AFMA,AQxBA,AFMA,A5KogBA;A+G5UA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AKfA,AxHwWA,AuFrQA,APqBA,AyB3EA,AtBkEA,AENA,ANkBA,AsDlKA,AMlBA,AFMA,A5KogBA;A+G5UA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AKfA,AxHwWA,AuFrQA,APqBA,AyB3EA,AtBkEA,AENA,ANkBA,AsDlKA,AMlBA,AFMA,A5KogBA;A+G5UA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AKfA,AxHwWA,AuFrQA,APqBA,AyB3EA,AtBkEA,AENA,ANkBA,AsDlKA,AMlBA,AFMA,A5KogBA;A+G5UA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AKfA,AxHwWA,AuFrQA,APqBA,AyB3EA,AtBkEA,AENA,ANkBA,AsDlKA,AMlBA,AFMA,A5KogBA;A+G5UA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AKfA,AxHwWA,AuFrQA,APqBA,AyB3EA,AtBkEA,AENA,ANkBA,AsDlKA,AMlBA,AFMA,A5KogBA;A+G5UA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AKfA,AxHwWA,AuFrQA,APqBA,AyB3EA,AtBkEA,AENA,ANkBA,AsDlKA,AMlBA,AFMA,A5KogBA;A+G5UA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AKfA,AxHwWA,AuFrQA,APqBA,AyB3EA,AtBkEA,AENA,ANkBA,AsDlKA,AMlBA,AFMA,A5KogBA;A+G5UA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AKfA,AxHwWA,AuFrQA,APqBA,AyB3EA,AtBkEA,AENA,ANkBA,AsDlKA,AMlBA,AFMA,A5KogBA;A+G5UA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AKfA,AxHwWA,AuFrQA,APqBA,AyB3EA,AtBkEA,AENA,ANkBA,AsDlKA,AMlBA,AFMA,A5KogBA;A+G5UA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AKfA,AxHwWA,AuFrQA,APqBA,AyB3EA,AtBkEA,AENA,ANkBA,AsDlKA,AMlBA,AFMA,A5KogBA;A+G5UA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AKfA,AxHwWA,AuFrQA,APqBA,AyB3EA,AtBkEA,AENA,ANkBA,AsDlKA,AMlBA,AFMA,A5KogBA;A+G5UA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AKfA,AxHwWA,AuFrQA,APqBA,AyB3EA,AtBkEA,AENA,ANkBA,AsDlKA,AMlBA,AFMA,A5KogBA;A+G5UA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AKfA,AxHwWA,AuFrQA,APqBA,AyB3EA,AtBkEA,AENA,ANkBA,A4DpLA,AFMA,A5KogBA;A+G5UA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AKfA,AxHwWA,AuFrQA,APqBA,AyB3EA,AtBkEA,AENA,ANkBA,A4DpLA,AFMA,A5KogBA;A+G5UA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AKfA,AxHwWA,AuFrQA,APqBA,AyB3EA,AtBkEA,AENA,ANkBA,A4DpLA,AFMA,A5KogBA;A+G5UA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AKfA,AxHwWA,AuFrQA,APqBA,AyB3EA,AtBkEA,AENA,ANkBA,A4DpLA,AFMA,A5KogBA;A+G5UA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AKfA,AxHwWA,AuFrQA,APqBA,AyB3EA,AtBkEA,AENA,ANkBA,A4DpLA,AFMA,A5KogBA;A+G5UA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AKfA,AxHwWA,AuFrQA,APqBA,AyB3EA,AtBkEA,AENA,ANkBA,A4DpLA,AFMA,A5KogBA;A+G5UA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AKfA,AxHwWA,AuFrQA,APqBA,AyB3EA,AtBkEA,AENA,ANkBA,A4DpLA,AFMA,A5KogBA;A+G5UA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AKfA,AxHwWA,AuFrQA,APqBA,AyB3EA,AtBkEA,AENA,ANkBA,A0D9KA,A5KogBA;A+G5UA,AzG2TA,AiEnMA,A5BoFA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AKfA,AxHwWA,AuFrQA,APqBA,AyB3EA,AtBkEA,AENA,ANkBA,A0D9KA,A5KogBA;A+G5UA,AzG2TA,AqC/GA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AKfA,AxHwWA,AuFrQA,APqBA,AyB3EA,AtBkEA,AENA,ANkBA,A0D9KA,A5KogBA;A+G5UA,AzG2TA,AqC/GA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AKfA,AxHwWA,AuFrQA,APqBA,AyB3EA,AtBkEA,AENA,ANkBA,A0D9KA,A5KogBA;A+G5UA,AzG2TA,AqC/GA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AKfA,AxHwWA,AuFrQA,APqBA,AyB3EA,AtBkEA,AENA,ANkBA,A0D9KA,A5KogBA;A+G5UA,AzG2TA,AqC/GA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AnHyVA,AuFrQA,APqBA,AyB3EA,AtBkEA,AENA,ANkBA,A0D9KA,A5KogBA;A+G5UA,AzG2TA,AqC/GA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AnHyVA,AuFrQA,APqBA,AyB3EA,AtBkEA,AENA,ANkBA,A0D9KA,A5KogBA;A+G5UA,AzG2TA,AqC/GA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AnHyVA,AuFrQA,APqBA,AyB3EA,AtBkEA,AENA,ANkBA,A0D9KA,A5KogBA;A+G5UA,AzG2TA,AqC/GA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AnHyVA,AuFrQA,APqBA,AyB3EA,AtBkEA,AENA,ANkBA,A0D9KA,A5KogBA;A+G5UA,AzG2TA,AqC/GA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AnHyVA,AuFrQA,APqBA,AyB3EA,AtBkEA,AENA,ANkBA,A0D9KA,A5KogBA;A+G5UA,AzG2TA,AqC/GA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AnHyVA,AuFrQA,APqBA,AyB3EA,AtBkEA,AENA,ANkBA,A0D9KA,A5KogBA;A+G5UA,AzG2TA,AqC/GA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AnHyVA,AuFrQA,APqBA,AyB3EA,AtBkEA,AENA,ANkBA,A0D9KA,A5KogBA;A+G5UA,AzG2TA,AqC/GA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AnHyVA,AuFrQA,APqBA,AyB3EA,AtBkEA,AENA,ANkBA,A0D9KA,A5KogBA;A+G5UA,AzG2TA,AqC/GA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AnHyVA,AuFrQA,APqBA,AyB3EA,AtBkEA,AENA,ANkBA,A0D9KA,A5KogBA;A+G5UA,AzG2TA,AqC/GA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AnHyVA,AuFrQA,APqBA,AyB3EA,AtBkEA,AENA,ANkBA,A0D9KA,A5KogBA;A+G5UA,AzG2TA,AqC/GA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AnHyVA,AuFrQA,APqBA,AyB3EA,AtBkEA,AENA,ANkBA,A0D9KA,A5KogBA;A+G5UA,AzG2TA,AqC/GA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AnHyVA,AuFrQA,APqBA,AyB3EA,AtBkEA,AENA,ANkBA,A0D9KA,A5KogBA;A+G5UA,AzG2TA,AqC/GA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AnHyVA,AuFrQA,APqBA,AyB3EA,AtBkEA,AENA,ANkBA,A0D9KA,A5KogBA;A+G5UA,AzG2TA,AqC/GA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AnHyVA,AuFrQA,APqBA,AyB3EA,AtBkEA,AENA,ANkBA,A0D9KA,A5KogBA;A+G5UA,AzG2TA,AqC/GA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AnHyVA,AuFrQA,APqBA,AyB3EA,ApB4DA,ANkBA,A0D9KA,A5KogBA;A+G5UA,AzG2TA,AqC/GA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AnHyVA,AuFrQA,APqBA,AyB3EA,ApB4DA,ANkBA,A0D9KA,A5KogBA;A+G5UA,AzG2TA,AqC/GA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AnHyVA,AuFrQA,APqBA,AyB3EA,ApB4DA,ANkBA,A0D9KA,A5KogBA;A+G5UA,AzG2TA,AqC/GA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AnHyVA,AuFrQA,APqBA,AyB3EA,ApB4DA,ANkBA,A0D9KA,A5KogBA;A+G5UA,AzG2TA,AqC/GA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AnHyVA,AuFrQA,APqBA,AyB3EA,ApB4DA,ANkBA,A0D9KA,A5KogBA;A+G5UA,AzG2TA,AqC/GA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AnHyVA,AuFrQA,APqBA,AyB3EA,ApB4DA,ANkBA,A0D9KA,A5KogBA;A+G5UA,AzG2TA,AqC/GA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AnHyVA,AuFrQA,APqBA,AyB3EA,ApB4DA,ANkBA,A0D9KA,A5KogBA;A+G5UA,AzG2TA,AqC/GA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AnHyVA,AuFrQA,APqBA,AyB3EA,ApB4DA,ANkBA,A0D9KA,A5KogBA;A+G5UA,AzG2TA,AqC/GA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AnHyVA,AuFrQA,APqBA,AyB3EA,ApB4DA,ANkBA,A0D9KA,A5KogBA;A+G5UA,AzG2TA,AqC/GA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AnHyVA,AuFrQA,APqBA,AyB3EA,ApB4DA,ANkBA,A0D9KA,A5KogBA;A+G5UA,AzG2TA,AqC/GA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AnHyVA,AuFrQA,APqBA,AyB3EA,ApB4DA,ANkBA,A0D9KA,A5KogBA;A+G5UA,AzG2TA,AqC/GA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AnHyVA,AuFrQA,APqBA,AyB3EA,ApB4DA,ANkBA,A0D9KA,A5KogBA;A+G5UA,AzG2TA,AqC/GA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AnHyVA,AuFrQA,APqBA,AyB3EA,ApB4DA,ANkBA,A0D9KA,A5KogBA;A+G5UA,AzG2TA,AqC/GA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AnHyVA,AuFrQA,APqBA,AyB3EA,ApB4DA,ANkBA,A0D9KA,A5KogBA;A+G5UA,AzG2TA,AqC/GA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AnHyVA,AuFrQA,APqBA,AyB3EA,ApB4DA,ANkBA,A0D9KA,A5KogBA;A+G5UA,AzG2TA,AqC/GA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AnHyVA,AuFrQA,APqBA,AyB3EA,ApB4DA,ANkBA,A0D9KA,A5KogBA;A+G5UA,AzG2TA,AqC/GA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AnHyVA,AuFrQA,APqBA,AyB3EA,ApB4DA,ANkBA,AlHsVA;A+G5UA,AzG2TA,AqC/GA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AnHyVA,AuFrQA,APqBA,AyB3EA,ApB4DA,ANkBA,AlHsVA;A+G5UA,AzG2TA,AqC/GA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AnHyVA,AuFrQA,APqBA,AyB3EA,ApB4DA,ANkBA,AlHsVA;A+G5UA,AzG2TA,AqC/GA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AnHyVA,AuFrQA,APqBA,AyB3EA,ApB4DA,ANkBA,AlHsVA;A+G5UA,AzG2TA,AqC/GA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AnHyVA,AuFrQA,APqBA,AyB3EA,ApB4DA,ANkBA,AlHsVA;A+G5UA,AzG2TA,AqC/GA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AnHyVA,AuFrQA,APqBA,AyB3EA,ApB4DA,ANkBA,AlHsVA;A+G5UA,AzG2TA,AqC/GA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AnHyVA,AuFrQA,APqBA,AyB3EA,ApB4DA,ANkBA,AlHsVA;A+G5UA,AzG2TA,AqC/GA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AnHyVA,AuFrQA,APqBA,AyB3EA,ApB4DA,ANkBA,AlHsVA;A+G5UA,AzG2TA,AqC/GA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AnHyVA,AuFrQA,APqBA,AyB3EA,ApB4DA,ANkBA,AlHsVA;A+G5UA,AzG2TA,AqC/GA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AnHyVA,AuFrQA,APqBA,AyB3EA,ApB4DA,ANkBA,AlHsVA;A+G5UA,AzG2TA,AqC/GA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AnHyVA,AuFrQA,APqBA,AyB3EA,ApB4DA,ANkBA,AlHsVA;A+G5UA,AzG2TA,AqC/GA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AnHyVA,AuFrQA,APqBA,AyB3EA,ApB4DA,ANkBA,AlHsVA;A+G5UA,AzG2TA,AqC/GA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AnHyVA,AuFrQA,APqBA,AyB3EA,ApB4DA,ANkBA,AlHsVA;A+G5UA,AzG2TA,AqC/GA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AnHyVA,AuFrQA,APqBA,AyB3EA,ApB4DA,ANkBA,AlHsVA;A+G5UA,AzG2TA,AqC/GA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AnHyVA,AuFrQA,APqBA,AyB3EA,ApB4DA,ANkBA,AlHsVA;A+G5UA,AzG2TA,AqC/GA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AnHyVA,AuFrQA,APqBA,AyB3EA,ApB4DA,ANkBA,AlHsVA;A+G5UA,AzG2TA,AqC/GA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AnHyVA,AuFrQA,APqBA,AyB3EA,ApB4DA,ANkBA,AlHsVA;A+G5UA,AzG2TA,AqC/GA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AnHyVA,AuFrQA,APqBA,AyB3EA,ApB4DA,ANkBA,AlHsVA;A+G5UA,AzG2TA,AqC/GA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AnHyVA,AuFrQA,APqBA,AyB3EA,ApB4DA,ANkBA,AlHsVA;A+G5UA,AzG2TA,AqC/GA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AnHyVA,AuFrQA,APqBA,AyB3EA,ApB4DA,ANkBA,AlHsVA;A+G5UA,AzG2TA,AqC/GA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AnHyVA,AuFrQA,APqBA,AyB3EA,ApB4DA,ANkBA,AlHsVA;A+G5UA,AzG2TA,AqC/GA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AnHyVA,AuFrQA,APqBA,AyB3EA,ApB4DA,ANkBA,AlHsVA;A+G5UA,AzG2TA,AqC/GA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AnHyVA,AuFrQA,APqBA,AyB3EA,ApB4DA,ANkBA,AlHsVA;A+G5UA,AzG2TA,AqC/GA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AnHyVA,AuFrQA,APqBA,AyB3EA,ApB4DA,ANkBA,AlHsVA;A+G5UA,AzG2TA,AqC/GA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AnHyVA,AuFrQA,APqBA,AyB3EA,ApB4DA,ANkBA,AlHsVA;A+G5UA,AzG2TA,AqC/GA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AnHyVA,AuFrQA,APqBA,AyB3EA,ApB4DA,ANkBA,AlHsVA;A+G5UA,AzG2TA,AqC/GA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AnHyVA,AuFrQA,APqBA,AyB3EA,ApB4DA,ANkBA,AlHsVA;A+G5UA,AzG2TA,AqC/GA,AhDgJA,A8J1dA,ACHA,APqBA,ACHA,AIZA,AFMA,AnHyVA,AuFrQA,APqBA,AyB3EA,ApB4DA,ANkBA,AlHsVA;A+G5UA,AzG2TA,AqC/GA,AhDgJA,A8J1dA,ACHA,APqBA,AKfA,AFMA,AnHyVA,AuFrQA,APqBA,AyB3EA,ApB4DA,ANkBA,AlHsVA;A+G5UA,AzG2TA,AqC/GA,AhDgJA,A8J1dA,ACHA,APqBA,AKfA,AFMA,AnHyVA,AuFrQA,APqBA,AyB3EA,ApB4DA,ANkBA,AlHsVA;A+G5UA,AzG2TA,AqC/GA,AhDgJA,A8J1dA,ACHA,APqBA,AKfA,AFMA,AnHyVA,AuFrQA,APqBA,AyB3EA,ApB4DA,ANkBA,AlHsVA;A+G5UA,AzG2TA,AqC/GA,AhDgJA,A8J1dA,ACHA,APqBA,AKfA,AFMA,AnHyVA,AuFrQA,APqBA,AyB3EA,ApB4DA,ANkBA,AlHsVA;A+G5UA,AzG2TA,AqC/GA,AhDgJA,A8J1dA,ACHA,APqBA,AKfA,AFMA,AnHyVA,AuFrQA,APqBA,AyB3EA,ApB4DA,ANkBA,AlHsVA;A+G5UA,AzG2TA,AqC/GA,AhDgJA,A8J1dA,ACHA,APqBA,AKfA,AFMA,AnHyVA,AuFrQA,APqBA,AyB3EA,ApB4DA,ANkBA,AlHsVA;A+G5UA,AzG2TA,AqC/GA,AhDgJA,A8J1dA,ACHA,APqBA,AKfA,AFMA,AnHyVA,AuFrQA,APqBA,AyB3EA,ApB4DA,ANkBA,AlHsVA;A+G5UA,AzG2TA,AqC/GA,AhDgJA,A8J1dA,ACHA,APqBA,AKfA,AFMA,AnHyVA,AuFrQA,APqBA,AyB3EA,ApB4DA,ANkBA,AlHsVA;A+G5UA,AzG2TA,AqC/GA,AhDgJA,A8J1dA,ACHA,APqBA,AKfA,AFMA,AnHyVA,AuFrQA,APqBA,AyB3EA,ApB4DA,ANkBA,AlHsVA;A+G5UA,AzG2TA,AqC/GA,AhDgJA,A8J1dA,ACHA,APqBA,AKfA,AFMA,AnHyVA,AuFrQA,APqBA,AyB3EA,ApB4DA,ANkBA,AlHsVA;A+G5UA,AzG2TA,AqC/GA,AhDgJA,A8J1dA,ACHA,APqBA,AKfA,AFMA,AnHyVA,AuFrQA,APqBA,AyB3EA,ApB4DA,ANkBA,AlHsVA;A+G5UA,AzG2TA,AqC/GA,AhDgJA,A8J1dA,ACHA,APqBA,AKfA,AFMA,AnHyVA,AuFrQA,APqBA,AyB3EA,ApB4DA,ANkBA,AlHsVA;A+G5UA,AzG2TA,AqC/GA,AhDgJA,A8J1dA,ACHA,APqBA,AKfA,AFMA,AnHyVA,AuFrQA,APqBA,AyB3EA,ApB4DA,ANkBA,AlHsVA;A+G5UA,AzG2TA,AqC/GA,AhDgJA,A8J1dA,ACHA,APqBA,AGTA,AnHyVA,AuFrQA,APqBA,AyB3EA,ApB4DA,ANkBA,AlHsVA;A+G5UA,AzG2TA,AqC/GA,AhDgJA,A8J1dA,ACHA,APqBA,AGTA,AnHyVA,AuFrQA,APqBA,AyB3EA,ApB4DA,ANkBA,AlHsVA;A+G5UA,AzG2TA,AqC/GA,AhDgJA,A8J1dA,ACHA,APqBA,AGTA,AnHyVA,AuFrQA,APqBA,AyB3EA,ApB4DA,ANkBA,AlHsVA;A+G5UA,AzG2TA,AqC/GA,AhDgJA,A8J1dA,ACHA,APqBA,AGTA,AnHyVA,AuFrQA,APqBA,AyB3EA,ApB4DA,ANkBA,AlHsVA;A+G5UA,AzG2TA,AqC/GA,AhDgJA,A8J1dA,ACHA,APqBA,AGTA,AnHyVA,AuFrQA,APqBA,AyB3EA,ApB4DA,ANkBA,AlHsVA;A+G5UA,AzG2TA,AqC/GA,AhDgJA,A8J1dA,ACHA,APqBA,AGTA,AnHyVA,AuFrQA,APqBA,AyB3EA,ApB4DA,ANkBA,AlHsVA;A+G5UA,AzG2TA,AqC/GA,AhDgJA,A8J1dA,ACHA,APqBA,AGTA,AnHyVA,AuFrQA,APqBA,AyB3EA,ApB4DA,ANkBA,AlHsVA;A+G5UA,AzG2TA,AqC/GA,AhDgJA,A8J1dA,ACHA,APqBA,AGTA,AnHyVA,AuFrQA,APqBA,AyB3EA,ApB4DA,ANkBA,AlHsVA;A+G5UA,AzG2TA,AqC/GA,AhDgJA,A8J1dA,ACHA,APqBA,AGTA,AnHyVA,AuFrQA,APqBA,AyB3EA,ApB4DA,ANkBA,AlHsVA;A+G5UA,AzG2TA,AqC/GA,A8G1UA,ACHA,APqBA,AGTA,AnHyVA,AuFrQA,APqBA,AyB3EA,ApB4DA,ANkBA,AlHsVA;A+G5UA,AzG2TA,AmJzbA,ACHA,APqBA,AGTA,AnHyVA,AuFrQA,APqBA,AyB3EA,ApB4DA,ANkBA,AlHsVA;A+G5UA,AzG2TA,AmJzbA,ACHA,APqBA,AGTA,AnHyVA,AuFrQA,APqBA,AyB3EA,ApB4DA,ANkBA,AlHsVA;A+G5UA,AzG2TA,AmJzbA,ACHA,APqBA,AGTA,AnHyVA,AuFrQA,APqBA,AyB3EA,ApB4DA,ANkBA,AlHsVA;A+G5UA,AzG2TA,AmJzbA,ACHA,APqBA,AGTA,AnHyVA,AuFrQA,APqBA,AyB3EA,ApB4DA,ANkBA,AlHsVA;A+G5UA,AzG2TA,AmJzbA,ACHA,APqBA,AGTA,AnHyVA,AuFrQA,APqBA,AyB3EA,ApB4DA,ANkBA,AlHsVA;A+G5UA,AzG2TA,AmJzbA,ACHA,APqBA,AGTA,AnHyVA,AuFrQA,APqBA,AyB3EA,ApB4DA,ANkBA,AlHsVA;A+G5UA,AzG2TA,AmJzbA,ACHA,APqBA,AGTA,AnHyVA,AuFrQA,APqBA,AyB3EA,ApB4DA,ANkBA,AlHsVA;A+G5UA,AzG2TA,AmJzbA,ACHA,APqBA,AGTA,AnHyVA,AuFrQA,APqBA,AyB3EA,ApB4DA,ANkBA,AlHsVA;A+G5UA,AzG2TA,AoJ5bA,APqBA,AGTA,AnHyVA,AuFrQA,APqBA,AyB3EA,ApB4DA,ANkBA,AlHsVA;A+G5UA,AzG2TA,AoJ5bA,APqBA,AGTA,AnHyVA,AuFrQA,APqBA,AyB3EA,ApB4DA,ANkBA,AlHsVA;A+G5UA,AzG2TA,AoJ5bA,APqBA,AGTA,AnHyVA,AuFrQA,APqBA,AyB3EA,ApB4DA,ANkBA,AlHsVA;A+G5UA,AzG2TA,AoJ5bA,APqBA,AGTA,AnHyVA,AuFrQA,APqBA,AyB3EA,ApB4DA,ANkBA,AlHsVA;A+G5UA,AzG2TA,AoJ5bA,APqBA,AGTA,AnHyVA,AuFrQA,APqBA,AyB3EA,ApB4DA,ANkBA,AlHsVA;A+G5UA,AzG2TA,AoJ5bA,APqBA,AGTA,AnHyVA,AuFrQA,APqBA,AyB3EA,ApB4DA,ANkBA,AlHsVA;A+G5UA,AzG2TA,AoJ5bA,APqBA,AGTA,AnHyVA,AuFrQA,APqBA,AyB3EA,ApB4DA,ANkBA,AlHsVA;A+G5UA,AzG2TA,AoJ5bA,APqBA,AGTA,AnHyVA,AuFrQA,APqBA,AyB3EA,ApB4DA,ANkBA,AlHsVA;A+G5UA,AzG2TA,AoJ5bA,APqBA,AGTA,AnHyVA,AuFrQA,APqBA,AyB3EA,ApB4DA,ANkBA,AlHsVA;A+G5UA,AzG2TA,AoJ5bA,APqBA,AGTA,AnHyVA,AuFrQA,APqBA,AyB3EA,ApB4DA,ANkBA,AlHsVA;A+G5UA,AzG2TA,AoJ5bA,APqBA,AGTA,AnHyVA,AuFrQA,APqBA,AyB3EA,ApB4DA,ANkBA,AlHsVA;A+G5UA,AzG2TA,AoJ5bA,APqBA,AGTA,AnHyVA,AuFrQA,APqBA,AyB3EA,ApB4DA,ANkBA,AlHsVA;A+G5UA,AzG2TA,AoJ5bA,APqBA,AGTA,AnHyVA,AuFrQA,APqBA,AyB3EA,ApB4DA,ANkBA,AlHsVA;A+G5UA,AzG2TA,AoJ5bA,APqBA,AGTA,AnHyVA,AuFrQA,APqBA,AyB3EA,ApB4DA,ANkBA,AlHsVA;A+G5UA,AzG2TA,A6IvaA,AGTA,AnHyVA,AuFrQA,APqBA,AyB3EA,ApB4DA,ANkBA,AlHsVA;A+G5UA,AzG2TA,A6IvaA,AGTA,AnHyVA,AuFrQA,APqBA,AyB3EA,ApB4DA,ANkBA,AlHsVA;A+G5UA,AzG2TA,A6IvaA,AGTA,AnHyVA,AuFrQA,APqBA,AyB3EA,ApB4DA,ANkBA,AlHsVA;A+G5UA,AzG2TA,AgJhbA,AnHyVA,AuFrQA,APqBA,AyB3EA,ApB4DA,ANkBA,AlHsVA;A+G5UA,AzG2TA,AgJhbA,AnHyVA,AuFrQA,APqBA,AyB3EA,ApB4DA,ANkBA,AlHsVA;A+G5UA,AzG2TA,AgJhbA,AnHyVA,AuFrQA,APqBA,AyB3EA,ApB4DA,ANkBA,AlHsVA;A+G5UA,AzG2TA,AgJhbA,AnHyVA,AuFrQA,APqBA,AyB3EA,ApB4DA,ANkBA,AlHsVA;A+G5UA,AzG2TA,AgJhbA,AnHyVA,AuFrQA,APqBA,AyB3EA,ApB4DA,ANkBA,AlHsVA;A+G5UA,AzG2TA,AgJhbA,AnHyVA,AuFrQA,APqBA,AyB3EA,ApB4DA,ANkBA,AlHsVA;A+G5UA,AzG2TA,AgJhbA,AnHyVA,AuFrQA,APqBA,AyB3EA,ApB4DA,ANkBA,AlHsVA;A+G5UA,AzG2TA,AgJhbA,AnHyVA,AuFrQA,APqBA,AyB3EA,ApB4DA,ANkBA,AlHsVA;A+G5UA,AzG2TA,AgJhbA,AnHyVA,AuFrQA,APqBA,AyB3EA,ApB4DA,ANkBA,AlHsVA;A+G5UA,AzG2TA,AgJhbA,AnHyVA,AuFrQA,APqBA,AyB3EA,ApB4DA,ANkBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,AKfA,ANkBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,AKfA,ANkBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,AKfA,ANkBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,AKfA,ANkBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,AKfA,ANkBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,AKfA,ANkBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,AKfA,ANkBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,AKfA,ANkBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,AKfA,ANkBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,AKfA,ANkBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,AKfA,ANkBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,AKfA,ANkBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,AKfA,ANkBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,AKfA,ANkBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,AKfA,ANkBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,AKfA,ANkBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,AKfA,ANkBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,AKfA,ANkBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,AKfA,ANkBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,AKfA,ANkBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,AKfA,ANkBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,AKfA,ANkBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,AKfA,ANkBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,AKfA,ANkBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,AKfA,ANkBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,AKfA,ANkBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,AKfA,ANkBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,AKfA,ANkBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,AKfA,ANkBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,AKfA,ANkBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,AKfA,ANkBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,AKfA,ANkBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,AKfA,ANkBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,AKfA,ANkBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,AKfA,ANkBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,AKfA,ANkBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,AKfA,ANkBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,AKfA,ANkBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,AKfA,ANkBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,AKfA,ANkBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,AKfA,ANkBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,AKfA,ANkBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,AKfA,ANkBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,AKfA,ANkBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,AKfA,ANkBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,AKfA,ANkBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,AKfA,ANkBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,AKfA,ANkBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,AKfA,ANkBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,AKfA,ANkBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,AKfA,ANkBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,AKfA,ANkBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,AKfA,ANkBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,AKfA,ANkBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,AKfA,ANkBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,AKfA,ANkBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,AKfA,ANkBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,AKfA,ANkBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,AKfA,ANkBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,AKfA,ANkBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,AKfA,ANkBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,AKfA,ANkBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,AKfA,ANkBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,AKfA,ANkBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,AKfA,ANkBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,AKfA,ANkBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,AKfA,ANkBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,AKfA,ANkBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,AKfA,ANkBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,AKfA,ANkBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,AKfA,ANkBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,AKfA,ANkBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,AKfA,ANkBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,AKfA,ANkBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,AKfA,ANkBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,AKfA,ANkBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,AKfA,ANkBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,AKfA,ANkBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,AKfA,ANkBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,AKfA,ANkBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,AKfA,ANkBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,AKfA,ANkBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,AKfA,ANkBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,AKfA,ANkBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,AKfA,ANkBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,AKfA,ANkBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,AKfA,ANkBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,AKfA,ANkBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,AKfA,ANkBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,AKfA,ANkBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,AKfA,ANkBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,AKfA,ANkBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,AKfA,ANkBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,AKfA,ANkBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,AKfA,ANkBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,AKfA,ANkBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,AKfA,ANkBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,AKfA,ANkBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,AKfA,ANkBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,AKfA,ANkBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,AKfA,ANkBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,AKfA,ANkBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,AKfA,ANkBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,AKfA,ANkBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,AKfA,ANkBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,ADGA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,ADGA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,ADGA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,ADGA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,ADGA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,ADGA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,ADGA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,ADGA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,ADGA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,ADGA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,ADGA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,ADGA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,ADGA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,ADGA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,ADGA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,ADGA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,ADGA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,ADGA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,ADGA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,ADGA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,ADGA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,ADGA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,ADGA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,ADGA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,ADGA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,ADGA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,ADGA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,ADGA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,ADGA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,ADGA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,ADGA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,ADGA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,ADGA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,ADGA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,ADGA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,ADGA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,ADGA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,ADGA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,ADGA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,ADGA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,ADGA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,ADGA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,ADGA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,ADGA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,ADGA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,ADGA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,ADGA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,ADGA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,ADGA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,ADGA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,ADGA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,ADGA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,ADGA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,ADGA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,ADGA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,ADGA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,ADGA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,ADGA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,ADGA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,ADGA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,ADGA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,ADGA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,ADGA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,ADGA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,ADGA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,ADGA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,ADGA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,ADGA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,ADGA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,ADGA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,ADGA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,ADGA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,ADGA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,ADGA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,ADGA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,ADGA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,ADGA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,ADGA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,ADGA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,ADGA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,ADGA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,ADGA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,ADGA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,ADGA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,ADGA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,APqBA,ADGA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,ARwBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,ARwBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,ARwBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,ARwBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,ARwBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,ARwBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,ARwBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,ARwBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,ARwBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,ARwBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,ARwBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,ARwBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,ARwBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,ARwBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,ARwBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,ARwBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,ARwBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,ARwBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,ARwBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,ARwBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,ARwBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,ARwBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,ARwBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,ARwBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,ARwBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,ARwBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,ARwBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,ARwBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,ARwBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,ARwBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,ARwBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,ARwBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,ARwBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,ARwBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,ARwBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,ARwBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,ARwBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,ARwBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,ARwBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,ARwBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,ARwBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,ARwBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,ARwBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,ARwBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,ARwBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,ARwBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,ARwBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,ARwBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,ARwBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,ARwBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,ARwBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,ARwBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,ARwBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,ARwBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,ARwBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,ARwBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,ARwBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,ARwBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,ARwBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,ARwBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,ARwBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,ARwBA,AlHsVA;A+G5UA,AzG2TA,A6BvFA,AuFrQA,ARwBA,AlHsVA;A+G5UA,AzG2TA,AoH5VA,ARwBA,AlHsVA;A+G5UA,AzG2TA,AoH5VA,ARwBA,AlHsVA;A+G5UA,AzG2TA,AoH5VA,ARwBA,AlHsVA;A+G5UA,AzG2TA,AoH5VA,ARwBA,AlHsVA;A+G5UA,AzG2TA,AoH5VA,ARwBA,AlHsVA;A+G5UA,AzG2TA,AoH5VA,ARwBA,AlHsVA;A+G5UA,AzG2TA,AoH5VA,ARwBA,AlHsVA;A+G5UA,AzG2TA,AoH5VA,ARwBA,AlHsVA;A+G5UA,AzG2TA,AoH5VA,ARwBA,AlHsVA;A+G5UA,AzG2TA,AoH5VA,ARwBA,AlHsVA;A+G5UA,AzG2TA,AoH5VA,ARwBA,AlHsVA;A+G5UA,AzG2TA,AoH5VA,ARwBA,AlHsVA;A+G5UA,AzG2TA,AoH5VA,ARwBA,AlHsVA;A+G5UA,AzG2TA,AoH5VA,ARwBA,AlHsVA;A+G5UA,AzG2TA,AoH5VA,ARwBA,AlHsVA;A+G5UA,AzG2TA,AoH5VA,ARwBA,AlHsVA;A+G5UA,AzG2TA,AoH5VA,ARwBA,AlHsVA;A+G5UA,AzG2TA,AoH5VA,ARwBA,AlHsVA;A+G5UA,AzG2TA,AoH5VA,ARwBA,AlHsVA;A+G5UA,AzG2TA,AoH5VA,ARwBA,AlHsVA;A+G5UA,AzG2TA,AoH5VA,ARwBA,AlHsVA;A+G5UA,AzG2TA,AoH5VA,ARwBA,AlHsVA;A+G5UA,AzG2TA,AoH5VA,ARwBA,AlHsVA;A+G5UA,AzG2TA,AoH5VA,ARwBA,AlHsVA;A+G5UA,AzG2TA,AoH5VA,ARwBA,AlHsVA;A+G5UA,AzG2TA,AoH5VA,ARwBA,AlHsVA;A+G5UA,AzG2TA,AoH5VA,ARwBA,AlHsVA;A+G5UA,AzG2TA,AoH5VA,ARwBA,AlHsVA;A+G5UA,AzG2TA,AoH5VA,ARwBA,AlHsVA;A+G5UA,AzG2TA,AoH5VA,ARwBA,AlHsVA;A+G5UA,AzG2TA,AoH5VA,ARwBA,AlHsVA;A+G5UA,AzG2TA,AoH5VA,ARwBA,AlHsVA;A+G5UA,AzG2TA,AoH5VA,ARwBA,AlHsVA;A+G5UA,AzG2TA,AoH5VA,ARwBA,AlHsVA;A+G5UA,AzG2TA,AoH5VA,ARwBA,AlHsVA;A+G5UA,AzG2TA,AoH5VA,ARwBA,AlHsVA;A+G5UA,AzG2TA,AoH5VA,ARwBA,AlHsVA;A+G5UA,AzG2TA,AoH5VA,ARwBA,AlHsVA;A+G5UA,AzG2TA,AoH5VA,ARwBA,AlHsVA;A+G5UA,AzG2TA,AoH5VA,ARwBA,AlHsVA;A+G5UA,AzG2TA,AoH5VA,ARwBA,AlHsVA;A+G5UA,AzG2TA,AoH5VA,ARwBA,AlHsVA;A+G5UA,AzG2TA,AoH5VA,ARwBA,AlHsVA;A+G5UA,AzG2TA,AoH5VA,ARwBA,AlHsVA;A+G5UA,AzG2TA,AoH5VA,ARwBA,AlHsVA;A+G5UA,AzG2TA,AoH5VA,ARwBA,AlHsVA;A+G5UA,AzG2TA,AoH5VA,ARwBA,AlHsVA;A+G5UA,AzG2TA,AoH5VA,ARwBA,AlHsVA;A+G5UA,AzG2TA,AoH5VA,ARwBA,AlHsVA;A+G5UA,AzG2TA,AoH5VA,ARwBA,AlHsVA;A+G5UA,AzG2TA,AoH5VA,ARwBA,AlHsVA;A+G5UA,AzG2TA,AoH5VA,ARwBA,AlHsVA;A+G5UA,AzG2TA,AoH5VA,ARwBA,AlHsVA;A+G5UA,AzG2TA,AoH5VA,ARwBA,AlHsVA;A+G5UA,AzG2TA,AoH5VA,ARwBA,AlHsVA;A+G5UA,AzG2TA,AoH5VA,ARwBA,AlHsVA;A+G5UA,AzG2TA,AoH5VA,ARwBA,AlHsVA;A+G5UA,AzG2TA,AoH5VA,ARwBA,AlHsVA;A+G5UA,AzG2TA,AoH5VA,ARwBA,AlHsVA;A+G5UA,AzG2TA,AoH5VA,ARwBA,AlHsVA;A+G5UA,AzG2TA,AoH5VA,ARwBA,AlHsVA;A+G5UA,AzG2TA,AoH5VA,ARwBA,AlHsVA;A+G5UA,AzG2TA,AoH5VA,ARwBA,AlHsVA;A+G5UA,AzG2TA,AoH5VA,ARwBA,AlHsVA;A+G5UA,AzG2TA,AoH5VA,ARwBA,AlHsVA;A+G5UA,AzG2TA,AoH5VA,ARwBA,AlHsVA;A+G5UA,AzG2TA,AoH5VA,ARwBA,AlHsVA;A+G5UA,AzG2TA,AoH5VA,ARwBA,AlHsVA;A+G5UA,AzG2TA,AoH5VA,ARwBA,AlHsVA;A+G5UA,AzG2TA,A4GpUA,AlHsVA;A+G5UA,AzG2TA,A4GpUA,AlHsVA;A+G5UA,AzG2TA,A4GpUA,AlHsVA;A+G5UA,AzG2TA,A4GpUA,AlHsVA;A+G5UA,AzG2TA,A4GpUA,AlHsVA;A+G5UA,AzG2TA,A4GpUA,AlHsVA;A+G5UA,AzG2TA,A4GpUA,AlHsVA;A+G5UA,AzG2TA,A4GpUA,AlHsVA;A+G5UA,AzG2TA,A4GpUA,AlHsVA;A+G5UA,AzG2TA,A4GpUA,AlHsVA;A+G5UA,AzG2TA,A4GpUA,AlHsVA;A+G5UA,AzG2TA,A4GpUA,AlHsVA;A+G5UA,AzG2TA,A4GpUA,AlHsVA;A+G5UA,AzG2TA,A4GpUA,AlHsVA;A+G5UA,AzG2TA,A4GpUA,AlHsVA;A+G5UA,AzG2TA,A4GpUA,AlHsVA;A+G5UA,AzG2TA,A4GpUA,AlHsVA;A+G5UA,AzG2TA,A4GpUA,AlHsVA;A+G5UA,AzG2TA,A4GpUA,AlHsVA;A+G5UA,AzG2TA,A4GpUA,AlHsVA;A+G5UA,AzG2TA,A4GpUA,AlHsVA;A+G5UA,AzG2TA,A4GpUA,AlHsVA;A+G5UA,AzG2TA,A4GpUA,AlHsVA;A+G5UA,AzG2TA,A4GpUA,AlHsVA;A+G5UA,AzG2TA,A4GpUA,AlHsVA;A+G5UA,AzG2TA,A4GpUA,AlHsVA;A+G5UA,AzG2TA,A4GpUA,AlHsVA;A+G5UA,AzG2TA,A4GpUA,AlHsVA;A+G5UA,AzG2TA,A4GpUA,AlHsVA;A+G5UA,AzG2TA,A4GpUA,AlHsVA;A+G5UA,AzG2TA,A4GpUA,AlHsVA;A+G5UA,AzG2TA,A4GpUA,AlHsVA;A+G5UA,AzG2TA,A4GpUA,AlHsVA;A+G5UA,AzG2TA,A4GpUA,AlHsVA;A+G5UA,AzG2TA,A4GpUA,AlHsVA;A+G5UA,AzG2TA,A4GpUA,AlHsVA;A+G5UA,AzG2TA,A4GpUA,AlHsVA;A+G5UA,AzG2TA,A4GpUA,AlHsVA;A+G5UA,AzG2TA,A4GpUA,AlHsVA;A+G5UA,AzG2TA,ANkBA;A+G5UA,AzG2TA,ANkBA;A+G5UA,AzG2TA,ANkBA;A+G5UA,AzG2TA,ANkBA;A+G5UA,AzG2TA,ANkBA;A+G5UA,AzG2TA,ANkBA;A+G5UA,AzG2TA,ANkBA;A+G5UA,AzG2TA,ANkBA;A+G5UA,AzG2TA,ANkBA;A+G5UA,AzG2TA,ANkBA;A+G5UA,AzG2TA,ANkBA;A+G5UA,AzG2TA,ANkBA;A+G5UA,AzG2TA,ANkBA;A+G5UA,AzG2TA,ANkBA;A+G5UA,AzG2TA,ANkBA;A+G5UA,AzG2TA,ANkBA;A+G5UA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA,AzG2TA;AyG1TA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA","file":"index.js","sourcesContent":["\n/**\n * @license\n * Copyright 2017 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nfunction __export(m) {\n    for (var p in m) if (!exports.hasOwnProperty(p)) exports[p] = m[p];\n}\nObject.defineProperty(exports, \"__esModule\", { value: true });\n// Engine is the global singleton that needs to be initialized before the rest\n// of the app.\nrequire(\"./engine\");\n// Register backend-agnostic flags.\nrequire(\"./flags\");\n// backend_cpu.ts and backend_webgl.ts are standalone files and should be\n// explicitly included here.\nrequire(\"./backends/webgl/backend_webgl\");\nrequire(\"./backends/cpu/backend_cpu\");\nrequire(\"./platforms/platform_browser\");\nrequire(\"./platforms/platform_node\");\nvar backend_util = require(\"./backends/backend_util\");\nexports.backend_util = backend_util;\nvar environment = require(\"./environment\");\nexports.environment = environment;\n// Serialization.\nvar io = require(\"./io/io\");\nexports.io = io;\nvar math = require(\"./math\");\nexports.math = math;\nvar browser = require(\"./ops/browser\");\nexports.browser = browser;\nvar serialization = require(\"./serialization\");\nexports.serialization = serialization;\nvar tensor_1 = require(\"./tensor\");\nvar tensor_util = require(\"./tensor_util\");\nexports.tensor_util = tensor_util;\nvar test_util = require(\"./test_util\");\nexports.test_util = test_util;\nvar util = require(\"./util\");\nexports.util = util;\nvar version_1 = require(\"./version\");\nexports.version_core = version_1.version;\nvar webgl = require(\"./webgl\");\nexports.webgl = webgl;\n// Optimizers.\nvar adadelta_optimizer_1 = require(\"./optimizers/adadelta_optimizer\");\nexports.AdadeltaOptimizer = adadelta_optimizer_1.AdadeltaOptimizer;\nvar adagrad_optimizer_1 = require(\"./optimizers/adagrad_optimizer\");\nexports.AdagradOptimizer = adagrad_optimizer_1.AdagradOptimizer;\nvar adam_optimizer_1 = require(\"./optimizers/adam_optimizer\");\nexports.AdamOptimizer = adam_optimizer_1.AdamOptimizer;\nvar adamax_optimizer_1 = require(\"./optimizers/adamax_optimizer\");\nexports.AdamaxOptimizer = adamax_optimizer_1.AdamaxOptimizer;\nvar momentum_optimizer_1 = require(\"./optimizers/momentum_optimizer\");\nexports.MomentumOptimizer = momentum_optimizer_1.MomentumOptimizer;\nvar optimizer_1 = require(\"./optimizers/optimizer\");\nexports.Optimizer = optimizer_1.Optimizer;\nvar rmsprop_optimizer_1 = require(\"./optimizers/rmsprop_optimizer\");\nexports.RMSPropOptimizer = rmsprop_optimizer_1.RMSPropOptimizer;\nvar sgd_optimizer_1 = require(\"./optimizers/sgd_optimizer\");\nexports.SGDOptimizer = sgd_optimizer_1.SGDOptimizer;\nvar tensor_2 = require(\"./tensor\");\nexports.Tensor = tensor_2.Tensor;\nexports.TensorBuffer = tensor_2.TensorBuffer;\nexports.variable = tensor_2.variable;\nexports.Variable = tensor_2.Variable;\nvar types_1 = require(\"./types\");\nexports.Rank = types_1.Rank;\n__export(require(\"./ops/ops\"));\nvar loss_ops_1 = require(\"./ops/loss_ops\");\nexports.Reduction = loss_ops_1.Reduction;\n__export(require(\"./train\"));\n__export(require(\"./globals\"));\nvar gradients_1 = require(\"./gradients\");\nexports.customGrad = gradients_1.customGrad;\nexports.grad = gradients_1.grad;\nexports.grads = gradients_1.grads;\nexports.valueAndGrad = gradients_1.valueAndGrad;\nexports.valueAndGrads = gradients_1.valueAndGrads;\nexports.variableGrads = gradients_1.variableGrads;\nvar environment_1 = require(\"./environment\");\nexports.ENV = environment_1.ENV;\nexports.Environment = environment_1.Environment;\n// Top-level method exports.\nvar browser_util_1 = require(\"./browser_util\");\nexports.nextFrame = browser_util_1.nextFrame;\n// Backend specific.\nvar backend_1 = require(\"./backends/backend\");\nexports.KernelBackend = backend_1.KernelBackend;\nexports.DataStorage = backend_1.DataStorage;\nvar ops = require(\"./ops/ops\");\ntensor_1.setOpHandler(ops);\n//# sourceMappingURL=index.js.map","\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : new P(function (resolve) { resolve(result.value); }).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nvar __generator = (this && this.__generator) || function (thisArg, body) {\n    var _ = { label: 0, sent: function() { if (t[0] & 1) throw t[1]; return t[1]; }, trys: [], ops: [] }, f, y, t, g;\n    return g = { next: verb(0), \"throw\": verb(1), \"return\": verb(2) }, typeof Symbol === \"function\" && (g[Symbol.iterator] = function() { return this; }), g;\n    function verb(n) { return function (v) { return step([n, v]); }; }\n    function step(op) {\n        if (f) throw new TypeError(\"Generator is already executing.\");\n        while (_) try {\n            if (f = 1, y && (t = op[0] & 2 ? y[\"return\"] : op[0] ? y[\"throw\"] || ((t = y[\"return\"]) && t.call(y), 0) : y.next) && !(t = t.call(y, op[1])).done) return t;\n            if (y = 0, t) op = [op[0] & 2, t.value];\n            switch (op[0]) {\n                case 0: case 1: t = op; break;\n                case 4: _.label++; return { value: op[1], done: false };\n                case 5: _.label++; y = op[1]; op = [0]; continue;\n                case 7: op = _.ops.pop(); _.trys.pop(); continue;\n                default:\n                    if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) { _ = 0; continue; }\n                    if (op[0] === 3 && (!t || (op[1] > t[0] && op[1] < t[3]))) { _.label = op[1]; break; }\n                    if (op[0] === 6 && _.label < t[1]) { _.label = t[1]; t = op; break; }\n                    if (t && _.label < t[2]) { _.label = t[2]; _.ops.push(op); break; }\n                    if (t[2]) _.ops.pop();\n                    _.trys.pop(); continue;\n            }\n            op = body.call(thisArg, _);\n        } catch (e) { op = [6, e]; y = 0; } finally { f = t = 0; }\n        if (op[0] & 5) throw op[1]; return { value: op[0] ? op[1] : void 0, done: true };\n    }\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar environment_1 = require(\"./environment\");\nvar profiler_1 = require(\"./profiler\");\nvar tape_1 = require(\"./tape\");\nvar tensor_1 = require(\"./tensor\");\nvar tensor_util_1 = require(\"./tensor_util\");\nvar util = require(\"./util\");\nvar util_1 = require(\"./util\");\nvar EngineState = /** @class */ (function () {\n    function EngineState() {\n        // Public since optimizers will use it.\n        this.registeredVariables = {};\n        this.nextTapeNodeId = 0;\n        this.numBytes = 0;\n        this.numTensors = 0;\n        this.numStringTensors = 0;\n        this.numDataBuffers = 0;\n        // Number of nested tf.grad() statements when computing higher-order\n        // gradients. E.g. `1` for first-order gradients and `2` for second-order\n        // gradients. Used to track if the tape should be removed after a backprop.\n        this.gradientDepth = 0;\n        // Number of nested kernel calls. When kernel depth is greater than 1, we turn\n        // off the tape.\n        this.kernelDepth = 0;\n        this.scopeStack = [];\n        this.nextScopeId = 0;\n        this.tensorInfo = new WeakMap();\n        this.profiling = false;\n        this.activeProfile = { newBytes: 0, newTensors: 0, peakBytes: 0, kernels: [], result: null };\n    }\n    EngineState.prototype.dispose = function () {\n        for (var variableName in this.registeredVariables) {\n            this.registeredVariables[variableName].dispose();\n        }\n    };\n    return EngineState;\n}());\nvar Engine = /** @class */ (function () {\n    function Engine(ENV) {\n        this.ENV = ENV;\n        this.registry = {};\n        this.registryFactory = {};\n        this.pendingBackendInitId = 0;\n        this.state = new EngineState();\n    }\n    Engine.prototype.ready = function () {\n        return __awaiter(this, void 0, void 0, function () {\n            var sortedBackends, i, backendName, success;\n            return __generator(this, function (_a) {\n                switch (_a.label) {\n                    case 0:\n                        if (this.pendingBackendInit != null) {\n                            return [2 /*return*/, this.pendingBackendInit.then(function () { })];\n                        }\n                        if (this.backendInstance != null) {\n                            return [2 /*return*/];\n                        }\n                        sortedBackends = this.getSortedBackends();\n                        i = 0;\n                        _a.label = 1;\n                    case 1:\n                        if (!(i < sortedBackends.length)) return [3 /*break*/, 4];\n                        backendName = sortedBackends[i];\n                        return [4 /*yield*/, this.initializeBackend(backendName).success];\n                    case 2:\n                        success = _a.sent();\n                        if (success) {\n                            this.setBackend(backendName);\n                            return [2 /*return*/];\n                        }\n                        _a.label = 3;\n                    case 3:\n                        i++;\n                        return [3 /*break*/, 1];\n                    case 4: throw new Error(\"Could not initialize any backends, all backend initializations \" +\n                        \"failed.\");\n                }\n            });\n        });\n    };\n    Object.defineProperty(Engine.prototype, \"backend\", {\n        get: function () {\n            if (this.pendingBackendInit != null) {\n                throw new Error(\"Backend '\" + this.backendName + \"' has not yet been initialized. Make \" +\n                    \"sure to await tf.ready() before calling other methods\");\n            }\n            if (this.backendInstance == null) {\n                var _a = this.initializeBackendsAndReturnBest(), name_1 = _a.name, asyncInit = _a.asyncInit;\n                if (asyncInit) {\n                    throw new Error(\"The highest priority backend '\" + name_1 + \"' has not yet been \" +\n                        \"initialized. Make sure to await tf.ready() before calling \" +\n                        \"other methods\");\n                }\n                this.setBackend(name_1);\n            }\n            return this.backendInstance;\n        },\n        enumerable: true,\n        configurable: true\n    });\n    Engine.prototype.backendNames = function () {\n        return Object.keys(this.registryFactory);\n    };\n    Engine.prototype.findBackend = function (backendName) {\n        if (!(backendName in this.registry)) {\n            // If the backend hasn't been initialized but we have a registry entry for\n            // it, initialize it and return it.\n            if (backendName in this.registryFactory) {\n                var asyncInit = this.initializeBackend(backendName).asyncInit;\n                if (asyncInit) {\n                    // Backend is not ready yet.\n                    return null;\n                }\n            }\n            else {\n                return null;\n            }\n        }\n        return this.registry[backendName];\n    };\n    Engine.prototype.findBackendFactory = function (backendName) {\n        if (!(backendName in this.registryFactory)) {\n            return null;\n        }\n        return this.registryFactory[backendName].factory;\n    };\n    Engine.prototype.registerBackend = function (backendName, factory, priority) {\n        if (priority === void 0) { priority = 1; }\n        if (backendName in this.registryFactory) {\n            console.warn(backendName + \" backend was already registered. \" +\n                \"Reusing existing backend factory.\");\n            return false;\n        }\n        this.registryFactory[backendName] = { factory: factory, priority: priority };\n        return true;\n    };\n    Engine.prototype.setBackend = function (backendName) {\n        return __awaiter(this, void 0, void 0, function () {\n            var _a, success, asyncInit, result, _b;\n            return __generator(this, function (_c) {\n                switch (_c.label) {\n                    case 0:\n                        if (this.registryFactory[backendName] == null) {\n                            throw new Error(\"Backend name '\" + backendName + \"' not found in registry\");\n                        }\n                        this.backendName = backendName;\n                        if (!(this.registry[backendName] == null)) return [3 /*break*/, 4];\n                        this.backendInstance = null;\n                        _a = this.initializeBackend(backendName), success = _a.success, asyncInit = _a.asyncInit;\n                        if (!asyncInit) return [3 /*break*/, 2];\n                        return [4 /*yield*/, success];\n                    case 1:\n                        _b = _c.sent();\n                        return [3 /*break*/, 3];\n                    case 2:\n                        _b = success;\n                        _c.label = 3;\n                    case 3:\n                        result = _b;\n                        if (!result) {\n                            return [2 /*return*/, false];\n                        }\n                        _c.label = 4;\n                    case 4:\n                        this.backendInstance = this.registry[backendName];\n                        // Reset the profiler.\n                        this.profiler = new profiler_1.Profiler(this.backendInstance);\n                        return [2 /*return*/, true];\n                }\n            });\n        });\n    };\n    /**\n     * Initializes a backend by looking up the backend name in the factory\n     * registry and calling the factory method. Returns a boolean representing\n     * whether the initialization of the backend suceeded. Throws an error if\n     * there is no backend in the factory registry.\n     */\n    Engine.prototype.initializeBackend = function (backendName) {\n        var _this = this;\n        var registryFactoryEntry = exports.ENGINE.registryFactory[backendName];\n        if (registryFactoryEntry == null) {\n            throw new Error(\"Cannot initialize backend \" + backendName + \", no registration found.\");\n        }\n        try {\n            var backend = registryFactoryEntry.factory();\n            // Test if the factory returns a promise.\n            if (Promise.resolve(backend) === backend) {\n                var promiseId_1 = ++this.pendingBackendInitId;\n                var success = backend\n                    .then(function (backendInstance) {\n                    // Outdated promise. Another backend was set in the meantime.\n                    if (promiseId_1 < _this.pendingBackendInitId) {\n                        return false;\n                    }\n                    _this.registry[backendName] = backendInstance;\n                    _this.pendingBackendInit = null;\n                    return true;\n                })\n                    .catch(function (err) {\n                    // Outdated promise. Another backend was set in the meantime.\n                    if (promiseId_1 < _this.pendingBackendInitId) {\n                        return false;\n                    }\n                    _this.pendingBackendInit = null;\n                    console.warn(\"Initialization of backend \" + backendName + \" failed\");\n                    console.warn(err.stack || err.message);\n                    return false;\n                });\n                this.pendingBackendInit = success;\n                return { success: success, asyncInit: true };\n            }\n            else {\n                this.registry[backendName] = backend;\n                return { success: true, asyncInit: false };\n            }\n        }\n        catch (err) {\n            console.warn(\"Initialization of backend \" + backendName + \" failed\");\n            console.warn(err.stack || err.message);\n            return { success: false, asyncInit: false };\n        }\n    };\n    Engine.prototype.removeBackend = function (backendName) {\n        if (!(backendName in this.registryFactory)) {\n            throw new Error(backendName + \" backend not found in registry\");\n        }\n        if (this.backendName === backendName && this.pendingBackendInit != null) {\n            // There is a pending promise of the backend we want to remove. Make it\n            // obsolete.\n            this.pendingBackendInitId++;\n        }\n        if (backendName in this.registry) {\n            this.registry[backendName].dispose();\n            delete this.registry[backendName];\n        }\n        delete this.registryFactory[backendName];\n        // Unset the backend if it is active.\n        if (this.backendName === backendName) {\n            this.pendingBackendInit = null;\n            this.backendName = null;\n            this.backendInstance = null;\n        }\n    };\n    Engine.prototype.getSortedBackends = function () {\n        var _this = this;\n        if (Object.keys(this.registryFactory).length === 0) {\n            throw new Error('No backend found in registry.');\n        }\n        return Object.keys(this.registryFactory).sort(function (a, b) {\n            // Highest priority comes first.\n            return _this.registryFactory[b].priority -\n                _this.registryFactory[a].priority;\n        });\n    };\n    Engine.prototype.initializeBackendsAndReturnBest = function () {\n        var sortedBackends = this.getSortedBackends();\n        for (var i = 0; i < sortedBackends.length; i++) {\n            var backendName = sortedBackends[i];\n            var _a = this.initializeBackend(backendName), success = _a.success, asyncInit = _a.asyncInit;\n            if (asyncInit || success) {\n                return { name: backendName, asyncInit: asyncInit };\n            }\n        }\n        throw new Error(\"Could not initialize any backends, all backend initializations \" +\n            \"failed.\");\n    };\n    Engine.prototype.moveData = function (destBackend, dataId) {\n        this.write(destBackend, dataId, this.readSync(dataId));\n    };\n    Engine.prototype.tidy = function (nameOrFn, fn) {\n        var _this = this;\n        var name = null;\n        if (fn == null) {\n            // Called with only 1 argument.\n            if (typeof nameOrFn !== 'function') {\n                throw new Error('Please provide a function to tidy()');\n            }\n            fn = nameOrFn;\n        }\n        else {\n            // Called with 2 arguments.\n            if (typeof nameOrFn !== 'string' && !(nameOrFn instanceof String)) {\n                throw new Error('When calling with two arguments, the first argument ' +\n                    'to tidy() must be a string');\n            }\n            if (typeof fn !== 'function') {\n                throw new Error('When calling with two arguments, the 2nd argument ' +\n                    'to tidy() must be a function');\n            }\n            name = nameOrFn;\n            // TODO(nsthorat,smilkov): Do operation logging and performance\n            // profiling.\n        }\n        var result;\n        return this.scopedRun(function () { return _this.startScope(name); }, function () { return _this.endScope(result); }, function () {\n            result = fn();\n            if (result instanceof Promise) {\n                console.error('Cannot return a Promise inside of tidy.');\n            }\n            return result;\n        });\n    };\n    Engine.prototype.scopedRun = function (start, end, f) {\n        start();\n        try {\n            var res = f();\n            end();\n            return res;\n        }\n        catch (ex) {\n            end();\n            throw ex;\n        }\n    };\n    Engine.prototype.nextTensorId = function () {\n        return Engine.nextTensorId++;\n    };\n    Engine.prototype.nextVariableId = function () {\n        return Engine.nextVariableId++;\n    };\n    /**\n     * This method is called instead of the public-facing tensor.clone() when\n     * saving a tensor for backwards pass. It makes sure to add the clone\n     * operation to the tape regardless of being called inside a kernel\n     * execution.\n     */\n    Engine.prototype.clone = function (x) {\n        var y = tensor_1.Tensor.make(x.shape, { dataId: x.dataId }, x.dtype);\n        this.addTapeNode([x], y, function (dy) { return [dy.toFloat()]; });\n        return y;\n    };\n    Engine.prototype.runKernel = function (forwardFunc, inputs, backwardsFunc) {\n        var _this = this;\n        var result;\n        var saved = [];\n        var isTapeOn = this.isTapeOn();\n        var scopeName = this.state.activeScope != null ? this.state.activeScope.name : '';\n        var saveFunc = function (tensors) {\n            // Do not save unless we are recording to the tape. Otherwise it would\n            // cause a mem leak since we would never run backprop, which disposes\n            // the kept tensors.\n            if (!isTapeOn) {\n                return;\n            }\n            saved = tensors.map(function (tensor) { return _this.keep(_this.clone(tensor)); });\n        };\n        var startingBytecount = this.state.numBytes;\n        var startingNumTensors = this.state.numTensors;\n        // Stop recording to a tape when running a kernel.\n        this.scopedRun(function () { return _this.state.kernelDepth++; }, function () { return _this.state.kernelDepth--; }, function () {\n            if (!_this.ENV.getBool('DEBUG')) {\n                result = forwardFunc(_this.backend, saveFunc);\n            }\n            else {\n                result = _this.profiler.profileKernel(scopeName, function () { return forwardFunc(_this.backend, saveFunc); });\n            }\n        });\n        if (isTapeOn) {\n            var tapeNode = {\n                id: this.state.nextTapeNodeId++,\n                name: scopeName,\n                inputs: inputs,\n                outputs: Array.isArray(result) ? result : [result],\n                saved: saved\n            };\n            if (backwardsFunc != null) {\n                tapeNode.gradient = function (dy) { return backwardsFunc(dy, saved); };\n            }\n            this.state.activeTape.push(tapeNode);\n        }\n        if (this.state.profiling) {\n            this.state.activeProfile.kernels.push({\n                name: scopeName,\n                bytesAdded: this.state.numBytes - startingBytecount,\n                totalBytesSnapshot: this.state.numBytes,\n                tensorsAdded: this.state.numTensors - startingNumTensors,\n                totalTensorsSnapshot: this.state.numTensors,\n                inputShapes: Object.keys(inputs).map(function (key) { return inputs[key].shape; }),\n                outputShape: Array.isArray(result) ?\n                    result.map(function (item) { return item.shape; }) :\n                    result.shape\n            });\n        }\n        return result;\n    };\n    // TensorManager implementation.\n    Engine.prototype.registerTensor = function (a, backend) {\n        var refCount = this.state.tensorInfo.has(a.dataId) ?\n            this.state.tensorInfo.get(a.dataId).refCount :\n            0;\n        this.state.numTensors++;\n        if (a.dtype === 'string') {\n            this.state.numStringTensors++;\n        }\n        if (refCount === 0) {\n            this.state.numDataBuffers++;\n            // Bytes for complex numbers are counted by their components. Bytes for\n            // string tensors are counted when writing values.\n            var bytes = 0;\n            if (a.dtype !== 'complex64' && a.dtype !== 'string') {\n                bytes = a.size * util.bytesPerElement(a.dtype);\n            }\n            this.state.tensorInfo.set(a.dataId, {\n                backend: backend != null ? backend : this.backend,\n                dtype: a.dtype,\n                shape: a.shape,\n                bytes: bytes,\n                refCount: 0\n            });\n            this.state.numBytes += bytes;\n            if (backend != null) {\n                backend.register(a.dataId, a.shape, a.dtype);\n            }\n            else {\n                this.backend.register(a.dataId, a.shape, a.dtype);\n            }\n        }\n        this.state.tensorInfo.get(a.dataId).refCount++;\n        if (!(a instanceof tensor_1.Variable)) {\n            this.track(a);\n        }\n    };\n    Engine.prototype.registerVariable = function (v) {\n        if (this.state.registeredVariables[v.name] != null) {\n            throw new Error(\"Variable with name \" + v.name + \" was already registered\");\n        }\n        this.state.registeredVariables[v.name] = v;\n    };\n    Engine.prototype.disposeTensor = function (a) {\n        if (!this.state.tensorInfo.has(a.dataId)) {\n            return;\n        }\n        this.state.numTensors--;\n        if (a.dtype === 'string') {\n            this.state.numStringTensors--;\n        }\n        var info = this.state.tensorInfo.get(a.dataId);\n        var refCount = info.refCount;\n        if (refCount <= 1) {\n            // Don't count bytes for complex numbers as they are counted by their\n            // components.\n            if (a.dtype !== 'complex64') {\n                this.state.numBytes -= info.bytes;\n            }\n            this.state.numDataBuffers--;\n            info.backend.disposeData(a.dataId);\n            this.state.tensorInfo.delete(a.dataId);\n        }\n        else {\n            this.state.tensorInfo.get(a.dataId).refCount--;\n        }\n        // TODO(nsthorat): Construct an error and save the stack trace for\n        // debugging when in debug mode. Creating a stack trace is too expensive\n        // to do unconditionally.\n    };\n    Engine.prototype.disposeVariables = function () {\n        for (var varName in this.state.registeredVariables) {\n            var v = this.state.registeredVariables[varName];\n            this.disposeVariable(v);\n        }\n    };\n    Engine.prototype.disposeVariable = function (v) {\n        this.disposeTensor(v);\n        if (this.state.registeredVariables[v.name] != null) {\n            delete this.state.registeredVariables[v.name];\n        }\n    };\n    Engine.prototype.memory = function () {\n        var info = this.backend.memory();\n        info.numTensors = this.state.numTensors;\n        info.numDataBuffers = this.state.numDataBuffers;\n        info.numBytes = this.state.numBytes;\n        if (this.state.numStringTensors > 0) {\n            info.unreliable = true;\n            if (info.reasons == null) {\n                info.reasons = [];\n            }\n            info.reasons.push('Memory usage by string tensors is approximate ' +\n                '(2 bytes per character)');\n        }\n        return info;\n    };\n    Engine.prototype.profile = function (query) {\n        return __awaiter(this, void 0, void 0, function () {\n            var startBytes, startNumTensors;\n            return __generator(this, function (_a) {\n                this.state.profiling = true;\n                startBytes = this.state.numBytes;\n                startNumTensors = this.state.numTensors;\n                this.state.activeProfile.kernels = [];\n                this.state.activeProfile.result = query();\n                this.state.profiling = false;\n                this.state.activeProfile.peakBytes = Math.max.apply(Math, this.state.activeProfile.kernels.map(function (d) { return d.totalBytesSnapshot; }));\n                this.state.activeProfile.newBytes = this.state.numBytes - startBytes;\n                this.state.activeProfile.newTensors =\n                    this.state.numTensors - startNumTensors;\n                return [2 /*return*/, this.state.activeProfile];\n            });\n        });\n    };\n    Engine.prototype.isTapeOn = function () {\n        return this.state.gradientDepth > 0 && this.state.kernelDepth === 0;\n    };\n    Engine.prototype.addTapeNode = function (inputs, result, gradientsFunc) {\n        var inputsMap = {};\n        inputs.forEach(function (input, idx) {\n            inputsMap[idx] = input;\n        });\n        var gradient = function (dy) {\n            var res = gradientsFunc(dy);\n            var resMap = {};\n            res.forEach(function (r, idx) {\n                resMap[idx] = function () { return r; };\n            });\n            return resMap;\n        };\n        var tapeNode = {\n            id: this.state.nextTapeNodeId++,\n            name: this.state.activeScope.name,\n            inputs: inputsMap,\n            outputs: [result],\n            gradient: gradient\n        };\n        this.state.activeTape.push(tapeNode);\n    };\n    Engine.prototype.keep = function (result) {\n        result.kept = true;\n        return result;\n    };\n    Engine.prototype.startTape = function () {\n        if (this.state.gradientDepth === 0) {\n            this.state.activeTape = [];\n        }\n        this.state.gradientDepth++;\n    };\n    Engine.prototype.endTape = function () {\n        this.state.gradientDepth--;\n    };\n    /**\n     * Start a scope. Use this with endScope() to achieve the same functionality\n     * as scope() without the need for a function closure.\n     */\n    Engine.prototype.startScope = function (name) {\n        var scopeInfo = {\n            track: [],\n            name: 'unnamed scope',\n            id: this.state.nextScopeId++\n        };\n        if (name) {\n            scopeInfo.name = name;\n        }\n        this.state.scopeStack.push(scopeInfo);\n        this.state.activeScope = scopeInfo;\n    };\n    /**\n     * End a scope. Use this with startScope() to achieve the same functionality\n     * as scope() without the need for a function closure.\n     */\n    Engine.prototype.endScope = function (result) {\n        var _this = this;\n        var tensorsToTrackInParent = tensor_util_1.getTensorsInContainer(result);\n        var tensorsToTrackInParentSet = new Set(tensorsToTrackInParent.map(function (t) { return t.id; }));\n        // Dispose the arrays tracked in this scope.\n        for (var i = 0; i < this.state.activeScope.track.length; i++) {\n            var tensor = this.state.activeScope.track[i];\n            if (!tensor.kept && !tensorsToTrackInParentSet.has(tensor.id)) {\n                tensor.dispose();\n            }\n        }\n        var oldScope = this.state.scopeStack.pop();\n        this.state.activeScope = this.state.scopeStack.length === 0 ?\n            null :\n            this.state.scopeStack[this.state.scopeStack.length - 1];\n        // Track the current result in the parent scope.\n        tensorsToTrackInParent.forEach(function (tensor) {\n            // Only track the tensor if was allocated in the inner scope and is not\n            // globally kept.\n            if (!tensor.kept && tensor.scopeId === oldScope.id) {\n                _this.track(tensor);\n            }\n        });\n    };\n    /**\n     * Returns gradients of `f` with respect to each of the `xs`. The gradients\n     * returned are of the same length as `xs`, but some might be null if `f`\n     * was not a function of that `x`. It also takes optional dy to multiply the\n     * gradient, which defaults to `1`.\n     */\n    Engine.prototype.gradients = function (f, xs, dy, allowNoGradients) {\n        var _this = this;\n        if (allowNoGradients === void 0) { allowNoGradients = false; }\n        util.assert(xs.length > 0, function () { return 'gradients() received an empty list of xs.'; });\n        if (dy != null && dy.dtype !== 'float32') {\n            throw new Error(\"dy must have 'float32' dtype, but has '\" + dy.dtype + \"'\");\n        }\n        var y = this.scopedRun(function () { return _this.startTape(); }, function () { return _this.endTape(); }, function () { return _this.tidy('forward', f); });\n        util.assert(y instanceof tensor_1.Tensor, function () { return 'The result y returned by f() must be a tensor.'; });\n        // Filter out the nodes that don't connect x => y.\n        var filteredTape = tape_1.getFilteredNodesXToY(this.state.activeTape, xs, y);\n        if (!allowNoGradients && filteredTape.length === 0 && xs.length > 0) {\n            throw new Error('Cannot compute gradient of y=f(x) with respect to x. Make sure ' +\n                'that the f you passed encloses all operations that lead from x ' +\n                'to y.');\n        }\n        return this.tidy('backward', function () {\n            var accumulatedGradientMap = {};\n            accumulatedGradientMap[y.id] = (dy == null) ? ones(y.shape) : dy;\n            // Backprop gradients through the filtered nodes.\n            tape_1.backpropagateGradients(accumulatedGradientMap, filteredTape, \n            // Pass the tidy function to avoid circular dep with `tape.ts`.\n            function (f) { return _this.tidy(f); });\n            var grads = xs.map(function (x) { return accumulatedGradientMap[x.id]; });\n            if (_this.state.gradientDepth === 0) {\n                // This means that we are not computing higher-order gradients\n                // and can clean up the tape.\n                _this.state.activeTape.forEach(function (node) {\n                    for (var key in node.saved) {\n                        node.saved[key].dispose();\n                    }\n                });\n                _this.state.activeTape = null;\n            }\n            return { value: y, grads: grads };\n        });\n    };\n    Engine.prototype.customGrad = function (f) {\n        var _this = this;\n        util.assert(util.isFunction(f), function () { return 'The f passed in customGrad(f) must be a function.'; });\n        return function () {\n            var inputs = [];\n            for (var _i = 0; _i < arguments.length; _i++) {\n                inputs[_i] = arguments[_i];\n            }\n            util.assert(inputs.every(function (t) { return t instanceof tensor_1.Tensor; }), function () { return 'The args passed in customGrad(f)(x1, x2,...) must all be ' +\n                'tensors'; });\n            var res;\n            var inputMap = {};\n            inputs.forEach(function (input, i) {\n                inputMap[i] = input;\n            });\n            return _this.runKernel(function (_, save) {\n                res = f.apply(void 0, inputs.concat([save]));\n                util.assert(res.value instanceof tensor_1.Tensor, function () { return 'The function f passed in customGrad(f) must return an ' +\n                    'object where `obj.value` is a tensor'; });\n                util.assert(util.isFunction(res.gradFunc), function () { return 'The function f passed in customGrad(f) must return an ' +\n                    'object where `obj.gradFunc` is a function.'; });\n                return res.value;\n            }, inputMap, function (dy, saved) {\n                var gradRes = res.gradFunc(dy, saved);\n                var grads = Array.isArray(gradRes) ? gradRes : [gradRes];\n                util.assert(grads.length === inputs.length, function () { return 'The function f passed in customGrad(f) must return an ' +\n                    'object where `obj.gradFunc` is a function that returns ' +\n                    'the same number of tensors as inputs passed to f(...).'; });\n                util.assert(grads.every(function (t) { return t instanceof tensor_1.Tensor; }), function () { return 'The function f passed in customGrad(f) must return an ' +\n                    'object where `obj.gradFunc` is a function that returns ' +\n                    'a list of only tensors.'; });\n                var gradMap = {};\n                grads.forEach(function (grad, i) {\n                    gradMap[i] = function () { return grad; };\n                });\n                return gradMap;\n            });\n        };\n    };\n    // Forwarding to backend.\n    Engine.prototype.write = function (destBackend, dataId, values) {\n        var info = this.state.tensorInfo.get(dataId);\n        var srcBackend = info.backend;\n        destBackend = destBackend || this.backend;\n        // Bytes for string tensors are counted when writing.\n        if (info.dtype === 'string') {\n            var newBytes = util_1.bytesFromStringArray(values);\n            this.state.numBytes += newBytes - info.bytes;\n            info.bytes = newBytes;\n        }\n        if (destBackend !== srcBackend) {\n            // Delete the tensor from the old backend and move it to the new\n            // backend.\n            srcBackend.disposeData(dataId);\n            info.backend = destBackend;\n            destBackend.register(dataId, info.shape, info.dtype);\n        }\n        destBackend.write(dataId, values);\n    };\n    Engine.prototype.readSync = function (dataId) {\n        // Route the read to the correct backend.\n        var info = this.state.tensorInfo.get(dataId);\n        return info.backend.readSync(dataId);\n    };\n    Engine.prototype.read = function (dataId) {\n        // Route the read to the correct backend.\n        var info = this.state.tensorInfo.get(dataId);\n        return info.backend.read(dataId);\n    };\n    Engine.prototype.fromPixels = function (pixels, numChannels) {\n        return this.backend.fromPixels(pixels, numChannels);\n    };\n    Engine.prototype.time = function (query) {\n        return __awaiter(this, void 0, void 0, function () {\n            var start, timingInfo;\n            return __generator(this, function (_a) {\n                switch (_a.label) {\n                    case 0:\n                        start = util_1.now();\n                        return [4 /*yield*/, this.backend.time(query)];\n                    case 1:\n                        timingInfo = _a.sent();\n                        timingInfo.wallMs = util_1.now() - start;\n                        return [2 /*return*/, timingInfo];\n                }\n            });\n        });\n    };\n    /**\n     * Tracks a Tensor in the current scope to be automatically cleaned up\n     * when the current scope ends, and returns the value.\n     *\n     * @param result The Tensor to track in the current scope.\n     */\n    Engine.prototype.track = function (result) {\n        if (this.state.activeScope != null) {\n            result.scopeId = this.state.activeScope.id;\n            this.state.activeScope.track.push(result);\n        }\n        return result;\n    };\n    Object.defineProperty(Engine.prototype, \"registeredVariables\", {\n        get: function () {\n            return this.state.registeredVariables;\n        },\n        enumerable: true,\n        configurable: true\n    });\n    /**\n     * Resets the engine state. Removes all backends but does not remove\n     * registered backend factories.\n     */\n    Engine.prototype.reset = function () {\n        // Make any pending promise obsolete.\n        this.pendingBackendInitId++;\n        this.state.dispose();\n        this.ENV.reset();\n        this.state = new EngineState();\n        for (var backendName in this.registry) {\n            this.registry[backendName].dispose();\n            delete this.registry[backendName];\n        }\n        this.backendName = null;\n        this.backendInstance = null;\n        this.pendingBackendInit = null;\n    };\n    Engine.nextTensorId = 0;\n    Engine.nextVariableId = 0;\n    return Engine;\n}());\nexports.Engine = Engine;\nfunction ones(shape) {\n    var values = util_1.makeOnesTypedArray(util_1.sizeFromShape(shape), 'float32');\n    return tensor_1.Tensor.make(shape, { values: values });\n}\nfunction getOrMakeEngine() {\n    var ns = environment_1.getGlobalNamespace();\n    if (ns._tfengine == null) {\n        ns._tfengine = new Engine(environment_1.ENV);\n    }\n    // Tell the current tensor interface that the global engine is responsible\n    // for tracking.\n    tensor_1.setTensorTracker(function () { return ns._tfengine; });\n    return ns._tfengine;\n}\nexports.ENGINE = getOrMakeEngine();\n//# sourceMappingURL=engine.js.map","\n/**\n * @license\n * Copyright 2017 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\n// Expects flags from URL in the format ?tfjsflags=FLAG1:1,FLAG2:true.\nvar TENSORFLOWJS_FLAGS_PREFIX = 'tfjsflags';\nvar Environment = /** @class */ (function () {\n    // tslint:disable-next-line: no-any\n    function Environment(global) {\n        this.global = global;\n        this.flags = {};\n        this.flagRegistry = {};\n        this.urlFlags = {};\n        this.populateURLFlags();\n    }\n    Environment.prototype.setPlatform = function (platformName, platform) {\n        if (this.platform != null) {\n            console.warn(\"Platform \" + this.platformName + \" has already been set. \" +\n                (\"Overwriting the platform with \" + platform + \".\"));\n        }\n        this.platformName = platformName;\n        this.platform = platform;\n    };\n    Environment.prototype.registerFlag = function (flagName, evaluationFn, setHook) {\n        this.flagRegistry[flagName] = { evaluationFn: evaluationFn, setHook: setHook };\n        // Override the flag value from the URL. This has to happen here because the\n        // environment is initialized before flags get registered.\n        if (this.urlFlags[flagName] != null) {\n            var flagValue = this.urlFlags[flagName];\n            console.warn(\"Setting feature override from URL \" + flagName + \": \" + flagValue + \".\");\n            this.set(flagName, flagValue);\n        }\n    };\n    Environment.prototype.get = function (flagName) {\n        if (flagName in this.flags) {\n            return this.flags[flagName];\n        }\n        this.flags[flagName] = this.evaluateFlag(flagName);\n        return this.flags[flagName];\n    };\n    Environment.prototype.getNumber = function (flagName) {\n        return this.get(flagName);\n    };\n    Environment.prototype.getBool = function (flagName) {\n        return this.get(flagName);\n    };\n    Environment.prototype.getFlags = function () {\n        return this.flags;\n    };\n    Object.defineProperty(Environment.prototype, \"features\", {\n        // For backwards compatibility.\n        get: function () {\n            return this.flags;\n        },\n        enumerable: true,\n        configurable: true\n    });\n    Environment.prototype.set = function (flagName, value) {\n        if (this.flagRegistry[flagName] == null) {\n            throw new Error(\"Cannot set flag \" + flagName + \" as it has not been registered.\");\n        }\n        this.flags[flagName] = value;\n        if (this.flagRegistry[flagName].setHook != null) {\n            this.flagRegistry[flagName].setHook(value);\n        }\n    };\n    Environment.prototype.evaluateFlag = function (flagName) {\n        if (this.flagRegistry[flagName] == null) {\n            throw new Error(\"Cannot evaluate flag '\" + flagName + \"': no evaluation function found.\");\n        }\n        return this.flagRegistry[flagName].evaluationFn();\n    };\n    Environment.prototype.setFlags = function (flags) {\n        this.flags = Object.assign({}, flags);\n    };\n    Environment.prototype.reset = function () {\n        this.flags = {};\n        this.urlFlags = {};\n        this.populateURLFlags();\n    };\n    Environment.prototype.populateURLFlags = function () {\n        var _this = this;\n        if (typeof this.global === 'undefined' ||\n            typeof this.global.location === 'undefined' ||\n            typeof this.global.location.search === 'undefined') {\n            return;\n        }\n        var urlParams = getQueryParams(this.global.location.search);\n        if (TENSORFLOWJS_FLAGS_PREFIX in urlParams) {\n            var keyValues = urlParams[TENSORFLOWJS_FLAGS_PREFIX].split(',');\n            keyValues.forEach(function (keyValue) {\n                var _a = keyValue.split(':'), key = _a[0], value = _a[1];\n                _this.urlFlags[key] = parseValue(key, value);\n            });\n        }\n    };\n    return Environment;\n}());\nexports.Environment = Environment;\nfunction getQueryParams(queryString) {\n    var params = {};\n    queryString.replace(/[?&]([^=?&]+)(?:=([^&]*))?/g, function (s) {\n        var t = [];\n        for (var _i = 1; _i < arguments.length; _i++) {\n            t[_i - 1] = arguments[_i];\n        }\n        decodeParam(params, t[0], t[1]);\n        return t.join('=');\n    });\n    return params;\n}\nexports.getQueryParams = getQueryParams;\nfunction decodeParam(params, name, value) {\n    params[decodeURIComponent(name)] = decodeURIComponent(value || '');\n}\nfunction parseValue(flagName, value) {\n    value = value.toLowerCase();\n    if (value === 'true' || value === 'false') {\n        return value === 'true';\n    }\n    else if (\"\" + +value === value) {\n        return +value;\n    }\n    throw new Error(\"Could not parse value flag value \" + value + \" for flag \" + flagName + \".\");\n}\n// tslint:disable-next-line:no-any\nvar GLOBAL;\nfunction getGlobalNamespace() {\n    if (GLOBAL == null) {\n        // tslint:disable-next-line:no-any\n        var ns = void 0;\n        if (typeof (window) !== 'undefined') {\n            ns = window;\n        }\n        else if (typeof (global) !== 'undefined') {\n            ns = global;\n        }\n        else if (typeof (process) !== 'undefined') {\n            ns = process;\n        }\n        else {\n            throw new Error('Could not find a global object');\n        }\n        GLOBAL = ns;\n    }\n    return GLOBAL;\n}\nexports.getGlobalNamespace = getGlobalNamespace;\nexports.ENV = new Environment(getGlobalNamespace());\n//# sourceMappingURL=environment.js.map","\n/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar util = require(\"./util\");\nvar Profiler = /** @class */ (function () {\n    function Profiler(backendTimer, logger) {\n        this.backendTimer = backendTimer;\n        this.logger = logger;\n        if (logger == null) {\n            this.logger = new Logger();\n        }\n    }\n    Profiler.prototype.profileKernel = function (name, f) {\n        var _this = this;\n        var result;\n        var holdResultWrapperFn = function () {\n            result = f();\n        };\n        var timer = this.backendTimer.time(holdResultWrapperFn);\n        var results = Array.isArray(result) ? result : [result];\n        results.forEach(function (r) {\n            var vals = r.dataSync();\n            util.checkComputationForErrors(vals, r.dtype, name);\n            timer.then(function (timing) {\n                var extraInfo = '';\n                if (timing.getExtraProfileInfo != null) {\n                    extraInfo = timing.getExtraProfileInfo();\n                }\n                _this.logger.logKernelProfile(name, r, vals, timing.kernelMs, extraInfo);\n            });\n        });\n        return result;\n    };\n    return Profiler;\n}());\nexports.Profiler = Profiler;\nvar Logger = /** @class */ (function () {\n    function Logger() {\n    }\n    Logger.prototype.logKernelProfile = function (name, result, vals, timeMs, extraInfo) {\n        var time = util.rightPad(timeMs + \"ms\", 9);\n        var paddedName = util.rightPad(name, 25);\n        var rank = result.rank;\n        var size = result.size;\n        var shape = util.rightPad(result.shape.toString(), 14);\n        console.log(\"%c\" + paddedName + \"\\t%c\" + time + \"\\t%c\" + rank + \"D \" + shape + \"\\t%c\" + size + \"\\t%c\" + extraInfo, 'font-weight:bold', 'color:red', 'color:blue', 'color: orange', 'color: green');\n    };\n    return Logger;\n}());\nexports.Logger = Logger;\n//# sourceMappingURL=profiler.js.map","\n/**\n * @license\n * Copyright 2017 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar environment_1 = require(\"./environment\");\n/**\n * Shuffles the array in-place using Fisher-Yates algorithm.\n *\n * ```js\n * const a = [1, 2, 3, 4, 5];\n * tf.util.shuffle(a);\n * console.log(a);\n * ```\n *\n * @param array The array to shuffle in-place.\n */\n/** @doc {heading: 'Util', namespace: 'util'} */\n// tslint:disable-next-line:no-any\nfunction shuffle(array) {\n    var counter = array.length;\n    var temp = 0;\n    var index = 0;\n    // While there are elements in the array\n    while (counter > 0) {\n        // Pick a random index\n        index = (Math.random() * counter) | 0;\n        // Decrease counter by 1\n        counter--;\n        // And swap the last element with it\n        temp = array[counter];\n        array[counter] = array[index];\n        array[index] = temp;\n    }\n}\nexports.shuffle = shuffle;\n/** Clamps a value to a specified range. */\nfunction clamp(min, x, max) {\n    return Math.max(min, Math.min(x, max));\n}\nexports.clamp = clamp;\nfunction nearestLargerEven(val) {\n    return val % 2 === 0 ? val : val + 1;\n}\nexports.nearestLargerEven = nearestLargerEven;\nfunction sum(arr) {\n    var sum = 0;\n    for (var i = 0; i < arr.length; i++) {\n        sum += arr[i];\n    }\n    return sum;\n}\nexports.sum = sum;\n/**\n * Returns a sample from a uniform [a, b) distribution.\n *\n * @param a The minimum support (inclusive).\n * @param b The maximum support (exclusive).\n * @return A pseudorandom number on the half-open interval [a,b).\n */\nfunction randUniform(a, b) {\n    var r = Math.random();\n    return (b * r) + (1 - r) * a;\n}\nexports.randUniform = randUniform;\n/** Returns the squared Euclidean distance between two vectors. */\nfunction distSquared(a, b) {\n    var result = 0;\n    for (var i = 0; i < a.length; i++) {\n        var diff = Number(a[i]) - Number(b[i]);\n        result += diff * diff;\n    }\n    return result;\n}\nexports.distSquared = distSquared;\n/**\n * Asserts that the expression is true. Otherwise throws an error with the\n * provided message.\n *\n * ```js\n * const x = 2;\n * tf.util.assert(x === 2, 'x is not 2');\n * ```\n *\n * @param expr The expression to assert (as a boolean).\n * @param msg A function that returns the message to report when throwing an\n *     error. We use a function for performance reasons.\n */\n/** @doc {heading: 'Util', namespace: 'util'} */\nfunction assert(expr, msg) {\n    if (!expr) {\n        throw new Error(typeof msg === 'string' ? msg : msg());\n    }\n}\nexports.assert = assert;\nfunction assertShapesMatch(shapeA, shapeB, errorMessagePrefix) {\n    if (errorMessagePrefix === void 0) { errorMessagePrefix = ''; }\n    assert(arraysEqual(shapeA, shapeB), function () { return errorMessagePrefix + (\" Shapes \" + shapeA + \" and \" + shapeB + \" must match\"); });\n}\nexports.assertShapesMatch = assertShapesMatch;\nfunction assertNonNull(a) {\n    assert(a != null, function () { return \"The input to the tensor constructor must be a non-null value.\"; });\n}\nexports.assertNonNull = assertNonNull;\n// NOTE: We explicitly type out what T extends instead of any so that\n// util.flatten on a nested array of number doesn't try to infer T as a\n// number[][], causing us to explicitly type util.flatten<number>().\n/**\n *  Flattens an arbitrarily nested array.\n *\n * ```js\n * const a = [[1, 2], [3, 4], [5, [6, [7]]]];\n * const flat = tf.util.flatten(a);\n * console.log(flat);\n * ```\n *\n *  @param arr The nested array to flatten.\n *  @param result The destination array which holds the elements.\n */\n/** @doc {heading: 'Util', namespace: 'util'} */\nfunction flatten(arr, result) {\n    if (result === void 0) { result = []; }\n    if (result == null) {\n        result = [];\n    }\n    if (Array.isArray(arr) || isTypedArray(arr)) {\n        for (var i = 0; i < arr.length; ++i) {\n            flatten(arr[i], result);\n        }\n    }\n    else {\n        result.push(arr);\n    }\n    return result;\n}\nexports.flatten = flatten;\n/**\n * Returns the size (number of elements) of the tensor given its shape.\n *\n * ```js\n * const shape = [3, 4, 2];\n * const size = tf.util.sizeFromShape(shape);\n * console.log(size);\n * ```\n */\n/** @doc {heading: 'Util', namespace: 'util'} */\nfunction sizeFromShape(shape) {\n    if (shape.length === 0) {\n        // Scalar.\n        return 1;\n    }\n    var size = shape[0];\n    for (var i = 1; i < shape.length; i++) {\n        size *= shape[i];\n    }\n    return size;\n}\nexports.sizeFromShape = sizeFromShape;\nfunction isScalarShape(shape) {\n    return shape.length === 0;\n}\nexports.isScalarShape = isScalarShape;\nfunction arraysEqual(n1, n2) {\n    if (n1 === n2) {\n        return true;\n    }\n    if (n1 == null || n2 == null) {\n        return false;\n    }\n    if (n1.length !== n2.length) {\n        return false;\n    }\n    for (var i = 0; i < n1.length; i++) {\n        if (n1[i] !== n2[i]) {\n            return false;\n        }\n    }\n    return true;\n}\nexports.arraysEqual = arraysEqual;\nfunction isInt(a) {\n    return a % 1 === 0;\n}\nexports.isInt = isInt;\nfunction tanh(x) {\n    // tslint:disable-next-line:no-any\n    if (Math.tanh != null) {\n        // tslint:disable-next-line:no-any\n        return Math.tanh(x);\n    }\n    if (x === Infinity) {\n        return 1;\n    }\n    else if (x === -Infinity) {\n        return -1;\n    }\n    else {\n        var e2x = Math.exp(2 * x);\n        return (e2x - 1) / (e2x + 1);\n    }\n}\nexports.tanh = tanh;\nfunction sizeToSquarishShape(size) {\n    var width = Math.ceil(Math.sqrt(size));\n    return [width, Math.ceil(size / width)];\n}\nexports.sizeToSquarishShape = sizeToSquarishShape;\nfunction createShuffledIndices(n) {\n    var shuffledIndices = new Uint32Array(n);\n    for (var i = 0; i < n; ++i) {\n        shuffledIndices[i] = i;\n    }\n    shuffle(shuffledIndices);\n    return shuffledIndices;\n}\nexports.createShuffledIndices = createShuffledIndices;\nfunction rightPad(a, size) {\n    if (size <= a.length) {\n        return a;\n    }\n    return a + ' '.repeat(size - a.length);\n}\nexports.rightPad = rightPad;\nfunction repeatedTry(checkFn, delayFn, maxCounter) {\n    if (delayFn === void 0) { delayFn = function (counter) { return 0; }; }\n    return new Promise(function (resolve, reject) {\n        var tryCount = 0;\n        var tryFn = function () {\n            if (checkFn()) {\n                resolve();\n                return;\n            }\n            tryCount++;\n            var nextBackoff = delayFn(tryCount);\n            if (maxCounter != null && tryCount >= maxCounter) {\n                reject();\n                return;\n            }\n            setTimeout(tryFn, nextBackoff);\n        };\n        tryFn();\n    });\n}\nexports.repeatedTry = repeatedTry;\n/**\n * Given the full size of the array and a shape that may contain -1 as the\n * implicit dimension, returns the inferred shape where -1 is replaced.\n * E.g. For shape=[2, -1, 3] and size=24, it will return [2, 4, 3].\n *\n * @param shape The shape, which may contain -1 in some dimension.\n * @param size The full size (number of elements) of the array.\n * @return The inferred shape where -1 is replaced with the inferred size.\n */\nfunction inferFromImplicitShape(shape, size) {\n    var shapeProd = 1;\n    var implicitIdx = -1;\n    for (var i = 0; i < shape.length; ++i) {\n        if (shape[i] >= 0) {\n            shapeProd *= shape[i];\n        }\n        else if (shape[i] === -1) {\n            if (implicitIdx !== -1) {\n                throw Error(\"Shapes can only have 1 implicit size. \" +\n                    (\"Found -1 at dim \" + implicitIdx + \" and dim \" + i));\n            }\n            implicitIdx = i;\n        }\n        else if (shape[i] < 0) {\n            throw Error(\"Shapes can not be < 0. Found \" + shape[i] + \" at dim \" + i);\n        }\n    }\n    if (implicitIdx === -1) {\n        if (size > 0 && size !== shapeProd) {\n            throw Error(\"Size(\" + size + \") must match the product of shape \" + shape);\n        }\n        return shape;\n    }\n    if (shapeProd === 0) {\n        throw Error(\"Cannot infer the missing size in [\" + shape + \"] when \" +\n            \"there are 0 elements\");\n    }\n    if (size % shapeProd !== 0) {\n        throw Error(\"The implicit shape can't be a fractional number. \" +\n            (\"Got \" + size + \" / \" + shapeProd));\n    }\n    var newShape = shape.slice();\n    newShape[implicitIdx] = size / shapeProd;\n    return newShape;\n}\nexports.inferFromImplicitShape = inferFromImplicitShape;\nfunction parseAxisParam(axis, shape) {\n    var rank = shape.length;\n    // Normalize input\n    axis = axis == null ? shape.map(function (s, i) { return i; }) : [].concat(axis);\n    // Check for valid range\n    assert(axis.every(function (ax) { return ax >= -rank && ax < rank; }), function () {\n        return \"All values in axis param must be in range [-\" + rank + \", \" + rank + \") but \" +\n            (\"got axis \" + axis);\n    });\n    // Check for only integers\n    assert(axis.every(function (ax) { return isInt(ax); }), function () { return \"All values in axis param must be integers but \" +\n        (\"got axis \" + axis); });\n    // Handle negative axis.\n    return axis.map(function (a) { return a < 0 ? rank + a : a; });\n}\nexports.parseAxisParam = parseAxisParam;\n/** Reduces the shape by removing all dimensions of shape 1. */\nfunction squeezeShape(shape, axis) {\n    var newShape = [];\n    var keptDims = [];\n    var axes = axis == null ? null : parseAxisParam(axis, shape).sort();\n    var j = 0;\n    for (var i = 0; i < shape.length; ++i) {\n        if (axes != null) {\n            if (axes[j] === i && shape[i] !== 1) {\n                throw new Error(\"Can't squeeze axis \" + i + \" since its dim '\" + shape[i] + \"' is not 1\");\n            }\n            if ((axes[j] == null || axes[j] > i) && shape[i] === 1) {\n                newShape.push(shape[i]);\n                keptDims.push(i);\n            }\n            if (axes[j] <= i) {\n                j++;\n            }\n        }\n        if (shape[i] !== 1) {\n            newShape.push(shape[i]);\n            keptDims.push(i);\n        }\n    }\n    return { newShape: newShape, keptDims: keptDims };\n}\nexports.squeezeShape = squeezeShape;\nfunction getTypedArrayFromDType(dtype, size) {\n    var values = null;\n    if (dtype == null || dtype === 'float32') {\n        values = new Float32Array(size);\n    }\n    else if (dtype === 'int32') {\n        values = new Int32Array(size);\n    }\n    else if (dtype === 'bool') {\n        values = new Uint8Array(size);\n    }\n    else {\n        throw new Error(\"Unknown data type \" + dtype);\n    }\n    return values;\n}\nexports.getTypedArrayFromDType = getTypedArrayFromDType;\nfunction getArrayFromDType(dtype, size) {\n    var values = null;\n    if (dtype == null || dtype === 'float32') {\n        values = new Float32Array(size);\n    }\n    else if (dtype === 'int32') {\n        values = new Int32Array(size);\n    }\n    else if (dtype === 'bool') {\n        values = new Uint8Array(size);\n    }\n    else if (dtype === 'string') {\n        values = new Array(size);\n    }\n    else {\n        throw new Error(\"Unknown data type \" + dtype);\n    }\n    return values;\n}\nexports.getArrayFromDType = getArrayFromDType;\nfunction checkComputationForErrors(vals, dtype, name) {\n    if (dtype !== 'float32') {\n        // Only floating point computations will generate NaN values\n        return;\n    }\n    for (var i = 0; i < vals.length; i++) {\n        var num = vals[i];\n        if (isNaN(num) || !isFinite(num)) {\n            throw Error(\"The result of the '\" + name + \"' is \" + num + \".\");\n        }\n    }\n}\nexports.checkComputationForErrors = checkComputationForErrors;\nfunction checkConversionForErrors(vals, dtype) {\n    for (var i = 0; i < vals.length; i++) {\n        var num = vals[i];\n        if (isNaN(num) || !isFinite(num)) {\n            throw Error(\"A tensor of type \" + dtype + \" being uploaded contains \" + num + \".\");\n        }\n    }\n}\nexports.checkConversionForErrors = checkConversionForErrors;\n/** Returns true if the dtype is valid. */\nfunction isValidDtype(dtype) {\n    return dtype === 'bool' || dtype === 'complex64' || dtype === 'float32' ||\n        dtype === 'int32' || dtype === 'string';\n}\nexports.isValidDtype = isValidDtype;\n/**\n * Returns true if the new type can't encode the old type without loss of\n * precision.\n */\nfunction hasEncodingLoss(oldType, newType) {\n    if (newType === 'complex64') {\n        return false;\n    }\n    if (newType === 'float32' && oldType !== 'complex64') {\n        return false;\n    }\n    if (newType === 'int32' && oldType !== 'float32' && oldType !== 'complex64') {\n        return false;\n    }\n    if (newType === 'bool' && oldType === 'bool') {\n        return false;\n    }\n    return true;\n}\nexports.hasEncodingLoss = hasEncodingLoss;\nfunction isTypedArray(a) {\n    return a instanceof Float32Array || a instanceof Int32Array ||\n        a instanceof Uint8Array;\n}\nexports.isTypedArray = isTypedArray;\nfunction bytesPerElement(dtype) {\n    if (dtype === 'float32' || dtype === 'int32') {\n        return 4;\n    }\n    else if (dtype === 'complex64') {\n        return 8;\n    }\n    else if (dtype === 'bool') {\n        return 1;\n    }\n    else {\n        throw new Error(\"Unknown dtype \" + dtype);\n    }\n}\nexports.bytesPerElement = bytesPerElement;\n/**\n * Returns the approximate number of bytes allocated in the string array - 2\n * bytes per character. Computing the exact bytes for a native string in JS is\n * not possible since it depends on the encoding of the html page that serves\n * the website.\n */\nfunction bytesFromStringArray(arr) {\n    if (arr == null) {\n        return 0;\n    }\n    var bytes = 0;\n    arr.forEach(function (x) { return bytes += x.length * 2; });\n    return bytes;\n}\nexports.bytesFromStringArray = bytesFromStringArray;\n/** Returns true if the value is a string. */\nfunction isString(value) {\n    return typeof value === 'string' || value instanceof String;\n}\nexports.isString = isString;\nfunction isBoolean(value) {\n    return typeof value === 'boolean';\n}\nexports.isBoolean = isBoolean;\nfunction isNumber(value) {\n    return typeof value === 'number';\n}\nexports.isNumber = isNumber;\nfunction inferDtype(values) {\n    if (Array.isArray(values)) {\n        return inferDtype(values[0]);\n    }\n    if (values instanceof Float32Array) {\n        return 'float32';\n    }\n    else if (values instanceof Int32Array || values instanceof Uint8Array) {\n        return 'int32';\n    }\n    else if (isNumber(values)) {\n        return 'float32';\n    }\n    else if (isString(values)) {\n        return 'string';\n    }\n    else if (isBoolean(values)) {\n        return 'bool';\n    }\n    return 'float32';\n}\nexports.inferDtype = inferDtype;\nfunction isFunction(f) {\n    return !!(f && f.constructor && f.call && f.apply);\n}\nexports.isFunction = isFunction;\nfunction nearestDivisor(size, start) {\n    for (var i = start; i < size; ++i) {\n        if (size % i === 0) {\n            return i;\n        }\n    }\n    return size;\n}\nexports.nearestDivisor = nearestDivisor;\nfunction computeStrides(shape) {\n    var rank = shape.length;\n    if (rank < 2) {\n        return [];\n    }\n    // Last dimension has implicit stride of 1, thus having D-1 (instead of D)\n    // strides.\n    var strides = new Array(rank - 1);\n    strides[rank - 2] = shape[rank - 1];\n    for (var i = rank - 3; i >= 0; --i) {\n        strides[i] = strides[i + 1] * shape[i + 1];\n    }\n    return strides;\n}\nexports.computeStrides = computeStrides;\nfunction toTypedArray(a, dtype, debugMode) {\n    if (dtype === 'string') {\n        throw new Error('Cannot convert a string[] to a TypedArray');\n    }\n    if (Array.isArray(a)) {\n        a = flatten(a);\n    }\n    if (debugMode) {\n        checkConversionForErrors(a, dtype);\n    }\n    if (noConversionNeeded(a, dtype)) {\n        return a;\n    }\n    if (dtype == null || dtype === 'float32' || dtype === 'complex64') {\n        return new Float32Array(a);\n    }\n    else if (dtype === 'int32') {\n        return new Int32Array(a);\n    }\n    else if (dtype === 'bool') {\n        var bool = new Uint8Array(a.length);\n        for (var i = 0; i < bool.length; ++i) {\n            if (Math.round(a[i]) !== 0) {\n                bool[i] = 1;\n            }\n        }\n        return bool;\n    }\n    else {\n        throw new Error(\"Unknown data type \" + dtype);\n    }\n}\nexports.toTypedArray = toTypedArray;\nfunction createNestedArray(offset, shape, a) {\n    var ret = new Array();\n    if (shape.length === 1) {\n        var d = shape[0];\n        for (var i = 0; i < d; i++) {\n            ret[i] = a[offset + i];\n        }\n    }\n    else {\n        var d = shape[0];\n        var rest = shape.slice(1);\n        var len = rest.reduce(function (acc, c) { return acc * c; });\n        for (var i = 0; i < d; i++) {\n            ret[i] = createNestedArray(offset + i * len, rest, a);\n        }\n    }\n    return ret;\n}\n// Provide a nested array of TypedArray in given shape.\nfunction toNestedArray(shape, a) {\n    if (shape.length === 0) {\n        // Scalar type should return a single number.\n        return a[0];\n    }\n    var size = shape.reduce(function (acc, c) { return acc * c; });\n    if (size === 0) {\n        // A tensor with shape zero should be turned into empty list.\n        return [];\n    }\n    if (size !== a.length) {\n        throw new Error(\"[\" + shape + \"] does not match the input size.\");\n    }\n    return createNestedArray(0, shape, a);\n}\nexports.toNestedArray = toNestedArray;\nfunction noConversionNeeded(a, dtype) {\n    return (a instanceof Float32Array && dtype === 'float32') ||\n        (a instanceof Int32Array && dtype === 'int32') ||\n        (a instanceof Uint8Array && dtype === 'bool');\n}\nfunction makeOnesTypedArray(size, dtype) {\n    var array = makeZerosTypedArray(size, dtype);\n    for (var i = 0; i < array.length; i++) {\n        array[i] = 1;\n    }\n    return array;\n}\nexports.makeOnesTypedArray = makeOnesTypedArray;\nfunction makeZerosTypedArray(size, dtype) {\n    if (dtype == null || dtype === 'float32' || dtype === 'complex64') {\n        return new Float32Array(size);\n    }\n    else if (dtype === 'int32') {\n        return new Int32Array(size);\n    }\n    else if (dtype === 'bool') {\n        return new Uint8Array(size);\n    }\n    else {\n        throw new Error(\"Unknown data type \" + dtype);\n    }\n}\nexports.makeZerosTypedArray = makeZerosTypedArray;\n/**\n * Returns the current high-resolution time in milliseconds relative to an\n * arbitrary time in the past. It works across different platforms (node.js,\n * browsers).\n *\n * ```js\n * console.log(tf.util.now());\n * ```\n */\n/** @doc {heading: 'Util', namespace: 'util'} */\nfunction now() {\n    if (typeof performance !== 'undefined') {\n        return performance.now();\n    }\n    else if (typeof process !== 'undefined') {\n        var time = process.hrtime();\n        return time[0] * 1000 + time[1] / 1000000;\n    }\n    else {\n        throw new Error('Cannot measure time in this environment. You should run tf.js ' +\n            'in the browser or in Node.js');\n    }\n}\nexports.now = now;\nfunction assertNonNegativeIntegerDimensions(shape) {\n    shape.forEach(function (dimSize) {\n        assert(Number.isInteger(dimSize) && dimSize >= 0, function () {\n            return \"Tensor must have a shape comprised of positive integers but got \" +\n                (\"shape [\" + shape + \"].\");\n        });\n    });\n}\nexports.assertNonNegativeIntegerDimensions = assertNonNegativeIntegerDimensions;\n/**\n * Returns a platform-specific implementation of\n * [`fetch`](https://developer.mozilla.org/en-US/docs/Web/API/Fetch_API).\n *\n * If `fetch` is defined on the global object (`window`, `process`, etc.),\n * `tf.util.fetch` returns that function.\n *\n * If not, `tf.util.fetch` returns a platform-specific solution.\n *\n * ```js\n * const resource = await tf.util.fetch('https://unpkg.com/@tensorflow/tfjs');\n * // handle response\n * ```\n */\n/** @doc {heading: 'Util'} */\nfunction fetch(path, requestInits) {\n    return environment_1.ENV.platform.fetch(path, requestInits);\n}\nexports.fetch = fetch;\n//# sourceMappingURL=util.js.map","\n/**\n * @license\n * Copyright 2017 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar tensor_1 = require(\"./tensor\");\nvar util = require(\"./util\");\n/**\n * Computes a list of TapeNodes that connect x to y, filtering everything else\n * out and preserving the order of the original tape elements.\n *\n * @param tape The tape elements to filter.\n * @param xs The input Tensors.\n * @param y The output Tensor.\n */\nfunction getFilteredNodesXToY(tape, xs, y) {\n    // Forward pass to compute all the nodes and Tensors that are transitively a\n    // function of x.\n    var tensorsFromX = {};\n    var nodesFromX = {};\n    for (var i = 0; i < xs.length; i++) {\n        tensorsFromX[xs[i].id] = true;\n    }\n    for (var i = 0; i < tape.length; i++) {\n        var node = tape[i];\n        var nodeInputs = node.inputs;\n        for (var inputName in nodeInputs) {\n            var input = nodeInputs[inputName];\n            var anyInputFromX = false;\n            for (var j = 0; j < xs.length; j++) {\n                if (tensorsFromX[input.id]) {\n                    node.outputs.forEach(function (output) { return tensorsFromX[output.id] = true; });\n                    anyInputFromX = true;\n                    nodesFromX[node.id] = true;\n                    break;\n                }\n            }\n            if (anyInputFromX) {\n                break;\n            }\n        }\n    }\n    // Backward pass to find all of the nodes and Tensors that lead to y.\n    var tensorsLeadToY = {};\n    tensorsLeadToY[y.id] = true;\n    var nodesToY = {};\n    for (var i = tape.length - 1; i >= 0; i--) {\n        var node = tape[i];\n        var nodeInputs = node.inputs;\n        // If any of the outputs lead to y, mark all of the inputs as leading to y.\n        for (var j = 0; j < node.outputs.length; j++) {\n            if (tensorsLeadToY[node.outputs[j].id]) {\n                for (var inputName in nodeInputs) {\n                    tensorsLeadToY[nodeInputs[inputName].id] = true;\n                    nodesToY[node.id] = true;\n                }\n                break;\n            }\n        }\n    }\n    // Return the paths that come from x and lead to y.\n    var filteredTape = [];\n    for (var i = 0; i < tape.length; i++) {\n        var node = tape[i];\n        if (nodesFromX[node.id] && nodesToY[node.id]) {\n            // Prune the inputs from the node that aren't a function of x.\n            var prunedInputs = {};\n            for (var inputName in node.inputs) {\n                var nodeInput = node.inputs[inputName];\n                if (tensorsFromX[nodeInput.id]) {\n                    prunedInputs[inputName] = nodeInput;\n                }\n            }\n            // Copy the node and overwrite inputsAndArgs to the pruned version.\n            var prunedNode = Object.assign({}, node);\n            prunedNode.inputs = prunedInputs;\n            prunedNode.outputs = node.outputs;\n            filteredTape.push(prunedNode);\n        }\n    }\n    return filteredTape;\n}\nexports.getFilteredNodesXToY = getFilteredNodesXToY;\n/**\n * Backpropagate gradients through the filtered TapeNodes.\n *\n * @param tensorAccumulatedGradientMap A map of Tensor to its gradient. This map\n * is mutated by this method.\n * @param filteredTape The filtered TapeNodes to backprop through.\n */\nfunction backpropagateGradients(tensorAccumulatedGradientMap, filteredTape, tidy) {\n    var _loop_1 = function (i) {\n        var node = filteredTape[i];\n        var dys = [];\n        node.outputs.forEach(function (o) {\n            var gradTensor = tensorAccumulatedGradientMap[o.id];\n            if (gradTensor != null) {\n                dys.push(gradTensor);\n            }\n            else {\n                // This particular output is not in the back-propagation subgraph, so it\n                // does not affect the final output, thus we put zeros for its dy.\n                var dy = tensor_1.Tensor.make(o.shape, { values: util.makeZerosTypedArray(o.size, o.dtype) }, o.dtype);\n                dys.push(dy);\n            }\n        });\n        if (node.gradient == null) {\n            throw new Error(\"Cannot compute gradient: gradient function not found \" +\n                (\"for \" + node.name + \".\"));\n        }\n        // Backprop dy through this node and accumulate gradients over the inputs.\n        var inputGradients = \n        // Grad functions of ops with single outputs expect a dy, while ops\n        // with multiple outputs expect dys (array of dy).\n        node.gradient(node.outputs.length === 1 ? dys[0] : dys);\n        var _loop_2 = function (inputName) {\n            if (!(inputName in inputGradients)) {\n                throw new Error(\"Cannot backprop through input \" + inputName + \". \" +\n                    (\"Available gradients found: \" + Object.keys(inputGradients) + \".\"));\n            }\n            // Call the gradient function.\n            var dx = tidy(function () { return inputGradients[inputName](); });\n            if (dx.dtype !== 'float32') {\n                throw new Error(\"Error in gradient for op \" + node.name + \". The gradient of input \" +\n                    (inputName + \" must have 'float32' dtype, but has '\" + dx.dtype + \"'\"));\n            }\n            var x = node.inputs[inputName];\n            if (!util.arraysEqual(dx.shape, x.shape)) {\n                throw new Error(\"Error in gradient for op \" + node.name + \". The gradient of input \" +\n                    (\"'\" + inputName + \"' has shape '\" + dx.shape + \"', which does not match \") +\n                    (\"the shape of the input '\" + x.shape + \"'\"));\n            }\n            if (tensorAccumulatedGradientMap[x.id] == null) {\n                tensorAccumulatedGradientMap[x.id] = dx;\n            }\n            else {\n                var curGradient = tensorAccumulatedGradientMap[x.id];\n                tensorAccumulatedGradientMap[x.id] = curGradient.add(dx);\n                curGradient.dispose();\n            }\n        };\n        for (var inputName in node.inputs) {\n            _loop_2(inputName);\n        }\n    };\n    // Walk the tape backward and keep a map of Tensor to its gradient.\n    for (var i = filteredTape.length - 1; i >= 0; i--) {\n        _loop_1(i);\n    }\n}\nexports.backpropagateGradients = backpropagateGradients;\n//# sourceMappingURL=tape.js.map","\n/**\n * @license\n * Copyright 2017 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar __extends = (this && this.__extends) || (function () {\n    var extendStatics = function (d, b) {\n        extendStatics = Object.setPrototypeOf ||\n            ({ __proto__: [] } instanceof Array && function (d, b) { d.__proto__ = b; }) ||\n            function (d, b) { for (var p in b) if (b.hasOwnProperty(p)) d[p] = b[p]; };\n        return extendStatics(d, b);\n    };\n    return function (d, b) {\n        extendStatics(d, b);\n        function __() { this.constructor = d; }\n        d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());\n    };\n})();\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : new P(function (resolve) { resolve(result.value); }).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nvar __generator = (this && this.__generator) || function (thisArg, body) {\n    var _ = { label: 0, sent: function() { if (t[0] & 1) throw t[1]; return t[1]; }, trys: [], ops: [] }, f, y, t, g;\n    return g = { next: verb(0), \"throw\": verb(1), \"return\": verb(2) }, typeof Symbol === \"function\" && (g[Symbol.iterator] = function() { return this; }), g;\n    function verb(n) { return function (v) { return step([n, v]); }; }\n    function step(op) {\n        if (f) throw new TypeError(\"Generator is already executing.\");\n        while (_) try {\n            if (f = 1, y && (t = op[0] & 2 ? y[\"return\"] : op[0] ? y[\"throw\"] || ((t = y[\"return\"]) && t.call(y), 0) : y.next) && !(t = t.call(y, op[1])).done) return t;\n            if (y = 0, t) op = [op[0] & 2, t.value];\n            switch (op[0]) {\n                case 0: case 1: t = op; break;\n                case 4: _.label++; return { value: op[1], done: false };\n                case 5: _.label++; y = op[1]; op = [0]; continue;\n                case 7: op = _.ops.pop(); _.trys.pop(); continue;\n                default:\n                    if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) { _ = 0; continue; }\n                    if (op[0] === 3 && (!t || (op[1] > t[0] && op[1] < t[3]))) { _.label = op[1]; break; }\n                    if (op[0] === 6 && _.label < t[1]) { _.label = t[1]; t = op; break; }\n                    if (t && _.label < t[2]) { _.label = t[2]; _.ops.push(op); break; }\n                    if (t[2]) _.ops.pop();\n                    _.trys.pop(); continue;\n            }\n            op = body.call(thisArg, _);\n        } catch (e) { op = [6, e]; y = 0; } finally { f = t = 0; }\n        if (op[0] & 5) throw op[1]; return { value: op[0] ? op[1] : void 0, done: true };\n    }\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar tensor_format_1 = require(\"./tensor_format\");\nvar util = require(\"./util\");\nvar util_1 = require(\"./util\");\n/**\n * A mutable object, similar to `tf.Tensor`, that allows users to set values\n * at locations before converting to an immutable `tf.Tensor`.\n *\n * See `tf.buffer` for creating a tensor buffer.\n */\n/** @doc {heading: 'Tensors', subheading: 'Classes'} */\nvar TensorBuffer = /** @class */ (function () {\n    function TensorBuffer(shape, dtype, values) {\n        var _this = this;\n        this.dtype = dtype;\n        this.shape = shape.slice();\n        this.size = util.sizeFromShape(shape);\n        if (values != null) {\n            var n_1 = values.length;\n            util.assert(n_1 === this.size, function () { return \"Length of values '\" + n_1 + \"' does not match the size \" +\n                (\"inferred by the shape '\" + _this.size + \"'.\"); });\n        }\n        if (dtype === 'complex64') {\n            throw new Error(\"complex64 dtype TensorBuffers are not supported. Please create \" +\n                \"a TensorBuffer for the real and imaginary parts separately and \" +\n                \"call tf.complex(real, imag).\");\n        }\n        this.values = values || util.getArrayFromDType(dtype, this.size);\n        this.strides = util_1.computeStrides(shape);\n    }\n    /**\n     * Sets a value in the buffer at a given location.\n     *\n     * @param value The value to set.\n     * @param locs  The location indices.\n     */\n    /** @doc {heading: 'Tensors', subheading: 'Creation'} */\n    TensorBuffer.prototype.set = function (value) {\n        var _this = this;\n        var locs = [];\n        for (var _i = 1; _i < arguments.length; _i++) {\n            locs[_i - 1] = arguments[_i];\n        }\n        if (locs.length === 0) {\n            locs = [0];\n        }\n        util.assert(locs.length === this.rank, function () { return \"The number of provided coordinates (\" + locs.length + \") must \" +\n            (\"match the rank (\" + _this.rank + \")\"); });\n        var index = this.locToIndex(locs);\n        this.values[index] = value;\n    };\n    /**\n     * Returns the value in the buffer at the provided location.\n     *\n     * @param locs The location indices.\n     */\n    /** @doc {heading: 'Tensors', subheading: 'Creation'} */\n    TensorBuffer.prototype.get = function () {\n        var locs = [];\n        for (var _i = 0; _i < arguments.length; _i++) {\n            locs[_i] = arguments[_i];\n        }\n        if (locs.length === 0) {\n            locs = [0];\n        }\n        var i = 0;\n        for (var _a = 0, locs_1 = locs; _a < locs_1.length; _a++) {\n            var loc = locs_1[_a];\n            if (loc < 0 || loc >= this.shape[i]) {\n                var msg = \"Requested out of range element at \" + locs + \". \" +\n                    (\"  Buffer shape=\" + this.shape);\n                throw new Error(msg);\n            }\n            i++;\n        }\n        var index = locs[locs.length - 1];\n        for (var i_1 = 0; i_1 < locs.length - 1; ++i_1) {\n            index += this.strides[i_1] * locs[i_1];\n        }\n        return this.values[index];\n    };\n    TensorBuffer.prototype.locToIndex = function (locs) {\n        if (this.rank === 0) {\n            return 0;\n        }\n        else if (this.rank === 1) {\n            return locs[0];\n        }\n        var index = locs[locs.length - 1];\n        for (var i = 0; i < locs.length - 1; ++i) {\n            index += this.strides[i] * locs[i];\n        }\n        return index;\n    };\n    TensorBuffer.prototype.indexToLoc = function (index) {\n        if (this.rank === 0) {\n            return [];\n        }\n        else if (this.rank === 1) {\n            return [index];\n        }\n        var locs = new Array(this.shape.length);\n        for (var i = 0; i < locs.length - 1; ++i) {\n            locs[i] = Math.floor(index / this.strides[i]);\n            index -= locs[i] * this.strides[i];\n        }\n        locs[locs.length - 1] = index;\n        return locs;\n    };\n    Object.defineProperty(TensorBuffer.prototype, \"rank\", {\n        get: function () {\n            return this.shape.length;\n        },\n        enumerable: true,\n        configurable: true\n    });\n    /**\n     * Creates an immutable `tf.Tensor` object from the buffer.\n     */\n    /** @doc {heading: 'Tensors', subheading: 'Creation'} */\n    TensorBuffer.prototype.toTensor = function () {\n        return Tensor.make(this.shape, { values: this.values }, this.dtype);\n    };\n    return TensorBuffer;\n}());\nexports.TensorBuffer = TensorBuffer;\n// For tracking tensor creation and disposal.\nvar trackerFn = null;\n// Used by chaining methods to call into ops.\nvar opHandler = null;\n// Used to warn about deprecated methods.\nvar deprecationWarningFn = null;\n// This here so that we can use this method on dev branches and keep the\n// functionality at master.\n// tslint:disable-next-line:no-unused-expression\n[deprecationWarningFn];\n/**\n * An external consumer can register itself as the tensor tracker. This way\n * the Tensor class can notify the tracker for every tensor created and\n * disposed.\n */\nfunction setTensorTracker(fn) {\n    trackerFn = fn;\n}\nexports.setTensorTracker = setTensorTracker;\n/**\n * An external consumer can register itself as the op handler. This way the\n * Tensor class can have chaining methods that call into ops via the op handler.\n */\nfunction setOpHandler(handler) {\n    opHandler = handler;\n}\nexports.setOpHandler = setOpHandler;\n/**\n * Sets the deprecation warning function to be used by this file. This way the\n * Tensor class can be a leaf but still use the environment.\n */\nfunction setDeprecationWarningFn(fn) {\n    deprecationWarningFn = fn;\n}\nexports.setDeprecationWarningFn = setDeprecationWarningFn;\n/**\n * A `tf.Tensor` object represents an immutable, multidimensional array of\n * numbers that has a shape and a data type.\n *\n * See `tf.tensor` for details on how to create a `tf.Tensor`.\n */\n/** @doc {heading: 'Tensors', subheading: 'Classes'} */\nvar Tensor = /** @class */ (function () {\n    function Tensor(shape, dtype, values, dataId, backend) {\n        /** Whether this tensor has been globally kept. */\n        this.kept = false;\n        this.isDisposedInternal = false;\n        this.shape = shape.slice();\n        this.dtype = dtype || 'float32';\n        this.size = util.sizeFromShape(shape);\n        this.strides = util_1.computeStrides(shape);\n        this.dataId = dataId != null ? dataId : {};\n        this.id = trackerFn().nextTensorId();\n        this.rankType = (this.rank < 5 ? this.rank.toString() : 'higher');\n        trackerFn().registerTensor(this, backend);\n        if (values != null) {\n            trackerFn().write(backend, this.dataId, values);\n        }\n    }\n    /**\n     * Makes a new tensor with the provided shape and values. Values should be in\n     * a flat array.\n     */\n    Tensor.make = function (shape, data, dtype, backend) {\n        return new Tensor(shape, dtype, data.values, data.dataId, backend);\n    };\n    /** Flatten a Tensor to a 1D array. */\n    /** @doc {heading: 'Tensors', subheading: 'Classes'} */\n    Tensor.prototype.flatten = function () {\n        this.throwIfDisposed();\n        return this.as1D();\n    };\n    /** Converts a size-1 `tf.Tensor` to a `tf.Scalar`. */\n    /** @doc {heading: 'Tensors', subheading: 'Classes'} */\n    Tensor.prototype.asScalar = function () {\n        this.throwIfDisposed();\n        util.assert(this.size === 1, function () { return 'The array must have only 1 element.'; });\n        return this.reshape([]);\n    };\n    /** Converts a `tf.Tensor` to a `tf.Tensor1D`. */\n    /** @doc {heading: 'Tensors', subheading: 'Classes'} */\n    Tensor.prototype.as1D = function () {\n        this.throwIfDisposed();\n        return this.reshape([this.size]);\n    };\n    /**\n     * Converts a `tf.Tensor` to a `tf.Tensor2D`.\n     *\n     * @param rows Number of rows in `tf.Tensor2D`.\n     * @param columns Number of columns in `tf.Tensor2D`.\n     */\n    /** @doc {heading: 'Tensors', subheading: 'Classes'} */\n    Tensor.prototype.as2D = function (rows, columns) {\n        this.throwIfDisposed();\n        return this.reshape([rows, columns]);\n    };\n    /**\n     * Converts a `tf.Tensor` to a `tf.Tensor3D`.\n     *\n     * @param rows Number of rows in `tf.Tensor3D`.\n     * @param columns Number of columns in `tf.Tensor3D`.\n     * @param depth Depth of `tf.Tensor3D`.\n     */\n    /** @doc {heading: 'Tensors', subheading: 'Classes'} */\n    Tensor.prototype.as3D = function (rows, columns, depth) {\n        this.throwIfDisposed();\n        return this.reshape([rows, columns, depth]);\n    };\n    /**\n     * Converts a `tf.Tensor` to a `tf.Tensor4D`.\n     *\n     * @param rows Number of rows in `tf.Tensor4D`.\n     * @param columns Number of columns in `tf.Tensor4D`.\n     * @param depth Depth of `tf.Tensor4D`.\n     * @param depth2 4th dimension of `tf.Tensor4D`.\n     */\n    /** @doc {heading: 'Tensors', subheading: 'Classes'} */\n    Tensor.prototype.as4D = function (rows, columns, depth, depth2) {\n        this.throwIfDisposed();\n        return this.reshape([rows, columns, depth, depth2]);\n    };\n    /**\n     * Converts a `tf.Tensor` to a `tf.Tensor5D`.\n     *\n     * @param rows Number of rows in `tf.Tensor5D`.\n     * @param columns Number of columns in `tf.Tensor5D`.\n     * @param depth Depth of `tf.Tensor5D`.\n     * @param depth2 4th dimension of `tf.Tensor5D`.\n     * @param depth3 5th dimension of 'tf.Tensor5D'\n     */\n    /** @doc {heading: 'Tensors', subheading: 'Classes'} */\n    Tensor.prototype.as5D = function (rows, columns, depth, depth2, depth3) {\n        this.throwIfDisposed();\n        return this.reshape([rows, columns, depth, depth2, depth3]);\n    };\n    /**\n     * Casts a `tf.Tensor` to a specified dtype.\n     *\n     * @param dtype Data-type to cast the tensor to.\n     */\n    /** @doc {heading: 'Tensors', subheading: 'Classes'} */\n    Tensor.prototype.asType = function (dtype) {\n        this.throwIfDisposed();\n        return opHandler.cast(this, dtype);\n    };\n    Object.defineProperty(Tensor.prototype, \"rank\", {\n        get: function () {\n            return this.shape.length;\n        },\n        enumerable: true,\n        configurable: true\n    });\n    /** Returns a promise of `tf.TensorBuffer` that holds the underlying data. */\n    /** @doc {heading: 'Tensors', subheading: 'Classes'} */\n    Tensor.prototype.buffer = function () {\n        return __awaiter(this, void 0, void 0, function () {\n            var vals;\n            return __generator(this, function (_a) {\n                switch (_a.label) {\n                    case 0: return [4 /*yield*/, this.data()];\n                    case 1:\n                        vals = _a.sent();\n                        return [2 /*return*/, opHandler.buffer(this.shape, this.dtype, vals)];\n                }\n            });\n        });\n    };\n    /** Returns a `tf.TensorBuffer` that holds the underlying data. */\n    /** @doc {heading: 'Tensors', subheading: 'Classes'} */\n    Tensor.prototype.bufferSync = function () {\n        return opHandler.buffer(this.shape, this.dtype, this.dataSync());\n    };\n    /**\n     * Returns the tensor data as a nested array. The transfer of data is done\n     * asynchronously.\n     */\n    /** @doc {heading: 'Tensors', subheading: 'Classes'} */\n    Tensor.prototype.array = function () {\n        return __awaiter(this, void 0, void 0, function () {\n            var vals;\n            return __generator(this, function (_a) {\n                switch (_a.label) {\n                    case 0: return [4 /*yield*/, this.data()];\n                    case 1:\n                        vals = _a.sent();\n                        return [2 /*return*/, util_1.toNestedArray(this.shape, vals)];\n                }\n            });\n        });\n    };\n    /**\n     * Returns the tensor data as a nested array. The transfer of data is done\n     * synchronously.\n     */\n    /** @doc {heading: 'Tensors', subheading: 'Classes'} */\n    Tensor.prototype.arraySync = function () {\n        return util_1.toNestedArray(this.shape, this.dataSync());\n    };\n    /**\n     * Asynchronously downloads the values from the `tf.Tensor`. Returns a promise\n     * of `TypedArray` that resolves when the computation has finished.\n     */\n    /** @doc {heading: 'Tensors', subheading: 'Classes'} */\n    Tensor.prototype.data = function () {\n        return __awaiter(this, void 0, void 0, function () {\n            return __generator(this, function (_a) {\n                this.throwIfDisposed();\n                return [2 /*return*/, trackerFn().read(this.dataId)];\n            });\n        });\n    };\n    /**\n     * Synchronously downloads the values from the `tf.Tensor`. This blocks the UI\n     * thread until the values are ready, which can cause performance issues.\n     */\n    /** @doc {heading: 'Tensors', subheading: 'Classes'} */\n    Tensor.prototype.dataSync = function () {\n        this.throwIfDisposed();\n        return trackerFn().readSync(this.dataId);\n    };\n    /**\n     * Disposes `tf.Tensor` from memory.\n     */\n    /** @doc {heading: 'Tensors', subheading: 'Classes'} */\n    Tensor.prototype.dispose = function () {\n        if (this.isDisposed) {\n            return;\n        }\n        trackerFn().disposeTensor(this);\n        this.isDisposedInternal = true;\n    };\n    Object.defineProperty(Tensor.prototype, \"isDisposed\", {\n        get: function () {\n            return this.isDisposedInternal;\n        },\n        enumerable: true,\n        configurable: true\n    });\n    Tensor.prototype.throwIfDisposed = function () {\n        if (this.isDisposed) {\n            throw new Error(\"Tensor is disposed.\");\n        }\n    };\n    /** Casts the array to type `float32` */\n    /** @doc {heading: 'Tensors', subheading: 'Classes'} */\n    Tensor.prototype.toFloat = function () {\n        return this.asType('float32');\n    };\n    /** Casts the array to type `int32` */\n    /** @doc {heading: 'Tensors', subheading: 'Classes'} */\n    Tensor.prototype.toInt = function () {\n        return this.asType('int32');\n    };\n    /** Casts the array to type `bool` */\n    /** @doc {heading: 'Tensors', subheading: 'Classes'} */\n    Tensor.prototype.toBool = function () {\n        return this.asType('bool');\n    };\n    /**\n     * Prints the `tf.Tensor`. See `tf.print` for details.\n     *\n     * @param verbose Whether to print verbose information about the tensor,\n     *    including dtype and size.\n     */\n    /** @doc {heading: 'Tensors', subheading: 'Classes'} */\n    Tensor.prototype.print = function (verbose) {\n        if (verbose === void 0) { verbose = false; }\n        return opHandler.print(this, verbose);\n    };\n    /**\n     * Reshapes the tensor into the provided shape.\n     * See `tf.reshape` for more details.\n     *\n     * @param newShape An array of integers defining the output tensor shape.\n     */\n    /** @doc {heading: 'Tensors', subheading: 'Classes'} */\n    Tensor.prototype.reshape = function (newShape) {\n        this.throwIfDisposed();\n        return opHandler.reshape(this, newShape);\n    };\n    /**\n     * Reshapes the tensor into the shape of the provided tensor.\n     *\n     * @param x The tensor of required shape.\n     */\n    /** @doc {heading: 'Tensors', subheading: 'Classes'} */\n    Tensor.prototype.reshapeAs = function (x) {\n        this.throwIfDisposed();\n        return this.reshape(x.shape);\n    };\n    /**\n     * Returns a `tf.Tensor` that has expanded rank, by inserting a dimension\n     * into the tensor's shape. See `tf.expandDims` for details.\n     *\n     * @param axis The dimension index at which to insert shape of 1. Defaults to\n     *    0 (the first dimension).\n     */\n    /** @doc {heading: 'Tensors', subheading: 'Classes'} */\n    Tensor.prototype.expandDims = function (axis) {\n        if (axis === void 0) { axis = 0; }\n        return opHandler.expandDims(this, axis);\n    };\n    /**\n     * Returns the cumulative sum of the `tf.Tensor` along `axis`.\n     *\n     * @param axis The axis along which to sum. Optional. Defaults to 0.\n     * @param exclusive Whether to perform exclusive cumulative sum. Defaults to\n     *    false. If set to true then the sum of each tensor entry does not include\n     *    its own value, but only the values previous to it along the specified\n     *    axis.\n     * @param reverse Whether to sum in the opposite direction. Defaults to\n     *    false.\n     */\n    /** @doc {heading: 'Tensors', subheading: 'Classes'} */\n    Tensor.prototype.cumsum = function (axis, exclusive, reverse) {\n        if (axis === void 0) { axis = 0; }\n        if (exclusive === void 0) { exclusive = false; }\n        if (reverse === void 0) { reverse = false; }\n        return opHandler.cumsum(this, axis, exclusive, reverse);\n    };\n    /**\n     * Returns a `tf.Tensor` with dimensions of size 1 removed from the shape.\n     * See `tf.squeeze` for more details.\n     *\n     * @param axis A list of numbers. If specified, only squeezes the\n     *    dimensions listed. The dimension index starts at 0. It is an error to\n     *    squeeze a dimension that is not 1.\n     */\n    /** @doc {heading: 'Tensors', subheading: 'Classes'} */\n    Tensor.prototype.squeeze = function (axis) {\n        this.throwIfDisposed();\n        return opHandler.squeeze(this, axis);\n    };\n    /** Returns a copy of the tensor. See `tf.clone` for details. */\n    /** @doc {heading: 'Tensors', subheading: 'Classes'} */\n    Tensor.prototype.clone = function () {\n        this.throwIfDisposed();\n        return opHandler.clone(this);\n    };\n    Tensor.prototype.oneHot = function (depth, onValue, offValue) {\n        this.throwIfDisposed();\n        return opHandler.oneHot(this, depth, onValue, offValue);\n    };\n    /** Returns a human-readable description of the tensor. Useful for logging. */\n    /** @doc {heading: 'Tensors', subheading: 'Classes'} */\n    Tensor.prototype.toString = function (verbose) {\n        if (verbose === void 0) { verbose = false; }\n        var vals = this.dataSync();\n        return tensor_format_1.tensorToString(vals, this.shape, this.dtype, verbose);\n    };\n    // Below is chain API that is not exposed to docs to avoid repetition. To\n    // expose a method, move it above this comment and add @doc and jsdoc.\n    Tensor.prototype.tile = function (reps) {\n        this.throwIfDisposed();\n        return opHandler.tile(this, reps);\n    };\n    Tensor.prototype.gather = function (indices, axis) {\n        if (axis === void 0) { axis = 0; }\n        this.throwIfDisposed();\n        return opHandler.gather(this, indices, axis);\n    };\n    Tensor.prototype.matMul = function (b, transposeA, transposeB) {\n        if (transposeA === void 0) { transposeA = false; }\n        if (transposeB === void 0) { transposeB = false; }\n        this.throwIfDisposed();\n        return opHandler.matMul(this, b, transposeA, transposeB);\n    };\n    Tensor.prototype.dot = function (b) {\n        this.throwIfDisposed();\n        return opHandler.dot(this, b);\n    };\n    Tensor.prototype.norm = function (ord, axis, keepDims) {\n        if (ord === void 0) { ord = 'euclidean'; }\n        if (axis === void 0) { axis = null; }\n        if (keepDims === void 0) { keepDims = false; }\n        this.throwIfDisposed();\n        return opHandler.norm(this, ord, axis, keepDims);\n    };\n    Tensor.prototype.slice = function (begin, size) {\n        this.throwIfDisposed();\n        return opHandler.slice(this, begin, size);\n    };\n    Tensor.prototype.reverse = function (axis) {\n        this.throwIfDisposed();\n        return opHandler.reverse(this, axis);\n    };\n    Tensor.prototype.concat = function (x, axis) {\n        if (axis === void 0) { axis = 0; }\n        this.throwIfDisposed();\n        if (x instanceof Tensor) {\n            x = [x];\n        }\n        return opHandler.concat([this].concat(x), axis);\n    };\n    Tensor.prototype.split = function (numOrSizeSplits, axis) {\n        if (axis === void 0) { axis = 0; }\n        this.throwIfDisposed();\n        return opHandler.split(this, numOrSizeSplits, axis);\n    };\n    Tensor.prototype.stack = function (x, axis) {\n        if (axis === void 0) { axis = 0; }\n        return opHandler.stack([this, x], axis);\n    };\n    Tensor.prototype.unstack = function (axis) {\n        if (axis === void 0) { axis = 0; }\n        return opHandler.unstack(this, axis);\n    };\n    Tensor.prototype.pad = function (paddings, constantValue) {\n        if (constantValue === void 0) { constantValue = 0; }\n        return opHandler.pad(this, paddings, constantValue);\n    };\n    /**\n     * @deprecated Use `tf.batchNorm` instead, and note the positional argument\n     *     change of scale, offset, and varianceEpsilon.\n     */\n    Tensor.prototype.batchNormalization = function (mean, variance, varianceEpsilon, scale, offset) {\n        if (varianceEpsilon === void 0) { varianceEpsilon = .001; }\n        deprecationWarningFn('tf.batchNormalization() is going away. ' +\n            'Use tf.batchNorm() instead, and note the positional argument change ' +\n            'of scale, offset, and varianceEpsilon');\n        return this.batchNorm(mean, variance, offset, scale, varianceEpsilon);\n    };\n    Tensor.prototype.batchNorm = function (mean, variance, offset, scale, varianceEpsilon) {\n        if (varianceEpsilon === void 0) { varianceEpsilon = .001; }\n        this.throwIfDisposed();\n        return opHandler.batchNorm(this, mean, variance, offset, scale, varianceEpsilon);\n    };\n    // Reduction ops.\n    Tensor.prototype.all = function (axis, keepDims) {\n        if (axis === void 0) { axis = null; }\n        if (keepDims === void 0) { keepDims = false; }\n        this.throwIfDisposed();\n        return opHandler.all(this, axis, keepDims);\n    };\n    Tensor.prototype.any = function (axis, keepDims) {\n        if (axis === void 0) { axis = null; }\n        if (keepDims === void 0) { keepDims = false; }\n        this.throwIfDisposed();\n        return opHandler.any(this, axis, keepDims);\n    };\n    Tensor.prototype.logSumExp = function (axis, keepDims) {\n        if (axis === void 0) { axis = null; }\n        if (keepDims === void 0) { keepDims = false; }\n        this.throwIfDisposed();\n        return opHandler.logSumExp(this, axis, keepDims);\n    };\n    Tensor.prototype.sum = function (axis, keepDims) {\n        if (axis === void 0) { axis = null; }\n        if (keepDims === void 0) { keepDims = false; }\n        this.throwIfDisposed();\n        return opHandler.sum(this, axis, keepDims);\n    };\n    Tensor.prototype.prod = function (axis, keepDims) {\n        if (axis === void 0) { axis = null; }\n        if (keepDims === void 0) { keepDims = false; }\n        this.throwIfDisposed();\n        return opHandler.prod(this, axis, keepDims);\n    };\n    Tensor.prototype.mean = function (axis, keepDims) {\n        if (axis === void 0) { axis = null; }\n        if (keepDims === void 0) { keepDims = false; }\n        this.throwIfDisposed();\n        return opHandler.mean(this, axis, keepDims);\n    };\n    Tensor.prototype.min = function (axis, keepDims) {\n        if (axis === void 0) { axis = null; }\n        if (keepDims === void 0) { keepDims = false; }\n        this.throwIfDisposed();\n        return opHandler.min(this, axis, keepDims);\n    };\n    Tensor.prototype.max = function (axis, keepDims) {\n        if (axis === void 0) { axis = null; }\n        if (keepDims === void 0) { keepDims = false; }\n        this.throwIfDisposed();\n        return opHandler.max(this, axis, keepDims);\n    };\n    Tensor.prototype.argMin = function (axis) {\n        if (axis === void 0) { axis = null; }\n        this.throwIfDisposed();\n        return opHandler.argMin(this, axis);\n    };\n    Tensor.prototype.argMax = function (axis) {\n        if (axis === void 0) { axis = null; }\n        this.throwIfDisposed();\n        return opHandler.argMax(this, axis);\n    };\n    // Transformations\n    Tensor.prototype.cast = function (dtype) {\n        this.throwIfDisposed();\n        return opHandler.cast(this, dtype);\n    };\n    // Binary ops.\n    Tensor.prototype.add = function (x) {\n        this.throwIfDisposed();\n        return opHandler.add(this, x);\n    };\n    Tensor.prototype.addStrict = function (x) {\n        this.throwIfDisposed();\n        return opHandler.addStrict(this, x);\n    };\n    Tensor.prototype.atan2 = function (x) {\n        this.throwIfDisposed();\n        return opHandler.atan2(this, x);\n    };\n    Tensor.prototype.sub = function (x) {\n        this.throwIfDisposed();\n        return opHandler.sub(this, x);\n    };\n    Tensor.prototype.subStrict = function (x) {\n        this.throwIfDisposed();\n        return opHandler.subStrict(this, x);\n    };\n    Tensor.prototype.pow = function (exp) {\n        this.throwIfDisposed();\n        return opHandler.pow(this, exp);\n    };\n    Tensor.prototype.powStrict = function (exp) {\n        this.throwIfDisposed();\n        return opHandler.powStrict(this, exp);\n    };\n    Tensor.prototype.mul = function (x) {\n        this.throwIfDisposed();\n        return opHandler.mul(this, x);\n    };\n    Tensor.prototype.mulStrict = function (x) {\n        this.throwIfDisposed();\n        return opHandler.mulStrict(this, x);\n    };\n    Tensor.prototype.div = function (x) {\n        this.throwIfDisposed();\n        return opHandler.div(this, x);\n    };\n    Tensor.prototype.floorDiv = function (x) {\n        this.throwIfDisposed();\n        return opHandler.floorDiv(this, x);\n    };\n    Tensor.prototype.divStrict = function (x) {\n        this.throwIfDisposed();\n        return opHandler.divStrict(this, x);\n    };\n    Tensor.prototype.minimum = function (x) {\n        this.throwIfDisposed();\n        return opHandler.minimum(this, x);\n    };\n    Tensor.prototype.minimumStrict = function (x) {\n        this.throwIfDisposed();\n        return opHandler.minimumStrict(this, x);\n    };\n    Tensor.prototype.maximum = function (x) {\n        this.throwIfDisposed();\n        return opHandler.maximum(this, x);\n    };\n    Tensor.prototype.maximumStrict = function (x) {\n        this.throwIfDisposed();\n        return opHandler.maximumStrict(this, x);\n    };\n    Tensor.prototype.mod = function (x) {\n        this.throwIfDisposed();\n        return opHandler.mod(this, x);\n    };\n    Tensor.prototype.modStrict = function (x) {\n        this.throwIfDisposed();\n        return opHandler.modStrict(this, x);\n    };\n    Tensor.prototype.squaredDifference = function (x) {\n        this.throwIfDisposed();\n        return opHandler.squaredDifference(this, x);\n    };\n    Tensor.prototype.squaredDifferenceStrict = function (x) {\n        this.throwIfDisposed();\n        return opHandler.squaredDifferenceStrict(this, x);\n    };\n    Tensor.prototype.transpose = function (perm) {\n        this.throwIfDisposed();\n        return opHandler.transpose(this, perm);\n    };\n    // Compare ops.\n    Tensor.prototype.notEqual = function (x) {\n        this.throwIfDisposed();\n        return opHandler.notEqual(this, x);\n    };\n    Tensor.prototype.notEqualStrict = function (x) {\n        this.throwIfDisposed();\n        return opHandler.notEqualStrict(this, x);\n    };\n    Tensor.prototype.less = function (x) {\n        this.throwIfDisposed();\n        return opHandler.less(this, x);\n    };\n    Tensor.prototype.lessStrict = function (x) {\n        this.throwIfDisposed();\n        return opHandler.lessStrict(this, x);\n    };\n    Tensor.prototype.equal = function (x) {\n        this.throwIfDisposed();\n        return opHandler.equal(this, x);\n    };\n    Tensor.prototype.equalStrict = function (x) {\n        this.throwIfDisposed();\n        return opHandler.equalStrict(this, x);\n    };\n    Tensor.prototype.lessEqual = function (x) {\n        this.throwIfDisposed();\n        return opHandler.lessEqual(this, x);\n    };\n    Tensor.prototype.lessEqualStrict = function (x) {\n        this.throwIfDisposed();\n        return opHandler.lessEqualStrict(this, x);\n    };\n    Tensor.prototype.greater = function (x) {\n        this.throwIfDisposed();\n        return opHandler.greater(this, x);\n    };\n    Tensor.prototype.greaterStrict = function (x) {\n        this.throwIfDisposed();\n        return opHandler.greaterStrict(this, x);\n    };\n    Tensor.prototype.greaterEqual = function (x) {\n        this.throwIfDisposed();\n        return opHandler.greaterEqual(this, x);\n    };\n    Tensor.prototype.greaterEqualStrict = function (x) {\n        this.throwIfDisposed();\n        return opHandler.greaterEqualStrict(this, x);\n    };\n    // Compare ops.\n    Tensor.prototype.logicalAnd = function (x) {\n        this.throwIfDisposed();\n        return opHandler.logicalAnd(this, x);\n    };\n    Tensor.prototype.logicalOr = function (x) {\n        this.throwIfDisposed();\n        return opHandler.logicalOr(this, x);\n    };\n    Tensor.prototype.logicalNot = function () {\n        this.throwIfDisposed();\n        return opHandler.logicalNot(this);\n    };\n    Tensor.prototype.logicalXor = function (x) {\n        this.throwIfDisposed();\n        return opHandler.logicalXor(this, x);\n    };\n    Tensor.prototype.where = function (condition, x) {\n        this.throwIfDisposed();\n        return opHandler.where(condition, this, x);\n    };\n    // Unary ops.\n    Tensor.prototype.neg = function () {\n        this.throwIfDisposed();\n        return opHandler.neg(this);\n    };\n    Tensor.prototype.ceil = function () {\n        this.throwIfDisposed();\n        return opHandler.ceil(this);\n    };\n    Tensor.prototype.floor = function () {\n        this.throwIfDisposed();\n        return opHandler.floor(this);\n    };\n    Tensor.prototype.sign = function () {\n        this.throwIfDisposed();\n        return opHandler.sign(this);\n    };\n    Tensor.prototype.isNaN = function () {\n        this.throwIfDisposed();\n        return opHandler.isNaN(this);\n    };\n    Tensor.prototype.isInf = function () {\n        this.throwIfDisposed();\n        return opHandler.isInf(this);\n    };\n    Tensor.prototype.isFinite = function () {\n        this.throwIfDisposed();\n        return opHandler.isFinite(this);\n    };\n    Tensor.prototype.exp = function () {\n        this.throwIfDisposed();\n        return opHandler.exp(this);\n    };\n    Tensor.prototype.expm1 = function () {\n        this.throwIfDisposed();\n        return opHandler.expm1(this);\n    };\n    Tensor.prototype.log = function () {\n        this.throwIfDisposed();\n        return opHandler.log(this);\n    };\n    Tensor.prototype.log1p = function () {\n        this.throwIfDisposed();\n        return opHandler.log1p(this);\n    };\n    Tensor.prototype.sqrt = function () {\n        this.throwIfDisposed();\n        return opHandler.sqrt(this);\n    };\n    Tensor.prototype.rsqrt = function () {\n        this.throwIfDisposed();\n        return opHandler.rsqrt(this);\n    };\n    Tensor.prototype.square = function () {\n        this.throwIfDisposed();\n        return opHandler.square(this);\n    };\n    Tensor.prototype.reciprocal = function () {\n        this.throwIfDisposed();\n        return opHandler.reciprocal(this);\n    };\n    Tensor.prototype.abs = function () {\n        this.throwIfDisposed();\n        return opHandler.abs(this);\n    };\n    Tensor.prototype.clipByValue = function (min, max) {\n        this.throwIfDisposed();\n        return opHandler.clipByValue(this, min, max);\n    };\n    Tensor.prototype.relu = function () {\n        this.throwIfDisposed();\n        return opHandler.relu(this);\n    };\n    Tensor.prototype.elu = function () {\n        this.throwIfDisposed();\n        return opHandler.elu(this);\n    };\n    Tensor.prototype.selu = function () {\n        this.throwIfDisposed();\n        return opHandler.selu(this);\n    };\n    Tensor.prototype.leakyRelu = function (alpha) {\n        if (alpha === void 0) { alpha = 0.2; }\n        this.throwIfDisposed();\n        return opHandler.leakyRelu(this, alpha);\n    };\n    Tensor.prototype.prelu = function (alpha) {\n        this.throwIfDisposed();\n        return opHandler.prelu(this, alpha);\n    };\n    Tensor.prototype.sigmoid = function () {\n        this.throwIfDisposed();\n        return opHandler.sigmoid(this);\n    };\n    Tensor.prototype.logSigmoid = function () {\n        this.throwIfDisposed();\n        return opHandler.logSigmoid(this);\n    };\n    Tensor.prototype.softplus = function () {\n        this.throwIfDisposed();\n        return opHandler.softplus(this);\n    };\n    Tensor.prototype.zerosLike = function () {\n        this.throwIfDisposed();\n        return opHandler.zerosLike(this);\n    };\n    Tensor.prototype.onesLike = function () {\n        this.throwIfDisposed();\n        return opHandler.onesLike(this);\n    };\n    Tensor.prototype.sin = function () {\n        this.throwIfDisposed();\n        return opHandler.sin(this);\n    };\n    Tensor.prototype.cos = function () {\n        this.throwIfDisposed();\n        return opHandler.cos(this);\n    };\n    Tensor.prototype.tan = function () {\n        this.throwIfDisposed();\n        return opHandler.tan(this);\n    };\n    Tensor.prototype.asin = function () {\n        this.throwIfDisposed();\n        return opHandler.asin(this);\n    };\n    Tensor.prototype.acos = function () {\n        this.throwIfDisposed();\n        return opHandler.acos(this);\n    };\n    Tensor.prototype.atan = function () {\n        this.throwIfDisposed();\n        return opHandler.atan(this);\n    };\n    Tensor.prototype.sinh = function () {\n        this.throwIfDisposed();\n        return opHandler.sinh(this);\n    };\n    Tensor.prototype.cosh = function () {\n        this.throwIfDisposed();\n        return opHandler.cosh(this);\n    };\n    Tensor.prototype.tanh = function () {\n        this.throwIfDisposed();\n        return opHandler.tanh(this);\n    };\n    Tensor.prototype.asinh = function () {\n        this.throwIfDisposed();\n        return opHandler.asinh(this);\n    };\n    Tensor.prototype.acosh = function () {\n        this.throwIfDisposed();\n        return opHandler.acosh(this);\n    };\n    Tensor.prototype.atanh = function () {\n        this.throwIfDisposed();\n        return opHandler.atanh(this);\n    };\n    Tensor.prototype.erf = function () {\n        this.throwIfDisposed();\n        return opHandler.erf(this);\n    };\n    Tensor.prototype.round = function () {\n        this.throwIfDisposed();\n        return opHandler.round(this);\n    };\n    Tensor.prototype.step = function (alpha) {\n        if (alpha === void 0) { alpha = 0.0; }\n        this.throwIfDisposed();\n        return opHandler.step(this, alpha);\n    };\n    Tensor.prototype.softmax = function (dim) {\n        if (dim === void 0) { dim = -1; }\n        this.throwIfDisposed();\n        return opHandler.softmax(this, dim);\n    };\n    Tensor.prototype.logSoftmax = function (axis) {\n        if (axis === void 0) { axis = -1; }\n        this.throwIfDisposed();\n        return opHandler.logSoftmax(this, axis);\n    };\n    // Image ops.\n    Tensor.prototype.resizeBilinear = function (newShape2D, alignCorners) {\n        if (alignCorners === void 0) { alignCorners = false; }\n        this.throwIfDisposed();\n        return opHandler.image.resizeBilinear(this, newShape2D, alignCorners);\n    };\n    Tensor.prototype.resizeNearestNeighbor = function (newShape2D, alignCorners) {\n        if (alignCorners === void 0) { alignCorners = false; }\n        this.throwIfDisposed();\n        return opHandler.image.resizeNearestNeighbor(this, newShape2D, alignCorners);\n    };\n    // Convolutions.\n    Tensor.prototype.conv1d = function (filter, stride, pad, dataFormat, dilation, dimRoundingMode) {\n        if (dataFormat === void 0) { dataFormat = 'NWC'; }\n        if (dilation === void 0) { dilation = 1; }\n        this.throwIfDisposed();\n        return opHandler.conv1d(this, filter, stride, pad, dataFormat, dilation, dimRoundingMode);\n    };\n    Tensor.prototype.conv2d = function (filter, strides, pad, dataFormat, dilations, dimRoundingMode) {\n        if (dataFormat === void 0) { dataFormat = 'NHWC'; }\n        if (dilations === void 0) { dilations = [1, 1]; }\n        this.throwIfDisposed();\n        return opHandler.conv2d(this, filter, strides, pad, dataFormat, dilations, dimRoundingMode);\n    };\n    Tensor.prototype.conv2dTranspose = function (filter, outputShape, strides, pad, dimRoundingMode) {\n        this.throwIfDisposed();\n        return opHandler.conv2dTranspose(this, filter, outputShape, strides, pad, dimRoundingMode);\n    };\n    Tensor.prototype.depthwiseConv2D = function (filter, strides, pad, dataFormat, dilations, dimRoundingMode) {\n        if (dataFormat === void 0) { dataFormat = 'NHWC'; }\n        if (dilations === void 0) { dilations = [1, 1]; }\n        this.throwIfDisposed();\n        return opHandler.depthwiseConv2d(this, filter, strides, pad, dataFormat, dilations, dimRoundingMode);\n    };\n    Tensor.prototype.separableConv2d = function (depthwiseFilter, pointwiseFilter, strides, pad, dilation, dataFormat) {\n        if (dilation === void 0) { dilation = [1, 1]; }\n        if (dataFormat === void 0) { dataFormat = 'NHWC'; }\n        this.throwIfDisposed();\n        return opHandler.separableConv2d(this, depthwiseFilter, pointwiseFilter, strides, pad, dilation, dataFormat);\n    };\n    // Pooling.\n    Tensor.prototype.avgPool = function (filterSize, strides, pad, dimRoundingMode) {\n        this.throwIfDisposed();\n        return opHandler.avgPool(this, filterSize, strides, pad, dimRoundingMode);\n    };\n    Tensor.prototype.maxPool = function (filterSize, strides, pad, dimRoundingMode) {\n        this.throwIfDisposed();\n        return opHandler.maxPool(this, filterSize, strides, pad, dimRoundingMode);\n    };\n    Tensor.prototype.localResponseNormalization = function (radius, bias, alpha, beta) {\n        if (radius === void 0) { radius = 5; }\n        if (bias === void 0) { bias = 1; }\n        if (alpha === void 0) { alpha = 1; }\n        if (beta === void 0) { beta = 0.5; }\n        return opHandler.localResponseNormalization(this, radius, bias, alpha, beta);\n    };\n    Tensor.prototype.pool = function (windowShape, poolingType, padding, dilationRate, strides) {\n        this.throwIfDisposed();\n        return opHandler.pool(this, windowShape, poolingType, padding, dilationRate, strides);\n    };\n    Tensor.prototype.variable = function (trainable, name, dtype) {\n        if (trainable === void 0) { trainable = true; }\n        this.throwIfDisposed();\n        return Variable.variable(this, trainable, name, dtype);\n    };\n    Tensor.prototype.unsortedSegmentSum = function (segmentIds, numSegments) {\n        this.throwIfDisposed();\n        return opHandler.unsortedSegmentSum(this, segmentIds, numSegments);\n    };\n    Tensor.prototype.batchToSpaceND = function (blockShape, crops) {\n        this.throwIfDisposed();\n        return opHandler.batchToSpaceND(this, blockShape, crops);\n    };\n    Tensor.prototype.spaceToBatchND = function (blockShape, paddings) {\n        this.throwIfDisposed();\n        return opHandler.spaceToBatchND(this, blockShape, paddings);\n    };\n    Tensor.prototype.topk = function (k, sorted) {\n        if (k === void 0) { k = 1; }\n        if (sorted === void 0) { sorted = true; }\n        this.throwIfDisposed();\n        return opHandler.topk(this, k, sorted);\n    };\n    Tensor.prototype.stridedSlice = function (begin, end, strides, beginMask, endMask, ellipsisMask, newAxisMask, shrinkAxisMask) {\n        if (beginMask === void 0) { beginMask = 0; }\n        if (endMask === void 0) { endMask = 0; }\n        if (ellipsisMask === void 0) { ellipsisMask = 0; }\n        if (newAxisMask === void 0) { newAxisMask = 0; }\n        if (shrinkAxisMask === void 0) { shrinkAxisMask = 0; }\n        this.throwIfDisposed();\n        return opHandler.stridedSlice(this, begin, end, strides, beginMask, endMask, ellipsisMask, newAxisMask, shrinkAxisMask);\n    };\n    Tensor.prototype.depthToSpace = function (blockSize, dataFormat) {\n        this.throwIfDisposed();\n        return opHandler.depthToSpace(this, blockSize, dataFormat);\n    };\n    Tensor.prototype.fft = function () {\n        this.throwIfDisposed();\n        return opHandler.spectral.fft(this);\n    };\n    Tensor.prototype.ifft = function () {\n        this.throwIfDisposed();\n        return opHandler.spectral.ifft(this);\n    };\n    Tensor.prototype.rfft = function () {\n        this.throwIfDisposed();\n        return opHandler.spectral.rfft(this);\n    };\n    Tensor.prototype.irfft = function () {\n        this.throwIfDisposed();\n        return opHandler.spectral.irfft(this);\n    };\n    return Tensor;\n}());\nexports.Tensor = Tensor;\nObject.defineProperty(Tensor, Symbol.hasInstance, {\n    value: function (instance) {\n        return !!instance && instance.dataId != null && instance.shape != null &&\n            instance.dtype != null;\n    }\n});\n/**\n * A mutable `tf.Tensor`, useful for persisting state, e.g. for training.\n */\n/** @doc {heading: 'Tensors', subheading: 'Classes'} */\nvar Variable = /** @class */ (function (_super) {\n    __extends(Variable, _super);\n    /**\n     * Private constructor since we cannot add logic before calling `super()`.\n     * Instead, we expose static `Variable.variable` method below, which will be\n     * added to global namespace.\n     */\n    function Variable(initialValue, trainable, name) {\n        if (trainable === void 0) { trainable = true; }\n        var _this = _super.call(this, initialValue.shape, initialValue.dtype, null /* values */, initialValue.dataId) || this;\n        _this.trainable = trainable;\n        _this.name = name;\n        if (_this.name == null) {\n            _this.name = trackerFn().nextVariableId().toString();\n        }\n        try {\n            trackerFn().registerVariable(_this);\n        }\n        catch (ex) {\n            trackerFn().disposeTensor(_this);\n            throw ex;\n        }\n        return _this;\n    }\n    /**\n     * Creates a new variable with the provided initial value.\n     * ```js\n     * const x = tf.variable(tf.tensor([1, 2, 3]));\n     * x.assign(tf.tensor([4, 5, 6]));\n     *\n     * x.print();\n     * ```\n     *\n     * @param initialValue Initial value for the tensor.\n     * @param trainable If true, optimizers are allowed to update it.\n     * @param name Name of the variable. Defaults to a unique id.\n     * @param dtype If set, initialValue will be converted to the given type.\n     */\n    /** @doc {heading: 'Tensors', subheading: 'Creation'} */\n    Variable.variable = function (initialValue, trainable, name, dtype) {\n        if (trainable === void 0) { trainable = true; }\n        if (dtype != null && dtype !== initialValue.dtype) {\n            initialValue = initialValue.asType(dtype);\n        }\n        return new Variable(initialValue, trainable, name);\n    };\n    /**\n     * Assign a new `tf.Tensor` to this variable. The new `tf.Tensor` must have\n     * the same shape and dtype as the old `tf.Tensor`.\n     *\n     * @param newValue New tensor to be assigned to this variable.\n     */\n    /** @doc {heading: 'Tensors', subheading: 'Classes'} */\n    Variable.prototype.assign = function (newValue) {\n        if (newValue.dtype !== this.dtype) {\n            throw new Error(\"dtype of the new value (\" + newValue.dtype + \") and \" +\n                (\"previous value (\" + this.dtype + \") must match\"));\n        }\n        if (!util.arraysEqual(newValue.shape, this.shape)) {\n            throw new Error(\"shape of the new value (\" + newValue.shape + \") and \" +\n                (\"previous value (\" + this.shape + \") must match\"));\n        }\n        trackerFn().disposeTensor(this);\n        this.dataId = newValue.dataId;\n        trackerFn().registerTensor(this);\n    };\n    Variable.prototype.dispose = function () {\n        trackerFn().disposeVariable(this);\n    };\n    return Variable;\n}(Tensor));\nexports.Variable = Variable;\nObject.defineProperty(Variable, Symbol.hasInstance, {\n    value: function (instance) {\n        return instance instanceof Tensor && instance.assign != null &&\n            instance.assign instanceof Function;\n    }\n});\nvar variable = Variable.variable;\nexports.variable = variable;\n//# sourceMappingURL=tensor.js.map","\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar util_1 = require(\"./util\");\n// Maximum number of values before we decide to show ellipsis.\nvar FORMAT_LIMIT_NUM_VALS = 20;\n// Number of first and last values to show when displaying a, b,...,y, z.\nvar FORMAT_NUM_FIRST_LAST_VALS = 3;\n// Number of significant digits to show.\nvar FORMAT_NUM_SIG_DIGITS = 7;\nfunction tensorToString(vals, shape, dtype, verbose) {\n    var strides = util_1.computeStrides(shape);\n    var padPerCol = computeMaxSizePerColumn(vals, shape, dtype, strides);\n    var rank = shape.length;\n    var valsLines = subTensorToString(vals, shape, dtype, strides, padPerCol);\n    var lines = ['Tensor'];\n    if (verbose) {\n        lines.push(\"  dtype: \" + dtype);\n        lines.push(\"  rank: \" + rank);\n        lines.push(\"  shape: [\" + shape + \"]\");\n        lines.push(\"  values:\");\n    }\n    lines.push(valsLines.map(function (l) { return '    ' + l; }).join('\\n'));\n    return lines.join('\\n');\n}\nexports.tensorToString = tensorToString;\nfunction computeMaxSizePerColumn(vals, shape, dtype, strides) {\n    var n = util_1.sizeFromShape(shape);\n    var numCols = strides[strides.length - 1];\n    var padPerCol = new Array(numCols).fill(0);\n    var rank = shape.length;\n    var valuesOrTuples = dtype === 'complex64' ? createComplexTuples(vals) : vals;\n    if (rank > 1) {\n        for (var row = 0; row < n / numCols; row++) {\n            var offset = row * numCols;\n            for (var j = 0; j < numCols; j++) {\n                padPerCol[j] = Math.max(padPerCol[j], valToString(valuesOrTuples[offset + j], 0, dtype).length);\n            }\n        }\n    }\n    return padPerCol;\n}\nfunction valToString(val, pad, dtype) {\n    var valStr;\n    if (Array.isArray(val)) {\n        valStr = parseFloat(val[0].toFixed(FORMAT_NUM_SIG_DIGITS)) + \" + \" +\n            (parseFloat(val[1].toFixed(FORMAT_NUM_SIG_DIGITS)) + \"j\");\n    }\n    else if (util_1.isString(val)) {\n        valStr = \"'\" + val + \"'\";\n    }\n    else if (dtype === 'bool') {\n        valStr = boolNumToString(val);\n    }\n    else {\n        valStr = parseFloat(val.toFixed(FORMAT_NUM_SIG_DIGITS)).toString();\n    }\n    return util_1.rightPad(valStr, pad);\n}\nfunction boolNumToString(v) {\n    return v === 0 ? 'false' : 'true';\n}\nfunction subTensorToString(vals, shape, dtype, strides, padPerCol, isLast) {\n    if (isLast === void 0) { isLast = true; }\n    var storagePerElement = dtype === 'complex64' ? 2 : 1;\n    var size = shape[0];\n    var rank = shape.length;\n    if (rank === 0) {\n        if (dtype === 'complex64') {\n            var complexTuple = createComplexTuples(vals);\n            return [valToString(complexTuple[0], 0, dtype)];\n        }\n        if (dtype === 'bool') {\n            return [boolNumToString(vals[0])];\n        }\n        return [vals[0].toString()];\n    }\n    if (rank === 1) {\n        if (size > FORMAT_LIMIT_NUM_VALS) {\n            var firstValsSize = FORMAT_NUM_FIRST_LAST_VALS * storagePerElement;\n            var firstVals = Array.from(vals.slice(0, firstValsSize));\n            var lastVals = Array.from(vals.slice(size - FORMAT_NUM_FIRST_LAST_VALS * storagePerElement, size));\n            if (dtype === 'complex64') {\n                firstVals = createComplexTuples(firstVals);\n                lastVals = createComplexTuples(lastVals);\n            }\n            return [\n                '[' + firstVals.map(function (x, i) { return valToString(x, padPerCol[i], dtype); }).join(', ') +\n                    ', ..., ' +\n                    lastVals\n                        .map(function (x, i) { return valToString(x, padPerCol[size - FORMAT_NUM_FIRST_LAST_VALS + i], dtype); })\n                        .join(', ') +\n                    ']'\n            ];\n        }\n        var displayVals = dtype === 'complex64' ? createComplexTuples(vals) :\n            Array.from(vals);\n        return [\n            '[' + displayVals.map(function (x, i) { return valToString(x, padPerCol[i], dtype); }).join(', ') +\n                ']'\n        ];\n    }\n    // The array is rank 2 or more.\n    var subshape = shape.slice(1);\n    var substrides = strides.slice(1);\n    var stride = strides[0] * storagePerElement;\n    var lines = [];\n    if (size > FORMAT_LIMIT_NUM_VALS) {\n        for (var i = 0; i < FORMAT_NUM_FIRST_LAST_VALS; i++) {\n            var start = i * stride;\n            var end = start + stride;\n            lines.push.apply(lines, subTensorToString(vals.slice(start, end), subshape, dtype, substrides, padPerCol, false /* isLast */));\n        }\n        lines.push('...');\n        for (var i = size - FORMAT_NUM_FIRST_LAST_VALS; i < size; i++) {\n            var start = i * stride;\n            var end = start + stride;\n            lines.push.apply(lines, subTensorToString(vals.slice(start, end), subshape, dtype, substrides, padPerCol, i === size - 1 /* isLast */));\n        }\n    }\n    else {\n        for (var i = 0; i < size; i++) {\n            var start = i * stride;\n            var end = start + stride;\n            lines.push.apply(lines, subTensorToString(vals.slice(start, end), subshape, dtype, substrides, padPerCol, i === size - 1 /* isLast */));\n        }\n    }\n    var sep = rank === 2 ? ',' : '';\n    lines[0] = '[' + lines[0] + sep;\n    for (var i = 1; i < lines.length - 1; i++) {\n        lines[i] = ' ' + lines[i] + sep;\n    }\n    var newLineSep = ',\\n';\n    for (var i = 2; i < rank; i++) {\n        newLineSep += '\\n';\n    }\n    lines[lines.length - 1] =\n        ' ' + lines[lines.length - 1] + ']' + (isLast ? '' : newLineSep);\n    return lines;\n}\nfunction createComplexTuples(vals) {\n    var complexTuples = [];\n    for (var i = 0; i < vals.length; i += 2) {\n        complexTuples.push([vals[i], vals[i + 1]]);\n    }\n    return complexTuples;\n}\n//# sourceMappingURL=tensor_format.js.map","\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar tensor_1 = require(\"./tensor\");\nvar types_1 = require(\"./types\");\nvar util_1 = require(\"./util\");\nfunction makeTypesMatch(a, b) {\n    if (a.dtype === b.dtype) {\n        return [a, b];\n    }\n    var dtype = types_1.upcastType(a.dtype, b.dtype);\n    return [a.cast(dtype), b.cast(dtype)];\n}\nexports.makeTypesMatch = makeTypesMatch;\nfunction assertTypesMatch(a, b) {\n    util_1.assert(a.dtype === b.dtype, function () { return \"The dtypes of the first(\" + a.dtype + \") and\" +\n        (\" second(\" + b.dtype + \") input must match\"); });\n}\nexports.assertTypesMatch = assertTypesMatch;\nfunction isTensorInList(tensor, tensorList) {\n    for (var i = 0; i < tensorList.length; i++) {\n        if (tensorList[i].id === tensor.id) {\n            return true;\n        }\n    }\n    return false;\n}\nexports.isTensorInList = isTensorInList;\n/**\n * Extracts any `Tensor`s found within the provided object.\n *\n * @param container an object that may be a `Tensor` or may directly contain\n *   `Tensor`s, such as a `Tensor[]` or `{key: Tensor, ...}`. In general it\n *   is safe to pass any object here, except that `Promise`s are not\n *   supported.\n * @returns An array of `Tensors` found within the passed object. If the\n *   argument is simply a `Tensor', a list containing that `Tensor` is\n *   returned. If the object is not a `Tensor` or does not\n *   contain `Tensors`, an empty list is returned.\n */\nfunction getTensorsInContainer(result) {\n    var list = [];\n    var seen = new Set();\n    walkTensorContainer(result, list, seen);\n    return list;\n}\nexports.getTensorsInContainer = getTensorsInContainer;\nfunction walkTensorContainer(container, list, seen) {\n    if (container == null) {\n        return;\n    }\n    if (container instanceof tensor_1.Tensor) {\n        list.push(container);\n        return;\n    }\n    if (!isIterable(container)) {\n        return;\n    }\n    // Iteration over keys works also for arrays.\n    var iterable = container;\n    for (var k in iterable) {\n        var val = iterable[k];\n        if (!seen.has(val)) {\n            seen.add(val);\n            walkTensorContainer(val, list, seen);\n        }\n    }\n}\n// tslint:disable-next-line:no-any\nfunction isIterable(obj) {\n    return Array.isArray(obj) || typeof obj === 'object';\n}\n//# sourceMappingURL=tensor_util.js.map","\n/**\n * @license\n * Copyright 2017 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar Rank;\n(function (Rank) {\n    Rank[\"R0\"] = \"R0\";\n    Rank[\"R1\"] = \"R1\";\n    Rank[\"R2\"] = \"R2\";\n    Rank[\"R3\"] = \"R3\";\n    Rank[\"R4\"] = \"R4\";\n    Rank[\"R5\"] = \"R5\";\n    Rank[\"R6\"] = \"R6\";\n})(Rank = exports.Rank || (exports.Rank = {}));\n// Looks for upcasting types. Used, for example, in operations with mixed dtype\n// inputs.\nvar UpcastInt32AndMap;\n(function (UpcastInt32AndMap) {\n    UpcastInt32AndMap[\"float32\"] = \"float32\";\n    UpcastInt32AndMap[\"int32\"] = \"int32\";\n    UpcastInt32AndMap[\"bool\"] = \"int32\";\n    UpcastInt32AndMap[\"complex64\"] = \"complex64\";\n})(UpcastInt32AndMap || (UpcastInt32AndMap = {}));\nvar UpcastBoolAndMap;\n(function (UpcastBoolAndMap) {\n    UpcastBoolAndMap[\"float32\"] = \"float32\";\n    UpcastBoolAndMap[\"int32\"] = \"int32\";\n    UpcastBoolAndMap[\"bool\"] = \"bool\";\n    UpcastBoolAndMap[\"complex64\"] = \"complex64\";\n})(UpcastBoolAndMap || (UpcastBoolAndMap = {}));\nvar UpcastFloat32AndMap;\n(function (UpcastFloat32AndMap) {\n    UpcastFloat32AndMap[\"float32\"] = \"float32\";\n    UpcastFloat32AndMap[\"int32\"] = \"float32\";\n    UpcastFloat32AndMap[\"bool\"] = \"float32\";\n    UpcastFloat32AndMap[\"complex64\"] = \"complex64\";\n})(UpcastFloat32AndMap || (UpcastFloat32AndMap = {}));\nvar UpcastComplex64AndMap;\n(function (UpcastComplex64AndMap) {\n    UpcastComplex64AndMap[\"float32\"] = \"complex64\";\n    UpcastComplex64AndMap[\"int32\"] = \"complex64\";\n    UpcastComplex64AndMap[\"bool\"] = \"complex64\";\n    UpcastComplex64AndMap[\"complex64\"] = \"complex64\";\n})(UpcastComplex64AndMap || (UpcastComplex64AndMap = {}));\nvar upcastTypeMap = {\n    'float32': UpcastFloat32AndMap,\n    'int32': UpcastInt32AndMap,\n    'bool': UpcastBoolAndMap,\n    'complex64': UpcastComplex64AndMap\n};\nfunction upcastType(typeA, typeB) {\n    if (typeA === 'string' || typeB === 'string') {\n        if (typeA === 'string' && typeB === 'string') {\n            return 'string';\n        }\n        throw new Error(\"Can not upcast \" + typeA + \" with \" + typeB);\n    }\n    return upcastTypeMap[typeA][typeB];\n}\nexports.upcastType = upcastType;\n/** Returns the output type after summation. */\nfunction sumOutType(type) {\n    return upcastType(type, 'int32');\n}\nexports.sumOutType = sumOutType;\n//# sourceMappingURL=types.js.map","\nObject.defineProperty(exports, \"__esModule\", { value: true });\n/**\n * @license\n * Copyright 2019 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar device_util = require(\"./device_util\");\nvar environment_1 = require(\"./environment\");\n/**\n * This file contains environment-related flag registrations.\n */\n/** Whether to enable debug mode. */\nenvironment_1.ENV.registerFlag('DEBUG', function () { return false; }, function (debugValue) {\n    if (debugValue) {\n        console.warn('Debugging mode is ON. The output of every math call will ' +\n            'be downloaded to CPU and checked for NaNs. ' +\n            'This significantly impacts performance.');\n    }\n});\n/** Whether we are in a browser (as versus, say, node.js) environment. */\nenvironment_1.ENV.registerFlag('IS_BROWSER', function () { return device_util.isBrowser(); });\n/** Whether we are in a browser (as versus, say, node.js) environment. */\nenvironment_1.ENV.registerFlag('IS_NODE', function () { return (typeof process !== 'undefined') &&\n    (typeof process.versions !== 'undefined') &&\n    (typeof process.versions.node !== 'undefined'); });\n/** Whether this browser is Chrome. */\nenvironment_1.ENV.registerFlag('IS_CHROME', function () { return typeof navigator !== 'undefined' && navigator != null &&\n    navigator.userAgent != null && /Chrome/.test(navigator.userAgent) &&\n    /Google Inc/.test(navigator.vendor); });\n/**\n * True when the environment is \"production\" where we disable safety checks\n * to gain performance.\n */\nenvironment_1.ENV.registerFlag('PROD', function () { return false; });\n/**\n * Whether to do sanity checks when inferring a shape from user-provided\n * values, used when creating a new tensor.\n */\nenvironment_1.ENV.registerFlag('TENSORLIKE_CHECK_SHAPE_CONSISTENCY', function () { return !environment_1.ENV.getBool('PROD'); });\n/** Whether deprecation warnings are enabled. */\nenvironment_1.ENV.registerFlag('DEPRECATION_WARNINGS_ENABLED', function () { return true; });\n/** True if running unit tests. */\nenvironment_1.ENV.registerFlag('IS_TEST', function () { return false; });\n//# sourceMappingURL=flags.js.map","\n/**\n * @license\n * Copyright 2017 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nfunction isMobile() {\n    // tslint:disable-next-line:no-any\n    var a = navigator.userAgent || navigator.vendor || window.opera;\n    // tslint:disable-next-line:max-line-length\n    return /(android|bb\\d+|meego).+mobile|avantgo|bada\\/|blackberry|blazer|compal|elaine|fennec|hiptop|iemobile|ip(hone|od)|iris|kindle|lge |maemo|midp|mmp|mobile.+firefox|netfront|opera m(ob|in)i|palm( os)?|phone|p(ixi|re)\\/|plucker|pocket|psp|series(4|6)0|symbian|treo|up\\.(browser|link)|vodafone|wap|windows ce|xda|xiino/i\n        .test(a) ||\n        // tslint:disable-next-line:max-line-length\n        /1207|6310|6590|3gso|4thp|50[1-6]i|770s|802s|a wa|abac|ac(er|oo|s\\-)|ai(ko|rn)|al(av|ca|co)|amoi|an(ex|ny|yw)|aptu|ar(ch|go)|as(te|us)|attw|au(di|\\-m|r |s )|avan|be(ck|ll|nq)|bi(lb|rd)|bl(ac|az)|br(e|v)w|bumb|bw\\-(n|u)|c55\\/|capi|ccwa|cdm\\-|cell|chtm|cldc|cmd\\-|co(mp|nd)|craw|da(it|ll|ng)|dbte|dc\\-s|devi|dica|dmob|do(c|p)o|ds(12|\\-d)|el(49|ai)|em(l2|ul)|er(ic|k0)|esl8|ez([4-7]0|os|wa|ze)|fetc|fly(\\-|_)|g1 u|g560|gene|gf\\-5|g\\-mo|go(\\.w|od)|gr(ad|un)|haie|hcit|hd\\-(m|p|t)|hei\\-|hi(pt|ta)|hp( i|ip)|hs\\-c|ht(c(\\-| |_|a|g|p|s|t)|tp)|hu(aw|tc)|i\\-(20|go|ma)|i230|iac( |\\-|\\/)|ibro|idea|ig01|ikom|im1k|inno|ipaq|iris|ja(t|v)a|jbro|jemu|jigs|kddi|keji|kgt( |\\/)|klon|kpt |kwc\\-|kyo(c|k)|le(no|xi)|lg( g|\\/(k|l|u)|50|54|\\-[a-w])|libw|lynx|m1\\-w|m3ga|m50\\/|ma(te|ui|xo)|mc(01|21|ca)|m\\-cr|me(rc|ri)|mi(o8|oa|ts)|mmef|mo(01|02|bi|de|do|t(\\-| |o|v)|zz)|mt(50|p1|v )|mwbp|mywa|n10[0-2]|n20[2-3]|n30(0|2)|n50(0|2|5)|n7(0(0|1)|10)|ne((c|m)\\-|on|tf|wf|wg|wt)|nok(6|i)|nzph|o2im|op(ti|wv)|oran|owg1|p800|pan(a|d|t)|pdxg|pg(13|\\-([1-8]|c))|phil|pire|pl(ay|uc)|pn\\-2|po(ck|rt|se)|prox|psio|pt\\-g|qa\\-a|qc(07|12|21|32|60|\\-[2-7]|i\\-)|qtek|r380|r600|raks|rim9|ro(ve|zo)|s55\\/|sa(ge|ma|mm|ms|ny|va)|sc(01|h\\-|oo|p\\-)|sdk\\/|se(c(\\-|0|1)|47|mc|nd|ri)|sgh\\-|shar|sie(\\-|m)|sk\\-0|sl(45|id)|sm(al|ar|b3|it|t5)|so(ft|ny)|sp(01|h\\-|v\\-|v )|sy(01|mb)|t2(18|50)|t6(00|10|18)|ta(gt|lk)|tcl\\-|tdg\\-|tel(i|m)|tim\\-|t\\-mo|to(pl|sh)|ts(70|m\\-|m3|m5)|tx\\-9|up(\\.b|g1|si)|utst|v400|v750|veri|vi(rg|te)|vk(40|5[0-3]|\\-v)|vm40|voda|vulc|vx(52|53|60|61|70|80|81|83|85|98)|w3c(\\-| )|webc|whit|wi(g |nc|nw)|wmlb|wonu|x700|yas\\-|your|zeto|zte\\-/i\n            .test(a.substr(0, 4));\n}\nexports.isMobile = isMobile;\nfunction isBrowser() {\n    return typeof window !== 'undefined';\n}\nexports.isBrowser = isBrowser;\n//# sourceMappingURL=device_util.js.map","\n/**\n * @license\n * Copyright 2017 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : new P(function (resolve) { resolve(result.value); }).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nvar __generator = (this && this.__generator) || function (thisArg, body) {\n    var _ = { label: 0, sent: function() { if (t[0] & 1) throw t[1]; return t[1]; }, trys: [], ops: [] }, f, y, t, g;\n    return g = { next: verb(0), \"throw\": verb(1), \"return\": verb(2) }, typeof Symbol === \"function\" && (g[Symbol.iterator] = function() { return this; }), g;\n    function verb(n) { return function (v) { return step([n, v]); }; }\n    function step(op) {\n        if (f) throw new TypeError(\"Generator is already executing.\");\n        while (_) try {\n            if (f = 1, y && (t = op[0] & 2 ? y[\"return\"] : op[0] ? y[\"throw\"] || ((t = y[\"return\"]) && t.call(y), 0) : y.next) && !(t = t.call(y, op[1])).done) return t;\n            if (y = 0, t) op = [op[0] & 2, t.value];\n            switch (op[0]) {\n                case 0: case 1: t = op; break;\n                case 4: _.label++; return { value: op[1], done: false };\n                case 5: _.label++; y = op[1]; op = [0]; continue;\n                case 7: op = _.ops.pop(); _.trys.pop(); continue;\n                default:\n                    if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) { _ = 0; continue; }\n                    if (op[0] === 3 && (!t || (op[1] > t[0] && op[1] < t[3]))) { _.label = op[1]; break; }\n                    if (op[0] === 6 && _.label < t[1]) { _.label = t[1]; t = op; break; }\n                    if (t && _.label < t[2]) { _.label = t[2]; _.ops.push(op); break; }\n                    if (t[2]) _.ops.pop();\n                    _.trys.pop(); continue;\n            }\n            op = body.call(thisArg, _);\n        } catch (e) { op = [6, e]; y = 0; } finally { f = t = 0; }\n        if (op[0] & 5) throw op[1]; return { value: op[0] ? op[1] : void 0, done: true };\n    }\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\n// Import webgl flags.\nrequire(\"./flags_webgl\");\nvar device_util = require(\"../../device_util\");\nvar engine_1 = require(\"../../engine\");\nvar environment_1 = require(\"../../environment\");\nvar globals_1 = require(\"../../globals\");\nvar log_1 = require(\"../../log\");\nvar array_ops_util = require(\"../../ops/array_ops_util\");\nvar axis_util = require(\"../../ops/axis_util\");\nvar concat_util_1 = require(\"../../ops/concat_util\");\nvar gather_nd_util = require(\"../../ops/gather_nd_util\");\nvar reduce_util = require(\"../../ops/reduce_util\");\nvar scatter_nd_util = require(\"../../ops/scatter_nd_util\");\nvar segment_util = require(\"../../ops/segment_util\");\nvar slice_util_1 = require(\"../../ops/slice_util\");\nvar softmax_1 = require(\"../../ops/softmax\");\nvar tensor_ops_1 = require(\"../../ops/tensor_ops\");\nvar tensor_1 = require(\"../../tensor\");\nvar types_1 = require(\"../../types\");\nvar util = require(\"../../util\");\nvar util_1 = require(\"../../util\");\nvar backend_1 = require(\"../backend\");\nvar backend_util = require(\"../backend_util\");\nvar complex_util_1 = require(\"../complex_util\");\nvar non_max_suppression_impl_1 = require(\"../non_max_suppression_impl\");\nvar split_shared_1 = require(\"../split_shared\");\nvar topk_impl_1 = require(\"../topk_impl\");\nvar where_impl_1 = require(\"../where_impl\");\nvar addn_gpu_1 = require(\"./addn_gpu\");\nvar addn_packed_gpu_1 = require(\"./addn_packed_gpu\");\nvar argminmax_gpu_1 = require(\"./argminmax_gpu\");\nvar argminmax_packed_gpu_1 = require(\"./argminmax_packed_gpu\");\nvar avg_pool_backprop_gpu_1 = require(\"./avg_pool_backprop_gpu\");\nvar batchnorm_gpu_1 = require(\"./batchnorm_gpu\");\nvar batchnorm_packed_gpu_1 = require(\"./batchnorm_packed_gpu\");\nvar binaryop_complex_gpu = require(\"./binaryop_complex_gpu\");\nvar binaryop_complex_gpu_1 = require(\"./binaryop_complex_gpu\");\nvar binaryop_gpu = require(\"./binaryop_gpu\");\nvar binaryop_gpu_1 = require(\"./binaryop_gpu\");\nvar binaryop_packed_gpu = require(\"./binaryop_packed_gpu\");\nvar binaryop_packed_gpu_1 = require(\"./binaryop_packed_gpu\");\nvar canvas_util_1 = require(\"./canvas_util\");\nvar clip_gpu_1 = require(\"./clip_gpu\");\nvar clip_packed_gpu_1 = require(\"./clip_packed_gpu\");\nvar complex_abs_gpu_1 = require(\"./complex_abs_gpu\");\nvar concat_gpu_1 = require(\"./concat_gpu\");\nvar concat_packed_gpu_1 = require(\"./concat_packed_gpu\");\nvar conv_backprop_gpu_1 = require(\"./conv_backprop_gpu\");\nvar conv_backprop_gpu_depthwise_1 = require(\"./conv_backprop_gpu_depthwise\");\nvar conv_gpu_1 = require(\"./conv_gpu\");\nvar conv_gpu_depthwise_1 = require(\"./conv_gpu_depthwise\");\nvar conv_packed_gpu_depthwise_1 = require(\"./conv_packed_gpu_depthwise\");\nvar crop_and_resize_gpu_1 = require(\"./crop_and_resize_gpu\");\nvar cumsum_gpu_1 = require(\"./cumsum_gpu\");\nvar depth_to_space_gpu_1 = require(\"./depth_to_space_gpu\");\nvar encode_float_gpu_1 = require(\"./encode_float_gpu\");\nvar fft_gpu = require(\"./fft_gpu\");\nvar fft_gpu_1 = require(\"./fft_gpu\");\nvar fill_gpu_1 = require(\"./fill_gpu\");\nvar from_pixels_gpu_1 = require(\"./from_pixels_gpu\");\nvar gather_gpu_1 = require(\"./gather_gpu\");\nvar gather_nd_gpu_1 = require(\"./gather_nd_gpu\");\nvar gpgpu_context_1 = require(\"./gpgpu_context\");\nvar gpgpu_math = require(\"./gpgpu_math\");\nvar im2col_packed_gpu_1 = require(\"./im2col_packed_gpu\");\nvar lrn_gpu_1 = require(\"./lrn_gpu\");\nvar lrn_grad_gpu_1 = require(\"./lrn_grad_gpu\");\nvar lrn_packed_gpu_1 = require(\"./lrn_packed_gpu\");\nvar max_pool_backprop_gpu_1 = require(\"./max_pool_backprop_gpu\");\nvar mulmat_packed_gpu_1 = require(\"./mulmat_packed_gpu\");\nvar multinomial_gpu_1 = require(\"./multinomial_gpu\");\nvar onehot_gpu_1 = require(\"./onehot_gpu\");\nvar pack_gpu_1 = require(\"./pack_gpu\");\nvar pad_gpu_1 = require(\"./pad_gpu\");\nvar pad_packed_gpu_1 = require(\"./pad_packed_gpu\");\nvar pool_gpu_1 = require(\"./pool_gpu\");\nvar reduce_gpu_1 = require(\"./reduce_gpu\");\nvar reshape_packed_gpu_1 = require(\"./reshape_packed_gpu\");\nvar resize_bilinear_backprop_gpu_1 = require(\"./resize_bilinear_backprop_gpu\");\nvar resize_bilinear_gpu_1 = require(\"./resize_bilinear_gpu\");\nvar resize_bilinear_packed_gpu_1 = require(\"./resize_bilinear_packed_gpu\");\nvar resize_nearest_neighbor_backprop_gpu_1 = require(\"./resize_nearest_neighbor_backprop_gpu\");\nvar resize_nearest_neighbor_gpu_1 = require(\"./resize_nearest_neighbor_gpu\");\nvar reverse_gpu_1 = require(\"./reverse_gpu\");\nvar reverse_packed_gpu_1 = require(\"./reverse_packed_gpu\");\nvar scatter_gpu_1 = require(\"./scatter_gpu\");\nvar segment_gpu_1 = require(\"./segment_gpu\");\nvar select_gpu_1 = require(\"./select_gpu\");\nvar slice_gpu_1 = require(\"./slice_gpu\");\nvar slice_packed_gpu_1 = require(\"./slice_packed_gpu\");\nvar strided_slice_gpu_1 = require(\"./strided_slice_gpu\");\nvar tex_util = require(\"./tex_util\");\nvar tex_util_1 = require(\"./tex_util\");\nvar texture_manager_1 = require(\"./texture_manager\");\nvar tile_gpu_1 = require(\"./tile_gpu\");\nvar transpose_gpu_1 = require(\"./transpose_gpu\");\nvar transpose_packed_gpu_1 = require(\"./transpose_packed_gpu\");\nvar unary_op = require(\"./unaryop_gpu\");\nvar unaryop_gpu_1 = require(\"./unaryop_gpu\");\nvar unary_packed_op = require(\"./unaryop_packed_gpu\");\nvar unaryop_packed_gpu_1 = require(\"./unaryop_packed_gpu\");\nvar unpack_gpu_1 = require(\"./unpack_gpu\");\nvar webgl_util = require(\"./webgl_util\");\nvar binaryCaches = {};\nfunction getBinaryCache(webGLVersion) {\n    if (webGLVersion in binaryCaches) {\n        return binaryCaches[webGLVersion];\n    }\n    binaryCaches[webGLVersion] = {};\n    return binaryCaches[webGLVersion];\n}\nfunction mapActivationToShaderProgram(activation, packed) {\n    if (packed === void 0) { packed = false; }\n    if (activation === 'linear') {\n        if (packed) {\n            return unary_packed_op.LINEAR;\n        }\n        return unary_op.LINEAR;\n    }\n    else if (activation === 'relu') {\n        if (packed) {\n            return unary_packed_op.RELU;\n        }\n        return unary_op.RELU;\n    }\n    throw new Error(\"Activation \" + activation + \" has not been implemented for the WebGL backend.\");\n}\n// Empirically determined constant used to determine size threshold for handing\n// off execution to the CPU.\nvar CPU_HANDOFF_SIZE_THRESHOLD = 128;\n// Empirically determined constant used to decide the number of MB on GPU\n// before we warn about high memory use. The MB are this constant * screen area\n// * dpi / 1024 / 1024.\nvar BEFORE_PAGING_CONSTANT = 600;\nfunction numMBBeforeWarning() {\n    if (environment_1.ENV.global.screen == null) {\n        return 1024; // 1 GB.\n    }\n    return (environment_1.ENV.global.screen.height * environment_1.ENV.global.screen.width *\n        window.devicePixelRatio) *\n        BEFORE_PAGING_CONSTANT / 1024 / 1024;\n}\n// Empirically determined minimal shared dimension in matmul before we forward\n// to a.mul(b).sum() in order to take advantage of GPU parallelism. See\n// https://github.com/tensorflow/tfjs-core/pull/1379 for benchmarks.\nexports.MATMUL_SHARED_DIM_THRESHOLD = 1000;\nvar MathBackendWebGL = /** @class */ (function () {\n    function MathBackendWebGL(gpgpu) {\n        this.gpgpu = gpgpu;\n        // Maps data ids that have a pending read operation, to list of subscribers.\n        this.pendingRead = new WeakMap();\n        // List of data ids that are scheduled for disposal, but are waiting on a\n        // pending read operation.\n        this.pendingDisposal = new WeakSet();\n        // Used to count the number of 'shallow' sliced tensors that point to the\n        // same data id.\n        this.dataRefCount = new WeakMap();\n        this.numBytesInGPU = 0;\n        // Accumulated time spent (including blocking) in uploading data to webgl.\n        this.uploadWaitMs = 0;\n        // Accumulated time spent (including blocking in downloading data from webgl.\n        this.downloadWaitMs = 0;\n        this.warnedAboutMemory = false;\n        this.disposed = false;\n        if (!environment_1.ENV.getBool('HAS_WEBGL')) {\n            throw new Error('WebGL is not supported on this device');\n        }\n        if (gpgpu == null) {\n            var gl = canvas_util_1.getWebGLContext(environment_1.ENV.getNumber('WEBGL_VERSION'));\n            this.binaryCache = getBinaryCache(environment_1.ENV.getNumber('WEBGL_VERSION'));\n            this.gpgpu = new gpgpu_context_1.GPGPUContext(gl);\n            this.canvas = gl.canvas;\n            this.gpgpuCreatedLocally = true;\n        }\n        else {\n            this.binaryCache = {};\n            this.gpgpuCreatedLocally = false;\n            this.canvas = gpgpu.gl.canvas;\n        }\n        this.textureManager = new texture_manager_1.TextureManager(this.gpgpu);\n        this.numMBBeforeWarning = numMBBeforeWarning();\n        this.texData = new backend_1.DataStorage(this, engine_1.ENGINE);\n    }\n    MathBackendWebGL.prototype.register = function (dataId, shape, dtype) {\n        if (this.texData.has(dataId)) {\n            throw new Error('Data buffer is already registered');\n        }\n        this.texData.set(dataId, { shape: shape, dtype: dtype });\n    };\n    MathBackendWebGL.prototype.fromPixels = function (pixels, numChannels) {\n        if (pixels == null) {\n            throw new Error('pixels passed to tf.browser.fromPixels() can not be null');\n        }\n        var texShape = [pixels.height, pixels.width];\n        var outShape = [pixels.height, pixels.width, numChannels];\n        if (environment_1.ENV.getBool('IS_BROWSER')) {\n            if (!(pixels instanceof HTMLVideoElement) &&\n                !(pixels instanceof HTMLImageElement) &&\n                !(pixels instanceof HTMLCanvasElement) &&\n                !(pixels instanceof ImageData) &&\n                !(pixels.data instanceof Uint8Array)) {\n                throw new Error('pixels passed to tf.browser.fromPixels() must be either an ' +\n                    \"HTMLVideoElement, HTMLImageElement, HTMLCanvasElement, ImageData\" +\n                    \" or {data: Uint32Array, width: number, height: number}, \" +\n                    (\"but was \" + pixels.constructor.name));\n            }\n            if (pixels instanceof HTMLVideoElement) {\n                if (this.fromPixels2DContext == null) {\n                    if (document.readyState !== 'complete') {\n                        throw new Error('The DOM is not ready yet. Please call ' +\n                            'tf.browser.fromPixels() once the DOM is ready. One way to ' +\n                            'do that is to add an event listener for `DOMContentLoaded` ' +\n                            'on the document object');\n                    }\n                    this.fromPixels2DContext =\n                        document.createElement('canvas').getContext('2d');\n                }\n                this.fromPixels2DContext.canvas.width = pixels.width;\n                this.fromPixels2DContext.canvas.height = pixels.height;\n                this.fromPixels2DContext.drawImage(pixels, 0, 0, pixels.width, pixels.height);\n                pixels = this.fromPixels2DContext.canvas;\n            }\n        }\n        var tempPixelHandle = this.makeTensorHandle(texShape, 'int32');\n        // This is a byte texture with pixels.\n        this.texData.get(tempPixelHandle.dataId).usage = tex_util_1.TextureUsage.PIXELS;\n        this.gpgpu.uploadPixelDataToTexture(this.getTexture(tempPixelHandle.dataId), pixels);\n        var program = new from_pixels_gpu_1.FromPixelsProgram(outShape);\n        var res = this.compileAndRun(program, [tempPixelHandle]);\n        this.disposeData(tempPixelHandle.dataId);\n        return res;\n    };\n    MathBackendWebGL.prototype.makeTensorHandle = function (shape, dtype) {\n        var dataId = {};\n        this.register(dataId, shape, dtype);\n        return { dataId: dataId, shape: shape, dtype: dtype };\n    };\n    MathBackendWebGL.prototype.write = function (dataId, values) {\n        if (values == null) {\n            throw new Error('MathBackendWebGL.write(): values can not be null');\n        }\n        if (environment_1.ENV.getBool('DEBUG')) {\n            for (var i = 0; i < values.length; i++) {\n                var num = values[i];\n                if (!webgl_util.canBeRepresented(num)) {\n                    throw Error(\"The value \" + num + \" cannot be represented on this device.\");\n                }\n            }\n        }\n        var texData = this.texData.get(dataId);\n        var dtype = texData.dtype;\n        if (dtype === 'complex64') {\n            throw new Error(\"Cannot write to a complex64 dtype. \" +\n                \"Please use tf.complex(real, imag).\");\n        }\n        this.releaseGPUData(dataId);\n        texData.usage = tex_util_1.TextureUsage.UPLOAD;\n        texData.values = values;\n    };\n    MathBackendWebGL.prototype.readSync = function (dataId) {\n        var texData = this.texData.get(dataId);\n        var values = texData.values, dtype = texData.dtype, complexTensors = texData.complexTensors, slice = texData.slice, shape = texData.shape;\n        if (slice != null) {\n            var program = new unaryop_gpu_1.UnaryOpProgram(shape, unary_op.CLONE);\n            var res = this.compileAndRun(program, [{ dataId: dataId, shape: shape, dtype: dtype }]);\n            var data = this.readSync(res.dataId);\n            res.dispose();\n            return data;\n        }\n        if (values != null) {\n            return this.convertAndCacheOnCPU(dataId);\n        }\n        if (dtype === 'string') {\n            return values;\n        }\n        var shouldTimeProgram = this.activeTimers != null;\n        var start;\n        if (shouldTimeProgram) {\n            start = performance.now();\n        }\n        var result;\n        if (dtype === 'complex64') {\n            var realValues = complexTensors.real.dataSync();\n            var imagValues = complexTensors.imag.dataSync();\n            result = complex_util_1.mergeRealAndImagArrays(realValues, imagValues);\n        }\n        else {\n            result = this.getValuesFromTexture(dataId);\n        }\n        if (shouldTimeProgram) {\n            this.downloadWaitMs += performance.now() - start;\n        }\n        return this.convertAndCacheOnCPU(dataId, result);\n    };\n    MathBackendWebGL.prototype.read = function (dataId) {\n        return __awaiter(this, void 0, void 0, function () {\n            var _a, _b, subscribers_1, texData, texture, values, texShape, isPacked, shape, slice, dtype, complexTensors, program, res, data, buffer, width, height, vals, ps, _c, realValues, imagValues, size, batch, rows, cols, dTypeVals, subscribers;\n            return __generator(this, function (_d) {\n                switch (_d.label) {\n                    case 0:\n                        if (this.pendingRead.has(dataId)) {\n                            subscribers_1 = this.pendingRead.get(dataId);\n                            return [2 /*return*/, new Promise(function (resolve) { return subscribers_1.push(resolve); })];\n                        }\n                        texData = this.texData.get(dataId);\n                        texture = texData.texture, values = texData.values, texShape = texData.texShape, isPacked = texData.isPacked, shape = texData.shape, slice = texData.slice, dtype = texData.dtype, complexTensors = texData.complexTensors;\n                        if (slice != null) {\n                            program = new unaryop_gpu_1.UnaryOpProgram(shape, unary_op.CLONE);\n                            res = this.compileAndRun(program, [{ dataId: dataId, shape: shape, dtype: dtype }]);\n                            data = this.read(res.dataId);\n                            res.dispose();\n                            return [2 /*return*/, data];\n                        }\n                        if (values != null) {\n                            return [2 /*return*/, this.convertAndCacheOnCPU(dataId)];\n                        }\n                        this.pendingRead.set(dataId, []);\n                        if (!environment_1.ENV.getBool('WEBGL_DOWNLOAD_FLOAT_ENABLED') &&\n                            environment_1.ENV.getNumber('WEBGL_VERSION') === 2) {\n                            throw new Error(\"tensor.data() with WEBGL_DOWNLOAD_FLOAT_ENABLED=false and \" +\n                                \"WEBGL_VERSION=2 not yet supported.\");\n                        }\n                        buffer = null;\n                        if (!(dtype !== 'complex64')) return [3 /*break*/, 2];\n                        width = texShape[1];\n                        height = texShape[0];\n                        if (isPacked) {\n                            _a = tex_util.getPackedMatrixTextureShapeWidthHeight(texShape[0], texShape[1]), width = _a[0], height = _a[1];\n                        }\n                        if (environment_1.ENV.get('WEBGL_BUFFER_SUPPORTED')) {\n                            buffer = this.gpgpu.createBufferFromTexture(texture, height, width);\n                        }\n                        // Create a fence and wait for it to resolve.\n                        return [4 /*yield*/, this.gpgpu.createAndWaitForFence()];\n                    case 1:\n                        // Create a fence and wait for it to resolve.\n                        _d.sent();\n                        _d.label = 2;\n                    case 2:\n                        if (!(dtype === 'complex64')) return [3 /*break*/, 4];\n                        ps = Promise.all([complexTensors.real.data(), complexTensors.imag.data()]);\n                        return [4 /*yield*/, ps];\n                    case 3:\n                        _c = _d.sent(), realValues = _c[0], imagValues = _c[1];\n                        vals = complex_util_1.mergeRealAndImagArrays(realValues, imagValues);\n                        return [3 /*break*/, 5];\n                    case 4:\n                        if (buffer == null) {\n                            vals = this.getValuesFromTexture(dataId);\n                        }\n                        else {\n                            size = util.sizeFromShape(shape);\n                            if (isPacked) {\n                                batch = webgl_util.getBatchDim(shape);\n                                rows = 1, cols = 1;\n                                if (shape.length) {\n                                    _b = webgl_util.getRowsCols(shape), rows = _b[0], cols = _b[1];\n                                }\n                                vals = this.gpgpu\n                                    .downloadPackedMatrixFromBuffer(buffer, batch, rows, cols, texShape[0], texShape[1])\n                                    .subarray(0, size);\n                            }\n                            else {\n                                vals = this.gpgpu\n                                    .downloadFloat32MatrixFromBuffer(buffer, texShape[0], texShape[1])\n                                    .subarray(0, size);\n                            }\n                        }\n                        _d.label = 5;\n                    case 5:\n                        dTypeVals = this.convertAndCacheOnCPU(dataId, vals);\n                        subscribers = this.pendingRead.get(dataId);\n                        this.pendingRead.delete(dataId);\n                        // Notify all pending reads.\n                        subscribers.forEach(function (resolve) { return resolve(dTypeVals); });\n                        if (this.pendingDisposal.has(dataId)) {\n                            this.pendingDisposal.delete(dataId);\n                            this.disposeData(dataId);\n                        }\n                        return [2 /*return*/, dTypeVals];\n                }\n            });\n        });\n    };\n    MathBackendWebGL.prototype.getValuesFromTexture = function (dataId) {\n        var _this = this;\n        var _a;\n        var _b = this.texData.get(dataId), shape = _b.shape, dtype = _b.dtype, texture = _b.texture, texShape = _b.texShape;\n        var size = util.sizeFromShape(shape);\n        if (environment_1.ENV.getBool('WEBGL_DOWNLOAD_FLOAT_ENABLED')) {\n            if (this.texData.get(dataId).isPacked) {\n                var batch = webgl_util.getBatchDim(shape);\n                var rows = 1, cols = 1;\n                if (shape.length) {\n                    _a = webgl_util.getRowsCols(shape), rows = _a[0], cols = _a[1];\n                }\n                return this.gpgpu\n                    .downloadMatrixFromPackedTexture(texture, batch, rows, cols, texShape[0], texShape[1])\n                    .subarray(0, size);\n            }\n            else {\n                return this.gpgpu\n                    .downloadFloat32MatrixFromOutputTexture(texture, texShape[0], texShape[1])\n                    .subarray(0, size);\n            }\n        }\n        var tmpTarget = this.makeTensorHandle(shape, 'float32');\n        tmpTarget.size = util_1.sizeFromShape(shape);\n        this.texData.get(tmpTarget.dataId).usage = tex_util_1.TextureUsage.DOWNLOAD;\n        var output = globals_1.tidy(function () {\n            var program = new encode_float_gpu_1.EncodeFloatProgram(shape);\n            return _this.compileAndRun(program, [{ shape: shape, dtype: dtype, dataId: dataId }], tmpTarget, null);\n        });\n        var tmpData = this.texData.get(output.dataId);\n        var vals = this.gpgpu\n            .downloadByteEncodedFloatMatrixFromOutputTexture(tmpData.texture, tmpData.texShape[0], tmpData.texShape[1])\n            .subarray(0, size);\n        this.disposeData(tmpTarget.dataId);\n        return vals;\n    };\n    MathBackendWebGL.prototype.time = function (f) {\n        return __awaiter(this, void 0, void 0, function () {\n            var oldActiveTimers, newActiveTimers, outerMostTime, flattenedActiveTimerQueries, flattenedActiveTimerNames, kernelMs, res;\n            return __generator(this, function (_a) {\n                switch (_a.label) {\n                    case 0:\n                        oldActiveTimers = this.activeTimers;\n                        newActiveTimers = [];\n                        outerMostTime = false;\n                        if (this.programTimersStack == null) {\n                            this.programTimersStack = newActiveTimers;\n                            outerMostTime = true;\n                        }\n                        else {\n                            this.activeTimers.push(newActiveTimers);\n                        }\n                        this.activeTimers = newActiveTimers;\n                        f();\n                        flattenedActiveTimerQueries = util.flatten(this.activeTimers.map(function (d) { return d.query; }))\n                            .filter(function (d) { return d != null; });\n                        flattenedActiveTimerNames = util.flatten(this.activeTimers.map(function (d) { return d.name; }))\n                            .filter(function (d) { return d != null; });\n                        this.activeTimers = oldActiveTimers;\n                        if (outerMostTime) {\n                            this.programTimersStack = null;\n                        }\n                        return [4 /*yield*/, Promise.all(flattenedActiveTimerQueries)];\n                    case 1:\n                        kernelMs = _a.sent();\n                        res = {\n                            uploadWaitMs: this.uploadWaitMs,\n                            downloadWaitMs: this.downloadWaitMs,\n                            kernelMs: util.sum(kernelMs),\n                            getExtraProfileInfo: function () {\n                                return kernelMs.map(function (d, i) { return ({ name: flattenedActiveTimerNames[i], ms: d }); })\n                                    .map(function (d) { return d.name + \": \" + d.ms; })\n                                    .join(', ');\n                            },\n                            wallMs: null // will be filled by the engine\n                        };\n                        this.uploadWaitMs = 0;\n                        this.downloadWaitMs = 0;\n                        return [2 /*return*/, res];\n                }\n            });\n        });\n    };\n    MathBackendWebGL.prototype.memory = function () {\n        return { unreliable: false, numBytesInGPU: this.numBytesInGPU };\n    };\n    MathBackendWebGL.prototype.startTimer = function () {\n        if (environment_1.ENV.getNumber('WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION') > 0) {\n            return this.gpgpu.beginQuery();\n        }\n        return { startMs: performance.now(), endMs: null };\n    };\n    MathBackendWebGL.prototype.endTimer = function (query) {\n        if (environment_1.ENV.getNumber('WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION') > 0) {\n            this.gpgpu.endQuery();\n            return query;\n        }\n        query.endMs = performance.now();\n        return query;\n    };\n    MathBackendWebGL.prototype.getQueryTime = function (query) {\n        return __awaiter(this, void 0, void 0, function () {\n            var timerQuery;\n            return __generator(this, function (_a) {\n                if (environment_1.ENV.getNumber('WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION') > 0) {\n                    return [2 /*return*/, this.gpgpu.waitForQueryAndGetTime(query)];\n                }\n                timerQuery = query;\n                return [2 /*return*/, timerQuery.endMs - timerQuery.startMs];\n            });\n        });\n    };\n    MathBackendWebGL.prototype.disposeData = function (dataId) {\n        if (this.pendingDisposal.has(dataId)) {\n            return;\n        }\n        if (this.pendingRead.has(dataId)) {\n            this.pendingDisposal.add(dataId);\n            return;\n        }\n        // No-op if already disposed.\n        if (!this.texData.has(dataId)) {\n            return;\n        }\n        this.releaseGPUData(dataId);\n        var complexTensors = this.texData.get(dataId).complexTensors;\n        if (complexTensors != null) {\n            complexTensors.real.dispose();\n            complexTensors.imag.dispose();\n        }\n        this.texData.delete(dataId);\n    };\n    MathBackendWebGL.prototype.releaseGPUData = function (dataId) {\n        var _a = this.texData.get(dataId), texture = _a.texture, dtype = _a.dtype, texShape = _a.texShape, usage = _a.usage, isPacked = _a.isPacked, slice = _a.slice;\n        var key = slice && slice.origDataId || dataId;\n        var refCount = this.dataRefCount.get(key);\n        if (refCount > 1) {\n            this.dataRefCount.set(key, refCount - 1);\n        }\n        else {\n            this.dataRefCount.delete(key);\n            if (texture != null) {\n                this.numBytesInGPU -= this.computeBytes(texShape, dtype);\n                this.textureManager.releaseTexture(texture, texShape, usage, isPacked);\n            }\n        }\n        var texData = this.texData.get(dataId);\n        texData.texture = null;\n        texData.texShape = null;\n        texData.isPacked = false;\n        texData.slice = null;\n    };\n    MathBackendWebGL.prototype.getTexture = function (dataId) {\n        this.uploadToGPU(dataId);\n        return this.texData.get(dataId).texture;\n    };\n    MathBackendWebGL.prototype.getCPUBackend = function () {\n        if (!environment_1.ENV.getBool('WEBGL_CPU_FORWARD')) {\n            return null;\n        }\n        if (this.cpuBackend == null) {\n            this.cpuBackend = engine_1.ENGINE.findBackend('cpu');\n        }\n        return this.cpuBackend;\n    };\n    /*\n    Tests whether all the inputs to an op are small and on the CPU. This heuristic\n    determines when it would be faster to execute a kernel on the CPU. WebGL\n    kernels opt into running this check and forwarding when appropriate.\n    TODO(https://github.com/tensorflow/tfjs/issues/872): Develop a more\n    sustainable strategy for optimizing backend execution of ops.\n     */\n    MathBackendWebGL.prototype.shouldExecuteOnCPU = function (inputs, sizeThreshold) {\n        var _this = this;\n        if (sizeThreshold === void 0) { sizeThreshold = CPU_HANDOFF_SIZE_THRESHOLD; }\n        return this.getCPUBackend() != null &&\n            inputs.every(function (input) { return _this.texData.get(input.dataId).texture == null &&\n                input.size < sizeThreshold; });\n    };\n    MathBackendWebGL.prototype.getGPGPUContext = function () {\n        return this.gpgpu;\n    };\n    MathBackendWebGL.prototype.getCanvas = function () {\n        return this.canvas;\n    };\n    MathBackendWebGL.prototype.complex = function (real, imag) {\n        var result = this.makeOutputArray(real.shape, 'complex64');\n        var resultData = this.texData.get(result.dataId);\n        // The backend owns the reference to the underlying real and imaginary\n        // clones. These will explicitly get disposed when the complex tensor is\n        // disposed.\n        resultData.complexTensors = {\n            real: engine_1.ENGINE.keep(real.clone()),\n            imag: engine_1.ENGINE.keep(imag.clone())\n        };\n        return result;\n    };\n    MathBackendWebGL.prototype.real = function (input) {\n        var resultData = this.texData.get(input.dataId);\n        return resultData.complexTensors.real.clone();\n    };\n    MathBackendWebGL.prototype.imag = function (input) {\n        var resultData = this.texData.get(input.dataId);\n        return resultData.complexTensors.imag.clone();\n    };\n    MathBackendWebGL.prototype.slice = function (x, begin, size) {\n        if (this.shouldExecuteOnCPU([x])) {\n            return this.cpuBackend.slice(x, begin, size);\n        }\n        // Short-circuit computation if the slice is zero-sized.\n        if (util.sizeFromShape(size) === 0) {\n            return tensor_ops_1.tensor([], size, x.dtype);\n        }\n        var isPacked = this.texData.get(x.dataId).isPacked;\n        var isContinous = slice_util_1.isSliceContinous(x.shape, begin, size);\n        if (isPacked || !isContinous) {\n            var program = environment_1.ENV.getBool('WEBGL_PACK_ARRAY_OPERATIONS') ?\n                new slice_packed_gpu_1.SlicePackedProgram(size) :\n                new slice_gpu_1.SliceProgram(size);\n            var customSetup = program.getCustomSetupFunc(begin);\n            return this.compileAndRun(program, [x], null, customSetup);\n        }\n        this.uploadToGPU(x.dataId);\n        return this.shallowSlice(x, begin, size);\n    };\n    MathBackendWebGL.prototype.shallowSlice = function (x, begin, size) {\n        var xTexData = this.texData.get(x.dataId);\n        var t = tensor_1.Tensor.make(size, {}, x.dtype, this);\n        var newTexData = this.texData.get(t.dataId);\n        // Copy texture data from the original tensor.\n        Object.assign(newTexData, xTexData);\n        newTexData.shape = size;\n        newTexData.dtype = x.dtype;\n        var flatOffset = slice_util_1.computeFlatOffset(begin, x.strides);\n        if (xTexData.slice) {\n            // We are slicing an already sliced tensor, so we have to accumulate\n            // the offset.\n            flatOffset += xTexData.slice.flatOffset;\n        }\n        newTexData.slice = {\n            flatOffset: flatOffset,\n            // Point to the original dataId, which is used to do ref counting.\n            origDataId: xTexData.slice && xTexData.slice.origDataId || x.dataId\n        };\n        // Increase the ref count for that data bucket.\n        var refCount = this.dataRefCount.get(newTexData.slice.origDataId) || 1;\n        this.dataRefCount.set(newTexData.slice.origDataId, refCount + 1);\n        return t;\n    };\n    MathBackendWebGL.prototype.stridedSlice = function (x, begin, end, strides, beginMask, endMask, ellipsisMask, newAxisMask, shrinkAxisMask) {\n        if (this.shouldExecuteOnCPU([x])) {\n            return this.cpuBackend.stridedSlice(x, begin, end, strides, beginMask, endMask, ellipsisMask, newAxisMask, shrinkAxisMask);\n        }\n        var _a = slice_util_1.getStridedSlicedInfo(x.shape, begin, end, strides, beginMask, endMask, ellipsisMask, newAxisMask, shrinkAxisMask), beginIndex = _a[0], size = _a[1], shrinkAxis = _a[2];\n        var shape = size.filter(function (v, index) { return shrinkAxis.indexOf(index) === -1; });\n        if (shape.some(function (axis) { return axis === 0; })) {\n            return tensor_ops_1.tensor([], shape);\n        }\n        var program = new strided_slice_gpu_1.StridedSliceProgram(beginIndex, strides, size, shrinkAxis);\n        return this.compileAndRun(program, [x]);\n    };\n    MathBackendWebGL.prototype.reverse = function (x, axis) {\n        var program = environment_1.ENV.getBool('WEBGL_PACK_ARRAY_OPERATIONS') ?\n            new reverse_packed_gpu_1.ReversePackedProgram(x.shape, axis) :\n            new reverse_gpu_1.ReverseProgram(x.shape, axis);\n        return this.compileAndRun(program, [x]);\n    };\n    MathBackendWebGL.prototype.concat = function (tensors, axis) {\n        if (this.shouldExecuteOnCPU(tensors)) {\n            return this.cpuBackend.concat(tensors, axis);\n        }\n        if (tensors.length === 1) {\n            return tensors[0];\n        }\n        if (tensors.length > environment_1.ENV.getNumber('WEBGL_MAX_TEXTURES_IN_SHADER')) {\n            var midIndex = Math.floor(tensors.length / 2);\n            var leftSide = this.concat(tensors.slice(0, midIndex), axis);\n            var rightSide = this.concat(tensors.slice(midIndex), axis);\n            return this.concat([leftSide, rightSide], axis);\n        }\n        if (environment_1.ENV.getBool('WEBGL_PACK_ARRAY_OPERATIONS') && tensors[0].rank > 1) {\n            var program_1 = new concat_packed_gpu_1.ConcatPackedProgram(tensors.map(function (t) { return t.shape; }), axis);\n            return this.compileAndRun(program_1, tensors);\n        }\n        // Any concat of n-dimensional tensors across any axis can be reduced to\n        // a concatenation of two-dimensional tensors across the axis 1 by first\n        // partitioning the axes of the original tensors into those less than the\n        // axis to be concatenated and the rest. Then reshape the tensors\n        // into a two-dimensional tensor by collapsing these two sets of axes and\n        // concatenate the resulting matrices across the axis 1, finally reshaping\n        // the result to have the proper shape.\n        var outShape = concat_util_1.computeOutShape(tensors.map(function (t) { return t.shape; }), axis);\n        var tensors2D = tensors.map(function (t) { return t.as2D(-1, util_1.sizeFromShape(t.shape.slice(axis))); });\n        var program = new concat_gpu_1.ConcatProgram(tensors2D.map(function (t) { return t.shape; }));\n        var res = this.compileAndRun(program, tensors2D);\n        return res.reshape(outShape);\n    };\n    MathBackendWebGL.prototype.neg = function (x) {\n        var program = new unaryop_gpu_1.UnaryOpProgram(x.shape, unary_op.NEG);\n        return this.compileAndRun(program, [x]);\n    };\n    MathBackendWebGL.prototype.batchMatMul = function (a, b, transposeA, transposeB) {\n        var outerShapeA = transposeA ? a.shape[2] : a.shape[1];\n        var outerShapeB = transposeB ? b.shape[1] : b.shape[2];\n        var sharedDim = transposeA ? a.shape[1] : a.shape[2];\n        var _a = a.shape, batch = _a[0];\n        // Since the matrices are vectors, it is faster to call mul().sum()\n        // because sum() is O(sqrt(N)) due to divide-and-conquer.\n        if ((outerShapeA === 1 || outerShapeB === 1) &&\n            sharedDim > exports.MATMUL_SHARED_DIM_THRESHOLD) {\n            if (transposeA) {\n                a = a.transpose([0, 2, 1]);\n            }\n            if (transposeB) {\n                b = b.transpose([0, 2, 1]);\n            }\n            var a3D = outerShapeB === 1 ? a : a.as3D(batch, sharedDim, 1);\n            var axis = outerShapeB === 1 ? 2 : 1;\n            var b3D = outerShapeB === 1 ? b.as3D(batch, 1, sharedDim) : b;\n            return this.multiply(a3D, b3D).sum(axis, true /* keepDims */);\n        }\n        var dtype = types_1.upcastType(a.dtype, b.dtype);\n        var program = new mulmat_packed_gpu_1.MatMulPackedProgram(a.shape, [batch, outerShapeA, outerShapeB], transposeA, transposeB);\n        var output = this.makePackedTensor(program.outputShape, dtype);\n        return this.compileAndRun(program, [a, b], output);\n    };\n    MathBackendWebGL.prototype.fusedBatchMatMul = function (a, b, transposeA, transposeB, bias, activation) {\n        var outerShapeA = transposeA ? a.shape[2] : a.shape[1];\n        var outerShapeB = transposeB ? b.shape[1] : b.shape[2];\n        var _a = a.shape, batch = _a[0];\n        var dtype = types_1.upcastType(a.dtype, b.dtype);\n        var program = new mulmat_packed_gpu_1.MatMulPackedProgram(a.shape, [batch, outerShapeA, outerShapeB], transposeA, transposeB, !!bias, activation ? mapActivationToShaderProgram(activation, true) : null);\n        var output = this.makePackedTensor(program.outputShape, dtype);\n        var inputs = [a, b];\n        if (bias) {\n            inputs.push(bias);\n        }\n        return this.compileAndRun(program, inputs, output);\n    };\n    MathBackendWebGL.prototype.multiply = function (a, b) {\n        if (a.dtype === 'complex64') {\n            var aData = this.texData.get(a.dataId);\n            var bData = this.texData.get(b.dataId);\n            var realProgram = new binaryop_complex_gpu_1.BinaryOpComplexProgram(binaryop_complex_gpu.COMPLEX_MULTIPLY.REAL, a.shape, b.shape);\n            var imagProgram = new binaryop_complex_gpu_1.BinaryOpComplexProgram(binaryop_complex_gpu.COMPLEX_MULTIPLY.IMAG, a.shape, b.shape);\n            var inputs = [\n                this.makeComplexComponentTensorHandle(a, aData.complexTensors.real),\n                this.makeComplexComponentTensorHandle(a, aData.complexTensors.imag),\n                this.makeComplexComponentTensorHandle(b, bData.complexTensors.real),\n                this.makeComplexComponentTensorHandle(b, bData.complexTensors.imag)\n            ];\n            var real = this.compileAndRun(realProgram, inputs);\n            var imag = this.compileAndRun(imagProgram, inputs);\n            var complex = this.complex(real, imag);\n            real.dispose();\n            imag.dispose();\n            return complex;\n        }\n        if (this.shouldExecuteOnCPU([a, b])) {\n            return this.cpuBackend.multiply(a, b);\n        }\n        if (environment_1.ENV.getBool('WEBGL_PACK_BINARY_OPERATIONS')) {\n            return this.packedBinaryOp(a, b, binaryop_gpu.MUL, a.dtype);\n        }\n        var program = new binaryop_gpu_1.BinaryOpProgram(binaryop_gpu.MUL, a.shape, b.shape);\n        var output = this.makeOutputArray(program.outputShape, a.dtype);\n        return this.compileAndRun(program, [a, b], output);\n    };\n    MathBackendWebGL.prototype.batchNormalization = function (x, mean, variance, varianceEpsilon, scale, offset) {\n        var inputs = [x, mean, variance];\n        var offsetShape = null;\n        if (offset != null) {\n            offsetShape = offset.shape;\n            inputs.push(offset);\n        }\n        var scaleShape = null;\n        if (scale != null) {\n            scaleShape = scale.shape;\n            inputs.push(scale);\n        }\n        if (environment_1.ENV.getBool('WEBGL_PACK_NORMALIZATION')) {\n            var batchNormPackedProgram = new batchnorm_packed_gpu_1.BatchNormPackedProgram(x.shape, mean.shape, variance.shape, offsetShape, scaleShape, varianceEpsilon);\n            return this.compileAndRun(batchNormPackedProgram, inputs);\n        }\n        var batchNormProgram = new batchnorm_gpu_1.BatchNormProgram(x.shape, mean.shape, variance.shape, offsetShape, scaleShape, varianceEpsilon);\n        return this.compileAndRun(batchNormProgram, inputs);\n    };\n    MathBackendWebGL.prototype.localResponseNormalization4D = function (x, radius, bias, alpha, beta) {\n        var program = environment_1.ENV.getBool('WEBGL_PACK_NORMALIZATION') ?\n            new lrn_packed_gpu_1.LRNPackedProgram(x.shape, radius, bias, alpha, beta) :\n            new lrn_gpu_1.LRNProgram(x.shape, radius, bias, alpha, beta);\n        return this.compileAndRun(program, [x]);\n    };\n    MathBackendWebGL.prototype.LRNGrad = function (dy, inputImage, outputImage, depthRadius, bias, alpha, beta) {\n        var program = new lrn_grad_gpu_1.LRNGradProgram(inputImage.shape, depthRadius, bias, alpha, beta);\n        return this.compileAndRun(program, [inputImage, outputImage, dy]);\n    };\n    MathBackendWebGL.prototype.tile = function (x, reps) {\n        var program = new tile_gpu_1.TileProgram(x.shape, reps);\n        return this.compileAndRun(program, [x]);\n    };\n    MathBackendWebGL.prototype.pad = function (x, paddings, constantValue) {\n        var program = environment_1.ENV.getBool('WEBGL_PACK_ARRAY_OPERATIONS') ?\n            new pad_packed_gpu_1.PadPackedProgram(x.shape, paddings, constantValue) :\n            new pad_gpu_1.PadProgram(x.shape, paddings, constantValue);\n        return this.compileAndRun(program, [x]);\n    };\n    MathBackendWebGL.prototype.transpose = function (x, perm) {\n        if (this.shouldExecuteOnCPU([x])) {\n            return this.cpuBackend.transpose(x, perm);\n        }\n        var program = environment_1.ENV.getBool('WEBGL_PACK_ARRAY_OPERATIONS') ?\n            new transpose_packed_gpu_1.TransposePackedProgram(x.shape, perm) :\n            new transpose_gpu_1.TransposeProgram(x.shape, perm);\n        return this.compileAndRun(program, [x]);\n    };\n    MathBackendWebGL.prototype.gather = function (x, indices, axis) {\n        if (this.shouldExecuteOnCPU([x, indices])) {\n            return this.cpuBackend.gather(x, indices, axis);\n        }\n        var program = new gather_gpu_1.GatherProgram(x.shape, indices.size, axis);\n        return this.compileAndRun(program, [x, indices]);\n    };\n    MathBackendWebGL.prototype.batchToSpaceND = function (x, blockShape, crops) {\n        util.assert(x.rank <= 4, function () { return 'batchToSpaceND for rank > 4 with a WebGL backend not ' +\n            'implemented yet'; });\n        var prod = blockShape.reduce(function (a, b) { return a * b; });\n        var reshaped = array_ops_util.getReshaped(x.shape, blockShape, prod);\n        var permuted = array_ops_util.getPermuted(reshaped.length, blockShape.length);\n        var reshapedPermuted = array_ops_util.getReshapedPermuted(x.shape, blockShape, prod);\n        var sliceBeginCoords = array_ops_util.getSliceBeginCoords(crops, blockShape.length);\n        var sliceSize = array_ops_util.getSliceSize(reshapedPermuted, crops, blockShape.length);\n        return x.reshape(reshaped)\n            .transpose(permuted)\n            .reshape(reshapedPermuted)\n            .slice(sliceBeginCoords, sliceSize);\n    };\n    MathBackendWebGL.prototype.spaceToBatchND = function (x, blockShape, paddings) {\n        util.assert(x.rank <= 4, function () { return 'spaceToBatchND for rank > 4 with a WebGL backend not ' +\n            'implemented yet'; });\n        var prod = blockShape.reduce(function (a, b) { return a * b; });\n        var completePaddings = [[0, 0]];\n        completePaddings.push.apply(completePaddings, paddings);\n        for (var i = 1 + blockShape.length; i < x.shape.length; ++i) {\n            completePaddings.push([0, 0]);\n        }\n        var paddedX = x.pad(completePaddings);\n        var reshapedPaddedShape = array_ops_util.getReshaped(paddedX.shape, blockShape, prod, false);\n        var permutedReshapedPaddedPermutation = array_ops_util.getPermuted(reshapedPaddedShape.length, blockShape.length, false);\n        var flattenShape = array_ops_util.getReshapedPermuted(paddedX.shape, blockShape, prod, false);\n        return paddedX.reshape(reshapedPaddedShape)\n            .transpose(permutedReshapedPaddedPermutation)\n            .reshape(flattenShape);\n    };\n    MathBackendWebGL.prototype.reduce = function (x, reduceType, dtype) {\n        var batchSize = x.shape[0];\n        var inSize = x.shape[1];\n        var windowSize = reduce_util.computeOptimalWindowSize(inSize);\n        var reduceInfo = { windowSize: windowSize, inSize: inSize, batchSize: batchSize };\n        var program = new reduce_gpu_1.ReduceProgram(reduceInfo, reduceType);\n        var _a = program.outputShape, rows = _a[0], cols = _a[1];\n        var output = this.makeOutputArray([rows, cols], dtype);\n        this.compileAndRun(program, [x], output);\n        // No need to run another GPGPU program.\n        if (output.shape[1] === 1) {\n            return output;\n        }\n        return this.reduce(output, reduceType, dtype);\n    };\n    MathBackendWebGL.prototype.argReduce = function (x, reduceType, bestIndicesA) {\n        if (bestIndicesA === void 0) { bestIndicesA = null; }\n        var batchSize = x.shape[0];\n        var inSize = x.shape[1];\n        if (bestIndicesA != null) {\n            batchSize = bestIndicesA.shape[0];\n            inSize = bestIndicesA.shape[1];\n        }\n        var windowSize = reduce_util.computeOptimalWindowSize(inSize);\n        var reduceInfo = { windowSize: windowSize, inSize: inSize, batchSize: batchSize };\n        var program = new argminmax_gpu_1.ArgMinMaxProgram(reduceInfo, reduceType, bestIndicesA == null);\n        var _a = program.outputShape, rows = _a[0], cols = _a[1];\n        var output = this.makeOutputArray([rows, cols], 'int32');\n        var inputs = [x];\n        if (bestIndicesA != null) {\n            inputs.push(bestIndicesA);\n        }\n        this.compileAndRun(program, inputs, output);\n        // No need to run another GPGPU program.\n        if (output.shape[1] === 1) {\n            return output;\n        }\n        return this.argReduce(x, reduceType, output);\n    };\n    MathBackendWebGL.prototype.argReducePacked = function (x, reduceType, bestIndicesA) {\n        if (bestIndicesA === void 0) { bestIndicesA = null; }\n        var inShape = bestIndicesA != null ? bestIndicesA.shape : x.shape;\n        var inSize = inShape[inShape.length - 1];\n        var windowSize = reduce_util.computeOptimalWindowSize(inSize);\n        var program = new argminmax_packed_gpu_1.ArgMinMaxPackedProgram(inShape, windowSize, reduceType, bestIndicesA == null);\n        var output = this.makePackedTensor(program.outputShape, 'int32');\n        var inputs = bestIndicesA == null ? [x] : [x, bestIndicesA];\n        this.compileAndRun(program, inputs, output);\n        if (output.rank === x.rank) {\n            return this.argReducePacked(x, reduceType, output);\n        }\n        return output;\n    };\n    MathBackendWebGL.prototype.sum = function (x, axes) {\n        axis_util.assertAxesAreInnerMostDims('sum', axes, x.rank);\n        var _a = axis_util.computeOutAndReduceShapes(x.shape, axes), outShape = _a[0], reduceShape = _a[1];\n        var inSize = util.sizeFromShape(reduceShape);\n        var a2D = x.as2D(-1, inSize);\n        var outputDType = types_1.sumOutType(x.dtype);\n        return this.reduce(a2D, 'sum', outputDType).reshape(outShape);\n    };\n    MathBackendWebGL.prototype.prod = function (x, axes) {\n        if (this.shouldExecuteOnCPU([x])) {\n            return this.cpuBackend.prod(x, axes);\n        }\n        var _a = axis_util.computeOutAndReduceShapes(x.shape, axes), outShape = _a[0], reduceShape = _a[1];\n        var inSize = util.sizeFromShape(reduceShape);\n        var a2D = x.as2D(-1, inSize);\n        var outputDType = types_1.sumOutType(x.dtype);\n        return this.reduce(a2D, 'prod', outputDType).reshape(outShape);\n    };\n    MathBackendWebGL.prototype.unsortedSegmentSum = function (x, segmentIds, numSegments) {\n        var axis = 0;\n        var permutation = axis_util.getAxesPermutation([axis], x.rank);\n        var permutedX = x;\n        if (permutation != null) {\n            permutedX = x.transpose(permutation);\n            axis = axis_util.getInnerMostAxes(1, x.rank)[0];\n        }\n        var outShape = segment_util.computeOutShape(permutedX.shape, axis, numSegments);\n        var inSize = util.sizeFromShape([permutedX.shape[axis]]);\n        var a2D = permutedX.as2D(-1, inSize);\n        var outputDType = types_1.sumOutType(x.dtype);\n        var result = this.segOpCompute(a2D, 'unsortedSegmentSum', segmentIds, outputDType, numSegments)\n            .reshape(outShape);\n        if (permutation != null) {\n            result = result.transpose(axis_util.getUndoAxesPermutation(permutation));\n        }\n        return result;\n    };\n    MathBackendWebGL.prototype.segOpCompute = function (x, segOpType, segmentIds, dtype, numSegments) {\n        var batchSize = x.shape[0];\n        var inSize = x.shape[1];\n        var windowSize = segment_util.segOpComputeOptimalWindowSize(inSize, numSegments);\n        var segOpInfo = { windowSize: windowSize, inSize: inSize, batchSize: batchSize, numSegments: numSegments };\n        var program = new segment_gpu_1.SegmentOpProgram(segOpInfo, segOpType);\n        var _a = program.outputShape, rows = _a[0], cols = _a[1];\n        var output = this.makeOutputArray([rows, cols], dtype);\n        this.compileAndRun(program, [x, segmentIds], output);\n        // No need to run another GPGPU program.\n        if (output.shape[1] === numSegments) {\n            return output;\n        }\n        segmentIds = tensor_ops_1.range(0, numSegments).tile([inSize / windowSize]);\n        return this.segOpCompute(output, segOpType, segmentIds, dtype, numSegments);\n    };\n    MathBackendWebGL.prototype.argMinMaxReduce = function (x, axis, reduceType) {\n        var axes = [axis];\n        axis_util.assertAxesAreInnerMostDims('arg' + reduceType.charAt(0).toUpperCase() + reduceType.slice(1), axes, x.rank);\n        if (!environment_1.ENV.getBool('WEBGL_PACK_REDUCE') || x.rank <= 2) {\n            var _a = axis_util.computeOutAndReduceShapes(x.shape, axes), outShape = _a[0], reduceShape = _a[1];\n            var inSize = util.sizeFromShape(reduceShape);\n            var a2D = x.as2D(-1, inSize);\n            return this.argReduce(a2D, reduceType).reshape(outShape);\n        }\n        return this.argReducePacked(x, reduceType);\n    };\n    MathBackendWebGL.prototype.argMin = function (x, axis) {\n        return this.argMinMaxReduce(x, axis, 'min');\n    };\n    MathBackendWebGL.prototype.argMax = function (x, axis) {\n        return this.argMinMaxReduce(x, axis, 'max');\n    };\n    MathBackendWebGL.prototype.cumsum = function (x, axis, exclusive, reverse) {\n        if (axis !== x.rank - 1) {\n            throw new Error(\"WebGL cumsum shader expects an inner-most axis=\" + (x.rank - 1) + \" \" +\n                (\"but got axis=\" + axis));\n        }\n        var program = new cumsum_gpu_1.CumSumProgram(x.shape, exclusive, reverse);\n        return this.compileAndRun(program, [x]);\n    };\n    MathBackendWebGL.prototype.equal = function (a, b) {\n        if (environment_1.ENV.getBool('WEBGL_PACK_BINARY_OPERATIONS')) {\n            return this.packedBinaryOp(a, b, binaryop_packed_gpu.EQUAL, 'bool');\n        }\n        var program = new binaryop_gpu_1.BinaryOpProgram(binaryop_gpu.EQUAL, a.shape, b.shape);\n        var output = this.makeOutputArray(program.outputShape, 'bool');\n        return this.compileAndRun(program, [a, b], output);\n    };\n    MathBackendWebGL.prototype.notEqual = function (a, b) {\n        if (environment_1.ENV.getBool('WEBGL_PACK_BINARY_OPERATIONS')) {\n            return this.packedBinaryOp(a, b, binaryop_packed_gpu.NOT_EQUAL, 'bool');\n        }\n        var program = new binaryop_gpu_1.BinaryOpProgram(binaryop_gpu.NOT_EQUAL, a.shape, b.shape);\n        var output = this.makeOutputArray(program.outputShape, 'bool');\n        return this.compileAndRun(program, [a, b], output);\n    };\n    MathBackendWebGL.prototype.less = function (a, b) {\n        if (this.shouldExecuteOnCPU([a, b])) {\n            return this.cpuBackend.less(a, b);\n        }\n        if (environment_1.ENV.getBool('WEBGL_PACK_BINARY_OPERATIONS')) {\n            return this.packedBinaryOp(a, b, binaryop_packed_gpu.LESS, 'bool');\n        }\n        var program = new binaryop_gpu_1.BinaryOpProgram(binaryop_gpu.LESS, a.shape, b.shape);\n        var output = this.makeOutputArray(program.outputShape, 'bool');\n        return this.compileAndRun(program, [a, b], output);\n    };\n    MathBackendWebGL.prototype.lessEqual = function (a, b) {\n        if (environment_1.ENV.getBool('WEBGL_PACK_BINARY_OPERATIONS')) {\n            return this.packedBinaryOp(a, b, binaryop_packed_gpu.LESS_EQUAL, 'bool');\n        }\n        var program = new binaryop_gpu_1.BinaryOpProgram(binaryop_gpu.LESS_EQUAL, a.shape, b.shape);\n        var output = this.makeOutputArray(program.outputShape, 'bool');\n        return this.compileAndRun(program, [a, b], output);\n    };\n    MathBackendWebGL.prototype.greater = function (a, b) {\n        if (this.shouldExecuteOnCPU([a, b])) {\n            return this.cpuBackend.greater(a, b);\n        }\n        if (environment_1.ENV.getBool('WEBGL_PACK_BINARY_OPERATIONS')) {\n            return this.packedBinaryOp(a, b, binaryop_packed_gpu.GREATER, 'bool');\n        }\n        var program = new binaryop_gpu_1.BinaryOpProgram(binaryop_gpu.GREATER, a.shape, b.shape);\n        var output = this.makeOutputArray(program.outputShape, 'bool');\n        return this.compileAndRun(program, [a, b], output);\n    };\n    MathBackendWebGL.prototype.greaterEqual = function (a, b) {\n        if (environment_1.ENV.getBool('WEBGL_PACK_BINARY_OPERATIONS')) {\n            return this.packedBinaryOp(a, b, binaryop_packed_gpu.GREATER_EQUAL, 'bool');\n        }\n        var program = new binaryop_gpu_1.BinaryOpProgram(binaryop_gpu.GREATER_EQUAL, a.shape, b.shape);\n        var output = this.makeOutputArray(program.outputShape, 'bool');\n        return this.compileAndRun(program, [a, b], output);\n    };\n    MathBackendWebGL.prototype.logicalNot = function (x) {\n        var program = new unaryop_gpu_1.UnaryOpProgram(x.shape, unary_op.LOGICAL_NOT);\n        return this.compileAndRun(program, [x]);\n    };\n    MathBackendWebGL.prototype.logicalAnd = function (a, b) {\n        if (environment_1.ENV.getBool('WEBGL_PACK_BINARY_OPERATIONS')) {\n            return this.packedBinaryOp(a, b, binaryop_packed_gpu.LOGICAL_AND, 'bool');\n        }\n        var program = new binaryop_gpu_1.BinaryOpProgram(binaryop_gpu.LOGICAL_AND, a.shape, b.shape);\n        var output = this.makeOutputArray(program.outputShape, 'bool');\n        return this.compileAndRun(program, [a, b], output);\n    };\n    MathBackendWebGL.prototype.logicalOr = function (a, b) {\n        if (environment_1.ENV.getBool('WEBGL_PACK_BINARY_OPERATIONS')) {\n            return this.packedBinaryOp(a, b, binaryop_packed_gpu.LOGICAL_OR, 'bool');\n        }\n        var program = new binaryop_gpu_1.BinaryOpProgram(binaryop_gpu.LOGICAL_OR, a.shape, b.shape);\n        var output = this.makeOutputArray(program.outputShape, 'bool');\n        return this.compileAndRun(program, [a, b], output);\n    };\n    MathBackendWebGL.prototype.select = function (condition, a, b) {\n        var program = new select_gpu_1.SelectProgram(condition.rank, a.shape, a.rank);\n        var output = this.makeOutputArray(program.outputShape, types_1.upcastType(a.dtype, b.dtype));\n        return this.compileAndRun(program, [condition, a, b], output);\n    };\n    MathBackendWebGL.prototype.where = function (condition) {\n        log_1.warn('tf.where() in webgl locks the UI thread. ' +\n            'Call tf.whereAsync() instead');\n        var condVals = condition.dataSync();\n        return where_impl_1.whereImpl(condition.shape, condVals);\n    };\n    MathBackendWebGL.prototype.topk = function (x, k, sorted) {\n        var xVals = x.dataSync();\n        return topk_impl_1.topkImpl(xVals, x.shape, x.dtype, k, sorted);\n    };\n    MathBackendWebGL.prototype.min = function (x, axes) {\n        axis_util.assertAxesAreInnerMostDims('min', axes, x.rank);\n        var _a = axis_util.computeOutAndReduceShapes(x.shape, axes), outShape = _a[0], reduceShape = _a[1];\n        var inSize = util.sizeFromShape(reduceShape);\n        var a2D = x.as2D(-1, inSize);\n        return this.reduce(a2D, 'min', a2D.dtype).reshape(outShape);\n    };\n    MathBackendWebGL.prototype.minimum = function (a, b) {\n        if (this.shouldExecuteOnCPU([a, b])) {\n            return this.cpuBackend.minimum(a, b);\n        }\n        var program = environment_1.ENV.getBool('WEBGL_PACK_BINARY_OPERATIONS') ?\n            new binaryop_packed_gpu_1.BinaryOpPackedProgram(binaryop_packed_gpu.MIN, a.shape, b.shape) :\n            new binaryop_gpu_1.BinaryOpProgram(binaryop_gpu.MIN, a.shape, b.shape);\n        return this.compileAndRun(program, [a, b]);\n    };\n    MathBackendWebGL.prototype.mod = function (a, b) {\n        var program = environment_1.ENV.getBool('WEBGL_PACK_BINARY_OPERATIONS') ?\n            new binaryop_packed_gpu_1.BinaryOpPackedProgram(binaryop_packed_gpu.MOD, a.shape, b.shape) :\n            new binaryop_gpu_1.BinaryOpProgram(binaryop_gpu.MOD, a.shape, b.shape);\n        return this.compileAndRun(program, [a, b]);\n    };\n    MathBackendWebGL.prototype.max = function (x, axes) {\n        if (this.shouldExecuteOnCPU([x])) {\n            return this.cpuBackend.max(x, axes);\n        }\n        axis_util.assertAxesAreInnerMostDims('max', axes, x.rank);\n        var _a = axis_util.computeOutAndReduceShapes(x.shape, axes), outShape = _a[0], reduceShape = _a[1];\n        var inSize = util.sizeFromShape(reduceShape);\n        var a2D = x.as2D(-1, inSize);\n        return this.reduce(a2D, 'max', a2D.dtype).reshape(outShape);\n    };\n    MathBackendWebGL.prototype.maximum = function (a, b) {\n        if (this.shouldExecuteOnCPU([a, b])) {\n            return this.cpuBackend.maximum(a, b);\n        }\n        var program = environment_1.ENV.getBool('WEBGL_PACK_BINARY_OPERATIONS') ?\n            new binaryop_packed_gpu_1.BinaryOpPackedProgram(binaryop_packed_gpu.MAX, a.shape, b.shape) :\n            new binaryop_gpu_1.BinaryOpProgram(binaryop_gpu.MAX, a.shape, b.shape);\n        return this.compileAndRun(program, [a, b]);\n    };\n    MathBackendWebGL.prototype.all = function (x, axes) {\n        axis_util.assertAxesAreInnerMostDims('all', axes, x.rank);\n        var _a = axis_util.computeOutAndReduceShapes(x.shape, axes), outShape = _a[0], reduceShape = _a[1];\n        var inSize = util.sizeFromShape(reduceShape);\n        var a2D = x.as2D(-1, inSize);\n        return this.reduce(a2D, 'all', a2D.dtype).reshape(outShape);\n    };\n    MathBackendWebGL.prototype.any = function (x, axes) {\n        axis_util.assertAxesAreInnerMostDims('any', axes, x.rank);\n        var _a = axis_util.computeOutAndReduceShapes(x.shape, axes), outShape = _a[0], reduceShape = _a[1];\n        var inSize = util.sizeFromShape(reduceShape);\n        var a2D = x.as2D(-1, inSize);\n        return this.reduce(a2D, 'any', a2D.dtype).reshape(outShape);\n    };\n    MathBackendWebGL.prototype.squaredDifference = function (a, b) {\n        var program = environment_1.ENV.getBool('WEBGL_PACK_BINARY_OPERATIONS') ?\n            new binaryop_packed_gpu_1.BinaryOpPackedProgram(binaryop_gpu.SQUARED_DIFFERENCE, a.shape, b.shape) :\n            new binaryop_gpu_1.BinaryOpProgram(binaryop_gpu.SQUARED_DIFFERENCE, a.shape, b.shape);\n        return this.compileAndRun(program, [a, b]);\n    };\n    MathBackendWebGL.prototype.realDivide = function (a, b) {\n        var op = binaryop_gpu.DIV;\n        var outputDtype = 'float32';\n        if (environment_1.ENV.getBool('WEBGL_PACK_BINARY_OPERATIONS')) {\n            var checkOutOfBounds = true;\n            return this.packedBinaryOp(a, b, binaryop_packed_gpu.DIV, outputDtype, checkOutOfBounds);\n        }\n        var program = new binaryop_gpu_1.BinaryOpProgram(op, a.shape, b.shape);\n        var output = this.makeOutputArray(program.outputShape, outputDtype);\n        return this.compileAndRun(program, [a, b], output);\n    };\n    MathBackendWebGL.prototype.floorDiv = function (a, b) {\n        var op = binaryop_gpu.INT_DIV;\n        var outputDtype = 'int32';\n        if (environment_1.ENV.getBool('WEBGL_PACK_BINARY_OPERATIONS')) {\n            return this.packedBinaryOp(a, b, binaryop_packed_gpu.INT_DIV, outputDtype);\n        }\n        var program = new binaryop_gpu_1.BinaryOpProgram(op, a.shape, b.shape);\n        var output = this.makeOutputArray(program.outputShape, outputDtype);\n        return this.compileAndRun(program, [a, b], output);\n    };\n    MathBackendWebGL.prototype.add = function (a, b) {\n        if (a.dtype === 'complex64' && b.dtype === 'complex64') {\n            return this.complexSeparableBinaryOp(a, b, binaryop_gpu.ADD);\n        }\n        if (this.shouldExecuteOnCPU([a, b])) {\n            return this.cpuBackend.add(a, b);\n        }\n        var dtype = types_1.upcastType(a.dtype, b.dtype);\n        if (environment_1.ENV.getBool('WEBGL_PACK_BINARY_OPERATIONS')) {\n            return this.packedBinaryOp(a, b, binaryop_gpu.ADD, dtype);\n        }\n        var program = new binaryop_gpu_1.BinaryOpProgram(binaryop_gpu.ADD, a.shape, b.shape);\n        var output = this.makeOutputArray(program.outputShape, dtype);\n        return this.compileAndRun(program, [a, b], output);\n    };\n    MathBackendWebGL.prototype.packedBinaryOp = function (a, b, op, dtype, checkOutOfBounds) {\n        if (checkOutOfBounds === void 0) { checkOutOfBounds = false; }\n        var program = new binaryop_packed_gpu_1.BinaryOpPackedProgram(op, a.shape, b.shape, checkOutOfBounds);\n        var output = this.makePackedTensor(program.outputShape, dtype);\n        return this.compileAndRun(program, [a, b], output);\n    };\n    /**\n     * Computes a complex binary operation that can be decomposed into a simple\n     * binary operation on both the real and imagary parts.\n     */\n    MathBackendWebGL.prototype.complexSeparableBinaryOp = function (a, b, op) {\n        var _this = this;\n        var aData = this.texData.get(a.dataId);\n        var bData = this.texData.get(b.dataId);\n        var _a = [\n            [aData.complexTensors.real, bData.complexTensors.real],\n            [aData.complexTensors.imag, bData.complexTensors.imag]\n        ].map(function (complexParts) {\n            var aPart = complexParts[0], bPart = complexParts[1];\n            var aHandle = _this.makeComplexComponentTensorHandle(a, aPart);\n            var bHandle = _this.makeComplexComponentTensorHandle(b, bPart);\n            var program = new binaryop_gpu_1.BinaryOpProgram(op, a.shape, b.shape);\n            var output = _this.makeOutputArray(program.outputShape, types_1.upcastType(aPart.dtype, bPart.dtype));\n            return _this.compileAndRun(program, [aHandle, bHandle], output);\n        }), real = _a[0], imag = _a[1];\n        var complex = this.complex(real, imag);\n        real.dispose();\n        imag.dispose();\n        return complex;\n    };\n    // Returns a TensorHandle with the complex shape and the dataId of the\n    // underlying part. We need to do this because a reshaped complex tensor is\n    // not reflected in its parts.\n    MathBackendWebGL.prototype.makeComplexComponentTensorHandle = function (complexTensor, complexPart) {\n        return {\n            dataId: complexPart.dataId,\n            dtype: complexPart.dtype,\n            shape: complexTensor.shape\n        };\n    };\n    MathBackendWebGL.prototype.addN = function (tensors) {\n        if (tensors.length === 1) {\n            return tensors[0];\n        }\n        // Limit the number of uploaded textures for optimization.\n        if (tensors.length > environment_1.ENV.get('WEBGL_MAX_TEXTURES_IN_SHADER')) {\n            var midIndex = Math.floor(tensors.length / 2);\n            var leftSide = this.addN(tensors.slice(0, midIndex));\n            var rightSide = this.addN(tensors.slice(midIndex));\n            return this.addN([leftSide, rightSide]);\n        }\n        var dtype = tensors.map(function (t) { return t.dtype; }).reduce(function (d1, d2) { return types_1.upcastType(d1, d2); });\n        var shapes = tensors.map(function (t) { return t.shape; });\n        // We can make sure shapes are identical in op level.\n        var usePackedOp = environment_1.ENV.getBool('WEBGL_PACK');\n        var program = usePackedOp ?\n            new addn_packed_gpu_1.AddNPackedProgram(tensors[0].shape, shapes) :\n            new addn_gpu_1.AddNProgram(tensors[0].shape, shapes);\n        var output = usePackedOp ?\n            this.makePackedTensor(program.outputShape, dtype) :\n            this.makeOutputArray(program.outputShape, dtype);\n        return this.compileAndRun(program, tensors, output);\n    };\n    MathBackendWebGL.prototype.subtract = function (a, b) {\n        if (a.dtype === 'complex64' && b.dtype === 'complex64') {\n            return this.complexSeparableBinaryOp(a, b, binaryop_gpu.SUB);\n        }\n        if (this.shouldExecuteOnCPU([a, b])) {\n            return this.cpuBackend.subtract(a, b);\n        }\n        var dtype = types_1.upcastType(a.dtype, b.dtype);\n        if (environment_1.ENV.getBool('WEBGL_PACK_BINARY_OPERATIONS')) {\n            return this.packedBinaryOp(a, b, binaryop_gpu.SUB, a.dtype);\n        }\n        var program = new binaryop_gpu_1.BinaryOpProgram(binaryop_gpu.SUB, a.shape, b.shape);\n        var output = this.makeOutputArray(program.outputShape, dtype);\n        return this.compileAndRun(program, [a, b], output);\n    };\n    MathBackendWebGL.prototype.pow = function (a, b) {\n        var usePackedOp = environment_1.ENV.getBool('WEBGL_PACK_BINARY_OPERATIONS');\n        var program = usePackedOp ?\n            new binaryop_packed_gpu_1.BinaryOpPackedProgram(binaryop_packed_gpu.POW, a.shape, b.shape) :\n            new binaryop_gpu_1.BinaryOpProgram(binaryop_gpu.POW, a.shape, b.shape);\n        var dtype = types_1.upcastType(a.dtype, b.dtype);\n        var output = usePackedOp ?\n            this.makePackedTensor(program.outputShape, dtype) :\n            this.makeOutputArray(program.outputShape, dtype);\n        return this.compileAndRun(program, [a, b], output);\n    };\n    MathBackendWebGL.prototype.ceil = function (x) {\n        var program = new unaryop_gpu_1.UnaryOpProgram(x.shape, unary_op.CEIL);\n        return this.compileAndRun(program, [x]);\n    };\n    MathBackendWebGL.prototype.floor = function (x) {\n        var program = new unaryop_gpu_1.UnaryOpProgram(x.shape, unary_op.FLOOR);\n        return this.compileAndRun(program, [x]);\n    };\n    MathBackendWebGL.prototype.sign = function (x) {\n        var program = new unaryop_gpu_1.UnaryOpProgram(x.shape, unary_op.SIGN);\n        return this.compileAndRun(program, [x]);\n    };\n    MathBackendWebGL.prototype.isNaN = function (x) {\n        var program = new unaryop_gpu_1.UnaryOpProgram(x.shape, unary_op.IS_NAN);\n        var output = this.makeOutputArray(program.outputShape, 'bool');\n        return this.compileAndRun(program, [x], output);\n    };\n    MathBackendWebGL.prototype.isInf = function (x) {\n        var program = new unaryop_gpu_1.UnaryOpProgram(x.shape, unary_op.IS_INF);\n        var output = this.makeOutputArray(program.outputShape, 'bool');\n        return this.compileAndRun(program, [x], output);\n    };\n    MathBackendWebGL.prototype.isFinite = function (x) {\n        var program = new unaryop_gpu_1.UnaryOpProgram(x.shape, unary_op.IS_FINITE);\n        var output = this.makeOutputArray(program.outputShape, 'bool');\n        return this.compileAndRun(program, [x], output);\n    };\n    MathBackendWebGL.prototype.round = function (x) {\n        var program = new unaryop_gpu_1.UnaryOpProgram(x.shape, unary_op.ROUND);\n        return this.compileAndRun(program, [x]);\n    };\n    MathBackendWebGL.prototype.exp = function (x) {\n        var program;\n        if (environment_1.ENV.getBool('WEBGL_PACK')) {\n            program = new unaryop_packed_gpu_1.UnaryOpPackedProgram(x.shape, unary_op.EXP);\n        }\n        else {\n            program = new unaryop_gpu_1.UnaryOpProgram(x.shape, unary_op.EXP);\n        }\n        return this.compileAndRun(program, [x]);\n    };\n    MathBackendWebGL.prototype.expm1 = function (x) {\n        var program = new unaryop_gpu_1.UnaryOpProgram(x.shape, unary_op.EXPM1);\n        return this.compileAndRun(program, [x]);\n    };\n    MathBackendWebGL.prototype.log = function (x) {\n        var program;\n        if (environment_1.ENV.getBool('WEBGL_PACK')) {\n            program = new unaryop_packed_gpu_1.UnaryOpPackedProgram(x.shape, unary_packed_op.LOG);\n        }\n        else {\n            program = new unaryop_gpu_1.UnaryOpProgram(x.shape, unary_op.LOG);\n        }\n        return this.compileAndRun(program, [x]);\n    };\n    MathBackendWebGL.prototype.log1p = function (x) {\n        var program = new unaryop_gpu_1.UnaryOpProgram(x.shape, unary_op.LOG1P);\n        return this.compileAndRun(program, [x]);\n    };\n    MathBackendWebGL.prototype.sqrt = function (x) {\n        var program = new unaryop_gpu_1.UnaryOpProgram(x.shape, unary_op.SQRT);\n        return this.compileAndRun(program, [x]);\n    };\n    MathBackendWebGL.prototype.rsqrt = function (x) {\n        if (this.shouldExecuteOnCPU([x])) {\n            return this.cpuBackend.rsqrt(x);\n        }\n        var program = new unaryop_gpu_1.UnaryOpProgram(x.shape, unary_op.RSQRT);\n        return this.compileAndRun(program, [x]);\n    };\n    MathBackendWebGL.prototype.square = function (x) {\n        var program = new unaryop_gpu_1.UnaryOpProgram(x.shape, unary_op.SQUARE);\n        return this.compileAndRun(program, [x]);\n    };\n    MathBackendWebGL.prototype.reciprocal = function (x) {\n        var program = new unaryop_gpu_1.UnaryOpProgram(x.shape, unary_op.RECIPROCAL);\n        return this.compileAndRun(program, [x]);\n    };\n    MathBackendWebGL.prototype.relu = function (x) {\n        var program;\n        if (environment_1.ENV.getBool('WEBGL_PACK')) {\n            program = new unaryop_packed_gpu_1.UnaryOpPackedProgram(x.shape, unary_packed_op.RELU);\n        }\n        else {\n            program = new unaryop_gpu_1.UnaryOpProgram(x.shape, unary_op.RELU);\n        }\n        return this.compileAndRun(program, [x]);\n    };\n    MathBackendWebGL.prototype.prelu = function (x, alpha) {\n        var program = environment_1.ENV.getBool('WEBGL_PACK_BINARY_OPERATIONS') ?\n            new binaryop_packed_gpu_1.BinaryOpPackedProgram(binaryop_packed_gpu.PRELU, x.shape, alpha.shape) :\n            new binaryop_gpu_1.BinaryOpProgram(binaryop_gpu.PRELU, x.shape, alpha.shape);\n        return this.compileAndRun(program, [x, alpha]);\n    };\n    MathBackendWebGL.prototype.elu = function (x) {\n        var program = new unaryop_gpu_1.UnaryOpProgram(x.shape, unary_op.ELU);\n        return this.compileAndRun(program, [x]);\n    };\n    MathBackendWebGL.prototype.eluDer = function (dy, y) {\n        var program = environment_1.ENV.getBool('WEBGL_PACK_BINARY_OPERATIONS') ?\n            new binaryop_packed_gpu_1.BinaryOpPackedProgram(binaryop_packed_gpu.ELU_DER, dy.shape, y.shape) :\n            new binaryop_gpu_1.BinaryOpProgram(binaryop_gpu.ELU_DER, dy.shape, y.shape);\n        return this.compileAndRun(program, [dy, y]);\n    };\n    MathBackendWebGL.prototype.selu = function (x) {\n        var program = new unaryop_gpu_1.UnaryOpProgram(x.shape, unary_op.SELU);\n        return this.compileAndRun(program, [x]);\n    };\n    MathBackendWebGL.prototype.int = function (x) {\n        var program = new unaryop_gpu_1.UnaryOpProgram(x.shape, unary_op.TO_INT);\n        var output = this.makeOutputArray(program.outputShape, 'int32');\n        return this.compileAndRun(program, [x], output);\n    };\n    MathBackendWebGL.prototype.clip = function (x, min, max) {\n        var program;\n        if (environment_1.ENV.getBool('WEBGL_PACK_CLIP')) {\n            program = new clip_packed_gpu_1.ClipPackedProgram(x.shape);\n        }\n        else {\n            program = new clip_gpu_1.ClipProgram(x.shape);\n        }\n        var customSetup = program.getCustomSetupFunc(min, max);\n        return this.compileAndRun(program, [x], null, customSetup);\n    };\n    MathBackendWebGL.prototype.abs = function (x) {\n        var program = new unaryop_gpu_1.UnaryOpProgram(x.shape, unary_op.ABS);\n        return this.compileAndRun(program, [x]);\n    };\n    MathBackendWebGL.prototype.complexAbs = function (x) {\n        var xData = this.texData.get(x.dataId);\n        var program = new complex_abs_gpu_1.ComplexAbsProgram(x.shape);\n        var inputs = [\n            this.makeComplexComponentTensorHandle(x, xData.complexTensors.real),\n            this.makeComplexComponentTensorHandle(x, xData.complexTensors.imag),\n        ];\n        return this.compileAndRun(program, inputs);\n    };\n    MathBackendWebGL.prototype.sigmoid = function (x) {\n        var program = new unaryop_gpu_1.UnaryOpProgram(x.shape, unary_op.SIGMOID);\n        return this.compileAndRun(program, [x]);\n    };\n    MathBackendWebGL.prototype.softplus = function (x) {\n        var program = new unaryop_gpu_1.UnaryOpProgram(x.shape, unary_op.SOFTPLUS);\n        return this.compileAndRun(program, [x]);\n    };\n    MathBackendWebGL.prototype.sin = function (x) {\n        var program = new unaryop_gpu_1.UnaryOpProgram(x.shape, unary_op.SIN);\n        return this.compileAndRun(program, [x]);\n    };\n    MathBackendWebGL.prototype.cos = function (x) {\n        var program = new unaryop_gpu_1.UnaryOpProgram(x.shape, unary_op.COS);\n        return this.compileAndRun(program, [x]);\n    };\n    MathBackendWebGL.prototype.tan = function (x) {\n        var program = new unaryop_gpu_1.UnaryOpProgram(x.shape, unary_op.TAN);\n        return this.compileAndRun(program, [x]);\n    };\n    MathBackendWebGL.prototype.asin = function (x) {\n        var program = new unaryop_gpu_1.UnaryOpProgram(x.shape, unary_op.ASIN);\n        return this.compileAndRun(program, [x]);\n    };\n    MathBackendWebGL.prototype.acos = function (x) {\n        var program = new unaryop_gpu_1.UnaryOpProgram(x.shape, unary_op.ACOS);\n        return this.compileAndRun(program, [x]);\n    };\n    MathBackendWebGL.prototype.atan = function (x) {\n        var program = new unaryop_gpu_1.UnaryOpProgram(x.shape, unary_op.ATAN);\n        return this.compileAndRun(program, [x]);\n    };\n    MathBackendWebGL.prototype.atan2 = function (a, b) {\n        var program = environment_1.ENV.getBool('WEBGL_PACK_BINARY_OPERATIONS') ?\n            new binaryop_packed_gpu_1.BinaryOpPackedProgram(binaryop_packed_gpu.ATAN2, a.shape, b.shape) :\n            new binaryop_gpu_1.BinaryOpProgram(binaryop_gpu.ATAN2, a.shape, b.shape);\n        return this.compileAndRun(program, [a, b]);\n    };\n    MathBackendWebGL.prototype.sinh = function (x) {\n        var program = new unaryop_gpu_1.UnaryOpProgram(x.shape, unary_op.SINH);\n        return this.compileAndRun(program, [x]);\n    };\n    MathBackendWebGL.prototype.cosh = function (x) {\n        var program = new unaryop_gpu_1.UnaryOpProgram(x.shape, unary_op.COSH);\n        return this.compileAndRun(program, [x]);\n    };\n    MathBackendWebGL.prototype.tanh = function (x) {\n        var program = new unaryop_gpu_1.UnaryOpProgram(x.shape, unary_op.TANH);\n        return this.compileAndRun(program, [x]);\n    };\n    MathBackendWebGL.prototype.asinh = function (x) {\n        var program = new unaryop_gpu_1.UnaryOpProgram(x.shape, unary_op.ASINH);\n        return this.compileAndRun(program, [x]);\n    };\n    MathBackendWebGL.prototype.acosh = function (x) {\n        var program = new unaryop_gpu_1.UnaryOpProgram(x.shape, unary_op.ACOSH);\n        return this.compileAndRun(program, [x]);\n    };\n    MathBackendWebGL.prototype.atanh = function (x) {\n        var program = new unaryop_gpu_1.UnaryOpProgram(x.shape, unary_op.ATANH);\n        return this.compileAndRun(program, [x]);\n    };\n    MathBackendWebGL.prototype.erf = function (x) {\n        var program = new unaryop_gpu_1.UnaryOpProgram(x.shape, unary_op.ERF);\n        return this.compileAndRun(program, [x]);\n    };\n    MathBackendWebGL.prototype.step = function (x, alpha) {\n        var program = new unaryop_gpu_1.UnaryOpProgram(x.shape, unary_op.STEP(alpha));\n        return this.compileAndRun(program, [x]);\n    };\n    MathBackendWebGL.prototype.conv2dByMatMul = function (x, filter, convInfo) {\n        // Reshapes conv2D input to 2D tensors, uses matMul and then reshape the\n        // result from 2D to 4D.\n        var xShape = x.shape;\n        var xTexData = this.texData.get(x.dataId);\n        var sharedMatMulDim = convInfo.inChannels;\n        var outerShapeX = xShape[0] * xShape[1] * xShape[2];\n        var outerShapeFilter = convInfo.outChannels;\n        // TODO: Once reduction ops are packed, batchMatMul will always be packed\n        // and we can remove this condition.\n        var batchMatMulWillBeUnpacked = (outerShapeX === 1 || outerShapeFilter === 1) &&\n            sharedMatMulDim > exports.MATMUL_SHARED_DIM_THRESHOLD;\n        var reshapeWillBeExpensive = xShape[2] % 2 !== 0 && !!xTexData.isPacked;\n        if (batchMatMulWillBeUnpacked || !environment_1.ENV.getBool('WEBGL_LAZILY_UNPACK') ||\n            !environment_1.ENV.getBool('WEBGL_PACK_BINARY_OPERATIONS') ||\n            !reshapeWillBeExpensive) {\n            var xReshaped_1 = this.reshape(x, [1, xShape[0] * xShape[1] * xShape[2], convInfo.inChannels]);\n            var filterReshaped_1 = this.reshape(filter, [1, convInfo.inChannels, convInfo.outChannels]);\n            return this.reshape(this.batchMatMul(xReshaped_1, filterReshaped_1, false, false), convInfo.outShape);\n        }\n        // Following optimization is specific to packed |x| with odd row count\n        // ('row count' refers to x.shape[2]): we avoid expensive packed 2x2\n        // reshape by padding row count to next, even number. When x.shape[2] is\n        // odd, the result of packed batchMatMul is the same (has the same texture\n        // layout and and values in the texture) as it is for even x.shape[2] + 1.\n        // We make the odd-rows tensor to look like even-rows tensor before the\n        // operation and, after the batchMatMul, fix the even-rows result to have\n        // odd number of rows.\n        var xReshaped = tensor_1.Tensor.make([1, xShape[0] * xShape[1] * (xShape[2] + 1), convInfo.inChannels], { dataId: x.dataId }, x.dtype, this);\n        // xTexData.shape gets referenced from GPGPUBinary.inShapeInfos.\n        // Decrementing row count, after batchMatMul->...->compileProgram leads to\n        // invalid row count within the reference in GPGPUBinary.inShapeInfos.\n        // Alternative fix would be to provide a copy to GPGPUBinary.inShapeInfos\n        // in compileProgram method, but that would affect compilation of all\n        // programs - instead, provide a copy here, with even row count, before\n        // calling batchMatMul->...->compileProgram and after that, the original\n        // xTexData.shape is restored.\n        var originalXTexDataShape = xTexData.shape;\n        xTexData.shape = xTexData.shape.slice();\n        xTexData.shape[xTexData.shape.length - 2]++;\n        util.assert(webgl_util.isReshapeFree(xTexData.shape, xReshaped.shape), function () { return \"packed reshape \" + xTexData.shape + \" to \" + xReshaped.shape + \" isn't free\"; });\n        var filterReshaped = this.reshape(filter, [1, convInfo.inChannels, convInfo.outChannels]);\n        var pointwiseConv = this.batchMatMul(xReshaped, filterReshaped, false, false);\n        var pointwiseConvTexData = this.texData.get(pointwiseConv.dataId);\n        util.assert(pointwiseConvTexData.isPacked, function () { return 'batchMatMul result is expected to be packed'; });\n        // Restore the input shape to original.\n        xTexData.shape = originalXTexDataShape;\n        // Set the output shape - there is no need for expensive reshape as data\n        // layout is already correct.\n        pointwiseConvTexData.shape = convInfo.outShape;\n        return tensor_1.Tensor.make(convInfo.outShape, { dataId: pointwiseConv.dataId }, pointwiseConv.dtype, this);\n    };\n    MathBackendWebGL.prototype.conv2dWithIm2Row = function (x, filter, convInfo) {\n        // Rearranges conv2d input so each block to be convolved over forms the\n        // column of a new matrix with shape [filterWidth * filterHeight *\n        // inChannels, outHeight * outWidth]. The filter is also rearranged so each\n        // output channel forms a row of a new matrix with shape [outChannels,\n        // filterWidth * filterHeight * inChannels]. The convolution is then\n        // computed by multiplying these matrices and reshaping the result.\n        var filterWidth = convInfo.filterWidth, filterHeight = convInfo.filterHeight, inChannels = convInfo.inChannels, outWidth = convInfo.outWidth, outHeight = convInfo.outHeight;\n        var sharedDim = filterWidth * filterHeight * inChannels;\n        var numCols = outHeight * outWidth;\n        var x2ColShape = [sharedDim, numCols];\n        var xSqueezed = x.squeeze([0]);\n        var w2Row = filter.reshape([1, sharedDim, -1]);\n        var im2ColProgram = new im2col_packed_gpu_1.Im2ColPackedProgram(x2ColShape, xSqueezed.shape, convInfo);\n        var im2Col = this.compileAndRun(im2ColProgram, [xSqueezed]).reshape([\n            1, x2ColShape[0], x2ColShape[1]\n        ]);\n        var matmulProgram = new mulmat_packed_gpu_1.MatMulPackedProgram(im2Col.shape, [1, numCols, convInfo.outChannels], true, false);\n        var product = this.compileAndRun(matmulProgram, [im2Col, w2Row]);\n        return product.reshape([1, outHeight, outWidth, convInfo.outChannels]);\n    };\n    MathBackendWebGL.prototype.conv2d = function (x, filter, convInfo) {\n        if (convInfo.filterHeight === 1 && convInfo.filterWidth === 1 &&\n            convInfo.dilationHeight === 1 && convInfo.dilationWidth === 1 &&\n            convInfo.strideHeight === 1 && convInfo.strideWidth === 1 &&\n            (convInfo.padInfo.type === 'SAME' ||\n                convInfo.padInfo.type === 'VALID')) {\n            return this.conv2dByMatMul(x, filter, convInfo);\n        }\n        if (environment_1.ENV.getBool('WEBGL_CONV_IM2COL') && x.shape[0] === 1) {\n            return this.conv2dWithIm2Row(x, filter, convInfo);\n        }\n        var program = new conv_gpu_1.Conv2DProgram(convInfo);\n        return this.compileAndRun(program, [x, filter]);\n    };\n    MathBackendWebGL.prototype.conv2dDerInput = function (dy, filter, convInfo) {\n        var program = new conv_backprop_gpu_1.Conv2DDerInputProgram(convInfo);\n        return this.compileAndRun(program, [dy, filter]);\n    };\n    MathBackendWebGL.prototype.conv2dDerFilter = function (x, dy, convInfo) {\n        var program = new conv_backprop_gpu_1.Conv2DDerFilterProgram(convInfo);\n        return this.compileAndRun(program, [x, dy]);\n    };\n    MathBackendWebGL.prototype.depthwiseConv2D = function (x, filter, convInfo) {\n        var program;\n        if (environment_1.ENV.getBool('WEBGL_PACK_DEPTHWISECONV') && convInfo.strideWidth <= 2 &&\n            convInfo.outChannels / convInfo.inChannels === 1) {\n            program = new conv_packed_gpu_depthwise_1.DepthwiseConvPacked2DProgram(convInfo);\n            return this.compileAndRun(program, [x, filter], this.makePackedTensor(convInfo.outShape, x.dtype));\n        }\n        program = new conv_gpu_depthwise_1.DepthwiseConv2DProgram(convInfo);\n        return this.compileAndRun(program, [x, filter]);\n    };\n    MathBackendWebGL.prototype.depthwiseConv2DDerInput = function (dy, filter, convInfo) {\n        var program = new conv_backprop_gpu_depthwise_1.DepthwiseConv2DDerInputProgram(convInfo);\n        return this.compileAndRun(program, [dy, filter]);\n    };\n    MathBackendWebGL.prototype.depthwiseConv2DDerFilter = function (x, dy, convInfo) {\n        var program = new conv_backprop_gpu_depthwise_1.DepthwiseConv2DDerFilterProgram(convInfo);\n        return this.compileAndRun(program, [x, dy]);\n    };\n    MathBackendWebGL.prototype.conv3d = function (x, filter, convInfo) {\n        var program = new conv_gpu_1.Conv3DProgram(convInfo);\n        return this.compileAndRun(program, [x, filter]);\n    };\n    MathBackendWebGL.prototype.conv3dDerInput = function (dy, filter, convInfo) {\n        var program = new conv_backprop_gpu_1.Conv3DDerInputProgram(convInfo);\n        return this.compileAndRun(program, [dy, filter]);\n    };\n    MathBackendWebGL.prototype.conv3dDerFilter = function (x, dy, convInfo) {\n        var program = new conv_backprop_gpu_1.Conv3DDerFilterProgram(convInfo);\n        return this.compileAndRun(program, [x, dy]);\n    };\n    MathBackendWebGL.prototype.maxPool = function (x, convInfo) {\n        var program = new pool_gpu_1.Pool2DProgram(convInfo, 'max', false);\n        var output = this.makeOutputArray(program.outputShape, x.dtype);\n        return this.compileAndRun(program, [x], output);\n    };\n    MathBackendWebGL.prototype.avgPool = function (x, convInfo) {\n        var program = new pool_gpu_1.Pool2DProgram(convInfo, 'avg', false);\n        var output = this.makeOutputArray(program.outputShape, 'float32');\n        return this.compileAndRun(program, [x], output);\n    };\n    MathBackendWebGL.prototype.maxPoolBackprop = function (dy, x, y, convInfo) {\n        var getPositions = true;\n        var maxPoolPositionsProgram = new pool_gpu_1.Pool2DProgram(convInfo, 'max', getPositions);\n        var maxPoolPositions = this.compileAndRun(maxPoolPositionsProgram, [x]);\n        var maxPoolBackPropProgram = new max_pool_backprop_gpu_1.MaxPool2DBackpropProgram(convInfo);\n        var output = this.makeOutputArray(maxPoolBackPropProgram.outputShape, x.dtype);\n        var result = this.compileAndRun(maxPoolBackPropProgram, [dy, maxPoolPositions], output);\n        maxPoolPositions.dispose();\n        return result;\n    };\n    MathBackendWebGL.prototype.avgPoolBackprop = function (dy, x, convInfo) {\n        var avgPoolBackpropProgram = new avg_pool_backprop_gpu_1.AvgPool2DBackpropProgram(convInfo);\n        var output = this.makeOutputArray(avgPoolBackpropProgram.outputShape, x.dtype);\n        return this.compileAndRun(avgPoolBackpropProgram, [dy], output);\n    };\n    MathBackendWebGL.prototype.cast = function (x, dtype) {\n        return backend_util.castTensor(x, dtype, this);\n    };\n    MathBackendWebGL.prototype.unstack = function (x, axis) {\n        var num = x.shape[axis];\n        var outShape = new Array(x.rank - 1);\n        var outIndex = 0;\n        for (var i = 0; i < x.rank; i++) {\n            if (i !== axis) {\n                outShape[outIndex++] = x.shape[i];\n            }\n        }\n        var begin = new Array(x.rank).fill(0);\n        var size = x.shape.slice();\n        size[axis] = 1;\n        var res = new Array(num);\n        for (var i = 0; i < res.length; i++) {\n            begin[axis] = i;\n            res[i] = this.slice(x, begin, size).reshape(outShape);\n        }\n        return res;\n    };\n    MathBackendWebGL.prototype.reshape = function (x, shape) {\n        var texData = this.texData.get(x.dataId);\n        if (texData.isPacked && !webgl_util.isReshapeFree(x.shape, shape) &&\n            !(texData.texture !== null &&\n                webgl_util.isReshapeFree(texData.shape, shape))) {\n            return this.packedReshape(x, shape);\n        }\n        return backend_util.reshapeTensor(x, shape);\n    };\n    MathBackendWebGL.prototype.resizeBilinear = function (x, newHeight, newWidth, alignCorners) {\n        var program = environment_1.ENV.getBool('WEBGL_PACK_IMAGE_OPERATIONS') ?\n            new resize_bilinear_packed_gpu_1.ResizeBilinearPackedProgram(x.shape, newHeight, newWidth, alignCorners) :\n            new resize_bilinear_gpu_1.ResizeBilinearProgram(x.shape, newHeight, newWidth, alignCorners);\n        return this.compileAndRun(program, [x]);\n    };\n    MathBackendWebGL.prototype.resizeBilinearBackprop = function (dy, x, alignCorners) {\n        var program = new resize_bilinear_backprop_gpu_1.ResizeBilinearBackpropProgram(dy, x, alignCorners);\n        return this.compileAndRun(program, [dy]);\n    };\n    MathBackendWebGL.prototype.resizeNearestNeighbor = function (x, newHeight, newWidth, alignCorners) {\n        var program = new resize_nearest_neighbor_gpu_1.ResizeNearestNeighborProgram(x.shape, newHeight, newWidth, alignCorners);\n        return this.compileAndRun(program, [x]);\n    };\n    MathBackendWebGL.prototype.resizeNearestNeighborBackprop = function (dy, x, alignCorners) {\n        var program = new resize_nearest_neighbor_backprop_gpu_1.ResizeNearestNeigborBackpropProgram(dy, x, alignCorners);\n        return this.compileAndRun(program, [dy]);\n    };\n    MathBackendWebGL.prototype.multinomial = function (logits, normalized, numSamples, seed) {\n        var probs = normalized ? logits : softmax_1.softmax(logits);\n        var batchSize = probs.shape[0];\n        var numOutcomes = probs.shape[1];\n        var program = new multinomial_gpu_1.MultinomialProgram(batchSize, numOutcomes, numSamples);\n        var output = this.makeOutputArray(program.outputShape, 'int32');\n        var customSetup = program.getCustomSetupFunc(seed);\n        return this.compileAndRun(program, [probs], output, customSetup);\n    };\n    MathBackendWebGL.prototype.oneHot = function (indices, depth, onValue, offValue) {\n        var program = new onehot_gpu_1.OneHotProgram(indices.size, depth, onValue, offValue);\n        return this.compileAndRun(program, [indices]);\n    };\n    MathBackendWebGL.prototype.nonMaxSuppression = function (boxes, scores, maxOutputSize, iouThreshold, scoreThreshold) {\n        log_1.warn('tf.nonMaxSuppression() in webgl locks the UI thread. ' +\n            'Call tf.nonMaxSuppressionAsync() instead');\n        var boxesVals = boxes.dataSync();\n        var scoresVals = scores.dataSync();\n        return non_max_suppression_impl_1.nonMaxSuppressionImpl(boxesVals, scoresVals, maxOutputSize, iouThreshold, scoreThreshold);\n    };\n    MathBackendWebGL.prototype.cropAndResize = function (image, boxes, boxIndex, cropSize, method, extrapolationValue) {\n        var program = new crop_and_resize_gpu_1.CropAndResizeProgram(image.shape, boxes.shape, cropSize, method, extrapolationValue);\n        return this.compileAndRun(program, [image, boxes, boxIndex]);\n    };\n    MathBackendWebGL.prototype.depthToSpace = function (x, blockSize, dataFormat) {\n        util.assert(blockSize > 1, function () {\n            return \"blockSize should be > 1 for depthToSpace, but was: \" + blockSize;\n        });\n        var batchSize = x.shape[0];\n        var inputHeight = (dataFormat === 'NHWC') ? x.shape[1] : x.shape[2];\n        var inputWidth = (dataFormat === 'NHWC') ? x.shape[2] : x.shape[3];\n        var inputDepth = (dataFormat === 'NHWC') ? x.shape[3] : x.shape[1];\n        var outputHeight = inputHeight * blockSize;\n        var outputWidth = inputWidth * blockSize;\n        var outputDepth = inputDepth / (blockSize * blockSize);\n        var outputShape = (dataFormat === 'NHWC') ?\n            [batchSize, outputHeight, outputWidth, outputDepth] :\n            [batchSize, outputDepth, outputHeight, outputWidth];\n        var program = new depth_to_space_gpu_1.DepthToSpaceProgram(outputShape, blockSize, dataFormat);\n        return this.compileAndRun(program, [x]);\n    };\n    MathBackendWebGL.prototype.split = function (x, sizeSplits, axis) {\n        return split_shared_1.split(x, sizeSplits, axis);\n    };\n    MathBackendWebGL.prototype.scatterND = function (indices, updates, shape) {\n        var _a = scatter_nd_util.calculateShapes(updates, indices, shape), sliceRank = _a.sliceRank, numUpdates = _a.numUpdates, sliceSize = _a.sliceSize, strides = _a.strides, outputSize = _a.outputSize;\n        var flattenShape = [outputSize / sliceSize, sliceSize];\n        var flattenIndices = indices.reshape([numUpdates, sliceRank]);\n        var flattenX = updates.reshape([numUpdates, sliceSize]);\n        if (outputSize === 0) {\n            return backend_util.reshapeTensor(tensor_ops_1.tensor([]), shape);\n        }\n        var defaultValue = tensor_ops_1.scalar(0);\n        var program = new scatter_gpu_1.ScatterProgram(numUpdates, sliceRank, flattenIndices.rank, flattenX.rank, strides, flattenShape);\n        return this.compileAndRun(program, [flattenX, flattenIndices, defaultValue])\n            .reshape(shape);\n    };\n    MathBackendWebGL.prototype.sparseToDense = function (sparseIndices, sparseValues, outputShape, defaultValue) {\n        var _a = scatter_nd_util.calculateShapes(sparseValues, sparseIndices, outputShape), sliceRank = _a.sliceRank, numUpdates = _a.numUpdates, strides = _a.strides, outputSize = _a.outputSize;\n        var sumDupeIndices = false;\n        var program = new scatter_gpu_1.ScatterProgram(numUpdates, sliceRank, sparseIndices.rank, sparseValues.rank, strides, [outputSize, 1], sumDupeIndices);\n        return this.compileAndRun(program, [sparseValues, sparseIndices, defaultValue])\n            .reshape(outputShape);\n    };\n    MathBackendWebGL.prototype.fft = function (x) {\n        var inverse = false;\n        return this.fftImpl(x, inverse);\n    };\n    MathBackendWebGL.prototype.ifft = function (x) {\n        var inverse = true;\n        return this.fftImpl(x, inverse);\n    };\n    MathBackendWebGL.prototype.fftImpl = function (x, inverse) {\n        var xData = this.texData.get(x.dataId);\n        var realProgram = new fft_gpu_1.FFTProgram(fft_gpu.COMPLEX_FFT.REAL, x.shape, inverse);\n        var imagProgram = new fft_gpu_1.FFTProgram(fft_gpu.COMPLEX_FFT.IMAG, x.shape, inverse);\n        var inputs = [\n            this.makeComplexComponentTensorHandle(x, xData.complexTensors.real),\n            this.makeComplexComponentTensorHandle(x, xData.complexTensors.imag),\n        ];\n        var real = this.compileAndRun(realProgram, inputs);\n        var imag = this.compileAndRun(imagProgram, inputs);\n        var complex = this.complex(real, imag).as2D(x.shape[0], x.shape[1]);\n        real.dispose();\n        imag.dispose();\n        return complex;\n    };\n    MathBackendWebGL.prototype.gatherND = function (x, indices) {\n        var indicesShape = indices.shape;\n        var sliceRank = indicesShape[indicesShape.length - 1];\n        var _a = gather_nd_util.prepareAndValidate(x, indices), resultShape = _a[0], numSlices = _a[1], sliceSize = _a[2], strides = _a[3];\n        var flattenIndices = indices.reshape([numSlices, sliceRank]);\n        var flattenX = x.reshape([x.size / sliceSize, sliceSize]);\n        var program = new gather_nd_gpu_1.GatherNDProgram(sliceRank, strides, [numSlices, sliceSize]);\n        return this.compileAndRun(program, [flattenX, flattenIndices])\n            .reshape(resultShape);\n    };\n    MathBackendWebGL.prototype.fill = function (shape, value, dtype) {\n        dtype = dtype || util_1.inferDtype(value);\n        if (dtype === 'string') {\n            // String type should be handled in CPU memory.\n            var values = util_1.getArrayFromDType(dtype, util_1.sizeFromShape(shape));\n            values.fill(value);\n            return tensor_1.Tensor.make(shape, { values: values }, dtype);\n        }\n        else {\n            var program = new fill_gpu_1.FillProgram(shape, value);\n            var customSetup = program.getCustomSetupFunc(value);\n            var output = this.makeOutputArray(shape, dtype);\n            return this.compileAndRun(program, [], output, customSetup);\n        }\n    };\n    MathBackendWebGL.prototype.onesLike = function (x) {\n        if (x.dtype === 'string') {\n            throw new Error('onesLike is not supported under string dtype');\n        }\n        else {\n            // TODO(cais, smilkov): Add WebGL shader for onesLike:\n            //   https://github.com/tensorflow/tfjs/issues/1293\n            return this.fill(x.shape, 1, x.dtype);\n        }\n    };\n    MathBackendWebGL.prototype.zerosLike = function (x) {\n        return this.fill(x.shape, x.dtype === 'string' ? '' : 0, x.dtype);\n    };\n    MathBackendWebGL.prototype.linspace = function (start, stop, num) {\n        // TODO: Use CPU implementation due to the precision problem in Safari.\n        return backend_util.linspaceImpl(start, stop, num);\n    };\n    MathBackendWebGL.prototype.makeOutputArray = function (shape, dtype) {\n        return tensor_1.Tensor.make(shape, {}, dtype, this);\n    };\n    MathBackendWebGL.prototype.makePackedTensor = function (shape, dtype) {\n        var packedTensor = tensor_1.Tensor.make(shape, {}, dtype, this);\n        this.texData.get(packedTensor.dataId).isPacked = true;\n        return packedTensor;\n    };\n    MathBackendWebGL.prototype.unpackTensor = function (input) {\n        var program = new unpack_gpu_1.UnpackProgram(input.shape);\n        return this.compileAndRun(program, [input], tensor_1.Tensor.make(program.outputShape, {}, input.dtype, this));\n    };\n    MathBackendWebGL.prototype.packTensor = function (input) {\n        var program = new pack_gpu_1.PackProgram(input.shape);\n        return this.compileAndRun(program, [input], this.makePackedTensor(input.shape, input.dtype));\n    };\n    MathBackendWebGL.prototype.packedReshape = function (input, afterShape) {\n        var inputAs3D = input.reshape([\n            webgl_util.getBatchDim(input.shape)\n        ].concat(webgl_util.getRowsCols(input.shape)));\n        var afterShapeAs3D = [\n            webgl_util.getBatchDim(afterShape)\n        ].concat(webgl_util.getRowsCols(afterShape));\n        var program = new reshape_packed_gpu_1.ReshapePackedProgram(afterShapeAs3D, inputAs3D.shape);\n        return this.compileAndRun(program, [inputAs3D])\n            .reshape(afterShape);\n    };\n    MathBackendWebGL.prototype.compileAndRun = function (program, inputs, output, customSetup) {\n        var _this = this;\n        if (output == null) {\n            if (program.usesPackedTextures) {\n                output = this.makePackedTensor(program.outputShape, inputs[0].dtype);\n            }\n            else {\n                output = this.makeOutputArray(program.outputShape, inputs[0].dtype);\n            }\n        }\n        if (output.size === 0) {\n            // Short-circuit the computation since the result is empty (has 0 in its\n            // shape).\n            this.texData.get(output.dataId).values =\n                util_1.getTypedArrayFromDType(output.dtype, 0);\n            return output;\n        }\n        var inputsData = inputs.map(function (input) {\n            if (input.dtype === 'complex64') {\n                throw new Error(\"GPGPUProgram does not support complex64 input. For complex64 \" +\n                    \"dtypes, please separate the program into real and imaginary \" +\n                    \"parts.\");\n            }\n            var texData = _this.texData.get(input.dataId);\n            if (texData.texture == null) {\n                if (!program.usesPackedTextures &&\n                    util.sizeFromShape(input.shape) <=\n                        environment_1.ENV.getNumber('WEBGL_SIZE_UPLOAD_UNIFORM')) {\n                    // Upload small tensors that live on the CPU as uniforms, not as\n                    // textures. Do this only when the environment supports 32bit floats\n                    // due to problems when comparing 16bit floats with 32bit floats.\n                    // TODO(https://github.com/tensorflow/tfjs/issues/821): Make it\n                    // possible for packed shaders to sample from uniforms.\n                    return {\n                        shape: input.shape,\n                        texData: null,\n                        isUniform: true,\n                        uniformValues: texData.values\n                    };\n                }\n                // This ensures that if a packed program's inputs have not yet been\n                // uploaded to the GPU, they get uploaded as packed right off the bat.\n                if (program.usesPackedTextures) {\n                    texData.isPacked = true;\n                    texData.shape = input.shape;\n                }\n            }\n            else if (!!texData.isPacked !== !!program.usesPackedTextures) {\n                input = texData.isPacked ? _this.unpackTensor(input) :\n                    _this.packTensor(input);\n                texData = _this.texData.get(input.dataId);\n            }\n            else if (texData.isPacked &&\n                !webgl_util.isReshapeFree(texData.shape, input.shape)) {\n                // This is a special case where a texture exists for a tensor\n                // but the shapes are incompatible (due to packing constraints) because\n                // the tensor did not have a chance to go through the packed reshape\n                // shader. This only happens when we reshape the *same* tensor to form\n                // *distinct* inputs to an op, e.g. dotting a vector with itself. This\n                // case will disappear once packed uploading is the default.\n                var savedInput = input;\n                var targetShape = input.shape;\n                input.shape = texData.shape;\n                input = _this.packedReshape(input, targetShape);\n                texData = _this.texData.get(input.dataId);\n                savedInput.shape = targetShape;\n            }\n            _this.uploadToGPU(input.dataId);\n            return { shape: input.shape, texData: texData, isUniform: false };\n        });\n        this.uploadToGPU(output.dataId);\n        var outputData = {\n            shape: output.shape,\n            texData: this.texData.get(output.dataId),\n            isUniform: false\n        };\n        var key = gpgpu_math.makeShaderKey(program, inputsData, outputData);\n        var binary = this.getAndSaveBinary(key, function () {\n            return gpgpu_math.compileProgram(_this.gpgpu, program, inputsData, outputData);\n        });\n        var shouldTimeProgram = this.activeTimers != null;\n        var query;\n        if (shouldTimeProgram) {\n            query = this.startTimer();\n        }\n        gpgpu_math.runProgram(this.gpgpu, binary, inputsData, outputData, customSetup);\n        if (shouldTimeProgram) {\n            query = this.endTimer(query);\n            this.activeTimers.push({ name: program.constructor.name, query: this.getQueryTime(query) });\n        }\n        if (!environment_1.ENV.getBool('WEBGL_LAZILY_UNPACK') &&\n            this.texData.get(output.dataId).isPacked && !program.isPackShader) {\n            return this.unpackTensor(output);\n        }\n        return output;\n    };\n    MathBackendWebGL.prototype.getAndSaveBinary = function (key, getBinary) {\n        if (!(key in this.binaryCache)) {\n            this.binaryCache[key] = getBinary();\n        }\n        return this.binaryCache[key];\n    };\n    MathBackendWebGL.prototype.getTextureManager = function () {\n        return this.textureManager;\n    };\n    MathBackendWebGL.prototype.dispose = function () {\n        if (this.disposed) {\n            return;\n        }\n        this.textureManager.dispose();\n        this.canvas.remove();\n        if (this.fromPixels2DContext != null) {\n            this.fromPixels2DContext.canvas.remove();\n        }\n        if (this.gpgpuCreatedLocally) {\n            this.gpgpu.program = null;\n            this.gpgpu.dispose();\n        }\n        this.disposed = true;\n    };\n    MathBackendWebGL.prototype.floatPrecision = function () {\n        var _this = this;\n        if (this.floatPrecisionValue == null) {\n            this.floatPrecisionValue = globals_1.tidy(function () {\n                // Momentarily switching DEBUG flag to false so we don't throw an error\n                // trying to upload a small value.\n                var debugFlag = environment_1.ENV.getBool('DEBUG');\n                environment_1.ENV.set('DEBUG', false);\n                var underflowCheckValue = _this.abs(tensor_ops_1.scalar(1e-8)).dataSync()[0];\n                environment_1.ENV.set('DEBUG', debugFlag);\n                if (underflowCheckValue > 0) {\n                    return 32;\n                }\n                return 16;\n            });\n        }\n        return this.floatPrecisionValue;\n    };\n    /** Returns the smallest representable number.  */\n    MathBackendWebGL.prototype.epsilon = function () {\n        return this.floatPrecision() === 32 ? backend_1.EPSILON_FLOAT32 : backend_1.EPSILON_FLOAT16;\n    };\n    MathBackendWebGL.prototype.uploadToGPU = function (dataId) {\n        var _a;\n        var texData = this.texData.get(dataId);\n        var shape = texData.shape, dtype = texData.dtype, values = texData.values, texture = texData.texture, usage = texData.usage, isPacked = texData.isPacked;\n        if (texture != null) {\n            // Array is already on GPU. No-op.\n            return;\n        }\n        var shouldTimeProgram = this.activeTimers != null;\n        var start;\n        if (shouldTimeProgram) {\n            start = performance.now();\n        }\n        var texShape = webgl_util.getTextureShapeFromLogicalShape(shape, isPacked);\n        texData.texShape = texShape;\n        var newTexture = this.acquireTexture(texShape, usage, dtype, isPacked);\n        texData.texture = newTexture;\n        if (values != null) {\n            // TODO(smilkov): Propagate the original typed array to gpgpu.\n            if (isPacked) {\n                var batch = webgl_util.getBatchDim(shape);\n                var rows = 1, cols = 1;\n                if (shape.length) {\n                    _a = webgl_util.getRowsCols(shape), rows = _a[0], cols = _a[1];\n                }\n                this.gpgpu.uploadMatrixToPackedTexture(newTexture, batch, rows, cols, texShape[0], texShape[1], typedArrayToFloat32(values));\n            }\n            else {\n                this.gpgpu.uploadMatrixToTexture(newTexture, texShape[0], texShape[1], typedArrayToFloat32(values));\n            }\n            // Once uploaded, don't store the values on cpu.\n            texData.values = null;\n            if (shouldTimeProgram) {\n                this.uploadWaitMs += performance.now() - start;\n            }\n        }\n    };\n    MathBackendWebGL.prototype.convertAndCacheOnCPU = function (dataId, float32Values) {\n        var texData = this.texData.get(dataId);\n        var dtype = texData.dtype;\n        this.releaseGPUData(dataId);\n        texData.usage = tex_util_1.TextureUsage.UPLOAD;\n        if (float32Values != null) {\n            texData.values = float32ToTypedArray(float32Values, dtype);\n        }\n        return texData.values;\n    };\n    MathBackendWebGL.prototype.acquireTexture = function (texShape, texType, dtype, isPacked) {\n        this.numBytesInGPU += this.computeBytes(texShape, dtype);\n        if (!this.warnedAboutMemory &&\n            this.numBytesInGPU > this.numMBBeforeWarning * 1024 * 1024) {\n            var mb = (this.numBytesInGPU / 1024 / 1024).toFixed(2);\n            this.warnedAboutMemory = true;\n            console.warn(\"High memory usage in GPU: \" + mb + \" MB, \" +\n                \"most likely due to a memory leak\");\n        }\n        return this.textureManager.acquireTexture(texShape, texType, isPacked);\n    };\n    MathBackendWebGL.prototype.computeBytes = function (shape, dtype) {\n        return shape[0] * shape[1] * util.bytesPerElement(dtype);\n    };\n    return MathBackendWebGL;\n}());\nexports.MathBackendWebGL = MathBackendWebGL;\nif (device_util.isBrowser()) {\n    engine_1.ENGINE.registerBackend('webgl', function () { return new MathBackendWebGL(); }, 2 /* priority */);\n}\nfunction float32ToTypedArray(a, dtype) {\n    if (dtype === 'float32' || dtype === 'complex64') {\n        return a;\n    }\n    else if (dtype === 'int32' || dtype === 'bool') {\n        var result = (dtype === 'int32') ? new Int32Array(a.length) :\n            new Uint8Array(a.length);\n        for (var i = 0; i < result.length; ++i) {\n            result[i] = Math.round(a[i]);\n        }\n        return result;\n    }\n    else {\n        throw new Error(\"Unknown dtype \" + dtype);\n    }\n}\nfunction typedArrayToFloat32(a) {\n    return (a instanceof Float32Array) ? a : new Float32Array(a);\n}\n//# sourceMappingURL=backend_webgl.js.map","\n/**\n * @license\n * Copyright 2019 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar device_util = require(\"../../device_util\");\nvar environment_1 = require(\"../../environment\");\nvar webgl_util = require(\"./webgl_util\");\n/**\n * This file contains WebGL-specific flag registrations.\n */\n/**\n * True if WebGL is supported.\n */\nenvironment_1.ENV.registerFlag('HAS_WEBGL', function () { return environment_1.ENV.getNumber('WEBGL_VERSION') > 0; });\n/** 0: No WebGL, 1: WebGL 1.0, 2: WebGL 2.0. */\nenvironment_1.ENV.registerFlag('WEBGL_VERSION', function () {\n    if (webgl_util.isWebGLVersionEnabled(2)) {\n        return 2;\n    }\n    else if (webgl_util.isWebGLVersionEnabled(1)) {\n        return 1;\n    }\n    return 0;\n});\nenvironment_1.ENV.registerFlag('WEBGL_BUFFER_SUPPORTED', function () { return environment_1.ENV.get('WEBGL_VERSION') === 2; });\n/** Whether the WebGL backend will sometimes forward ops to the CPU. */\nenvironment_1.ENV.registerFlag('WEBGL_CPU_FORWARD', function () { return true; });\n/** Whether to turn all packing related flags on. */\nenvironment_1.ENV.registerFlag('WEBGL_PACK', function () { return environment_1.ENV.getBool('HAS_WEBGL'); });\n/** Whether we will pack the batchnormalization op. */\nenvironment_1.ENV.registerFlag('WEBGL_PACK_NORMALIZATION', function () { return environment_1.ENV.getBool('WEBGL_PACK'); });\n/** Whether we will pack the clip op. */\nenvironment_1.ENV.registerFlag('WEBGL_PACK_CLIP', function () { return environment_1.ENV.getBool('WEBGL_PACK'); });\n/** Whether we will pack the depthwise conv op. */\nenvironment_1.ENV.registerFlag('WEBGL_PACK_DEPTHWISECONV', function () { return environment_1.ENV.getBool('WEBGL_PACK'); });\n/** Whether we will pack binary ops. */\nenvironment_1.ENV.registerFlag('WEBGL_PACK_BINARY_OPERATIONS', function () { return environment_1.ENV.getBool('WEBGL_PACK'); });\n/** Whether we will pack array ops. */\nenvironment_1.ENV.registerFlag('WEBGL_PACK_ARRAY_OPERATIONS', function () { return environment_1.ENV.getBool('WEBGL_PACK'); });\n/** Whether we will pack image ops. */\nenvironment_1.ENV.registerFlag('WEBGL_PACK_IMAGE_OPERATIONS', function () { return environment_1.ENV.getBool('WEBGL_PACK'); });\n/** Whether we will pack reduce ops. */\nenvironment_1.ENV.registerFlag('WEBGL_PACK_REDUCE', function () { return environment_1.ENV.getBool('WEBGL_PACK'); });\n/** Whether packed WebGL kernels lazily unpack their outputs. */\nenvironment_1.ENV.registerFlag('WEBGL_LAZILY_UNPACK', function () { return environment_1.ENV.getBool('WEBGL_PACK'); });\n/** Whether we will use the im2col algorithm to speed up convolutions. */\nenvironment_1.ENV.registerFlag('WEBGL_CONV_IM2COL', function () { return environment_1.ENV.getBool('WEBGL_PACK'); });\n/** The maximum texture dimension. */\nenvironment_1.ENV.registerFlag('WEBGL_MAX_TEXTURE_SIZE', function () { return webgl_util.getWebGLMaxTextureSize(environment_1.ENV.getNumber('WEBGL_VERSION')); });\n/** The maximum texture dimension. */\nenvironment_1.ENV.registerFlag('WEBGL_MAX_TEXTURES_IN_SHADER', function () { return webgl_util.getMaxTexturesInShader(environment_1.ENV.getNumber('WEBGL_VERSION')); });\n/**\n * The disjoint_query_timer extension version.\n * 0: disabled, 1: EXT_disjoint_timer_query, 2:\n * EXT_disjoint_timer_query_webgl2.\n * In Firefox with WebGL 2.0,\n * EXT_disjoint_timer_query_webgl2 is not available, so we must use the\n * WebGL 1.0 extension.\n */\nenvironment_1.ENV.registerFlag('WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION', function () {\n    var webGLVersion = environment_1.ENV.getNumber('WEBGL_VERSION');\n    if (webGLVersion === 0) {\n        return 0;\n    }\n    return webgl_util.getWebGLDisjointQueryTimerVersion(webGLVersion);\n});\n/**\n * Whether the timer object from the disjoint_query_timer extension gives\n * timing information that is reliable.\n */\nenvironment_1.ENV.registerFlag('WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_RELIABLE', function () { return environment_1.ENV.getNumber('WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION') > 0 &&\n    !device_util.isMobile(); });\n/**\n * Whether rendering to float32 textures is enabled. If disabled, renders to\n * float16 textures.\n */\nenvironment_1.ENV.registerFlag('WEBGL_RENDER_FLOAT32_ENABLED', function () { return webgl_util.isRenderToFloatTextureEnabled(environment_1.ENV.getNumber('WEBGL_VERSION')); });\n/**\n * Whether downloading float textures is enabled (16 or 32 bit). If disabled,\n * uses IEEE 754 encoding of the float32 values to 4 uint8 when downloading.\n */\nenvironment_1.ENV.registerFlag('WEBGL_DOWNLOAD_FLOAT_ENABLED', function () { return webgl_util.isDownloadFloatTextureEnabled(environment_1.ENV.getNumber('WEBGL_VERSION')); });\n/** Whether the fence API is available. */\nenvironment_1.ENV.registerFlag('WEBGL_FENCE_API_ENABLED', function () { return webgl_util.isWebGLFenceEnabled(environment_1.ENV.getNumber('WEBGL_VERSION')); });\n/**\n * Tensors with size <= than this will be uploaded as uniforms, not textures.\n */\nenvironment_1.ENV.registerFlag('WEBGL_SIZE_UPLOAD_UNIFORM', function () {\n    // Use uniform uploads only when 32bit floats are supported. In\n    // 16bit\n    // environments there are problems with comparing a 16bit texture value\n    // with a 32bit uniform value.\n    var useUniforms = environment_1.ENV.getBool('WEBGL_RENDER_FLOAT32_ENABLED');\n    return useUniforms ? 4 : 0;\n});\n//# sourceMappingURL=flags_webgl.js.map","\n/**\n * @license\n * Copyright 2017 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar environment_1 = require(\"../../environment\");\nvar util = require(\"../../util\");\nvar canvas_util_1 = require(\"./canvas_util\");\nfunction callAndCheck(gl, debugMode, func) {\n    var returnValue = func();\n    if (debugMode) {\n        checkWebGLError(gl);\n    }\n    return returnValue;\n}\nexports.callAndCheck = callAndCheck;\nfunction checkWebGLError(gl) {\n    var error = gl.getError();\n    if (error !== gl.NO_ERROR) {\n        throw new Error('WebGL Error: ' + getWebGLErrorMessage(gl, error));\n    }\n}\n// https://en.wikipedia.org/wiki/Half-precision_floating-point_format\nvar MIN_FLOAT16 = 5.96e-8;\nvar MAX_FLOAT16 = 65504;\nfunction canBeRepresented(num) {\n    if (environment_1.ENV.getBool('WEBGL_RENDER_FLOAT32_ENABLED') || num === 0 ||\n        (MIN_FLOAT16 < Math.abs(num) && Math.abs(num) < MAX_FLOAT16)) {\n        return true;\n    }\n    return false;\n}\nexports.canBeRepresented = canBeRepresented;\nfunction getWebGLErrorMessage(gl, status) {\n    switch (status) {\n        case gl.NO_ERROR:\n            return 'NO_ERROR';\n        case gl.INVALID_ENUM:\n            return 'INVALID_ENUM';\n        case gl.INVALID_VALUE:\n            return 'INVALID_VALUE';\n        case gl.INVALID_OPERATION:\n            return 'INVALID_OPERATION';\n        case gl.INVALID_FRAMEBUFFER_OPERATION:\n            return 'INVALID_FRAMEBUFFER_OPERATION';\n        case gl.OUT_OF_MEMORY:\n            return 'OUT_OF_MEMORY';\n        case gl.CONTEXT_LOST_WEBGL:\n            return 'CONTEXT_LOST_WEBGL';\n        default:\n            return \"Unknown error code \" + status;\n    }\n}\nexports.getWebGLErrorMessage = getWebGLErrorMessage;\nfunction getExtensionOrThrow(gl, debug, extensionName) {\n    return throwIfNull(gl, debug, function () { return gl.getExtension(extensionName); }, 'Extension \"' + extensionName + '\" not supported on this browser.');\n}\nexports.getExtensionOrThrow = getExtensionOrThrow;\nfunction createVertexShader(gl, debug, vertexShaderSource) {\n    var vertexShader = throwIfNull(gl, debug, function () { return gl.createShader(gl.VERTEX_SHADER); }, 'Unable to create vertex WebGLShader.');\n    callAndCheck(gl, debug, function () { return gl.shaderSource(vertexShader, vertexShaderSource); });\n    callAndCheck(gl, debug, function () { return gl.compileShader(vertexShader); });\n    if (gl.getShaderParameter(vertexShader, gl.COMPILE_STATUS) === false) {\n        console.log(gl.getShaderInfoLog(vertexShader));\n        throw new Error('Failed to compile vertex shader.');\n    }\n    return vertexShader;\n}\nexports.createVertexShader = createVertexShader;\nfunction createFragmentShader(gl, debug, fragmentShaderSource) {\n    var fragmentShader = throwIfNull(gl, debug, function () { return gl.createShader(gl.FRAGMENT_SHADER); }, 'Unable to create fragment WebGLShader.');\n    callAndCheck(gl, debug, function () { return gl.shaderSource(fragmentShader, fragmentShaderSource); });\n    callAndCheck(gl, debug, function () { return gl.compileShader(fragmentShader); });\n    if (gl.getShaderParameter(fragmentShader, gl.COMPILE_STATUS) === false) {\n        logShaderSourceAndInfoLog(fragmentShaderSource, gl.getShaderInfoLog(fragmentShader));\n        throw new Error('Failed to compile fragment shader.');\n    }\n    return fragmentShader;\n}\nexports.createFragmentShader = createFragmentShader;\nvar lineNumberRegex = /ERROR: [0-9]+:([0-9]+):/g;\nfunction logShaderSourceAndInfoLog(shaderSource, shaderInfoLog) {\n    var lineNumberRegexResult = lineNumberRegex.exec(shaderInfoLog);\n    if (lineNumberRegexResult == null) {\n        console.log(\"Couldn't parse line number in error: \" + shaderInfoLog);\n        console.log(shaderSource);\n        return;\n    }\n    var lineNumber = +lineNumberRegexResult[1];\n    var shaderLines = shaderSource.split('\\n');\n    var pad = shaderLines.length.toString().length + 2;\n    var linesWithLineNumbers = shaderLines.map(function (line, lineNumber) {\n        return util.rightPad((lineNumber + 1).toString(), pad) + line;\n    });\n    var maxLineLength = 0;\n    for (var i = 0; i < linesWithLineNumbers.length; i++) {\n        maxLineLength = Math.max(linesWithLineNumbers[i].length, maxLineLength);\n    }\n    var beforeErrorLines = linesWithLineNumbers.slice(0, lineNumber - 1);\n    var errorLine = linesWithLineNumbers.slice(lineNumber - 1, lineNumber);\n    var afterErrorLines = linesWithLineNumbers.slice(lineNumber);\n    console.log(beforeErrorLines.join('\\n'));\n    console.log(shaderInfoLog.split('\\n')[0]);\n    console.log(\"%c \" + util.rightPad(errorLine[0], maxLineLength), 'border:1px solid red; background-color:#e3d2d2; color:#a61717');\n    console.log(afterErrorLines.join('\\n'));\n}\nfunction createProgram(gl, debug) {\n    return throwIfNull(gl, debug, function () { return gl.createProgram(); }, 'Unable to create WebGLProgram.');\n}\nexports.createProgram = createProgram;\nfunction linkProgram(gl, debug, program) {\n    callAndCheck(gl, debug, function () { return gl.linkProgram(program); });\n    if (gl.getProgramParameter(program, gl.LINK_STATUS) === false) {\n        console.log(gl.getProgramInfoLog(program));\n        throw new Error('Failed to link vertex and fragment shaders.');\n    }\n}\nexports.linkProgram = linkProgram;\nfunction validateProgram(gl, debug, program) {\n    callAndCheck(gl, debug, function () { return gl.validateProgram(program); });\n    if (gl.getProgramParameter(program, gl.VALIDATE_STATUS) === false) {\n        console.log(gl.getProgramInfoLog(program));\n        throw new Error('Shader program validation failed.');\n    }\n}\nexports.validateProgram = validateProgram;\nfunction createStaticVertexBuffer(gl, debug, data) {\n    var buffer = throwIfNull(gl, debug, function () { return gl.createBuffer(); }, 'Unable to create WebGLBuffer');\n    callAndCheck(gl, debug, function () { return gl.bindBuffer(gl.ARRAY_BUFFER, buffer); });\n    callAndCheck(gl, debug, function () { return gl.bufferData(gl.ARRAY_BUFFER, data, gl.STATIC_DRAW); });\n    return buffer;\n}\nexports.createStaticVertexBuffer = createStaticVertexBuffer;\nfunction createStaticIndexBuffer(gl, debug, data) {\n    var buffer = throwIfNull(gl, debug, function () { return gl.createBuffer(); }, 'Unable to create WebGLBuffer');\n    callAndCheck(gl, debug, function () { return gl.bindBuffer(gl.ELEMENT_ARRAY_BUFFER, buffer); });\n    callAndCheck(gl, debug, function () { return gl.bufferData(gl.ELEMENT_ARRAY_BUFFER, data, gl.STATIC_DRAW); });\n    return buffer;\n}\nexports.createStaticIndexBuffer = createStaticIndexBuffer;\nfunction getNumChannels() {\n    if (environment_1.ENV.getNumber('WEBGL_VERSION') === 2) {\n        return 1;\n    }\n    return 4;\n}\nexports.getNumChannels = getNumChannels;\nfunction createTexture(gl, debug) {\n    return throwIfNull(gl, debug, function () { return gl.createTexture(); }, 'Unable to create WebGLTexture.');\n}\nexports.createTexture = createTexture;\nfunction validateTextureSize(width, height) {\n    var maxTextureSize = environment_1.ENV.getNumber('WEBGL_MAX_TEXTURE_SIZE');\n    if ((width <= 0) || (height <= 0)) {\n        var requested = \"[\" + width + \"x\" + height + \"]\";\n        throw new Error('Requested texture size ' + requested + ' is invalid.');\n    }\n    if ((width > maxTextureSize) || (height > maxTextureSize)) {\n        var requested = \"[\" + width + \"x\" + height + \"]\";\n        var max = \"[\" + maxTextureSize + \"x\" + maxTextureSize + \"]\";\n        throw new Error('Requested texture size ' + requested +\n            ' greater than WebGL maximum on this browser / GPU ' + max + '.');\n    }\n}\nexports.validateTextureSize = validateTextureSize;\nfunction createFramebuffer(gl, debug) {\n    return throwIfNull(gl, debug, function () { return gl.createFramebuffer(); }, 'Unable to create WebGLFramebuffer.');\n}\nexports.createFramebuffer = createFramebuffer;\nfunction bindVertexBufferToProgramAttribute(gl, debug, program, attribute, buffer, arrayEntriesPerItem, itemStrideInBytes, itemOffsetInBytes) {\n    var loc = gl.getAttribLocation(program, attribute);\n    if (loc === -1) {\n        // The GPU compiler decided to strip out this attribute because it's unused,\n        // thus no need to bind.\n        return false;\n    }\n    callAndCheck(gl, debug, function () { return gl.bindBuffer(gl.ARRAY_BUFFER, buffer); });\n    callAndCheck(gl, debug, function () { return gl.vertexAttribPointer(loc, arrayEntriesPerItem, gl.FLOAT, false, itemStrideInBytes, itemOffsetInBytes); });\n    callAndCheck(gl, debug, function () { return gl.enableVertexAttribArray(loc); });\n    return true;\n}\nexports.bindVertexBufferToProgramAttribute = bindVertexBufferToProgramAttribute;\nfunction bindTextureUnit(gl, debug, texture, textureUnit) {\n    validateTextureUnit(gl, textureUnit);\n    callAndCheck(gl, debug, function () { return gl.activeTexture(gl.TEXTURE0 + textureUnit); });\n    callAndCheck(gl, debug, function () { return gl.bindTexture(gl.TEXTURE_2D, texture); });\n}\nexports.bindTextureUnit = bindTextureUnit;\nfunction unbindTextureUnit(gl, debug, textureUnit) {\n    validateTextureUnit(gl, textureUnit);\n    callAndCheck(gl, debug, function () { return gl.activeTexture(gl.TEXTURE0 + textureUnit); });\n    callAndCheck(gl, debug, function () { return gl.bindTexture(gl.TEXTURE_2D, null); });\n}\nexports.unbindTextureUnit = unbindTextureUnit;\nfunction getProgramUniformLocationOrThrow(gl, debug, program, uniformName) {\n    return throwIfNull(gl, debug, function () { return gl.getUniformLocation(program, uniformName); }, 'uniform \"' + uniformName + '\" not present in program.');\n}\nexports.getProgramUniformLocationOrThrow = getProgramUniformLocationOrThrow;\nfunction getProgramUniformLocation(gl, program, uniformName) {\n    return gl.getUniformLocation(program, uniformName);\n}\nexports.getProgramUniformLocation = getProgramUniformLocation;\nfunction bindTextureToProgramUniformSampler(gl, debug, program, texture, uniformSamplerLocation, textureUnit) {\n    callAndCheck(gl, debug, function () { return bindTextureUnit(gl, debug, texture, textureUnit); });\n    callAndCheck(gl, debug, function () { return gl.uniform1i(uniformSamplerLocation, textureUnit); });\n}\nexports.bindTextureToProgramUniformSampler = bindTextureToProgramUniformSampler;\nfunction bindCanvasToFramebuffer(gl, debug) {\n    callAndCheck(gl, debug, function () { return gl.bindFramebuffer(gl.FRAMEBUFFER, null); });\n    callAndCheck(gl, debug, function () { return gl.viewport(0, 0, gl.canvas.width, gl.canvas.height); });\n    callAndCheck(gl, debug, function () { return gl.scissor(0, 0, gl.canvas.width, gl.canvas.height); });\n}\nexports.bindCanvasToFramebuffer = bindCanvasToFramebuffer;\nfunction bindColorTextureToFramebuffer(gl, debug, texture, framebuffer) {\n    callAndCheck(gl, debug, function () { return gl.bindFramebuffer(gl.FRAMEBUFFER, framebuffer); });\n    callAndCheck(gl, debug, function () { return gl.framebufferTexture2D(gl.FRAMEBUFFER, gl.COLOR_ATTACHMENT0, gl.TEXTURE_2D, texture, 0); });\n}\nexports.bindColorTextureToFramebuffer = bindColorTextureToFramebuffer;\nfunction unbindColorTextureFromFramebuffer(gl, debug, framebuffer) {\n    callAndCheck(gl, debug, function () { return gl.bindFramebuffer(gl.FRAMEBUFFER, framebuffer); });\n    callAndCheck(gl, debug, function () { return gl.framebufferTexture2D(gl.FRAMEBUFFER, gl.COLOR_ATTACHMENT0, gl.TEXTURE_2D, null, 0); });\n}\nexports.unbindColorTextureFromFramebuffer = unbindColorTextureFromFramebuffer;\nfunction validateFramebuffer(gl) {\n    var status = gl.checkFramebufferStatus(gl.FRAMEBUFFER);\n    if (status !== gl.FRAMEBUFFER_COMPLETE) {\n        throw new Error('Error binding framebuffer: ' + getFramebufferErrorMessage(gl, status));\n    }\n}\nexports.validateFramebuffer = validateFramebuffer;\nfunction getFramebufferErrorMessage(gl, status) {\n    switch (status) {\n        case gl.FRAMEBUFFER_INCOMPLETE_ATTACHMENT:\n            return 'FRAMEBUFFER_INCOMPLETE_ATTACHMENT';\n        case gl.FRAMEBUFFER_INCOMPLETE_MISSING_ATTACHMENT:\n            return 'FRAMEBUFFER_INCOMPLETE_MISSING_ATTACHMENT';\n        case gl.FRAMEBUFFER_INCOMPLETE_DIMENSIONS:\n            return 'FRAMEBUFFER_INCOMPLETE_DIMENSIONS';\n        case gl.FRAMEBUFFER_UNSUPPORTED:\n            return 'FRAMEBUFFER_UNSUPPORTED';\n        default:\n            return \"unknown error \" + status;\n    }\n}\nexports.getFramebufferErrorMessage = getFramebufferErrorMessage;\nfunction throwIfNull(gl, debug, returnTOrNull, failureMessage) {\n    var tOrNull = callAndCheck(gl, debug, function () { return returnTOrNull(); });\n    if (tOrNull == null) {\n        throw new Error(failureMessage);\n    }\n    return tOrNull;\n}\nfunction validateTextureUnit(gl, textureUnit) {\n    var maxTextureUnit = gl.MAX_COMBINED_TEXTURE_IMAGE_UNITS - 1;\n    var glTextureUnit = textureUnit + gl.TEXTURE0;\n    if (glTextureUnit < gl.TEXTURE0 || glTextureUnit > maxTextureUnit) {\n        var textureUnitRange = \"[gl.TEXTURE0, gl.TEXTURE\" + maxTextureUnit + \"]\";\n        throw new Error(\"textureUnit must be in \" + textureUnitRange + \".\");\n    }\n}\nfunction getBatchDim(shape, dimsToSkip) {\n    if (dimsToSkip === void 0) { dimsToSkip = 2; }\n    return util.sizeFromShape(shape.slice(0, shape.length - dimsToSkip));\n}\nexports.getBatchDim = getBatchDim;\nfunction getRowsCols(shape) {\n    if (shape.length === 0) {\n        throw Error('Cannot get rows and columns of an empty shape array.');\n    }\n    return [\n        shape.length > 1 ? shape[shape.length - 2] : 1, shape[shape.length - 1]\n    ];\n}\nexports.getRowsCols = getRowsCols;\nfunction getTextureShapeFromLogicalShape(logShape, isPacked) {\n    if (isPacked === void 0) { isPacked = false; }\n    var _a;\n    var maxTexSize = environment_1.ENV.getNumber('WEBGL_MAX_TEXTURE_SIZE');\n    if (isPacked) {\n        maxTexSize = maxTexSize * 2;\n        // This logic ensures we accurately count the number of packed texels needed\n        // to accommodate the tensor. We can only pack values in the same texel if\n        // they are from adjacent pairs of rows/cols within the same batch. So if a\n        // tensor has 3 rows, we pretend it has 4 rows in order to account for the\n        // fact that the texels containing the third row are half empty.\n        logShape = logShape.map(function (d, i) { return i >= logShape.length - 2 ?\n            util.nearestLargerEven(logShape[i]) :\n            logShape[i]; });\n        // Packed texture height is at least 2 (the channel height of a single\n        // texel).\n        if (logShape.length === 1) {\n            logShape = [2, logShape[0]];\n        }\n    }\n    // If logical shape is 2, we don't squeeze, since we want to match physical.\n    if (logShape.length !== 2) {\n        var squeezeResult = util.squeezeShape(logShape);\n        logShape = squeezeResult.newShape;\n    }\n    var size = util.sizeFromShape(logShape);\n    if (logShape.length <= 1 && size <= maxTexSize) {\n        return [1, size];\n    }\n    else if (logShape.length === 2 && logShape[0] <= maxTexSize &&\n        logShape[1] <= maxTexSize) {\n        return logShape;\n    }\n    else if (logShape.length === 3 && logShape[0] * logShape[1] <= maxTexSize &&\n        logShape[2] <= maxTexSize) {\n        return [logShape[0] * logShape[1], logShape[2]];\n    }\n    else if (logShape.length === 3 && logShape[0] <= maxTexSize &&\n        logShape[1] * logShape[2] <= maxTexSize) {\n        return [logShape[0], logShape[1] * logShape[2]];\n    }\n    else if (logShape.length === 4 &&\n        logShape[0] * logShape[1] * logShape[2] <= maxTexSize &&\n        logShape[3] <= maxTexSize) {\n        return [logShape[0] * logShape[1] * logShape[2], logShape[3]];\n    }\n    else if (logShape.length === 4 && logShape[0] <= maxTexSize &&\n        logShape[1] * logShape[2] * logShape[3] <= maxTexSize) {\n        return [logShape[0], logShape[1] * logShape[2] * logShape[3]];\n    }\n    else {\n        if (isPacked) {\n            // For packed textures size equals the number of channels required to\n            // accommodate the texture data. However in order to squarify such that\n            // inner dimensions stay even, we rewrite size to equal the number of\n            // texels. Then in the return statement we rehydrate the squarified\n            // dimensions to channel units.\n            var batchDim = getBatchDim(logShape);\n            var rows = 2, cols = 2;\n            if (logShape.length) {\n                _a = getRowsCols(logShape), rows = _a[0], cols = _a[1];\n            }\n            size = batchDim * (rows / 2) * (cols / 2);\n            return util.sizeToSquarishShape(size).map(function (d) { return d * 2; });\n        }\n        return util.sizeToSquarishShape(size);\n    }\n}\nexports.getTextureShapeFromLogicalShape = getTextureShapeFromLogicalShape;\nfunction isEven(n) {\n    return n % 2 === 0;\n}\n/**\n * This determines whether reshaping a packed texture requires rearranging\n * the data within the texture, assuming 2x2 packing.\n */\nfunction isReshapeFree(shape1, shape2) {\n    shape1 = shape1.slice(-2);\n    shape2 = shape2.slice(-2);\n    if (util.arraysEqual(shape1, shape2)) {\n        return true;\n    }\n    if (!shape1.length || !shape2.length) { // One of the shapes is a scalar.\n        return true;\n    }\n    if (shape1[0] === 0 || shape1[1] === 0 || shape2[0] === 0 ||\n        shape2[1] === 0) {\n        return true;\n    }\n    if (shape1.length !== shape2.length) { // One of the shapes is a vector.\n        var shape1Cols = shape1.slice(-1)[0];\n        var shape2Cols = shape2.slice(-1)[0];\n        if (shape1Cols === shape2Cols) {\n            return true;\n        }\n        if (isEven(shape1Cols) && isEven(shape2Cols) &&\n            (shape1[0] === 1 || shape2[0] === 1)) {\n            return true;\n        }\n    }\n    return shape1[1] === shape2[1] && isEven(shape1[0]) && isEven(shape2[0]);\n}\nexports.isReshapeFree = isReshapeFree;\nfunction getWebGLMaxTextureSize(webGLVersion) {\n    if (exports.MAX_TEXTURE_SIZE == null) {\n        var gl = canvas_util_1.getWebGLContext(webGLVersion);\n        exports.MAX_TEXTURE_SIZE = gl.getParameter(gl.MAX_TEXTURE_SIZE);\n    }\n    return exports.MAX_TEXTURE_SIZE;\n}\nexports.getWebGLMaxTextureSize = getWebGLMaxTextureSize;\nfunction getMaxTexturesInShader(webGLVersion) {\n    if (exports.MAX_TEXTURES_IN_SHADER == null) {\n        var gl = canvas_util_1.getWebGLContext(webGLVersion);\n        exports.MAX_TEXTURES_IN_SHADER = gl.getParameter(gl.MAX_TEXTURE_IMAGE_UNITS);\n    }\n    // We cap at 16 to avoid spurious runtime \"memory exhausted\" error.\n    return Math.min(16, exports.MAX_TEXTURES_IN_SHADER);\n}\nexports.getMaxTexturesInShader = getMaxTexturesInShader;\nfunction getWebGLDisjointQueryTimerVersion(webGLVersion) {\n    if (webGLVersion === 0) {\n        return 0;\n    }\n    var queryTimerVersion;\n    var gl = canvas_util_1.getWebGLContext(webGLVersion);\n    if (hasExtension(gl, 'EXT_disjoint_timer_query_webgl2') &&\n        webGLVersion === 2) {\n        queryTimerVersion = 2;\n    }\n    else if (hasExtension(gl, 'EXT_disjoint_timer_query')) {\n        queryTimerVersion = 1;\n    }\n    else {\n        queryTimerVersion = 0;\n    }\n    return queryTimerVersion;\n}\nexports.getWebGLDisjointQueryTimerVersion = getWebGLDisjointQueryTimerVersion;\nfunction hasExtension(gl, extensionName) {\n    var ext = gl.getExtension(extensionName);\n    return ext != null;\n}\nfunction isWebGLVersionEnabled(webGLVersion) {\n    try {\n        var gl = canvas_util_1.getWebGLContext(webGLVersion);\n        if (gl != null) {\n            return true;\n        }\n    }\n    catch (e) {\n        return false;\n    }\n    return false;\n}\nexports.isWebGLVersionEnabled = isWebGLVersionEnabled;\nfunction isRenderToFloatTextureEnabled(webGLVersion) {\n    if (webGLVersion === 0) {\n        return false;\n    }\n    var gl = canvas_util_1.getWebGLContext(webGLVersion);\n    if (webGLVersion === 1) {\n        if (!hasExtension(gl, 'OES_texture_float')) {\n            return false;\n        }\n    }\n    else {\n        if (!hasExtension(gl, 'EXT_color_buffer_float')) {\n            return false;\n        }\n    }\n    var isFrameBufferComplete = createFloatTextureAndBindToFramebuffer(gl, webGLVersion);\n    return isFrameBufferComplete;\n}\nexports.isRenderToFloatTextureEnabled = isRenderToFloatTextureEnabled;\nfunction isDownloadFloatTextureEnabled(webGLVersion) {\n    if (webGLVersion === 0) {\n        return false;\n    }\n    var gl = canvas_util_1.getWebGLContext(webGLVersion);\n    if (webGLVersion === 1) {\n        if (!hasExtension(gl, 'OES_texture_float')) {\n            return false;\n        }\n        if (!hasExtension(gl, 'WEBGL_color_buffer_float')) {\n            return false;\n        }\n    }\n    else {\n        if (!hasExtension(gl, 'EXT_color_buffer_float')) {\n            return false;\n        }\n    }\n    var isFrameBufferComplete = createFloatTextureAndBindToFramebuffer(gl, webGLVersion);\n    return isFrameBufferComplete;\n}\nexports.isDownloadFloatTextureEnabled = isDownloadFloatTextureEnabled;\nfunction createFloatTextureAndBindToFramebuffer(gl, webGLVersion) {\n    var frameBuffer = gl.createFramebuffer();\n    var texture = gl.createTexture();\n    gl.bindTexture(gl.TEXTURE_2D, texture);\n    // tslint:disable-next-line:no-any\n    var internalFormat = webGLVersion === 2 ? gl.RGBA32F : gl.RGBA;\n    gl.texImage2D(gl.TEXTURE_2D, 0, internalFormat, 1, 1, 0, gl.RGBA, gl.FLOAT, null);\n    gl.bindFramebuffer(gl.FRAMEBUFFER, frameBuffer);\n    gl.framebufferTexture2D(gl.FRAMEBUFFER, gl.COLOR_ATTACHMENT0, gl.TEXTURE_2D, texture, 0);\n    var isFrameBufferComplete = gl.checkFramebufferStatus(gl.FRAMEBUFFER) === gl.FRAMEBUFFER_COMPLETE;\n    gl.bindTexture(gl.TEXTURE_2D, null);\n    gl.bindFramebuffer(gl.FRAMEBUFFER, null);\n    gl.deleteTexture(texture);\n    gl.deleteFramebuffer(frameBuffer);\n    return isFrameBufferComplete;\n}\nfunction isWebGLFenceEnabled(webGLVersion) {\n    if (webGLVersion !== 2) {\n        return false;\n    }\n    var gl = canvas_util_1.getWebGLContext(webGLVersion);\n    // tslint:disable-next-line:no-any\n    var isEnabled = gl.fenceSync != null;\n    return isEnabled;\n}\nexports.isWebGLFenceEnabled = isWebGLFenceEnabled;\n//# sourceMappingURL=webgl_util.js.map","\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar contexts = {};\nvar WEBGL_ATTRIBUTES = {\n    alpha: false,\n    antialias: false,\n    premultipliedAlpha: false,\n    preserveDrawingBuffer: false,\n    depth: false,\n    stencil: false,\n    failIfMajorPerformanceCaveat: true\n};\nfunction setWebGLContext(webGLVersion, gl) {\n    contexts[webGLVersion] = gl;\n}\nexports.setWebGLContext = setWebGLContext;\nfunction getWebGLContext(webGLVersion) {\n    if (!(webGLVersion in contexts)) {\n        contexts[webGLVersion] = getWebGLRenderingContext(webGLVersion);\n    }\n    var gl = contexts[webGLVersion];\n    if (gl.isContextLost()) {\n        delete contexts[webGLVersion];\n        return getWebGLContext(webGLVersion);\n    }\n    gl.disable(gl.DEPTH_TEST);\n    gl.disable(gl.STENCIL_TEST);\n    gl.disable(gl.BLEND);\n    gl.disable(gl.DITHER);\n    gl.disable(gl.POLYGON_OFFSET_FILL);\n    gl.disable(gl.SAMPLE_COVERAGE);\n    gl.enable(gl.SCISSOR_TEST);\n    gl.enable(gl.CULL_FACE);\n    gl.cullFace(gl.BACK);\n    return contexts[webGLVersion];\n}\nexports.getWebGLContext = getWebGLContext;\nfunction getWebGLRenderingContext(webGLVersion) {\n    if (webGLVersion !== 1 && webGLVersion !== 2) {\n        throw new Error('Cannot get WebGL rendering context, WebGL is disabled.');\n    }\n    var canvas = document.createElement('canvas');\n    canvas.addEventListener('webglcontextlost', function (ev) {\n        ev.preventDefault();\n        delete contexts[webGLVersion];\n    }, false);\n    if (webGLVersion === 1) {\n        return (canvas.getContext('webgl', WEBGL_ATTRIBUTES) ||\n            canvas.getContext('experimental-webgl', WEBGL_ATTRIBUTES));\n    }\n    return canvas.getContext('webgl2', WEBGL_ATTRIBUTES);\n}\n//# sourceMappingURL=canvas_util.js.map","\n/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar engine_1 = require(\"./engine\");\nvar environment_1 = require(\"./environment\");\nvar tensor_1 = require(\"./tensor\");\nvar tensor_util_1 = require(\"./tensor_util\");\n/**\n * Enables production mode which disables correctness checks in favor of\n * performance.\n */\n/** @doc {heading: 'Environment'} */\nfunction enableProdMode() {\n    environment_1.ENV.set('PROD', true);\n}\nexports.enableProdMode = enableProdMode;\n/**\n * Enables debug mode which will log information about all executed kernels:\n * the ellapsed time of the kernel execution, as well as the rank, shape, and\n * size of the output tensor.\n *\n * Debug mode will significantly slow down your application as it will\n * download the result of every operation to the CPU. This should not be used in\n * production. Debug mode does not affect the timing information of the kernel\n * execution as we do not measure download time in the kernel execution time.\n *\n * See also: `tf.profile`, `tf.memory`.\n */\n/** @doc {heading: 'Environment'} */\nfunction enableDebugMode() {\n    environment_1.ENV.set('DEBUG', true);\n}\nexports.enableDebugMode = enableDebugMode;\n/** Globally disables deprecation warnings */\nfunction disableDeprecationWarnings() {\n    environment_1.ENV.set('DEPRECATION_WARNINGS_ENABLED', false);\n    console.warn(\"TensorFlow.js deprecation warnings have been disabled.\");\n}\nexports.disableDeprecationWarnings = disableDeprecationWarnings;\n/** Warn users about deprecated functionality. */\nfunction deprecationWarn(msg) {\n    if (environment_1.ENV.getBool('DEPRECATION_WARNINGS_ENABLED')) {\n        console.warn(msg + ' You can disable deprecation warnings with ' +\n            'tf.disableDeprecationWarnings().');\n    }\n}\nexports.deprecationWarn = deprecationWarn;\ntensor_1.setDeprecationWarningFn(deprecationWarn);\n/**\n * Dispose all variables kept in backend engine.\n */\n/** @doc {heading: 'Environment'} */\nfunction disposeVariables() {\n    engine_1.ENGINE.disposeVariables();\n}\nexports.disposeVariables = disposeVariables;\n/**\n * Returns memory info at the current time in the program. The result is an\n * object with the following properties:\n *\n * - `numBytes`: Number of bytes allocated (undisposed) at this time.\n * - `numTensors`: Number of unique tensors allocated.\n * - `numDataBuffers`: Number of unique data buffers allocated\n *   (undisposed) at this time, which is  the number of tensors\n *   (e.g. `a.reshape(newShape)` makes a new Tensor that shares the same\n *   data buffer with `a`).\n * - `unreliable`: True if the memory usage is unreliable. See `reasons` when\n *    `unrealible` is true.\n * - `reasons`: `string[]`, reasons why the memory is unreliable, present if\n *    `unreliable` is true.\n */\n/** @doc {heading: 'Performance', subheading: 'Memory'} */\nfunction memory() {\n    return engine_1.ENGINE.memory();\n}\nexports.memory = memory;\n/**\n * Executes the provided function `f()` and returns a promise that resolves\n * with information about the function's memory use:\n * - `newBytes`: tne number of new bytes allocated\n * - `newTensors`: the number of new tensors created\n * - `peakBytes`: the peak number of bytes allocated\n * - `kernels`: an array of objects for each kernel involved that reports\n * their input and output shapes, number of bytes used, and number of new\n * tensors created.\n *\n * ```js\n * const profile = await tf.profile(() => {\n *   const x = tf.tensor1d([1, 2, 3]);\n *   let x2 = x.square();\n *   x2.dispose();\n *   x2 = x.square();\n *   x2.dispose();\n *   return x;\n * });\n *\n * console.log(`newBytes: ${profile.newBytes}`);\n * console.log(`newTensors: ${profile.newTensors}`);\n * console.log(`byte usage over all kernels: ${profile.kernels.map(k =>\n * k.totalBytesSnapshot)}`);\n * ```\n *\n */\n/** @doc {heading: 'Performance', subheading: 'Profile'} */\nfunction profile(f) {\n    return engine_1.ENGINE.profile(f);\n}\nexports.profile = profile;\n/**\n * Executes the provided function `fn` and after it is executed, cleans up all\n * intermediate tensors allocated by `fn` except those returned by `fn`.\n * `fn` must not return a Promise (async functions not allowed). The returned\n * result can be a complex object.\n *\n * Using this method helps avoid memory leaks. In general, wrap calls to\n * operations in `tf.tidy` for automatic memory cleanup.\n *\n * NOTE: Variables do *not* get cleaned up when inside a tidy(). If you want to\n * dispose variables, please use `tf.disposeVariables` or call dispose()\n * directly on variables.\n *\n * ```js\n * // y = 2 ^ 2 + 1\n * const y = tf.tidy(() => {\n *   // a, b, and one will be cleaned up when the tidy ends.\n *   const one = tf.scalar(1);\n *   const a = tf.scalar(2);\n *   const b = a.square();\n *\n *   console.log('numTensors (in tidy): ' + tf.memory().numTensors);\n *\n *   // The value returned inside the tidy function will return\n *   // through the tidy, in this case to the variable y.\n *   return b.add(one);\n * });\n *\n * console.log('numTensors (outside tidy): ' + tf.memory().numTensors);\n * y.print();\n * ```\n *\n * @param nameOrFn The name of the closure, or the function to execute.\n *     If a name is provided, the 2nd argument should be the function.\n *     If debug mode is on, the timing and the memory usage of the function\n *     will be tracked and displayed on the console using the provided name.\n * @param fn The function to execute.\n */\n/** @doc {heading: 'Performance', subheading: 'Memory'} */\nfunction tidy(nameOrFn, fn) {\n    return engine_1.ENGINE.tidy(nameOrFn, fn);\n}\nexports.tidy = tidy;\n/**\n * Disposes any `tf.Tensor`s found within the provided object.\n *\n * @param container an object that may be a `tf.Tensor` or may directly\n *     contain `tf.Tensor`s, such as a `Tensor[]` or `{key: Tensor, ...}`. If\n *     the object is not a `tf.Tensor` or does not contain `Tensors`, nothing\n *     happens. In general it is safe to pass any object here, except that\n *     `Promise`s are not supported.\n */\n/** @doc {heading: 'Performance', subheading: 'Memory'} */\nfunction dispose(container) {\n    var tensors = tensor_util_1.getTensorsInContainer(container);\n    tensors.forEach(function (tensor) { return tensor.dispose(); });\n}\nexports.dispose = dispose;\n/**\n * Keeps a `tf.Tensor` generated inside a `tf.tidy` from being disposed\n * automatically.\n *\n * ```js\n * let b;\n * const y = tf.tidy(() => {\n *   const one = tf.scalar(1);\n *   const a = tf.scalar(2);\n *\n *   // b will not be cleaned up by the tidy. a and one will be cleaned up\n *   // when the tidy ends.\n *   b = tf.keep(a.square());\n *\n *   console.log('numTensors (in tidy): ' + tf.memory().numTensors);\n *\n *   // The value returned inside the tidy function will return\n *   // through the tidy, in this case to the variable y.\n *   return b.add(one);\n * });\n *\n * console.log('numTensors (outside tidy): ' + tf.memory().numTensors);\n * console.log('y:');\n * y.print();\n * console.log('b:');\n * b.print();\n * ```\n *\n * @param result The tensor to keep from being disposed.\n */\n/** @doc {heading: 'Performance', subheading: 'Memory'} */\nfunction keep(result) {\n    return engine_1.ENGINE.keep(result);\n}\nexports.keep = keep;\n/**\n * Executes `f()` and returns a promise that resolves with timing\n * information.\n *\n * The result is an object with the following properties:\n *\n * - `wallMs`: Wall execution time.\n * - `kernelMs`: Kernel execution time, ignoring data transfer.\n * - On `WebGL` The following additional properties exist:\n *   - `uploadWaitMs`: CPU blocking time on texture uploads.\n *   - `downloadWaitMs`: CPU blocking time on texture downloads (readPixels).\n *\n * ```js\n * const x = tf.randomNormal([20, 20]);\n * const time = await tf.time(() => x.matMul(x));\n *\n * console.log(`kernelMs: ${time.kernelMs}, wallTimeMs: ${time.wallMs}`);\n * ```\n *\n * @param f The function to execute and time.\n */\n/** @doc {heading: 'Performance', subheading: 'Timing'} */\nfunction time(f) {\n    return engine_1.ENGINE.time(f);\n}\nexports.time = time;\n/**\n * Sets the backend (cpu, webgl, etc) responsible for creating tensors and\n * executing operations on those tensors. Returns a promise that resolves\n * to a boolean if the backend initialization was successful.\n *\n * Note this disposes the current backend, if any, as well as any tensors\n * associated with it. A new backend is initialized, even if it is of the\n * same type as the previous one.\n *\n * @param backendName The name of the backend. Currently supports\n *     `'webgl'|'cpu'` in the browser, and `'tensorflow'` under node.js\n *     (requires tfjs-node).\n */\n/** @doc {heading: 'Backends'} */\nfunction setBackend(backendName) {\n    return engine_1.ENGINE.setBackend(backendName);\n}\nexports.setBackend = setBackend;\n/**\n * Returns a promise that resolves when the currently selected backend (or the\n * highest priority one) has initialized. Await this promise when you are using\n * a backend that has async initialization.\n */\n/** @doc {heading: 'Backends'} */\nfunction ready() {\n    return engine_1.ENGINE.ready();\n}\nexports.ready = ready;\n/**\n * Returns the current backend name (cpu, webgl, etc). The backend is\n * responsible for creating tensors and executing operations on those tensors.\n */\n/** @doc {heading: 'Backends'} */\nfunction getBackend() {\n    return engine_1.ENGINE.backendName;\n}\nexports.getBackend = getBackend;\n/**\n * Removes a backend and the registered factory.\n */\n/** @doc {heading: 'Backends'} */\nfunction removeBackend(name) {\n    engine_1.ENGINE.removeBackend(name);\n}\nexports.removeBackend = removeBackend;\n/**\n * Finds the backend registered under the provided name. Returns null if the\n * name is not in the registry, or the registration hasn't finished yet.\n */\nfunction findBackend(name) {\n    return engine_1.ENGINE.findBackend(name);\n}\nexports.findBackend = findBackend;\n/**\n * Finds the backend factory registered under the provided name. Returns a\n * function that produces a new backend when called. Returns null if the name\n * is not in the registry.\n */\nfunction findBackendFactory(name) {\n    return engine_1.ENGINE.findBackendFactory(name);\n}\nexports.findBackendFactory = findBackendFactory;\n/**\n * Registers a global backend. The registration should happen when importing\n * a module file (e.g. when importing `backend_webgl.ts`), and is used for\n * modular builds (e.g. custom tfjs bundle with only webgl support).\n *\n * @param factory The backend factory function. When called, it should\n * return a backend instance, or a promise of an instance.\n * @param priority The priority of the backend (higher = more important).\n *     In case multiple backends are registered, the priority is used to find\n *     the best backend. Defaults to 1.\n * @return False if there is already a registered backend under this name, true\n *     if not.\n */\n/** @doc {heading: 'Backends'} */\nfunction registerBackend(name, factory, priority) {\n    if (priority === void 0) { priority = 1; }\n    return engine_1.ENGINE.registerBackend(name, factory, priority);\n}\nexports.registerBackend = registerBackend;\n/**\n * Gets the current backend. If no backends have been initialized, this will\n * attempt to initialize the best backend. Will throw an error if the highest\n * priority backend has async initialization, in which case, you should call\n * 'await tf.ready()' before running other code.\n */\n/** @doc {heading: 'Backends'} */\nfunction backend() {\n    return engine_1.ENGINE.backend;\n}\nexports.backend = backend;\n/**\n * Sets the global platform.\n *\n * @param platformName The name of this platform.\n * @param platform A platform implementation.\n */\nfunction setPlatform(platformName, platform) {\n    environment_1.ENV.setPlatform(platformName, platform);\n}\nexports.setPlatform = setPlatform;\n//# sourceMappingURL=globals.js.map","\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar environment_1 = require(\"./environment\");\nfunction warn() {\n    var msg = [];\n    for (var _i = 0; _i < arguments.length; _i++) {\n        msg[_i] = arguments[_i];\n    }\n    if (!environment_1.ENV.getBool('IS_TEST')) {\n        console.warn.apply(console, msg);\n    }\n}\nexports.warn = warn;\nfunction log() {\n    var msg = [];\n    for (var _i = 0; _i < arguments.length; _i++) {\n        msg[_i] = arguments[_i];\n    }\n    if (!environment_1.ENV.getBool('IS_TEST')) {\n        console.log.apply(console, msg);\n    }\n}\nexports.log = log;\n//# sourceMappingURL=log.js.map","\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\n/**\n * Gets the new shape of the input Tensor after it's been reshaped\n * to:\n * [blockShape[0], ..., blockShape[M-1], batch / prod(blockShape),\n * inputShape[1], ..., inputShape[N-1]]\n *\n * See step 1: https://www.tensorflow.org/api_docs/python/tf/batch_to_space_nd\n */\nfunction getReshaped(inputShape, blockShape, prod, batchToSpace) {\n    if (batchToSpace === void 0) { batchToSpace = true; }\n    var reshaped = [];\n    if (batchToSpace) {\n        reshaped = reshaped.concat(blockShape.slice(0));\n        reshaped.push(inputShape[0] / prod);\n        reshaped = reshaped.concat(inputShape.slice(1));\n    }\n    else {\n        reshaped = reshaped.concat(inputShape[0]);\n        var spatialLength = blockShape.length;\n        for (var i = 0; i < spatialLength; ++i) {\n            reshaped =\n                reshaped.concat([inputShape[i + 1] / blockShape[i], blockShape[i]]);\n        }\n        reshaped = reshaped.concat(inputShape.slice(spatialLength + 1));\n    }\n    return reshaped;\n}\nexports.getReshaped = getReshaped;\n/**\n * Gets the permutation that will transpose the dimensions of the\n * reshaped tensor to shape:\n *\n * [batch / prod(block_shape),inputShape[1], blockShape[0], ...,\n * inputShape[M], blockShape[M-1],inputShape[M+1], ..., inputShape[N-1]]\n *\n * see step 2: https://www.tensorflow.org/api_docs/python/tf/batch_to_space_nd\n */\nfunction getPermuted(reshapedRank, blockShapeRank, batchToSpace) {\n    if (batchToSpace === void 0) { batchToSpace = true; }\n    var permuted = [];\n    if (batchToSpace) {\n        permuted.push(blockShapeRank);\n        for (var i = blockShapeRank + 1; i < reshapedRank; ++i) {\n            if (i <= 2 * blockShapeRank) {\n                permuted.push(i);\n                permuted.push(i - (blockShapeRank + 1));\n            }\n            else {\n                permuted.push(i);\n            }\n        }\n    }\n    else {\n        var permutedBeforeBatch = [];\n        var permutedAfterBatch = [];\n        for (var i = 1; i < reshapedRank; ++i) {\n            if (i >= blockShapeRank * 2 + 1 || i % 2 === 1) {\n                permutedAfterBatch.push(i);\n            }\n            else {\n                permutedBeforeBatch.push(i);\n            }\n        }\n        permuted.push.apply(permuted, permutedBeforeBatch);\n        permuted.push(0);\n        permuted.push.apply(permuted, permutedAfterBatch);\n    }\n    return permuted;\n}\nexports.getPermuted = getPermuted;\n/**\n * Gets the shape of the reshaped and permuted input Tensor before any cropping\n * is applied.  The new shape will be:\n *\n * [batch / prod(blockShape),inputShape[1] * blockShape[0], ...,\n * inputShape[M] * blockShape[M-1],inputShape[M+1], ..., inputShape[N-1]]\n *\n * See step 3: https://www.tensorflow.org/api_docs/python/tf/batch_to_space_nd\n */\nfunction getReshapedPermuted(inputShape, blockShape, prod, batchToSpace) {\n    if (batchToSpace === void 0) { batchToSpace = true; }\n    var reshapedPermuted = [];\n    if (batchToSpace) {\n        reshapedPermuted.push(inputShape[0] / prod);\n    }\n    else {\n        reshapedPermuted.push(inputShape[0] * prod);\n    }\n    for (var i = 1; i < inputShape.length; ++i) {\n        if (i <= blockShape.length) {\n            if (batchToSpace) {\n                reshapedPermuted.push(blockShape[i - 1] * inputShape[i]);\n            }\n            else {\n                reshapedPermuted.push(inputShape[i] / blockShape[i - 1]);\n            }\n        }\n        else {\n            reshapedPermuted.push(inputShape[i]);\n        }\n    }\n    return reshapedPermuted;\n}\nexports.getReshapedPermuted = getReshapedPermuted;\n/**\n * Converts the crops argument into the beginning coordinates of a slice\n * operation.\n */\nfunction getSliceBeginCoords(crops, blockShape) {\n    var sliceBeginCoords = [0];\n    for (var i = 0; i < blockShape; ++i) {\n        sliceBeginCoords.push(crops[i][0]);\n    }\n    return sliceBeginCoords;\n}\nexports.getSliceBeginCoords = getSliceBeginCoords;\n/**\n * Converts the crops argument into the size of a slice operation.  When\n * combined with getSliceBeginCoords this function allows the reshaped and\n * permuted Tensor to be cropped to its final output shape of:\n *\n * inputShape[1] * blockShape[0] - crops[0,0] - crops[0,1], ...,\n * inputShape[M] * blockShape[M-1] -crops[M-1,0] -\n * crops[M-1,1],inputShape[M+1], ..., inputShape[N-1]]\n *\n * See step 4: https://www.tensorflow.org/api_docs/python/tf/batch_to_space_nd\n */\nfunction getSliceSize(uncroppedShape, crops, blockShape) {\n    var sliceSize = uncroppedShape.slice(0, 1);\n    for (var i = 0; i < blockShape; ++i) {\n        sliceSize.push(uncroppedShape[i + 1] - crops[i][0] - crops[i][1]);\n    }\n    return sliceSize;\n}\nexports.getSliceSize = getSliceSize;\n//# sourceMappingURL=array_ops_util.js.map","\n/**\n * @license\n * Copyright 2017 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar util = require(\"../util\");\n/**\n * Returns true if the axis specifies the inner most dimensions of the\n * array.\n */\nfunction axesAreInnerMostDims(axes, rank) {\n    for (var i = 0; i < axes.length; ++i) {\n        if (axes[axes.length - i - 1] !== rank - 1 - i) {\n            return false;\n        }\n    }\n    return true;\n}\nexports.axesAreInnerMostDims = axesAreInnerMostDims;\nfunction combineLocations(outputLoc, reduceLoc, axes) {\n    var rank = outputLoc.length + reduceLoc.length;\n    var loc = [];\n    var outIdx = 0;\n    var reduceIdx = 0;\n    for (var dim = 0; dim < rank; dim++) {\n        if (axes.indexOf(dim) === -1) {\n            loc.push(outputLoc[outIdx++]);\n        }\n        else {\n            loc.push(reduceLoc[reduceIdx++]);\n        }\n    }\n    return loc;\n}\nexports.combineLocations = combineLocations;\nfunction computeOutAndReduceShapes(aShape, axes) {\n    var outShape = [];\n    var rank = aShape.length;\n    for (var dim = 0; dim < rank; dim++) {\n        if (axes.indexOf(dim) === -1) {\n            outShape.push(aShape[dim]);\n        }\n    }\n    var reduceShape = axes.map(function (dim) { return aShape[dim]; });\n    return [outShape, reduceShape];\n}\nexports.computeOutAndReduceShapes = computeOutAndReduceShapes;\nfunction expandShapeToKeepDim(shape, axes) {\n    var reduceSubShape = axes.map(function (x) { return 1; });\n    return combineLocations(shape, reduceSubShape, axes);\n}\nexports.expandShapeToKeepDim = expandShapeToKeepDim;\nfunction assertAxesAreInnerMostDims(msg, axes, rank) {\n    util.assert(axesAreInnerMostDims(axes, rank), function () { return msg + \" supports only inner-most axes for now. \" +\n        (\"Got axes \" + axes + \" and rank-\" + rank + \" input.\"); });\n}\nexports.assertAxesAreInnerMostDims = assertAxesAreInnerMostDims;\n/**\n * Returns the axes permutation to be used with `tf.transpose`, if such\n * permutation is necessary. Otherwise it returns null. This method is used by\n * operations that operate only on inner-most axes.\n */\nfunction getAxesPermutation(axes, rank) {\n    if (axesAreInnerMostDims(axes, rank)) {\n        return null;\n    }\n    var result = [];\n    for (var i = 0; i < rank; ++i) {\n        if (axes.indexOf(i) === -1) {\n            result.push(i);\n        }\n    }\n    axes.forEach(function (axis) { return result.push(axis); });\n    return result;\n}\nexports.getAxesPermutation = getAxesPermutation;\n/** Returns the axes permutation that undoes the original permutation. */\nfunction getUndoAxesPermutation(axes) {\n    return axes.map(function (axis, i) { return [i, axis]; })\n        .sort(function (a, b) { return a[1] - b[1]; })\n        .map(function (x) { return x[0]; });\n}\nexports.getUndoAxesPermutation = getUndoAxesPermutation;\nfunction getInnerMostAxes(numAxes, rank) {\n    var res = [];\n    for (var i = rank - numAxes; i < rank; ++i) {\n        res.push(i);\n    }\n    return res;\n}\nexports.getInnerMostAxes = getInnerMostAxes;\n//# sourceMappingURL=axis_util.js.map","\n/**\n * @license\n * Copyright 2017 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar util = require(\"../util\");\nfunction assertParamsConsistent(shapes, axis) {\n    var rank = shapes[0].length;\n    shapes.forEach(function (shape, i) {\n        util.assert(shape.length === rank, function () {\n            return \"Error in concat\" + rank + \"D: rank of tensors[\" + i + \"] must be the same \" +\n                (\"as the rank of the rest (\" + rank + \")\");\n        });\n    });\n    util.assert(axis >= 0 && axis < rank, function () { return \"Error in concat\" + rank + \"D: axis must be between 0 and \" + (rank - 1) + \".\"; });\n    var firstShape = shapes[0];\n    shapes.forEach(function (shape, i) {\n        for (var r = 0; r < rank; r++) {\n            util.assert((r === axis) || (shape[r] === firstShape[r]), function () { return \"Error in concat\" + rank + \"D: Shape of tensors[\" + i + \"] (\" + shape + \") \" +\n                (\"does not match the shape of the rest (\" + firstShape + \") \") +\n                (\"along the non-concatenated axis \" + i + \".\"); });\n        }\n    });\n}\nexports.assertParamsConsistent = assertParamsConsistent;\nfunction computeOutShape(shapes, axis) {\n    var outputShape = shapes[0].slice();\n    for (var i = 1; i < shapes.length; i++) {\n        outputShape[axis] += shapes[i][axis];\n    }\n    return outputShape;\n}\nexports.computeOutShape = computeOutShape;\n//# sourceMappingURL=concat_util.js.map","\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar util_1 = require(\"../util\");\n/**\n * Validate gather nd inputs.\n *\n * @param tensor The tensor contains the source values.\n * @param indices The tensor contains the indices to slice the source.\n *\n * @returns [resultShape, numUpdates, sliceSize, strides]\n */\nfunction prepareAndValidate(tensor, indices) {\n    if (tensor.rank < 1) {\n        throw new Error('tf.gatherND() expects the input to be rank 1 or higher,' +\n            (\" but the rank was \" + tensor.rank + \".\"));\n    }\n    if (indices.rank < 1) {\n        throw new Error('tf.gatherND() expects the indices to be rank 1 or higher,' +\n            (\" but the rank was \" + indices.rank + \".\"));\n    }\n    if (indices.dtype !== 'int32') {\n        throw new Error('tf.gatherND() expects the indices to be int32 type,' +\n            (\" but the dtype was \" + indices.dtype + \".\"));\n    }\n    if (indices.shape[indices.rank - 1] > tensor.rank) {\n        throw new Error('index innermost dimension length must be <= tensor rank; saw: ' +\n            (indices.shape[indices.rank - 1] + \" vs. \" + tensor.rank));\n    }\n    if (tensor.size === 0) {\n        throw new Error('Requested more than 0 entries, but input is empty.' +\n            (\" Input shape: \" + tensor.shape + \".\"));\n    }\n    var indicesShape = indices.shape;\n    var sliceRank = indicesShape[indicesShape.length - 1];\n    // The result shape is\n    //   indices.shape[:-1] + params.shape[indices.shape[-1]:]\n    var nResult = 1;\n    for (var i = 0; i < indicesShape.length - 1; ++i) {\n        nResult *= indicesShape[i];\n    }\n    var inputShape = tensor.shape;\n    var resultShape = indicesShape.slice();\n    resultShape.pop();\n    var sliceSize = 1;\n    for (var i = sliceRank; i < tensor.rank; ++i) {\n        sliceSize *= inputShape[i];\n        resultShape.push(inputShape[i]);\n    }\n    var strides = util_1.computeStrides(tensor.shape).map(function (stride) { return stride / sliceSize; }).concat([1]).slice(0, sliceRank);\n    return [resultShape, nResult, sliceSize, strides];\n}\nexports.prepareAndValidate = prepareAndValidate;\n//# sourceMappingURL=gather_nd_util.js.map","\n/**\n * @license\n * Copyright 2017 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\n/**\n * Inputs of size above this threshold will be parallelized by calling multiple\n * shader programs.\n */\nvar util_1 = require(\"../util\");\nexports.PARALLELIZE_THRESHOLD = 30;\nfunction computeOptimalWindowSize(inSize) {\n    if (inSize <= exports.PARALLELIZE_THRESHOLD) {\n        return inSize;\n    }\n    return util_1.nearestDivisor(inSize, Math.floor(Math.sqrt(inSize)));\n}\nexports.computeOptimalWindowSize = computeOptimalWindowSize;\n//# sourceMappingURL=reduce_util.js.map","\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar util_1 = require(\"../util\");\n/**\n * Check whether updates.shape = indices.shape[:batchDim] +\n * shape[sliceDim:]\n *\n * @param x The input tensor.\n */\nfunction validateUpdateShape(shape, indices, updates) {\n    var sliceDim = (indices.rank > 1) ? indices.shape[indices.rank - 1] : 1;\n    var batchDim = (indices.rank > 1) ? indices.rank - 1 : 1;\n    var shapeError = 'Must have updates.shape = indices.shape[:batchDim] + ' +\n        (\"shape[sliceDim:], got updates.shape: \" + updates.shape) +\n        (\", indices.shape: \" + indices.shape + \", shape: \" + shape) +\n        (\", sliceDim: \" + sliceDim + \", and batchDim: \" + batchDim + \".\");\n    if (updates.rank < batchDim) {\n        throw new Error(shapeError + (\" update.rank < \" + batchDim + \". \"));\n    }\n    if (shape.length < sliceDim + (updates.rank - batchDim)) {\n        throw new Error(shapeError +\n            (\" Output shape length < \" + (sliceDim + (updates.rank - batchDim))));\n    }\n    if (updates.rank !== batchDim + shape.length - sliceDim) {\n        throw new Error(shapeError + (\" update.rank != \" + (batchDim + shape.length - sliceDim)));\n    }\n    for (var d = 0; d < batchDim; ++d) {\n        if (updates.shape[d] !== indices.shape[d]) {\n            throw new Error(shapeError +\n                (\" updates.shape[\" + d + \"] (\" + updates.shape[d] + \") != indices.shape[\" + d + \"] (\" + indices.shape[d] + \").\"));\n        }\n    }\n    for (var d = 0; d < updates.rank - batchDim; ++d) {\n        if (updates.shape[d + batchDim] !== shape[d + sliceDim]) {\n            throw new Error(shapeError +\n                (\" updates.shape[\" + (d + batchDim) + \"] (\" + updates.shape[d + batchDim] + \") != shape[\" + (d + batchDim) + \"] (\" + shape[d + batchDim] + \")\"));\n        }\n    }\n}\nexports.validateUpdateShape = validateUpdateShape;\n/**\n * Validate scatter nd inputs.\n *\n * @param update The tensor contains the update values.\n * @param indices The tensor contains the indices for the update values.\n * @param shape The shape of the output tensor.\n */\nfunction validateInput(updates, indices, shape) {\n    if (indices.rank < 1) {\n        throw new Error('tf.scatterND() expects the indices to be rank 1 or higher,' +\n            (\" but the rank was \" + indices.rank + \".\"));\n    }\n    if (updates.rank < 1) {\n        throw new Error('tf.scatterND() expects the updates to be rank 1 or higher,' +\n            (\" but the rank was \" + updates.rank + \".\"));\n    }\n    if (indices.dtype !== 'int32') {\n        throw new Error(\"The dtype of 'indices' should be int32, but got dtype: \" + indices.dtype);\n    }\n    if (shape.length < 1) {\n        throw new Error(\"Output rank must be greater or equal to 1, but got shape: \" + shape);\n    }\n    if (shape.length === 0) {\n        if (indices.size === 0) {\n            throw new Error(\"Indices specified for empty output. indices shape: \" + indices.shape);\n        }\n        if (updates.size === 0) {\n            throw new Error(\"Updates specified for empty output. updates shape: \" + updates.shape);\n        }\n    }\n    validateUpdateShape(shape, indices, updates);\n}\nexports.validateInput = validateInput;\n/**\n * Calculate the shape information for the output.\n *\n * @param update The tensor contains the update values.\n * @param indices The tensor contains the indices for the update values.\n * @param shape The shape of the output tensor.\n *\n * @returns ScatterShapeInfo\n */\nfunction calculateShapes(updates, indices, shape) {\n    // Calculate the number of dimensions in indices\n    var sliceRank = (indices.rank > 1) ? indices.shape[indices.rank - 1] : 1;\n    // Calculate the number of elements that make up each slice of our updated\n    // tensor. This allows us to work with flattened tensors and copy over whole\n    // slices at a time.\n    var totalNd = shape.length;\n    var sliceSize = 1;\n    for (var i = sliceRank; i < totalNd; ++i) {\n        sliceSize *= shape[i];\n    }\n    var safeSliceDim = (sliceRank < 1) ? 1 : sliceRank;\n    var numUpdates = indices.size / safeSliceDim;\n    var strides = util_1.computeStrides(shape.slice(0, sliceRank)).concat([1]);\n    var outputSize = util_1.sizeFromShape(shape);\n    return { sliceRank: sliceRank, numUpdates: numUpdates, sliceSize: sliceSize, strides: strides, outputSize: outputSize };\n}\nexports.calculateShapes = calculateShapes;\n//# sourceMappingURL=scatter_nd_util.js.map","\n/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar util_1 = require(\"../util\");\nvar reduce_util_1 = require(\"./reduce_util\");\nfunction segOpComputeOptimalWindowSize(inSize, numSegments) {\n    var done = false;\n    var res;\n    if (inSize <= reduce_util_1.PARALLELIZE_THRESHOLD) {\n        res = inSize;\n        done = true;\n    }\n    else {\n        res = util_1.nearestDivisor(inSize, Math.floor(Math.sqrt(inSize)));\n    }\n    while (!done) {\n        if (res > numSegments || res === inSize) {\n            done = true;\n        }\n        else {\n            res = util_1.nearestDivisor(inSize, res + 1);\n        }\n    }\n    return res;\n}\nexports.segOpComputeOptimalWindowSize = segOpComputeOptimalWindowSize;\nfunction computeOutShape(aShape, axis, numSegments) {\n    var outShape = [];\n    var rank = aShape.length;\n    for (var dim = 0; dim < rank; dim++) {\n        if (dim !== axis) {\n            outShape.push(aShape[dim]);\n        }\n        else {\n            outShape.push(numSegments);\n        }\n    }\n    return outShape;\n}\nexports.computeOutShape = computeOutShape;\nfunction collectGatherOpShapeInfo(x, indices, axis) {\n    var dimSize = x.shape[axis];\n    var outputShape = [];\n    var batchSize = 1;\n    var sliceSize = 1;\n    for (var i = 0; i < axis; i++) {\n        outputShape.push(x.shape[i]);\n        batchSize *= x.shape[i];\n    }\n    for (var i = 0; i < indices.rank; i++) {\n        outputShape.push(indices.shape[i]);\n    }\n    for (var i = axis + 1; i < x.rank; i++) {\n        outputShape.push(x.shape[i]);\n        sliceSize *= x.shape[i];\n    }\n    return { batchSize: batchSize, sliceSize: sliceSize, dimSize: dimSize, outputShape: outputShape };\n}\nexports.collectGatherOpShapeInfo = collectGatherOpShapeInfo;\n//# sourceMappingURL=segment_util.js.map","\n/**\n * @license\n * Copyright 2017 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar util = require(\"../util\");\nfunction assertParamsValid(input, begin, size) {\n    util.assert(input.rank === begin.length, function () { return \"Error in slice\" + input.rank + \"D: Length of begin \" + begin + \" must \" +\n        (\"match the rank of the array (\" + input.rank + \").\"); });\n    util.assert(input.rank === size.length, function () { return \"Error in slice\" + input.rank + \"D: Length of size \" + size + \" must \" +\n        (\"match the rank of the array (\" + input.rank + \").\"); });\n    var _loop_1 = function (i) {\n        util.assert(begin[i] + size[i] <= input.shape[i], function () { return \"Error in slice\" + input.rank + \"D: begin[\" + i + \"] + size[\" + i + \"] \" +\n            (\"(\" + (begin[i] + size[i]) + \") would overflow input.shape[\" + i + \"] (\" + input.shape[i] + \")\"); });\n    };\n    for (var i = 0; i < input.rank; ++i) {\n        _loop_1(i);\n    }\n}\nexports.assertParamsValid = assertParamsValid;\n/**\n * Calculate the start index and output tensor shape for strided slice op.\n * @returns array of [startIndex, size, shrinkAxis]\n */\nfunction getStridedSlicedInfo(shape, begin, end, strides, beginMask, endMask, ellipsisMask, newAxisMask, shrinkAxisMask) {\n    if (beginMask === void 0) { beginMask = 0; }\n    if (endMask === void 0) { endMask = 0; }\n    if (ellipsisMask === void 0) { ellipsisMask = 0; }\n    if (newAxisMask === void 0) { newAxisMask = 0; }\n    if (shrinkAxisMask === void 0) { shrinkAxisMask = 0; }\n    if (ellipsisMask !== 0) {\n        throw new Error('ellipsis mask is not yet supported');\n    }\n    if (newAxisMask !== 0) {\n        throw new Error('new axis mask is not yet supported');\n    }\n    // Note that the axis orders are reversed for runtime ops, so the indices,\n    // strides and masks must be as well too.\n    var startIndex = [];\n    var endIndex = [];\n    var shrinkAxis = [];\n    for (var i = 0; i < shape.length; i++) {\n        startIndex[i] = startForAxis(beginMask, begin, strides, shape, i);\n        endIndex[i] = stopForAxis(endMask, end, strides, shape, i);\n        // When shrinking an axis, use startIndex + 1 for endIndex.\n        // Check the axis bit from right of shrinkAxisMask\n        if (shrinkAxisMask & 1 << i) {\n            endIndex[i] = startIndex[i] + 1;\n            shrinkAxis.push(i);\n        }\n    }\n    var size = new Array(shape.length).fill(0);\n    size = size.map(function (d, i) {\n        var count = 0;\n        var stride = strides[i] || 1;\n        for (var start = startIndex[i]; !(stride > 0 ? start >= endIndex[i] : start <= endIndex[i]); start += stride) {\n            count += 1;\n        }\n        return count;\n    });\n    return [startIndex, size, shrinkAxis];\n}\nexports.getStridedSlicedInfo = getStridedSlicedInfo;\nfunction startForAxis(beginMask, startIndices, strides, inputShape, axis) {\n    // Begin with the specified index\n    var start = startIndices[axis];\n    var stride = strides[axis] || 1;\n    // Check the axis bit from right of beginMask or the begin index is not set\n    // for the axis.\n    if (beginMask & 1 << axis || start == null) {\n        if (stride > 0) {\n            // Forward iteration - use the first element. These values will get\n            // clamped below (Note: We could have set them to 0 and axis_size-1, but\n            // use lowest() and max() to maintain symmetry with StopForAxis())\n            start = Number.MIN_SAFE_INTEGER;\n        }\n        else {\n            // Backward iteration - use the last element.\n            start = Number.MAX_SAFE_INTEGER;\n        }\n    }\n    // Handle negative indices\n    var axisSize = inputShape[axis];\n    if (start < 0) {\n        start += axisSize;\n    }\n    // Clamping\n    start = util.clamp(0, start, axisSize - 1);\n    return start;\n}\nexports.startForAxis = startForAxis;\nfunction stopForAxis(endMask, stopIndices, strides, inputShape, axis) {\n    // Begin with the specified index\n    var stop = stopIndices[axis];\n    var stride = strides[axis] || 1;\n    // Check the axis bit from right of endMask or if the stop index is not set\n    // for this axis.\n    if (endMask & (1 << axis) || stop == null) {\n        if (stride > 0) {\n            // Forward iteration - use the last element. These values will get\n            // clamped below\n            stop = Number.MAX_SAFE_INTEGER;\n        }\n        else {\n            // Backward iteration - use the first element.\n            stop = Number.MIN_SAFE_INTEGER;\n        }\n    }\n    // Handle negative indices\n    var axisSize = inputShape[axis];\n    if (stop < 0) {\n        stop += axisSize;\n    }\n    // Clamping\n    // Because the end index points one past the last element, we need slightly\n    // different clamping ranges depending on the direction.\n    if (stride > 0) {\n        // Forward iteration\n        stop = util.clamp(0, stop, axisSize);\n    }\n    else {\n        // Backward iteration\n        stop = util.clamp(-1, stop, axisSize - 1);\n    }\n    return stop;\n}\nexports.stopForAxis = stopForAxis;\n/**\n * Returns true if the slice occupies a continous set of elements in the\n * 'flat' space.\n */\nfunction isSliceContinous(shape, begin, size) {\n    // Index of the first axis that has size > 1.\n    var firstNonOneAxis = size.length;\n    for (var i = 0; i < size.length; i++) {\n        if (size[i] > 1) {\n            firstNonOneAxis = i;\n            break;\n        }\n    }\n    for (var i = firstNonOneAxis + 1; i < size.length; i++) {\n        if (begin[i] > 0 || size[i] !== shape[i]) {\n            return false;\n        }\n    }\n    return true;\n}\nexports.isSliceContinous = isSliceContinous;\nfunction computeFlatOffset(begin, strides) {\n    var flatOffset = begin.length > 0 ? begin[begin.length - 1] : 1;\n    for (var i = 0; i < begin.length - 1; i++) {\n        flatOffset += begin[i] * strides[i];\n    }\n    return flatOffset;\n}\nexports.computeFlatOffset = computeFlatOffset;\n//# sourceMappingURL=slice_util.js.map","\n/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar gradients_1 = require(\"../gradients\");\nvar tensor_util_env_1 = require(\"../tensor_util_env\");\nvar operation_1 = require(\"./operation\");\n/**\n * Computes the softmax normalized vector given the logits.\n *\n * ```js\n * const a = tf.tensor1d([1, 2, 3]);\n *\n * a.softmax().print();  // or tf.softmax(a)\n * ```\n *\n * ```js\n * const a = tf.tensor2d([2, 4, 6, 1, 2, 3], [2, 3]);\n *\n * a.softmax().print();  // or tf.softmax(a)\n * ```\n *\n * @param logits The logits array.\n * @param dim The dimension softmax would be performed on. Defaults to `-1`\n *     which indicates the last dimension.\n */\n/** @doc {heading: 'Operations', subheading: 'Normalization'} */\nfunction softmax_(logits, dim) {\n    if (dim === void 0) { dim = -1; }\n    var $logits = tensor_util_env_1.convertToTensor(logits, 'logits', 'softmax');\n    if (dim === -1) {\n        dim = $logits.rank - 1;\n    }\n    if (dim !== $logits.rank - 1) {\n        throw Error('Softmax along a non-last dimension is not yet supported. ' +\n            (\"Logits was rank \" + $logits.rank + \" and dim was \" + dim));\n    }\n    var customOp = gradients_1.customGrad(function (logits, save) {\n        // Do it in log space for numerical stability.\n        // exp(X - logSumExp(X))\n        var keepDims = true;\n        var lse = logits.logSumExp([dim], keepDims);\n        var logResult = logits.toFloat().sub(lse);\n        var y = logResult.exp();\n        save([y]);\n        var gradFunc = function (dy, saved) {\n            var y = saved[0];\n            var dyTimesY = dy.mul(y);\n            var keepDims = true;\n            return dyTimesY.sub(dyTimesY.sum([dim], keepDims).mul(y));\n        };\n        return { value: y, gradFunc: gradFunc };\n    });\n    return customOp($logits);\n}\n/**\n * Computes the log softmax.\n *\n * ```js\n * const a = tf.tensor1d([1, 2, 3]);\n *\n * a.logSoftmax().print();  // or tf.logSoftmax(a)\n * ```\n *\n * ```js\n * const a = tf.tensor2d([2, 4, 6, 1, 2, 3], [2, 3]);\n *\n * a.logSoftmax().print();  // or tf.logSoftmax(a)\n * ```\n *\n * @param logits The logits array.\n * @param axis The dimension softmax would be performed on. Defaults to `-1`\n *     which indicates the last dimension.\n */\n/** @doc {heading: 'Operations', subheading: 'Normalization'} */\nfunction logSoftmax_(logits, axis) {\n    if (axis === void 0) { axis = -1; }\n    var $logits = tensor_util_env_1.convertToTensor(logits, 'logits', 'logSoftmax');\n    if (axis === -1) {\n        axis = $logits.rank - 1;\n    }\n    if (axis !== $logits.rank - 1) {\n        throw Error('Log Softmax along a non-last dimension is not yet supported. ' +\n            (\"Logits was rank \" + $logits.rank + \" and axis was \" + axis));\n    }\n    var customOp = gradients_1.customGrad(function (logits, save) {\n        var keepDims = true;\n        var xMax = logits.max(axis, true);\n        var shifted = logits.sub(xMax);\n        var value = shifted.toFloat().sub(shifted.exp().sum(axis, keepDims).log());\n        save([value]);\n        var gradFunc = function (dy, saved) {\n            var value = saved[0];\n            var softmax = value.exp();\n            return dy.sub(dy.sum(axis, keepDims).mul(softmax));\n        };\n        return { value: value, gradFunc: gradFunc };\n    });\n    return customOp($logits);\n}\nexports.softmax = operation_1.op({ softmax_: softmax_ });\nexports.logSoftmax = operation_1.op({ logSoftmax_: logSoftmax_ });\n//# sourceMappingURL=softmax.js.map","\n/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar engine_1 = require(\"./engine\");\nvar tensor_1 = require(\"./tensor\");\nvar tensor_util_env_1 = require(\"./tensor_util_env\");\nvar util = require(\"./util\");\n/**\n * Provided `f(x)`, returns another function `g(x, dy?)`, which gives the\n * gradient of `f(x)` with respect to `x`.\n *\n * If `dy` is provided, the gradient of `f(x).mul(dy).sum()` with respect to\n * `x` is computed instead. `f(x)` must take a single tensor `x` and return a\n * single tensor `y`. If `f()` takes multiple inputs, use `tf.grads` instead.\n *\n * ```js\n * // f(x) = x ^ 2\n * const f = x => x.square();\n * // f'(x) = 2x\n * const g = tf.grad(f);\n *\n * const x = tf.tensor1d([2, 3]);\n * g(x).print();\n * ```\n *\n * ```js\n * // f(x) = x ^ 3\n * const f = x => x.pow(tf.scalar(3, 'int32'));\n * // f'(x) = 3x ^ 2\n * const g = tf.grad(f);\n * // f''(x) = 6x\n * const gg = tf.grad(g);\n *\n * const x = tf.tensor1d([2, 3]);\n * gg(x).print();\n * ```\n *\n * @param f The function f(x), to compute gradient for.\n */\n/** @doc {heading: 'Training', subheading: 'Gradients'} */\nfunction grad(f) {\n    util.assert(util.isFunction(f), function () { return 'The f passed in grad(f) must be a function'; });\n    return function (x, dy) {\n        // x can be of any dtype, thus null as the last argument.\n        var $x = tensor_util_env_1.convertToTensor(x, 'x', 'tf.grad', null);\n        var $dy = (dy != null) ? tensor_util_env_1.convertToTensor(dy, 'dy', 'tf.grad') : null;\n        return engine_1.ENGINE.tidy(function () {\n            var _a = engine_1.ENGINE.gradients(function () { return f($x); }, [$x], $dy), value = _a.value, grads = _a.grads;\n            if ($dy != null) {\n                util.assertShapesMatch(value.shape, $dy.shape, 'The shape of dy passed in grad(f)(x, dy) must match the shape ' +\n                    'returned by f(x)');\n            }\n            checkGrads(grads);\n            return grads[0];\n        });\n    };\n}\nexports.grad = grad;\n/**\n * Provided `f(x1, x2,...)`, returns another function `g([x1, x2,...], dy?)`,\n * which gives an array of gradients of `f()` with respect to each input\n * [`x1`,`x2`,...].\n *\n * If `dy` is passed when calling `g()`, the gradient of\n * `f(x1,...).mul(dy).sum()` with respect to each input is computed instead.\n * The provided `f` must take one or more tensors and return a single tensor\n * `y`. If `f()` takes a single input, we recommend using `tf.grad` instead.\n *\n * ```js\n * // f(a, b) = a * b\n * const f = (a, b) => a.mul(b);\n * // df / da = b, df / db = a\n * const g = tf.grads(f);\n *\n * const a = tf.tensor1d([2, 3]);\n * const b = tf.tensor1d([-2, -3]);\n * const [da, db] = g([a, b]);\n * console.log('da');\n * da.print();\n * console.log('db');\n * db.print();\n * ```\n *\n * @param f The function `f(x1, x2,...)` to compute gradients for.\n */\n/** @doc {heading: 'Training', subheading: 'Gradients'} */\nfunction grads(f) {\n    util.assert(util.isFunction(f), function () { return 'The f passed in grads(f) must be a function'; });\n    return function (args, dy) {\n        util.assert(Array.isArray(args), function () { return 'The args passed in grads(f)(args) must be an array ' +\n            'of `Tensor`s or `TensorLike`s'; });\n        // args can be of any dtype, thus null as the last argument.\n        var $args = tensor_util_env_1.convertToTensorArray(args, 'args', 'tf.grads', null);\n        var $dy = (dy != null) ? tensor_util_env_1.convertToTensor(dy, 'dy', 'tf.grads') : null;\n        return engine_1.ENGINE.tidy(function () {\n            var _a = engine_1.ENGINE.gradients(function () { return f.apply(void 0, $args); }, $args, $dy), value = _a.value, grads = _a.grads;\n            if ($dy != null) {\n                util.assertShapesMatch(value.shape, $dy.shape, 'The shape of dy passed in grads(f)([x1,...], dy) must ' +\n                    'match the shape returned by f([x1,...])');\n            }\n            checkGrads(grads);\n            return grads;\n        });\n    };\n}\nexports.grads = grads;\n/**\n * Like `tf.grad`, but also returns the value of `f()`. Useful when `f()`\n * returns a metric you want to show.\n *\n * The result is a rich object with the following properties:\n * - grad: The gradient of `f(x)` w.r.t `x` (result of `tf.grad`).\n * - value: The value returned by `f(x)`.\n *\n * ```js\n * // f(x) = x ^ 2\n * const f = x => x.square();\n * // f'(x) = 2x\n * const g = tf.valueAndGrad(f);\n *\n * const x = tf.tensor1d([2, 3]);\n * const {value, grad} = g(x);\n *\n * console.log('value');\n * value.print();\n * console.log('grad');\n * grad.print();\n * ```\n */\n/** @doc {heading: 'Training', subheading: 'Gradients'} */\nfunction valueAndGrad(f) {\n    util.assert(util.isFunction(f), function () { return 'The f passed in valueAndGrad(f) must be a function'; });\n    return function (x, dy) {\n        util.assert(x instanceof tensor_1.Tensor, function () { return 'The x passed in valueAndGrad(f)(x) must be a tensor'; });\n        util.assert(dy == null || dy instanceof tensor_1.Tensor, function () { return 'The dy passed in valueAndGrad(f)(x, dy) must be a tensor'; });\n        var _a = engine_1.ENGINE.gradients(function () { return f(x); }, [x], dy), grads = _a.grads, value = _a.value;\n        checkGrads(grads);\n        return { grad: grads[0], value: value };\n    };\n}\nexports.valueAndGrad = valueAndGrad;\n/**\n * Like `tf.grads`, but returns also the value of `f()`. Useful when `f()`\n * returns a metric you want to show.\n *\n * The result is a rich object with the following properties:\n * - grads: The gradients of `f()` w.r.t each input (result of `tf.grads`).\n * - value: The value returned by `f(x)`.\n *\n * ```js\n * // f(a, b) = a * b\n * const f = (a, b) => a.mul(b);\n * // df/da = b, df/db = a\n * const g = tf.valueAndGrads(f);\n *\n * const a = tf.tensor1d([2, 3]);\n * const b = tf.tensor1d([-2, -3]);\n * const {value, grads} = g([a, b]);\n *\n * const [da, db] = grads;\n *\n * console.log('value');\n * value.print();\n *\n * console.log('da');\n * da.print();\n * console.log('db');\n * db.print();\n * ```\n */\n/** @doc {heading: 'Training', subheading: 'Gradients'} */\nfunction valueAndGrads(f) {\n    util.assert(util.isFunction(f), function () { return 'The f passed in valueAndGrads(f) must be a function'; });\n    return function (args, dy) {\n        util.assert(Array.isArray(args) && args.every(function (arg) { return arg instanceof tensor_1.Tensor; }), function () { return 'The args passed in valueAndGrads(f)(args) must be array of ' +\n            'tensors'; });\n        util.assert(dy == null || dy instanceof tensor_1.Tensor, function () { return 'The dy passed in valueAndGrads(f)(args, dy) must be a tensor'; });\n        var res = engine_1.ENGINE.gradients(function () { return f.apply(void 0, args); }, args, dy);\n        if (dy != null) {\n            util.assertShapesMatch(res.value.shape, dy.shape, 'The shape of dy passed in valueAndGrads(f)([x1,...], dy) must ' +\n                'match the shape returned by f([x1,...])');\n        }\n        checkGrads(res.grads);\n        return res;\n    };\n}\nexports.valueAndGrads = valueAndGrads;\n/**\n * Computes and returns the gradient of f(x) with respect to the list of\n * trainable variables provided by `varList`. If no list is provided, it\n * defaults to all trainable variables.\n *\n * ```js\n * const a = tf.variable(tf.tensor1d([3, 4]));\n * const b = tf.variable(tf.tensor1d([5, 6]));\n * const x = tf.tensor1d([1, 2]);\n *\n * // f(a, b) = a * x ^ 2 + b * x\n * const f = () => a.mul(x.square()).add(b.mul(x)).sum();\n * // df/da = x ^ 2, df/db = x\n * const {value, grads} = tf.variableGrads(f);\n *\n * Object.keys(grads).forEach(varName => grads[varName].print());\n * ```\n *\n * @param f The function to execute. f() should return a scalar.\n * @param varList The list of variables to compute the gradients with respect\n *     to. Defaults to all trainable variables.\n * @returns An object with the following keys and values:\n *   - `value`: The value of the function `f`.\n *   - `grads`: A map from the names of the variables to the gradients.\n *     If the `varList` argument is provided explicitly and contains a subset of\n *     non-trainable variables, this map in the return value will contain keys\n *     that map the names of the non-trainable variables to `null`.\n */\n/** @doc {heading: 'Training', subheading: 'Gradients'} */\nfunction variableGrads(f, varList) {\n    util.assert(util.isFunction(f), function () { return 'The f passed in variableGrads(f) must be a function'; });\n    util.assert(varList == null ||\n        Array.isArray(varList) && varList.every(function (v) { return v instanceof tensor_1.Variable; }), function () {\n        return 'The varList passed in variableGrads(f, varList) must be an array ' +\n            'of variables';\n    });\n    var specifiedVarList = varList != null;\n    if (!specifiedVarList) {\n        // Get all of the trainable variables.\n        varList = [];\n        for (var varName in engine_1.ENGINE.registeredVariables) {\n            varList.push(engine_1.ENGINE.registeredVariables[varName]);\n        }\n    }\n    var specifiedNonTrainable = specifiedVarList ? varList.filter(function (variable) { return !variable.trainable; }) : null;\n    // Prune non-trainable variables.\n    var originalVarCount = varList.length;\n    varList = varList.filter(function (variable) { return variable.trainable; });\n    util.assert(varList.length > 0, function () { return \"variableGrads() expects at least one of the input variables to \" +\n        (\"be trainable, but none of the \" + originalVarCount + \" variables is \") +\n        \"trainable.\"; });\n    var allowNoGradients = true;\n    var _a = engine_1.ENGINE.gradients(f, varList, null, allowNoGradients), value = _a.value, grads = _a.grads;\n    util.assert(grads.some(function (g) { return g != null; }), function () { return 'Cannot find a connection between any variable and the result of ' +\n        'the loss function y=f(x). Please make sure the operations that ' +\n        'use variables are inside the function f passed to minimize().'; });\n    util.assert(value.rank === 0, function () { return \"The f passed in variableGrads(f) must return a scalar, but it \" +\n        (\"returned a rank-\" + value.rank + \" tensor\"); });\n    var namedGrads = {};\n    varList.forEach(function (v, i) {\n        if (grads[i] != null) {\n            namedGrads[v.name] = grads[i];\n        }\n    });\n    if (specifiedNonTrainable != null) {\n        // If varList is explicitly provided and contains non-trainable values,\n        // add them to the returned gradients with `null` values.\n        specifiedNonTrainable.forEach(function (v) { return namedGrads[v.name] = null; });\n    }\n    return { value: value, grads: namedGrads };\n}\nexports.variableGrads = variableGrads;\n/**\n * Overrides the gradient computation of a function `f`.\n *\n * Takes a function\n * `f(...inputs, save) => {value: Tensor, gradFunc: (dy, saved) => Tensor[]}`\n * and returns another function `g(...inputs)` which takes the same inputs as\n * `f`. When called, `g` returns `f().value`. In backward mode, custom gradients\n * with respect to each input of `f` are computed using `f().gradFunc`.\n *\n * The `save` function passsed to `f` should be used for saving tensors needed\n * in the gradient. And the `saved` passed to the `gradFunc` is a\n * `NamedTensorMap`, which contains those saved tensor.\n *\n * ```js\n * const customOp = tf.customGrad((x, save) => {\n *   // Save x to make sure it's available later for the gradient.\n *   save([x]);\n *   // Override gradient of our custom x ^ 2 op to be dy * abs(x);\n *   return {\n *     value: x.square(),\n *     // Note `saved.x` which points to the `x` we saved earlier.\n *     gradFunc: (dy, saved) => [dy.mul(saved[0].abs())]\n *   };\n * });\n *\n * const x = tf.tensor1d([-1, -2, 3]);\n * const dx = tf.grad(x => customOp(x));\n *\n * console.log(`f(x):`);\n * customOp(x).print();\n * console.log(`f'(x):`);\n * dx(x).print();\n * ```\n *\n * @param f The function to evaluate in forward mode, which should return\n *     `{value: Tensor, gradFunc: (dy, saved) => Tensor[]}`, where `gradFunc`\n *     returns the custom gradients of `f` with respect to its inputs.\n */\n/** @doc {heading: 'Training', subheading: 'Gradients'} */\nfunction customGrad(f) {\n    return engine_1.ENGINE.customGrad(f);\n}\nexports.customGrad = customGrad;\nfunction checkGrads(grads) {\n    var numNullGradients = grads.filter(function (g) { return g == null; }).length;\n    if (numNullGradients > 0) {\n        throw new Error(\"Cannot compute gradient of y=f(x) with respect to x. Make sure that\\n    the f you passed encloses all operations that lead from x to y.\");\n    }\n}\n//# sourceMappingURL=gradients.js.map","\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar environment_1 = require(\"./environment\");\nvar tensor_1 = require(\"./tensor\");\nvar util_1 = require(\"./util\");\nfunction inferShape(val) {\n    var firstElem = val;\n    if (util_1.isTypedArray(val)) {\n        return [val.length];\n    }\n    if (!Array.isArray(val)) {\n        return []; // Scalar.\n    }\n    var shape = [];\n    while (Array.isArray(firstElem) || util_1.isTypedArray(firstElem)) {\n        shape.push(firstElem.length);\n        firstElem = firstElem[0];\n    }\n    if (Array.isArray(val) && environment_1.ENV.getBool('TENSORLIKE_CHECK_SHAPE_CONSISTENCY')) {\n        deepAssertShapeConsistency(val, shape, []);\n    }\n    return shape;\n}\nexports.inferShape = inferShape;\nfunction deepAssertShapeConsistency(val, shape, indices) {\n    indices = indices || [];\n    if (!(Array.isArray(val)) && !util_1.isTypedArray(val)) {\n        util_1.assert(shape.length === 0, function () { return \"Element arr[\" + indices.join('][') + \"] is a primitive, \" +\n            (\"but should be an array/TypedArray of \" + shape[0] + \" elements\"); });\n        return;\n    }\n    util_1.assert(shape.length > 0, function () { return \"Element arr[\" + indices.join('][') + \"] should be a primitive, \" +\n        (\"but is an array of \" + val.length + \" elements\"); });\n    util_1.assert(val.length === shape[0], function () { return \"Element arr[\" + indices.join('][') + \"] should have \" + shape[0] + \" \" +\n        (\"elements, but has \" + val.length + \" elements\"); });\n    var subShape = shape.slice(1);\n    for (var i = 0; i < val.length; ++i) {\n        deepAssertShapeConsistency(val[i], subShape, indices.concat(i));\n    }\n}\nfunction assertDtype(expectedDtype, actualDType, argName, functionName) {\n    if (expectedDtype == null) {\n        return;\n    }\n    if (expectedDtype !== 'numeric' && expectedDtype !== actualDType ||\n        expectedDtype === 'numeric' && actualDType === 'string') {\n        throw new Error(\"Argument '\" + argName + \"' passed to '\" + functionName + \"' must \" +\n            (\"be \" + expectedDtype + \" tensor, but got \" + actualDType + \" tensor\"));\n    }\n}\nfunction convertToTensor(x, argName, functionName, parseAsDtype) {\n    if (parseAsDtype === void 0) { parseAsDtype = 'numeric'; }\n    if (x instanceof tensor_1.Tensor) {\n        assertDtype(parseAsDtype, x.dtype, argName, functionName);\n        return x;\n    }\n    var inferredDtype = util_1.inferDtype(x);\n    // If the user expects a bool/int/float, use that info to update the\n    // inferredDtype when it is not a string.\n    if (inferredDtype !== 'string' &&\n        ['bool', 'int32', 'float32'].indexOf(parseAsDtype) >= 0) {\n        inferredDtype = parseAsDtype;\n    }\n    assertDtype(parseAsDtype, inferredDtype, argName, functionName);\n    if ((x == null) ||\n        (!util_1.isTypedArray(x) && !Array.isArray(x) && typeof x !== 'number' &&\n            typeof x !== 'boolean' && typeof x !== 'string')) {\n        var type = x == null ? 'null' : x.constructor.name;\n        throw new Error(\"Argument '\" + argName + \"' passed to '\" + functionName + \"' must be a \" +\n            (\"Tensor or TensorLike, but got '\" + type + \"'\"));\n    }\n    var inferredShape = inferShape(x);\n    if (!util_1.isTypedArray(x) && !Array.isArray(x)) {\n        x = [x];\n    }\n    var values = inferredDtype !== 'string' ?\n        util_1.toTypedArray(x, inferredDtype, environment_1.ENV.getBool('DEBUG')) :\n        util_1.flatten(x);\n    return tensor_1.Tensor.make(inferredShape, { values: values }, inferredDtype);\n}\nexports.convertToTensor = convertToTensor;\nfunction convertToTensorArray(arg, argName, functionName, parseAsDtype) {\n    if (parseAsDtype === void 0) { parseAsDtype = 'numeric'; }\n    if (!Array.isArray(arg)) {\n        throw new Error(\"Argument \" + argName + \" passed to \" + functionName + \" must be a \" +\n            '`Tensor[]` or `TensorLike[]`');\n    }\n    var tensors = arg;\n    return tensors.map(function (t, i) { return convertToTensor(t, argName + \"[\" + i + \"]\", functionName); }, parseAsDtype);\n}\nexports.convertToTensorArray = convertToTensorArray;\n//# sourceMappingURL=tensor_util_env.js.map","\nObject.defineProperty(exports, \"__esModule\", { value: true });\n/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar engine_1 = require(\"../engine\");\n/**\n * Used for wrapping functions that perform math operations on\n * Tensors. The function will be wrapped in a named scope that cleans all\n * memory usage after the function is done.\n */\nfunction op(f) {\n    var keys = Object.keys(f);\n    if (keys.length !== 1) {\n        throw new Error(\"Please provide an object with a single key \" +\n            \"(operation name) mapping to a function. Got an object with \" +\n            (keys.length + \" keys.\"));\n    }\n    var opName = keys[0];\n    var fn = f[opName];\n    // Strip the underscore from the end of the function name.\n    if (opName.endsWith('_')) {\n        opName = opName.substring(0, opName.length - 1);\n    }\n    // tslint:disable-next-line:no-any\n    var f2 = function () {\n        var args = [];\n        for (var _i = 0; _i < arguments.length; _i++) {\n            args[_i] = arguments[_i];\n        }\n        engine_1.ENGINE.startScope(opName);\n        try {\n            var result = fn.apply(void 0, args);\n            if (result instanceof Promise) {\n                console.error('Cannot return a Promise inside of tidy.');\n            }\n            engine_1.ENGINE.endScope(result);\n            return result;\n        }\n        catch (ex) {\n            engine_1.ENGINE.endScope(null);\n            throw ex;\n        }\n    };\n    Object.defineProperty(f2, 'name', { value: opName, configurable: true });\n    // tslint:disable-next-line:no-any\n    return f2;\n}\nexports.op = op;\n//# sourceMappingURL=operation.js.map","\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar engine_1 = require(\"../engine\");\nvar environment_1 = require(\"../environment\");\nvar tensor_1 = require(\"../tensor\");\nvar tensor_util_env_1 = require(\"../tensor_util_env\");\nvar util_1 = require(\"../util\");\nvar complex_ops_1 = require(\"./complex_ops\");\nvar operation_1 = require(\"./operation\");\n/**\n * Creates a `tf.Tensor` with the provided values, shape and dtype.\n *\n * ```js\n * // Pass an array of values to create a vector.\n * tf.tensor([1, 2, 3, 4]).print();\n * ```\n *\n * ```js\n * // Pass a nested array of values to make a matrix or a higher\n * // dimensional tensor.\n * tf.tensor([[1, 2], [3, 4]]).print();\n * ```\n *\n * ```js\n * // Pass a flat array and specify a shape yourself.\n * tf.tensor([1, 2, 3, 4], [2, 2]).print();\n * ```\n *\n * @param values The values of the tensor. Can be nested array of numbers,\n *     or a flat array, or a `TypedArray`.\n * @param shape The shape of the tensor. Optional. If not provided,\n *   it is inferred from `values`.\n * @param dtype The data type.\n */\n/** @doc {heading: 'Tensors', subheading: 'Creation'} */\nfunction tensor(values, shape, dtype) {\n    if (dtype == null) {\n        dtype = util_1.inferDtype(values);\n    }\n    if (dtype === 'complex64') {\n        throw new Error(\"Cannot construct a complex64 tensor directly. \" +\n            \"Please use tf.complex(real, imag).\");\n    }\n    if (!util_1.isTypedArray(values) && !Array.isArray(values) &&\n        typeof values !== 'number' && typeof values !== 'boolean' &&\n        typeof values !== 'string') {\n        throw new Error('values passed to tensor(values) must be a number/boolean/string or ' +\n            'an array of numbers/booleans/strings, or a TypedArray');\n    }\n    var inferredShape = tensor_util_env_1.inferShape(values);\n    if (shape != null) {\n        util_1.assertNonNegativeIntegerDimensions(shape);\n        var providedSize_1 = util_1.sizeFromShape(shape);\n        var inferredSize_1 = util_1.sizeFromShape(inferredShape);\n        util_1.assert(providedSize_1 === inferredSize_1, function () {\n            return \"Based on the provided shape, [\" + shape + \"], the tensor should have \" +\n                (providedSize_1 + \" values but has \" + inferredSize_1);\n        });\n        for (var i = 0; i < inferredShape.length; ++i) {\n            var inferred = inferredShape[i];\n            var flatDimsDontMatch = i === inferredShape.length - 1 ?\n                inferred !== util_1.sizeFromShape(shape.slice(i)) :\n                true;\n            util_1.assert(inferredShape[i] === shape[i] || !flatDimsDontMatch, function () { return \"Error creating a new Tensor. Inferred shape \" +\n                (\"(\" + inferredShape + \") does not match the provided \") +\n                (\"shape (\" + shape + \"). \"); });\n        }\n    }\n    if (!util_1.isTypedArray(values) && !Array.isArray(values)) {\n        values = [values];\n    }\n    shape = shape || inferredShape;\n    values = dtype !== 'string' ?\n        util_1.toTypedArray(values, dtype, environment_1.ENV.getBool('DEBUG')) :\n        util_1.flatten(values);\n    return tensor_1.Tensor.make(shape, { values: values }, dtype);\n}\nexports.tensor = tensor;\n/**\n * Creates rank-0 `tf.Tensor` (scalar) with the provided value and dtype.\n *\n * The same functionality can be achieved with `tf.tensor`, but in general\n * we recommend using `tf.scalar` as it makes the code more readable.\n *\n * ```js\n * tf.scalar(3.14).print();\n * ```\n *\n * @param value The value of the scalar.\n * @param dtype The data type.\n */\n/** @doc {heading: 'Tensors', subheading: 'Creation'} */\nfunction scalar(value, dtype) {\n    if ((util_1.isTypedArray(value) || Array.isArray(value)) && dtype !== 'complex64') {\n        throw new Error('Error creating a new Scalar: value must be a primitive ' +\n            '(number|boolean|string)');\n    }\n    return tensor(value, [], dtype);\n}\nexports.scalar = scalar;\n/**\n * Creates rank-1 `tf.Tensor` with the provided values, shape and dtype.\n *\n * The same functionality can be achieved with `tf.tensor`, but in general\n * we recommend using `tf.tensor1d` as it makes the code more readable.\n *\n * ```js\n * tf.tensor1d([1, 2, 3]).print();\n * ```\n *\n * @param values The values of the tensor. Can be array of numbers,\n *     or a `TypedArray`.\n * @param dtype The data type.\n */\n/** @doc {heading: 'Tensors', subheading: 'Creation'} */\nfunction tensor1d(values, dtype) {\n    util_1.assertNonNull(values);\n    var inferredShape = tensor_util_env_1.inferShape(values);\n    if (inferredShape.length !== 1) {\n        throw new Error('tensor1d() requires values to be a flat/TypedArray');\n    }\n    return tensor(values, inferredShape, dtype);\n}\nexports.tensor1d = tensor1d;\n/**\n * Creates rank-2 `tf.Tensor` with the provided values, shape and dtype.\n *\n * The same functionality can be achieved with `tf.tensor`, but in general\n * we recommend using `tf.tensor2d` as it makes the code more readable.\n *\n *  ```js\n * // Pass a nested array.\n * tf.tensor2d([[1, 2], [3, 4]]).print();\n * ```\n * ```js\n * // Pass a flat array and specify a shape.\n * tf.tensor2d([1, 2, 3, 4], [2, 2]).print();\n * ```\n *\n * @param values The values of the tensor. Can be nested array of numbers,\n *     or a flat array, or a `TypedArray`.\n * @param shape The shape of the tensor. If not provided, it is inferred from\n *     `values`.\n * @param dtype The data type.\n */\n/** @doc {heading: 'Tensors', subheading: 'Creation'} */\nfunction tensor2d(values, shape, dtype) {\n    util_1.assertNonNull(values);\n    if (shape != null && shape.length !== 2) {\n        throw new Error('tensor2d() requires shape to have two numbers');\n    }\n    var inferredShape = tensor_util_env_1.inferShape(values);\n    if (inferredShape.length !== 2 && inferredShape.length !== 1) {\n        throw new Error('tensor2d() requires values to be number[][] or flat/TypedArray');\n    }\n    if (inferredShape.length === 1 && shape == null) {\n        throw new Error('tensor2d() requires shape to be provided when `values` ' +\n            'are a flat/TypedArray');\n    }\n    shape = shape || inferredShape;\n    return tensor(values, shape, dtype);\n}\nexports.tensor2d = tensor2d;\n/**\n * Creates rank-3 `tf.Tensor` with the provided values, shape and dtype.\n *\n * The same functionality can be achieved with `tf.tensor`, but in general\n * we recommend using `tf.tensor3d` as it makes the code more readable.\n *\n *  ```js\n * // Pass a nested array.\n * tf.tensor3d([[[1], [2]], [[3], [4]]]).print();\n * ```\n * ```js\n * // Pass a flat array and specify a shape.\n * tf.tensor3d([1, 2, 3, 4], [2, 2, 1]).print();\n * ```\n *\n * @param values The values of the tensor. Can be nested array of numbers,\n *     or a flat array, or a `TypedArray`.\n * @param shape The shape of the tensor. If not provided,  it is inferred from\n *     `values`.\n * @param dtype The data type.\n */\n/** @doc {heading: 'Tensors', subheading: 'Creation'} */\nfunction tensor3d(values, shape, dtype) {\n    util_1.assertNonNull(values);\n    if (shape != null && shape.length !== 3) {\n        throw new Error('tensor3d() requires shape to have three numbers');\n    }\n    var inferredShape = tensor_util_env_1.inferShape(values);\n    if (inferredShape.length !== 3 && inferredShape.length !== 1) {\n        throw new Error('tensor3d() requires values to be number[][][] or flat/TypedArray');\n    }\n    if (inferredShape.length === 1 && shape == null) {\n        throw new Error('tensor3d() requires shape to be provided when `values` ' +\n            'are a flat array');\n    }\n    shape = shape || inferredShape;\n    return tensor(values, shape, dtype);\n}\nexports.tensor3d = tensor3d;\n/**\n * Creates rank-4 `tf.Tensor` with the provided values, shape and dtype.\n *\n * The same functionality can be achieved with `tf.tensor`, but in general\n * we recommend using `tf.tensor4d` as it makes the code more readable.\n *\n *  ```js\n * // Pass a nested array.\n * tf.tensor4d([[[[1], [2]], [[3], [4]]]]).print();\n * ```\n * ```js\n * // Pass a flat array and specify a shape.\n * tf.tensor4d([1, 2, 3, 4], [1, 2, 2, 1]).print();\n * ```\n *\n * @param values The values of the tensor. Can be nested array of numbers,\n *     or a flat array, or a `TypedArray`.\n * @param shape The shape of the tensor. Optional. If not provided,\n *   it is inferred from `values`.\n * @param dtype The data type.\n */\n/** @doc {heading: 'Tensors', subheading: 'Creation'} */\nfunction tensor4d(values, shape, dtype) {\n    util_1.assertNonNull(values);\n    if (shape != null && shape.length !== 4) {\n        throw new Error('tensor4d() requires shape to have four numbers');\n    }\n    var inferredShape = tensor_util_env_1.inferShape(values);\n    if (inferredShape.length !== 4 && inferredShape.length !== 1) {\n        throw new Error('tensor4d() requires values to be number[][][][] or flat/TypedArray');\n    }\n    if (inferredShape.length === 1 && shape == null) {\n        throw new Error('tensor4d() requires shape to be provided when `values` ' +\n            'are a flat array');\n    }\n    shape = shape || inferredShape;\n    return tensor(values, shape, dtype);\n}\nexports.tensor4d = tensor4d;\n/**\n * Creates rank-5 `tf.Tensor` with the provided values, shape and dtype.\n *\n * The same functionality can be achieved with `tf.tensor`, but in general\n * we recommend using `tf.tensor5d` as it makes the code more readable.\n *\n *  ```js\n * // Pass a nested array.\n * tf.tensor5d([[[[[1], [2]], [[3], [4]]]]]).print();\n * ```\n * ```js\n * // Pass a flat array and specify a shape.\n * tf.tensor5d([1, 2, 3, 4, 5, 6, 7, 8], [1, 2, 2, 2, 1]).print();\n * ```\n *\n * @param values The values of the tensor. Can be nested array of numbers,\n *     or a flat array, or a `TypedArray`.\n * @param shape The shape of the tensor. Optional. If not provided,\n *   it is inferred from `values`.\n * @param dtype The data type.\n */\n/** @doc {heading: 'Tensors', subheading: 'Creation'} */\nfunction tensor5d(values, shape, dtype) {\n    util_1.assertNonNull(values);\n    if (shape != null && shape.length !== 5) {\n        throw new Error('tensor5d() requires shape to have five numbers');\n    }\n    var inferredShape = tensor_util_env_1.inferShape(values);\n    if (inferredShape.length !== 5 && inferredShape.length !== 1) {\n        throw new Error('tensor5d() requires values to be ' +\n            'number[][][][][] or flat/TypedArray');\n    }\n    if (inferredShape.length === 1 && shape == null) {\n        throw new Error('tensor5d() requires shape to be provided when `values` ' +\n            'are a flat array');\n    }\n    shape = shape || inferredShape;\n    return tensor(values, shape, dtype);\n}\nexports.tensor5d = tensor5d;\n/**\n * Creates rank-6 `tf.Tensor` with the provided values, shape and dtype.\n *\n * The same functionality can be achieved with `tf.tensor`, but in general\n * we recommend using `tf.tensor6d` as it makes the code more readable.\n *\n *  ```js\n * // Pass a nested array.\n * tf.tensor6d([[[[[[1],[2]],[[3],[4]]],[[[5],[6]],[[7],[8]]]]]]).print();\n * ```\n * ```js\n * // Pass a flat array and specify a shape.\n * tf.tensor6d([1, 2, 3, 4, 5, 6, 7, 8], [1, 1, 2, 2, 2, 1]).print();\n * ```\n *\n * @param values The values of the tensor. Can be nested array of numbers,\n *     or a flat array, or a `TypedArray`.\n * @param shape The shape of the tensor. Optional. If not provided,\n *   it is inferred from `values`.\n * @param dtype The data type.\n */\n/** @doc {heading: 'Tensors', subheading: 'Creation'} */\nfunction tensor6d(values, shape, dtype) {\n    util_1.assertNonNull(values);\n    if (shape != null && shape.length !== 6) {\n        throw new Error('tensor6d() requires shape to have six numbers');\n    }\n    var inferredShape = tensor_util_env_1.inferShape(values);\n    if (inferredShape.length !== 6 && inferredShape.length !== 1) {\n        throw new Error('tensor6d() requires values to be number[][][][][][] or ' +\n            'flat/TypedArray');\n    }\n    if (inferredShape.length === 1 && shape == null) {\n        throw new Error('tensor6d() requires shape to be provided when `values` ' +\n            'are a flat array');\n    }\n    shape = shape ||\n        inferredShape;\n    return tensor(values, shape, dtype);\n}\nexports.tensor6d = tensor6d;\n/**\n * Creates a `tf.Tensor` with all elements set to 1.\n *\n * ```js\n * tf.ones([2, 2]).print();\n * ```\n *\n * @param shape An array of integers defining the output tensor shape.\n * @param dtype The type of an element in the resulting tensor. Defaults to\n *     'float'.\n */\n/** @doc {heading: 'Tensors', subheading: 'Creation'} */\nfunction ones(shape, dtype) {\n    if (dtype === void 0) { dtype = 'float32'; }\n    if (dtype === 'complex64') {\n        var real_1 = ones(shape, 'float32');\n        var imag_1 = zeros(shape, 'float32');\n        return complex_ops_1.complex(real_1, imag_1);\n    }\n    var values = util_1.makeOnesTypedArray(util_1.sizeFromShape(shape), dtype);\n    return tensor_1.Tensor.make(shape, { values: values }, dtype);\n}\nexports.ones = ones;\n/**\n * Creates a `tf.Tensor` with all elements set to 0.\n *\n * ```js\n * tf.zeros([2, 2]).print();\n * ```\n *\n * @param shape An array of integers defining the output tensor shape.\n * @param dtype The type of an element in the resulting tensor. Can\n *     be 'float32', 'int32' or 'bool'. Defaults to 'float'.\n */\n/** @doc {heading: 'Tensors', subheading: 'Creation'} */\nfunction zeros(shape, dtype) {\n    if (dtype === void 0) { dtype = 'float32'; }\n    if (dtype === 'complex64') {\n        var real_2 = zeros(shape, 'float32');\n        var imag_2 = zeros(shape, 'float32');\n        return complex_ops_1.complex(real_2, imag_2);\n    }\n    var values = util_1.makeZerosTypedArray(util_1.sizeFromShape(shape), dtype);\n    return tensor_1.Tensor.make(shape, { values: values }, dtype);\n}\nexports.zeros = zeros;\n/**\n * Creates a `tf.Tensor` filled with a scalar value.\n *\n * ```js\n * tf.fill([2, 2], 4).print();\n * ```\n *\n * @param shape An array of integers defining the output tensor shape.\n * @param value The scalar value to fill the tensor with.\n * @param dtype The type of an element in the resulting tensor. Defaults to\n * 'float'.\n */\n/** @doc {heading: 'Tensors', subheading: 'Creation'} */\nfunction fill(shape, value, dtype) {\n    return engine_1.ENGINE.runKernel(function (backend) { return backend.fill(shape, value, dtype); }, {});\n}\nexports.fill = fill;\n/**\n * Creates a `tf.Tensor` with all elements set to 1 with the same shape as the\n * given tensor.\n *\n * ```js\n * const x = tf.tensor([1, 2]);\n * tf.onesLike(x).print();\n * ```\n * @param x A tensor.\n */\n/** @doc {heading: 'Tensors', subheading: 'Creation'} */\nfunction onesLike_(x) {\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'onesLike');\n    if ($x.dtype === 'complex64') {\n        var r = exports.onesLike(complex_ops_1.real($x));\n        var i = exports.zerosLike(complex_ops_1.imag($x));\n        return complex_ops_1.complex(r, i);\n    }\n    var der = function (dy, saved) { return ({ $x: function () { return exports.zerosLike(dy); } }); };\n    return engine_1.ENGINE.runKernel(function (backend) { return backend.onesLike($x); }, { $x: $x }, der);\n}\n/**\n * Creates a `tf.Tensor` with all elements set to 0 with the same shape as the\n * given tensor.\n *\n * ```js\n * const x = tf.tensor([1, 2]);\n * tf.zerosLike(x).print();\n * ```\n *\n * @param x The tensor of required shape.\n */\n/** @doc {heading: 'Tensors', subheading: 'Creation'} */\nfunction zerosLike_(x) {\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'zerosLike');\n    var der = function (dy, saved) { return ({ $x: function () { return exports.zerosLike(dy); } }); };\n    return engine_1.ENGINE.runKernel(function (backend) { return backend.zerosLike($x); }, { $x: $x }, der);\n}\n/**\n * Return an evenly spaced sequence of numbers over the given interval.\n *\n * ```js\n * tf.linspace(0, 9, 10).print();\n * ```\n * @param start The start value of the sequence.\n * @param stop The end value of the sequence.\n * @param num The number of values to generate.\n */\n/** @doc {heading: 'Tensors', subheading: 'Creation'} */\nfunction linspace(start, stop, num) {\n    if (num <= 0) {\n        throw new Error('The number of values should be positive.');\n    }\n    return engine_1.ENGINE.runKernel(function (backend) { return backend.linspace(start, stop, num); }, {});\n}\nexports.linspace = linspace;\n/**\n * Creates a new `tf.Tensor1D` filled with the numbers in the range provided.\n *\n * The tensor is a is half-open interval meaning it includes start, but\n * excludes stop. Decrementing ranges and negative step values are also\n * supported.\n *\n * ```js\n * tf.range(0, 9, 2).print();\n * ```\n *\n * @param start An integer start value\n * @param stop An integer stop value\n * @param step An integer increment (will default to 1 or -1)\n * @param dtype The data type of the output tensor. Defaults to 'float32'.\n */\n/** @doc {heading: 'Tensors', subheading: 'Creation'} */\nfunction range(start, stop, step, dtype) {\n    if (step === void 0) { step = 1; }\n    if (dtype === void 0) { dtype = 'float32'; }\n    if (step === 0) {\n        throw new Error('Cannot have a step of zero');\n    }\n    var sameStartStop = start === stop;\n    var increasingRangeNegativeStep = start < stop && step < 0;\n    var decreasingRangePositiveStep = stop < start && step > 1;\n    if (sameStartStop || increasingRangeNegativeStep ||\n        decreasingRangePositiveStep) {\n        return zeros([0], dtype);\n    }\n    var numElements = Math.abs(Math.ceil((stop - start) / step));\n    var values = util_1.makeZerosTypedArray(numElements, dtype);\n    if (stop < start && step === 1) {\n        // Auto adjust the step's sign if it hasn't been set\n        // (or was set to 1)\n        step = -1;\n    }\n    values[0] = start;\n    for (var i = 1; i < values.length; i++) {\n        values[i] = values[i - 1] + step;\n    }\n    return tensor1d(values, dtype);\n}\nexports.range = range;\nexports.onesLike = operation_1.op({ onesLike_: onesLike_ });\nexports.zerosLike = operation_1.op({ zerosLike_: zerosLike_ });\n//# sourceMappingURL=tensor_ops.js.map","\nObject.defineProperty(exports, \"__esModule\", { value: true });\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar engine_1 = require(\"../engine\");\nvar tensor_util_env_1 = require(\"../tensor_util_env\");\nvar util = require(\"../util\");\nvar operation_1 = require(\"./operation\");\n/**\n * Converts two real numbers to a complex number.\n *\n * Given a tensor `real` representing the real part of a complex number, and a\n * tensor `imag` representing the imaginary part of a complex number, this\n * operation returns complex numbers elementwise of the form [r0, i0, r1, i1],\n * where r represents the real part and i represents the imag part.\n *\n * The input tensors real and imag must have the same shape.\n *\n * ```js\n * const real = tf.tensor1d([2.25, 3.25]);\n * const imag = tf.tensor1d([4.75, 5.75]);\n * const complex = tf.complex(real, imag);\n *\n * complex.print();\n * ```\n */\n/** @doc {heading: 'Tensors', subheading: 'Creation'} */\nfunction complex_(real, imag) {\n    var $real = tensor_util_env_1.convertToTensor(real, 'real', 'complex');\n    var $imag = tensor_util_env_1.convertToTensor(imag, 'imag', 'complex');\n    util.assertShapesMatch($real.shape, $imag.shape, \"real and imag shapes, \" + $real.shape + \" and \" + $imag.shape + \", \" +\n        \"must match in call to tf.complex().\");\n    return engine_1.ENGINE.runKernel(function (backend) { return backend.complex($real, $imag); }, { $real: $real, $imag: $imag });\n}\n/**\n * Returns the real part of a complex (or real) tensor.\n *\n * Given a tensor input, this operation returns a tensor of type float that is\n * the real part of each element in input considered as a complex number.\n *\n * If the input is real, it simply makes a clone.\n *\n * ```js\n * const x = tf.complex([-2.25, 3.25], [4.75, 5.75]);\n * tf.real(x).print();\n * ```\n */\n/** @doc {heading: 'Tensors', subheading: 'Creation'} */\nfunction real_(input) {\n    var $input = tensor_util_env_1.convertToTensor(input, 'input', 'real');\n    return engine_1.ENGINE.runKernel(function (backend) { return backend.real($input); }, { $input: $input });\n}\n/**\n * Returns the imaginary part of a complex (or real) tensor.\n *\n * Given a tensor input, this operation returns a tensor of type float that is\n * the imaginary part of each element in input considered as a complex number.\n * If input is real, a tensor of all zeros is returned.\n *\n * ```js\n * const x = tf.complex([-2.25, 3.25], [4.75, 5.75]);\n * tf.imag(x).print();\n * ```\n */\n/** @doc {heading: 'Tensors', subheading: 'Creation'} */\nfunction imag_(input) {\n    var $input = tensor_util_env_1.convertToTensor(input, 'input', 'imag');\n    return engine_1.ENGINE.runKernel(function (backend) { return backend.imag($input); }, { $input: $input });\n}\nexports.complex = operation_1.op({ complex_: complex_ });\nexports.real = operation_1.op({ real_: real_ });\nexports.imag = operation_1.op({ imag_: imag_ });\n//# sourceMappingURL=complex_ops.js.map","\n/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.EPSILON_FLOAT32 = 1e-7;\nexports.EPSILON_FLOAT16 = 1e-4;\n/** Convenient class for storing tensor-related data. */\nvar DataStorage = /** @class */ (function () {\n    function DataStorage(backend, dataMover) {\n        this.backend = backend;\n        this.dataMover = dataMover;\n        this.data = new WeakMap();\n    }\n    DataStorage.prototype.get = function (dataId) {\n        if (!this.data.has(dataId)) {\n            this.dataMover.moveData(this.backend, dataId);\n        }\n        return this.data.get(dataId);\n    };\n    DataStorage.prototype.set = function (dataId, value) {\n        this.data.set(dataId, value);\n    };\n    DataStorage.prototype.has = function (dataId) {\n        return this.data.has(dataId);\n    };\n    DataStorage.prototype.delete = function (dataId) {\n        return this.data.delete(dataId);\n    };\n    return DataStorage;\n}());\nexports.DataStorage = DataStorage;\n/**\n * The interface that defines the kernels that should be implemented when\n * adding a new backend. New backends don't need to implement every one of the\n * methods, this can be done gradually (throw an error for unimplemented\n * methods).\n */\nvar KernelBackend = /** @class */ (function () {\n    function KernelBackend() {\n    }\n    KernelBackend.prototype.time = function (f) {\n        throw new Error('Not yet implemented.');\n    };\n    KernelBackend.prototype.read = function (dataId) {\n        throw new Error('Not yet implemented.');\n    };\n    KernelBackend.prototype.readSync = function (dataId) {\n        throw new Error('Not yet implemented.');\n    };\n    KernelBackend.prototype.disposeData = function (dataId) {\n        throw new Error('Not yet implemented.');\n    };\n    KernelBackend.prototype.write = function (dataId, values) {\n        throw new Error('Not yet implemented.');\n    };\n    KernelBackend.prototype.fromPixels = function (pixels, numChannels) {\n        throw new Error('Not yet implemented.');\n    };\n    KernelBackend.prototype.register = function (dataId, shape, dtype) {\n        throw new Error('Not yet implemented.');\n    };\n    KernelBackend.prototype.memory = function () {\n        throw new Error('Not yet implemented.');\n    };\n    /** Returns the highest precision for floats in bits (e.g. 16 or 32) */\n    KernelBackend.prototype.floatPrecision = function () {\n        throw new Error('Not yet implemented');\n    };\n    /** Returns the smallest representable number.  */\n    KernelBackend.prototype.epsilon = function () {\n        return this.floatPrecision() === 32 ? exports.EPSILON_FLOAT32 : exports.EPSILON_FLOAT16;\n    };\n    KernelBackend.prototype.batchMatMul = function (a, b, transposeA, transposeB) {\n        throw new Error('Not yet implemented');\n    };\n    KernelBackend.prototype.fusedBatchMatMul = function (a, b, transposeA, transposeB, bias, activation) {\n        throw new Error('Not yet implemented');\n    };\n    KernelBackend.prototype.slice = function (x, begin, size) {\n        throw new Error('Not yet implemented');\n    };\n    KernelBackend.prototype.stridedSlice = function (x, begin, end, strides, beginMask, endMask, ellipsisMask, newAxisMask, shrinkAxisMask) {\n        throw new Error('Not yet implemented');\n    };\n    KernelBackend.prototype.unstack = function (x, axis) {\n        throw new Error('Not yet implemented');\n    };\n    KernelBackend.prototype.reverse = function (a, axis) {\n        throw new Error('Not yet implemented');\n    };\n    KernelBackend.prototype.concat = function (tensors, axis) {\n        throw new Error('Not yet implemented');\n    };\n    KernelBackend.prototype.neg = function (a) {\n        throw new Error('Not yet implemented');\n    };\n    KernelBackend.prototype.add = function (a, b) {\n        throw new Error('Not yet implemented');\n    };\n    KernelBackend.prototype.addN = function (tensors) {\n        throw new Error('Not yet implemented');\n    };\n    KernelBackend.prototype.subtract = function (a, b) {\n        throw new Error('Not yet implemented');\n    };\n    KernelBackend.prototype.multiply = function (a, b) {\n        throw new Error('Not yet implemented');\n    };\n    KernelBackend.prototype.realDivide = function (a, b) {\n        throw new Error('Not yet implemented');\n    };\n    KernelBackend.prototype.floorDiv = function (a, b) {\n        throw new Error('Not yet implemented');\n    };\n    KernelBackend.prototype.sum = function (x, axes) {\n        throw new Error('Not yet implemented');\n    };\n    KernelBackend.prototype.prod = function (x, axes) {\n        throw new Error('Not yet implemented');\n    };\n    KernelBackend.prototype.unsortedSegmentSum = function (x, segmentIds, numSegments) {\n        throw new Error('Not yet implemented');\n    };\n    KernelBackend.prototype.argMin = function (x, axis) {\n        throw new Error('Not yet implemented');\n    };\n    KernelBackend.prototype.argMax = function (x, axis) {\n        throw new Error('Not yet implemented');\n    };\n    KernelBackend.prototype.equal = function (a, b) {\n        throw new Error('Not yet implemented');\n    };\n    KernelBackend.prototype.notEqual = function (a, b) {\n        throw new Error('Not yet implemented');\n    };\n    KernelBackend.prototype.less = function (a, b) {\n        throw new Error('Not yet implemented');\n    };\n    KernelBackend.prototype.lessEqual = function (a, b) {\n        throw new Error('Not yet implemented');\n    };\n    KernelBackend.prototype.greater = function (a, b) {\n        throw new Error('Not yet implemented');\n    };\n    KernelBackend.prototype.greaterEqual = function (a, b) {\n        throw new Error('Not yet implemented');\n    };\n    KernelBackend.prototype.logicalNot = function (a) {\n        throw new Error('Not yet implemented');\n    };\n    KernelBackend.prototype.logicalAnd = function (a, b) {\n        throw new Error('Not yet implemented');\n    };\n    KernelBackend.prototype.logicalOr = function (a, b) {\n        throw new Error('Not yet implemented');\n    };\n    KernelBackend.prototype.where = function (condition) {\n        throw new Error('Not yet implemented');\n    };\n    KernelBackend.prototype.select = function (condition, a, b) {\n        throw new Error('Not yet implemented');\n    };\n    KernelBackend.prototype.topk = function (x, k, sorted) {\n        throw new Error('Not yet implemented');\n    };\n    KernelBackend.prototype.min = function (x, axes) {\n        throw new Error('Not yet implemented');\n    };\n    KernelBackend.prototype.minimum = function (a, b) {\n        throw new Error('Not yet implemented');\n    };\n    KernelBackend.prototype.mod = function (a, b) {\n        throw new Error('Not yet implemented');\n    };\n    KernelBackend.prototype.max = function (x, axes) {\n        throw new Error('Not yet implemented');\n    };\n    KernelBackend.prototype.maximum = function (a, b) {\n        throw new Error('Not yet implemented');\n    };\n    KernelBackend.prototype.all = function (x, axes) {\n        throw new Error('Not yet implemented');\n    };\n    KernelBackend.prototype.any = function (x, axes) {\n        throw new Error('Not yet implemented');\n    };\n    KernelBackend.prototype.squaredDifference = function (a, b) {\n        throw new Error('Not yet implemented');\n    };\n    KernelBackend.prototype.ceil = function (x) {\n        throw new Error('Not yet implemented');\n    };\n    KernelBackend.prototype.floor = function (x) {\n        throw new Error('Not yet implemented');\n    };\n    KernelBackend.prototype.round = function (x) {\n        throw new Error('Not yet implemented');\n    };\n    KernelBackend.prototype.sign = function (x) {\n        throw new Error('Not yet implemented');\n    };\n    KernelBackend.prototype.isNaN = function (x) {\n        throw new Error('Not yet implemented');\n    };\n    KernelBackend.prototype.isInf = function (x) {\n        throw new Error('Not yet implemented');\n    };\n    KernelBackend.prototype.isFinite = function (x) {\n        throw new Error('Not yet implemented');\n    };\n    KernelBackend.prototype.pow = function (a, b) {\n        throw new Error('Not yet implemented');\n    };\n    KernelBackend.prototype.exp = function (x) {\n        throw new Error('Not yet implemented');\n    };\n    KernelBackend.prototype.expm1 = function (x) {\n        throw new Error('Not yet implemented');\n    };\n    KernelBackend.prototype.log = function (x) {\n        throw new Error('Not yet implemented');\n    };\n    KernelBackend.prototype.log1p = function (x) {\n        throw new Error('Not yet implemented');\n    };\n    KernelBackend.prototype.sqrt = function (x) {\n        throw new Error('Not yet implemented');\n    };\n    KernelBackend.prototype.rsqrt = function (x) {\n        throw new Error('Not yet implemented');\n    };\n    KernelBackend.prototype.square = function (x) {\n        throw new Error('Not yet implemented');\n    };\n    KernelBackend.prototype.reciprocal = function (x) {\n        throw new Error('Not yet implemented');\n    };\n    KernelBackend.prototype.relu = function (x) {\n        throw new Error('Not yet implemented');\n    };\n    KernelBackend.prototype.prelu = function (x, a) {\n        throw new Error('Not yet implemented');\n    };\n    KernelBackend.prototype.elu = function (x) {\n        throw new Error('Not yet implemented');\n    };\n    KernelBackend.prototype.eluDer = function (dy, y) {\n        throw new Error('Not yet implemented');\n    };\n    KernelBackend.prototype.selu = function (x) {\n        throw new Error('Not yet implemented');\n    };\n    KernelBackend.prototype.int = function (x) {\n        throw new Error('Not yet implemented');\n    };\n    KernelBackend.prototype.clip = function (x, min, max) {\n        throw new Error('Not yet implemented');\n    };\n    KernelBackend.prototype.abs = function (x) {\n        throw new Error('Not yet implemented');\n    };\n    KernelBackend.prototype.complexAbs = function (x) {\n        throw new Error('Not yet implemented');\n    };\n    KernelBackend.prototype.sigmoid = function (x) {\n        throw new Error('Not yet implemented');\n    };\n    KernelBackend.prototype.softplus = function (x) {\n        throw new Error('Not yet implemented');\n    };\n    KernelBackend.prototype.sin = function (x) {\n        throw new Error('Not yet implemented');\n    };\n    KernelBackend.prototype.cos = function (x) {\n        throw new Error('Not yet implemented');\n    };\n    KernelBackend.prototype.tan = function (x) {\n        throw new Error('Not yet implemented');\n    };\n    KernelBackend.prototype.asin = function (x) {\n        throw new Error('Not yet implemented');\n    };\n    KernelBackend.prototype.acos = function (x) {\n        throw new Error('Not yet implemented');\n    };\n    KernelBackend.prototype.atan = function (x) {\n        throw new Error('Not yet implemented');\n    };\n    KernelBackend.prototype.atan2 = function (a, b) {\n        throw new Error('Not yet implemented');\n    };\n    KernelBackend.prototype.sinh = function (x) {\n        throw new Error('Not yet implemented');\n    };\n    KernelBackend.prototype.cosh = function (x) {\n        throw new Error('Not yet implemented');\n    };\n    KernelBackend.prototype.tanh = function (x) {\n        throw new Error('Not yet implemented');\n    };\n    KernelBackend.prototype.asinh = function (x) {\n        throw new Error('Not yet implemented');\n    };\n    KernelBackend.prototype.acosh = function (x) {\n        throw new Error('Not yet implemented');\n    };\n    KernelBackend.prototype.atanh = function (x) {\n        throw new Error('Not yet implemented');\n    };\n    KernelBackend.prototype.erf = function (x) {\n        throw new Error('Not yet implemented');\n    };\n    KernelBackend.prototype.step = function (x, alpha) {\n        throw new Error('Not yet implemented');\n    };\n    KernelBackend.prototype.conv2d = function (x, filter, convInfo) {\n        throw new Error('Not yet implemented');\n    };\n    KernelBackend.prototype.conv2dDerInput = function (dy, filter, convInfo) {\n        throw new Error('Not yet implemented');\n    };\n    KernelBackend.prototype.conv2dDerFilter = function (x, dY, convInfo) {\n        throw new Error('Not yet implemented');\n    };\n    KernelBackend.prototype.depthwiseConv2D = function (input, filter, convInfo) {\n        throw new Error('Not yet implemented');\n    };\n    KernelBackend.prototype.depthwiseConv2DDerInput = function (dy, filter, convInfo) {\n        throw new Error('Not yet implemented');\n    };\n    KernelBackend.prototype.depthwiseConv2DDerFilter = function (x, dY, convInfo) {\n        throw new Error('Not yet implemented');\n    };\n    KernelBackend.prototype.conv3d = function (x, filter, convInfo) {\n        throw new Error('Not yet implemented');\n    };\n    KernelBackend.prototype.conv3dDerInput = function (dy, filter, convInfo) {\n        throw new Error('Not yet implemented');\n    };\n    KernelBackend.prototype.conv3dDerFilter = function (x, dY, convInfo) {\n        throw new Error('Not yet implemented');\n    };\n    KernelBackend.prototype.maxPool = function (x, convInfo) {\n        throw new Error('Not yet implemented');\n    };\n    KernelBackend.prototype.maxPoolBackprop = function (dy, x, y, convInfo) {\n        throw new Error('Not yet implemented');\n    };\n    KernelBackend.prototype.avgPool = function (x, convInfo) {\n        throw new Error('Not yet implemented');\n    };\n    KernelBackend.prototype.avgPoolBackprop = function (dy, x, convInfo) {\n        throw new Error('Not yet implemented');\n    };\n    KernelBackend.prototype.reshape = function (x, shape) {\n        throw new Error('Not yet implemented');\n    };\n    KernelBackend.prototype.cast = function (x, dtype) {\n        throw new Error('Not yet implemented');\n    };\n    KernelBackend.prototype.tile = function (x, reps) {\n        throw new Error('Not yet implemented');\n    };\n    KernelBackend.prototype.pad = function (x, paddings, constantValue) {\n        throw new Error('Not yet implemented');\n    };\n    KernelBackend.prototype.transpose = function (x, perm) {\n        throw new Error('Not yet implemented');\n    };\n    KernelBackend.prototype.gather = function (x, indices, axis) {\n        throw new Error('Not yet implemented');\n    };\n    KernelBackend.prototype.gatherND = function (x, indices) {\n        throw new Error('Not yet implemented');\n    };\n    KernelBackend.prototype.scatterND = function (indices, updates, shape) {\n        throw new Error('Not yet implemented');\n    };\n    KernelBackend.prototype.batchToSpaceND = function (x, blockShape, crops) {\n        throw new Error('Not yet implemented');\n    };\n    KernelBackend.prototype.spaceToBatchND = function (x, blockShape, paddings) {\n        throw new Error('Not yet implemented');\n    };\n    KernelBackend.prototype.resizeBilinear = function (x, newHeight, newWidth, alignCorners) {\n        throw new Error('Not yet implemented');\n    };\n    KernelBackend.prototype.resizeBilinearBackprop = function (dy, x, alignCorners) {\n        throw new Error('Not yet implemented');\n    };\n    KernelBackend.prototype.resizeNearestNeighbor = function (x, newHEight, newWidth, alignCorners) {\n        throw new Error('Not yet implemented');\n    };\n    KernelBackend.prototype.resizeNearestNeighborBackprop = function (dy, x, alignCorners) {\n        throw new Error('Not yet implemented');\n    };\n    KernelBackend.prototype.batchNormalization = function (x, mean, variance, varianceEpsilon, scale, offset) {\n        throw new Error('Not yet implemented');\n    };\n    KernelBackend.prototype.localResponseNormalization4D = function (x, radius, bias, alpha, beta) {\n        throw new Error('Not yet implemented');\n    };\n    KernelBackend.prototype.LRNGrad = function (dy, inputImage, outputImage, radius, bias, alpha, beta) {\n        throw new Error('Not yet implemented');\n    };\n    KernelBackend.prototype.multinomial = function (logits, normalized, numSamples, seed) {\n        throw new Error('Not yet implemented');\n    };\n    KernelBackend.prototype.oneHot = function (indices, depth, onValue, offValue) {\n        throw new Error('Not yet implemented');\n    };\n    KernelBackend.prototype.cumsum = function (x, axis, exclusive, reverse) {\n        throw new Error('Not yet implemented');\n    };\n    KernelBackend.prototype.nonMaxSuppression = function (boxes, scores, maxOutputSize, iouThreshold, scoreThreshold) {\n        throw new Error('Not yet implemented');\n    };\n    KernelBackend.prototype.fft = function (x) {\n        throw new Error('Not yet implemented');\n    };\n    KernelBackend.prototype.ifft = function (x) {\n        throw new Error('Not yet implemented');\n    };\n    KernelBackend.prototype.complex = function (real, imag) {\n        throw new Error('Not yet implemented');\n    };\n    KernelBackend.prototype.real = function (input) {\n        throw new Error('Not yet implemented');\n    };\n    KernelBackend.prototype.imag = function (input) {\n        throw new Error('Not yet implemented');\n    };\n    KernelBackend.prototype.cropAndResize = function (image, boxes, boxIndex, cropSize, method, extrapolationValue) {\n        throw new Error('Not yet implemented');\n    };\n    KernelBackend.prototype.depthToSpace = function (x, blockSize, dataFormat) {\n        throw new Error('Not yet implemented');\n    };\n    // Aligns with the \"SplitV\" kernel in TensorFlow.\n    KernelBackend.prototype.split = function (value, sizeSplits, axis) {\n        throw new Error('Not yet implemented');\n    };\n    KernelBackend.prototype.sparseToDense = function (sparseIndices, sparseValues, outputShape, defaultValue) {\n        throw new Error('Not yet implemented');\n    };\n    KernelBackend.prototype.fill = function (shape, value, dtype) {\n        throw new Error('Not yet implemented.');\n    };\n    KernelBackend.prototype.onesLike = function (x) {\n        throw new Error('Not yet implemented');\n    };\n    KernelBackend.prototype.zerosLike = function (x) {\n        throw new Error('Not yet implemented');\n    };\n    KernelBackend.prototype.linspace = function (start, stop, num) {\n        throw new Error('Not yet implemented');\n    };\n    KernelBackend.prototype.dispose = function () {\n        throw new Error('Not yet implemented');\n    };\n    return KernelBackend;\n}());\nexports.KernelBackend = KernelBackend;\n//# sourceMappingURL=backend.js.map","\n/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nfunction __export(m) {\n    for (var p in m) if (!exports.hasOwnProperty(p)) exports[p] = m[p];\n}\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar tensor_ops_1 = require(\"../ops/tensor_ops\");\nvar tensor_1 = require(\"../tensor\");\nvar util_1 = require(\"../util\");\n// Utilities needed by backend consumers of tf-core.\n__export(require(\"../ops/axis_util\"));\n__export(require(\"../ops/broadcast_util\"));\n__export(require(\"../ops/concat_util\"));\n__export(require(\"../ops/conv_util\"));\nvar types_1 = require(\"../types\");\nexports.upcastType = types_1.upcastType;\nfunction castTensor(x, dtype, backend) {\n    if (dtype === 'complex64') {\n        if (x.dtype === 'complex64') {\n            return x.clone();\n        }\n        var zerosTensor = tensor_ops_1.zeros(x.shape);\n        var floatX = x.toFloat();\n        var result = backend.complex(floatX, zerosTensor);\n        zerosTensor.dispose();\n        floatX.dispose();\n        return result;\n    }\n    if (!util_1.hasEncodingLoss(x.dtype, dtype)) {\n        // We don't change the underlying data, since we cast to higher\n        // precision.\n        return tensor_1.Tensor.make(x.shape, { dataId: x.dataId }, dtype);\n    }\n    if (x.dtype === 'complex64') {\n        var real = backend.real(x);\n        var result = real.cast(dtype);\n        real.dispose();\n        return result;\n    }\n    if (dtype === 'int32') {\n        return backend.int(x);\n    }\n    else if (dtype === 'bool') {\n        var zero = tensor_ops_1.scalar(0, x.dtype);\n        var result = backend.notEqual(x, zero);\n        zero.dispose();\n        return result;\n    }\n    else {\n        throw new Error(\"Error in Cast: failed to cast \" + x.dtype + \" to \" + dtype);\n    }\n}\nexports.castTensor = castTensor;\nfunction reshapeTensor(x, shape) {\n    return tensor_1.Tensor.make(shape, { dataId: x.dataId }, x.dtype);\n}\nexports.reshapeTensor = reshapeTensor;\nfunction linspaceImpl(start, stop, num) {\n    var step = (stop - start) / (num - 1);\n    var values = util_1.makeZerosTypedArray(num, 'float32');\n    values[0] = start;\n    for (var i = 1; i < values.length; i++) {\n        values[i] = values[i - 1] + step;\n    }\n    return tensor_ops_1.tensor1d(values, 'float32');\n}\nexports.linspaceImpl = linspaceImpl;\n//# sourceMappingURL=backend_util.js.map","\n/**\n * @license\n * Copyright 2017 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\n/**\n * Returns the dimensions in the input shape that are broadcasted to\n * produce the provided output shape.\n *\n * The returned dimensions are 0-indexed and sorted. An example:\n * inShape = [4, 1, 3]\n * outShape = [5, 4, 3, 3]\n * result = [1]. Dimension 1 (2nd dimension of input) gets broadcasted 1 => 3.\n */\nfunction getBroadcastDims(inShape, outShape) {\n    var inRank = inShape.length;\n    var dims = [];\n    for (var i = 0; i < inRank; i++) {\n        var dim = inRank - 1 - i;\n        var a = inShape[dim] || 1;\n        var b = outShape[outShape.length - 1 - i] || 1;\n        if (b > 1 && a === 1) {\n            dims.unshift(dim);\n        }\n    }\n    return dims;\n}\nexports.getBroadcastDims = getBroadcastDims;\n/**\n * Returns the axes in the output space that should be reduced to produce\n * the input space.\n */\nfunction getReductionAxes(inShape, outShape) {\n    var result = [];\n    for (var i = 0; i < outShape.length; i++) {\n        var inDim = inShape[inShape.length - i - 1];\n        var outAxis = outShape.length - i - 1;\n        var outDim = outShape[outAxis];\n        if (inDim == null || (inDim === 1 && outDim > 1)) {\n            result.unshift(outAxis);\n        }\n    }\n    return result;\n}\nexports.getReductionAxes = getReductionAxes;\nfunction assertAndGetBroadcastShape(shapeA, shapeB) {\n    var result = [];\n    var l = Math.max(shapeA.length, shapeB.length);\n    for (var i = 0; i < l; i++) {\n        var a = shapeA[shapeA.length - i - 1];\n        if (a == null) {\n            a = 1;\n        }\n        var b = shapeB[shapeB.length - i - 1];\n        if (b == null) {\n            b = 1;\n        }\n        if (a === 1) {\n            result.unshift(b);\n        }\n        else if (b === 1) {\n            result.unshift(a);\n        }\n        else if (a !== b) {\n            var errMsg = \"Operands could not be broadcast together with shapes \" +\n                (shapeA + \" and \" + shapeB + \".\");\n            throw Error(errMsg);\n        }\n        else {\n            result.unshift(a);\n        }\n    }\n    return result;\n}\nexports.assertAndGetBroadcastShape = assertAndGetBroadcastShape;\n//# sourceMappingURL=broadcast_util.js.map","\n/**\n * @license\n * Copyright 2017 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar util = require(\"../util\");\nfunction computePool2DInfo(inShape, filterSize, strides, dilations, pad, roundingMode, dataFormat) {\n    if (dataFormat === void 0) { dataFormat = 'channelsLast'; }\n    var _a = parseTupleParam(filterSize), filterHeight = _a[0], filterWidth = _a[1];\n    var filterShape;\n    if (dataFormat === 'channelsLast') {\n        filterShape = [filterHeight, filterWidth, inShape[3], inShape[3]];\n    }\n    else if (dataFormat === 'channelsFirst') {\n        filterShape = [filterHeight, filterWidth, inShape[1], inShape[1]];\n    }\n    else {\n        throw new Error(\"Unknown dataFormat \" + dataFormat);\n    }\n    return computeConv2DInfo(inShape, filterShape, strides, dilations, pad, roundingMode, false, dataFormat);\n}\nexports.computePool2DInfo = computePool2DInfo;\n/**\n * Computes the information for a forward pass of a convolution/pooling\n * operation.\n */\nfunction computeConv2DInfo(inShape, filterShape, strides, dilations, pad, roundingMode, depthwise, dataFormat) {\n    if (depthwise === void 0) { depthwise = false; }\n    if (dataFormat === void 0) { dataFormat = 'channelsLast'; }\n    var _a = [-1, -1, -1, -1], batchSize = _a[0], inHeight = _a[1], inWidth = _a[2], inChannels = _a[3];\n    if (dataFormat === 'channelsLast') {\n        batchSize = inShape[0], inHeight = inShape[1], inWidth = inShape[2], inChannels = inShape[3];\n    }\n    else if (dataFormat === 'channelsFirst') {\n        batchSize = inShape[0], inChannels = inShape[1], inHeight = inShape[2], inWidth = inShape[3];\n    }\n    else {\n        throw new Error(\"Unknown dataFormat \" + dataFormat);\n    }\n    var filterHeight = filterShape[0], filterWidth = filterShape[1], filterChannels = filterShape[3];\n    var _b = parseTupleParam(strides), strideHeight = _b[0], strideWidth = _b[1];\n    var _c = parseTupleParam(dilations), dilationHeight = _c[0], dilationWidth = _c[1];\n    var effectiveFilterHeight = getEffectiveFilterSize(filterHeight, dilationHeight);\n    var effectiveFilterWidth = getEffectiveFilterSize(filterWidth, dilationWidth);\n    var _d = getPadAndOutInfo(pad, inHeight, inWidth, strideHeight, strideWidth, effectiveFilterHeight, effectiveFilterWidth, roundingMode), padInfo = _d.padInfo, outHeight = _d.outHeight, outWidth = _d.outWidth;\n    var outChannels = depthwise ? filterChannels * inChannels : filterChannels;\n    var outShape;\n    if (dataFormat === 'channelsFirst') {\n        outShape = [batchSize, outChannels, outHeight, outWidth];\n    }\n    else if (dataFormat === 'channelsLast') {\n        outShape = [batchSize, outHeight, outWidth, outChannels];\n    }\n    return {\n        batchSize: batchSize,\n        dataFormat: dataFormat,\n        inHeight: inHeight,\n        inWidth: inWidth,\n        inChannels: inChannels,\n        outHeight: outHeight,\n        outWidth: outWidth,\n        outChannels: outChannels,\n        padInfo: padInfo,\n        strideHeight: strideHeight,\n        strideWidth: strideWidth,\n        filterHeight: filterHeight,\n        filterWidth: filterWidth,\n        effectiveFilterHeight: effectiveFilterHeight,\n        effectiveFilterWidth: effectiveFilterWidth,\n        dilationHeight: dilationHeight,\n        dilationWidth: dilationWidth,\n        inShape: inShape,\n        outShape: outShape,\n        filterShape: filterShape\n    };\n}\nexports.computeConv2DInfo = computeConv2DInfo;\n/**\n * Computes the information for a forward pass of a 3D convolution/pooling\n * operation.\n */\nfunction computeConv3DInfo(inShape, filterShape, strides, dilations, pad, depthwise, dataFormat) {\n    if (depthwise === void 0) { depthwise = false; }\n    if (dataFormat === void 0) { dataFormat = 'channelsLast'; }\n    var _a = [-1, -1, -1, -1, -1], batchSize = _a[0], inDepth = _a[1], inHeight = _a[2], inWidth = _a[3], inChannels = _a[4];\n    if (dataFormat === 'channelsLast') {\n        batchSize = inShape[0], inDepth = inShape[1], inHeight = inShape[2], inWidth = inShape[3], inChannels = inShape[4];\n    }\n    else if (dataFormat === 'channelsFirst') {\n        batchSize = inShape[0], inChannels = inShape[1], inDepth = inShape[2], inHeight = inShape[3], inWidth = inShape[4];\n    }\n    else {\n        throw new Error(\"Unknown dataFormat \" + dataFormat);\n    }\n    var filterDepth = filterShape[0], filterHeight = filterShape[1], filterWidth = filterShape[2], filterChannels = filterShape[4];\n    var _b = parse3TupleParam(strides), strideDepth = _b[0], strideHeight = _b[1], strideWidth = _b[2];\n    var _c = parse3TupleParam(dilations), dilationDepth = _c[0], dilationHeight = _c[1], dilationWidth = _c[2];\n    var effectiveFilterDepth = getEffectiveFilterSize(filterDepth, dilationDepth);\n    var effectiveFilterHeight = getEffectiveFilterSize(filterHeight, dilationHeight);\n    var effectiveFilterWidth = getEffectiveFilterSize(filterWidth, dilationWidth);\n    var _d = get3DPadAndOutInfo(pad, inDepth, inHeight, inWidth, strideDepth, strideHeight, strideWidth, effectiveFilterDepth, effectiveFilterHeight, effectiveFilterWidth), padInfo = _d.padInfo, outDepth = _d.outDepth, outHeight = _d.outHeight, outWidth = _d.outWidth;\n    var outChannels = depthwise ? filterChannels * inChannels : filterChannels;\n    var outShape;\n    if (dataFormat === 'channelsFirst') {\n        outShape = [batchSize, outChannels, outDepth, outHeight, outWidth];\n    }\n    else if (dataFormat === 'channelsLast') {\n        outShape = [batchSize, outDepth, outHeight, outWidth, outChannels];\n    }\n    return {\n        batchSize: batchSize,\n        dataFormat: dataFormat,\n        inDepth: inDepth,\n        inHeight: inHeight,\n        inWidth: inWidth,\n        inChannels: inChannels,\n        outDepth: outDepth,\n        outHeight: outHeight,\n        outWidth: outWidth,\n        outChannels: outChannels,\n        padInfo: padInfo,\n        strideDepth: strideDepth,\n        strideHeight: strideHeight,\n        strideWidth: strideWidth,\n        filterDepth: filterDepth,\n        filterHeight: filterHeight,\n        filterWidth: filterWidth,\n        dilationDepth: dilationDepth,\n        dilationHeight: dilationHeight,\n        dilationWidth: dilationWidth,\n        inShape: inShape,\n        outShape: outShape,\n        filterShape: filterShape\n    };\n}\nexports.computeConv3DInfo = computeConv3DInfo;\nfunction computeOutputShape3D(inShape, fieldSize, outDepth, stride, zeroPad, roundingMode) {\n    if (zeroPad == null) {\n        zeroPad = computeDefaultPad(inShape, fieldSize, stride);\n    }\n    var inputRows = inShape[0];\n    var inputCols = inShape[1];\n    var outputRows = conditionalRound((inputRows - fieldSize + 2 * zeroPad) / stride + 1, roundingMode);\n    util.assert(util.isInt(outputRows), function () { return \"The output # of rows (\" + outputRows + \") must be an integer. \" +\n        \"Change the stride and/or zero pad parameters\"; });\n    var outputCols = conditionalRound((inputCols - fieldSize + 2 * zeroPad) / stride + 1, roundingMode);\n    util.assert(util.isInt(outputCols), function () { return \"The output # of columns (\" + outputCols + \") must be an integer. \" +\n        \"Change the stride and/or zero pad parameters\"; });\n    return [outputRows, outputCols, outDepth];\n}\nfunction computeDefaultPad(inputShape, fieldSize, stride, dilation) {\n    if (dilation === void 0) { dilation = 1; }\n    var effectiveFieldSize = getEffectiveFilterSize(fieldSize, dilation);\n    return Math.floor((inputShape[0] * (stride - 1) - stride + effectiveFieldSize) / 2);\n}\nexports.computeDefaultPad = computeDefaultPad;\nfunction parseTupleParam(param) {\n    return typeof param === 'number' ? [param, param] : param;\n}\nfunction parse3TupleParam(param) {\n    return typeof param === 'number' ? [param, param, param] : param;\n}\n/* See https://www.tensorflow.org/api_docs/python/tf/nn/atrous_conv2d\n * Atrous convolution is equivalent to standard convolution with upsampled\n * filters with effective_filter_height =\n * filter_height + (filter_height - 1) * (dilation - 1)\n * and effective_filter_width =\n * filter_width + (filter_width - 1) * (dilation - 1),\n * produced by inserting dilation - 1 zeros along consecutive elements across\n * the filters' spatial dimensions.\n * When there is a dilation, this converts a filter dimension to the\n * effective filter dimension, so it can be used in a standard convolution.\n */\nfunction getEffectiveFilterSize(filterSize, dilation) {\n    if (dilation <= 1) {\n        return filterSize;\n    }\n    return filterSize + (filterSize - 1) * (dilation - 1);\n}\nfunction getPadAndOutInfo(pad, inHeight, inWidth, strideHeight, strideWidth, filterHeight, filterWidth, roundingMode) {\n    var padInfo;\n    var outHeight;\n    var outWidth;\n    if (typeof pad === 'number') {\n        var padType = (pad === 0) ? 'VALID' : 'NUMBER';\n        padInfo = { top: pad, bottom: pad, left: pad, right: pad, type: padType };\n        var outShape = computeOutputShape3D([inHeight, inWidth, 1], filterHeight, 1, strideHeight, pad, roundingMode);\n        outHeight = outShape[0];\n        outWidth = outShape[1];\n    }\n    else if (pad === 'same') {\n        outHeight = Math.ceil(inHeight / strideHeight);\n        outWidth = Math.ceil(inWidth / strideWidth);\n        var padAlongHeight = Math.max(0, (outHeight - 1) * strideHeight + filterHeight - inHeight);\n        var padAlongWidth = Math.max(0, (outWidth - 1) * strideWidth + filterWidth - inWidth);\n        var top_1 = Math.floor(padAlongHeight / 2);\n        var bottom = padAlongHeight - top_1;\n        var left = Math.floor(padAlongWidth / 2);\n        var right = padAlongWidth - left;\n        padInfo = { top: top_1, bottom: bottom, left: left, right: right, type: 'SAME' };\n    }\n    else if (pad === 'valid') {\n        padInfo = { top: 0, bottom: 0, left: 0, right: 0, type: 'VALID' };\n        outHeight = Math.ceil((inHeight - filterHeight + 1) / strideHeight);\n        outWidth = Math.ceil((inWidth - filterWidth + 1) / strideWidth);\n    }\n    else {\n        throw Error(\"Unknown padding parameter: \" + pad);\n    }\n    return { padInfo: padInfo, outHeight: outHeight, outWidth: outWidth };\n}\nfunction get3DPadAndOutInfo(pad, inDepth, inHeight, inWidth, strideDepth, strideHeight, strideWidth, filterDepth, filterHeight, filterWidth) {\n    var padInfo;\n    var outDepth;\n    var outHeight;\n    var outWidth;\n    if (pad === 'same') {\n        outDepth = Math.ceil(inDepth / strideDepth);\n        outHeight = Math.ceil(inHeight / strideHeight);\n        outWidth = Math.ceil(inWidth / strideWidth);\n        var padAlongDepth = (outDepth - 1) * strideDepth + filterDepth - inDepth;\n        var padAlongHeight = (outHeight - 1) * strideHeight + filterHeight - inHeight;\n        var padAlongWidth = (outWidth - 1) * strideWidth + filterWidth - inWidth;\n        var front = Math.floor(padAlongDepth / 2);\n        var back = padAlongDepth - front;\n        var top_2 = Math.floor(padAlongHeight / 2);\n        var bottom = padAlongHeight - top_2;\n        var left = Math.floor(padAlongWidth / 2);\n        var right = padAlongWidth - left;\n        padInfo = { top: top_2, bottom: bottom, left: left, right: right, front: front, back: back, type: 'SAME' };\n    }\n    else if (pad === 'valid') {\n        padInfo = {\n            top: 0,\n            bottom: 0,\n            left: 0,\n            right: 0,\n            front: 0,\n            back: 0,\n            type: 'VALID'\n        };\n        outDepth = Math.ceil((inDepth - filterDepth + 1) / strideDepth);\n        outHeight = Math.ceil((inHeight - filterHeight + 1) / strideHeight);\n        outWidth = Math.ceil((inWidth - filterWidth + 1) / strideWidth);\n    }\n    else {\n        throw Error(\"Unknown padding parameter: \" + pad);\n    }\n    return { padInfo: padInfo, outDepth: outDepth, outHeight: outHeight, outWidth: outWidth };\n}\n/**\n * Rounds a value depending on the rounding mode\n * @param value\n * @param roundingMode\n */\nfunction conditionalRound(value, roundingMode) {\n    if (!roundingMode) {\n        return value;\n    }\n    switch (roundingMode) {\n        case 'round':\n            // used for Caffe Conv\n            return Math.round(value);\n        case 'ceil':\n            // used for Caffe Pool\n            return Math.ceil(value);\n        case 'floor':\n            return Math.floor(value);\n        default:\n            throw new Error(\"Unknown roundingMode \" + roundingMode);\n    }\n}\nfunction tupleValuesAreOne(param) {\n    var _a = parseTupleParam(param), dimA = _a[0], dimB = _a[1];\n    return dimA === 1 && dimB === 1;\n}\nexports.tupleValuesAreOne = tupleValuesAreOne;\nfunction eitherStridesOrDilationsAreOne(strides, dilations) {\n    return tupleValuesAreOne(strides) || tupleValuesAreOne(dilations);\n}\nexports.eitherStridesOrDilationsAreOne = eitherStridesOrDilationsAreOne;\n//# sourceMappingURL=conv_util.js.map","\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\n/**\n * Merges real and imaginary Float32Arrays into a single complex Float32Array.\n *\n * The memory layout is interleaved as follows:\n * real: [r0, r1, r2]\n * imag: [i0, i1, i2]\n * complex: [r0, i0, r1, i1, r2, i2]\n *\n * This is the inverse of splitRealAndImagArrays.\n *\n * @param real The real values of the complex tensor values.\n * @param imag The imag values of the complex tensor values.\n * @returns A complex tensor as a Float32Array with merged values.\n */\nfunction mergeRealAndImagArrays(real, imag) {\n    if (real.length !== imag.length) {\n        throw new Error(\"Cannot merge real and imag arrays of different lengths. real:\" +\n            (real.length + \", imag: \" + imag.length + \".\"));\n    }\n    var result = new Float32Array(real.length * 2);\n    for (var i = 0; i < result.length; i += 2) {\n        result[i] = real[i / 2];\n        result[i + 1] = imag[i / 2];\n    }\n    return result;\n}\nexports.mergeRealAndImagArrays = mergeRealAndImagArrays;\n/**\n * Splits a complex Float32Array into real and imag parts.\n *\n * The memory layout is interleaved as follows:\n * complex: [r0, i0, r1, i1, r2, i2]\n * real: [r0, r1, r2]\n * imag: [i0, i1, i2]\n *\n * This is the inverse of mergeRealAndImagArrays.\n *\n * @param complex The complex tensor values.\n * @returns An object with real and imag Float32Array components of the complex\n *     tensor.\n */\nfunction splitRealAndImagArrays(complex) {\n    var real = new Float32Array(complex.length / 2);\n    var imag = new Float32Array(complex.length / 2);\n    for (var i = 0; i < complex.length; i += 2) {\n        real[i / 2] = complex[i];\n        imag[i / 2] = complex[i + 1];\n    }\n    return { real: real, imag: imag };\n}\nexports.splitRealAndImagArrays = splitRealAndImagArrays;\n/**\n * Extracts even indexed complex values in the given array.\n * @param complex The complex tensor values\n */\nfunction complexWithEvenIndex(complex) {\n    var len = Math.ceil(complex.length / 4);\n    var real = new Float32Array(len);\n    var imag = new Float32Array(len);\n    for (var i = 0; i < complex.length; i += 4) {\n        real[Math.floor(i / 4)] = complex[i];\n        imag[Math.floor(i / 4)] = complex[i + 1];\n    }\n    return { real: real, imag: imag };\n}\nexports.complexWithEvenIndex = complexWithEvenIndex;\n/**\n * Extracts odd indexed comple values in the given array.\n * @param complex The complex tensor values\n */\nfunction complexWithOddIndex(complex) {\n    var len = Math.floor(complex.length / 4);\n    var real = new Float32Array(len);\n    var imag = new Float32Array(len);\n    for (var i = 2; i < complex.length; i += 4) {\n        real[Math.floor(i / 4)] = complex[i];\n        imag[Math.floor(i / 4)] = complex[i + 1];\n    }\n    return { real: real, imag: imag };\n}\nexports.complexWithOddIndex = complexWithOddIndex;\n/**\n * Get the map representing a complex value in the given array.\n * @param complex The complex tensor values.\n * @param index An index of the target complex value.\n */\nfunction getComplexWithIndex(complex, index) {\n    var real = complex[index * 2];\n    var imag = complex[index * 2 + 1];\n    return { real: real, imag: imag };\n}\nexports.getComplexWithIndex = getComplexWithIndex;\n/**\n * Insert a given complex value into the TypedArray.\n * @param data The array in which the complex value is inserted.\n * @param c The complex value to be inserted.\n * @param index An index of the target complex value.\n */\nfunction assignToTypedArray(data, real, imag, index) {\n    data[index * 2] = real;\n    data[index * 2 + 1] = imag;\n}\nexports.assignToTypedArray = assignToTypedArray;\n/**\n * Make the list of exponent terms used by FFT.\n */\nfunction exponents(n, inverse) {\n    var real = new Float32Array(n / 2);\n    var imag = new Float32Array(n / 2);\n    for (var i = 0; i < Math.ceil(n / 2); i++) {\n        var x = (inverse ? 2 : -2) * Math.PI * (i / n);\n        real[i] = Math.cos(x);\n        imag[i] = Math.sin(x);\n    }\n    return { real: real, imag: imag };\n}\nexports.exponents = exponents;\n/**\n * Make the exponent term used by FFT.\n */\nfunction exponent(k, n, inverse) {\n    var x = (inverse ? 2 : -2) * Math.PI * (k / n);\n    var real = Math.cos(x);\n    var imag = Math.sin(x);\n    return { real: real, imag: imag };\n}\nexports.exponent = exponent;\n//# sourceMappingURL=complex_util.js.map","\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\n/**\n * Implementation of the NonMaxSuppression kernel shared between webgl and cpu.\n */\nvar tensor_ops_1 = require(\"../ops/tensor_ops\");\nfunction nonMaxSuppressionImpl(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold) {\n    var candidates = Array.from(scores)\n        .map(function (score, boxIndex) { return ({ score: score, boxIndex: boxIndex }); })\n        .filter(function (c) { return c.score > scoreThreshold; })\n        .sort(function (c1, c2) { return c2.score - c1.score; });\n    var selected = [];\n    for (var i = 0; i < candidates.length; i++) {\n        var _a = candidates[i], score = _a.score, boxIndex = _a.boxIndex;\n        if (score < scoreThreshold) {\n            break;\n        }\n        var ignoreCandidate = false;\n        for (var j = selected.length - 1; j >= 0; --j) {\n            var iou = intersectionOverUnion(boxes, boxIndex, selected[j]);\n            if (iou >= iouThreshold) {\n                ignoreCandidate = true;\n                break;\n            }\n        }\n        if (!ignoreCandidate) {\n            selected.push(boxIndex);\n            if (selected.length >= maxOutputSize) {\n                break;\n            }\n        }\n    }\n    return tensor_ops_1.tensor1d(selected, 'int32');\n}\nexports.nonMaxSuppressionImpl = nonMaxSuppressionImpl;\nfunction intersectionOverUnion(boxes, i, j) {\n    var iCoord = boxes.subarray(i * 4, i * 4 + 4);\n    var jCoord = boxes.subarray(j * 4, j * 4 + 4);\n    var yminI = Math.min(iCoord[0], iCoord[2]);\n    var xminI = Math.min(iCoord[1], iCoord[3]);\n    var ymaxI = Math.max(iCoord[0], iCoord[2]);\n    var xmaxI = Math.max(iCoord[1], iCoord[3]);\n    var yminJ = Math.min(jCoord[0], jCoord[2]);\n    var xminJ = Math.min(jCoord[1], jCoord[3]);\n    var ymaxJ = Math.max(jCoord[0], jCoord[2]);\n    var xmaxJ = Math.max(jCoord[1], jCoord[3]);\n    var areaI = (ymaxI - yminI) * (xmaxI - xminI);\n    var areaJ = (ymaxJ - yminJ) * (xmaxJ - xminJ);\n    if (areaI <= 0 || areaJ <= 0) {\n        return 0.0;\n    }\n    var intersectionYmin = Math.max(yminI, yminJ);\n    var intersectionXmin = Math.max(xminI, xminJ);\n    var intersectionYmax = Math.min(ymaxI, ymaxJ);\n    var intersectionXmax = Math.min(xmaxI, xmaxJ);\n    var intersectionArea = Math.max(intersectionYmax - intersectionYmin, 0.0) *\n        Math.max(intersectionXmax - intersectionXmin, 0.0);\n    return intersectionArea / (areaI + areaJ - intersectionArea);\n}\n//# sourceMappingURL=non_max_suppression_impl.js.map","\n/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\n/** Shared implementation of the split kernel across WebGL and CPU. */\nfunction split(x, sizeSplits, axis) {\n    var begin = new Array(x.rank).fill(0);\n    var size = x.shape.slice();\n    return sizeSplits.map(function (s) {\n        size[axis] = s;\n        var slice = x.slice(begin, size);\n        begin[axis] += s;\n        return slice;\n    });\n}\nexports.split = split;\n//# sourceMappingURL=split_shared.js.map","\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\n/** An implementation of the TopK kernel shared between webgl and cpu. */\nvar tensor_ops_1 = require(\"../ops/tensor_ops\");\nvar util_1 = require(\"../util\");\nfunction topkImpl(x, xShape, xDtype, k, sorted) {\n    // Reshape into a 2d tensor [batch, lastDim] and compute topk along lastDim.\n    var lastDim = xShape[xShape.length - 1];\n    var _a = [x.length / lastDim, lastDim], batch = _a[0], size = _a[1];\n    var allTopKVals = util_1.getTypedArrayFromDType(xDtype, batch * k);\n    var allTopKIndices = util_1.getTypedArrayFromDType('int32', batch * k);\n    for (var b = 0; b < batch; b++) {\n        var offset = b * size;\n        var vals = x.subarray(offset, offset + size);\n        var valAndInd = [];\n        for (var i = 0; i < vals.length; i++) {\n            valAndInd.push({ value: vals[i], index: i });\n        }\n        valAndInd.sort(function (a, b) { return b.value - a.value; });\n        var outOffset = b * k;\n        var topKVals = allTopKVals.subarray(outOffset, outOffset + k);\n        var topKIndices = allTopKIndices.subarray(outOffset, outOffset + k);\n        for (var i = 0; i < k; i++) {\n            topKVals[i] = valAndInd[i].value;\n            topKIndices[i] = valAndInd[i].index;\n        }\n    }\n    // Reshape back to the original input shape, except that the last\n    // dimension is k.\n    var outputShape = xShape.slice();\n    outputShape[outputShape.length - 1] = k;\n    return [\n        tensor_ops_1.tensor(allTopKVals, outputShape, xDtype),\n        tensor_ops_1.tensor(allTopKIndices, outputShape, 'int32')\n    ];\n}\nexports.topkImpl = topkImpl;\n//# sourceMappingURL=topk_impl.js.map","\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\n/** An implementation of the Where kernel shared between cpu and webgl */\nvar array_ops_1 = require(\"../ops/array_ops\");\nfunction whereImpl(condShape, condVals) {\n    var indices = [];\n    for (var i = 0; i < condVals.length; i++) {\n        if (condVals[i]) {\n            indices.push(i);\n        }\n    }\n    var inBuffer = array_ops_1.buffer(condShape, 'int32');\n    var out = array_ops_1.buffer([indices.length, condShape.length], 'int32');\n    for (var i = 0; i < indices.length; i++) {\n        var loc = inBuffer.indexToLoc(indices[i]);\n        var offset = i * condShape.length;\n        out.values.set(loc, offset);\n    }\n    return out.toTensor();\n}\nexports.whereImpl = whereImpl;\n//# sourceMappingURL=where_impl.js.map","\n/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : new P(function (resolve) { resolve(result.value); }).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nvar __generator = (this && this.__generator) || function (thisArg, body) {\n    var _ = { label: 0, sent: function() { if (t[0] & 1) throw t[1]; return t[1]; }, trys: [], ops: [] }, f, y, t, g;\n    return g = { next: verb(0), \"throw\": verb(1), \"return\": verb(2) }, typeof Symbol === \"function\" && (g[Symbol.iterator] = function() { return this; }), g;\n    function verb(n) { return function (v) { return step([n, v]); }; }\n    function step(op) {\n        if (f) throw new TypeError(\"Generator is already executing.\");\n        while (_) try {\n            if (f = 1, y && (t = op[0] & 2 ? y[\"return\"] : op[0] ? y[\"throw\"] || ((t = y[\"return\"]) && t.call(y), 0) : y.next) && !(t = t.call(y, op[1])).done) return t;\n            if (y = 0, t) op = [op[0] & 2, t.value];\n            switch (op[0]) {\n                case 0: case 1: t = op; break;\n                case 4: _.label++; return { value: op[1], done: false };\n                case 5: _.label++; y = op[1]; op = [0]; continue;\n                case 7: op = _.ops.pop(); _.trys.pop(); continue;\n                default:\n                    if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) { _ = 0; continue; }\n                    if (op[0] === 3 && (!t || (op[1] > t[0] && op[1] < t[3]))) { _.label = op[1]; break; }\n                    if (op[0] === 6 && _.label < t[1]) { _.label = t[1]; t = op; break; }\n                    if (t && _.label < t[2]) { _.label = t[2]; _.ops.push(op); break; }\n                    if (t[2]) _.ops.pop();\n                    _.trys.pop(); continue;\n            }\n            op = body.call(thisArg, _);\n        } catch (e) { op = [6, e]; y = 0; } finally { f = t = 0; }\n        if (op[0] & 5) throw op[1]; return { value: op[0] ? op[1] : void 0, done: true };\n    }\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar engine_1 = require(\"../engine\");\nvar tensor_1 = require(\"../tensor\");\nvar tensor_util_env_1 = require(\"../tensor_util_env\");\nvar util = require(\"../util\");\nvar axis_util_1 = require(\"./axis_util\");\nvar concat_split_1 = require(\"./concat_split\");\nvar operation_1 = require(\"./operation\");\nvar rand_1 = require(\"./rand\");\nvar tensor_ops_1 = require(\"./tensor_ops\");\n/**\n * Creates a new tensor with the same values and shape as the specified\n * tensor.\n *\n * ```js\n * const x = tf.tensor([1, 2]);\n *\n * x.clone().print();\n * ```\n *\n * @param x The tensor to clone.\n */\n/** @doc {heading: 'Tensors', subheading: 'Creation'} */\nfunction clone_(x) {\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'clone', null);\n    var der = function (dy) {\n        return { $x: function () { return dy.toFloat(); } };\n    };\n    return engine_1.ENGINE.runKernel(function (backend) {\n        return tensor_1.Tensor.make($x.shape, { dataId: $x.dataId }, $x.dtype);\n    }, { $x: $x }, der);\n}\n/**\n * Create an identity matrix.\n *\n * @param numRows Number of rows.\n * @param numColumns Number of columns. Defaults to `numRows`.\n * @param batchShape If provided, will add the batch shape to the beginning\n *   of the shape of the returned `tf.Tensor` by repeating the identity\n *   matrix.\n * @param dtype Data type.\n * @returns Identity matrix of the specified size and data type, possibly\n *   with batch repetition if `batchShape` is specified.\n */\n/** @doc {heading: 'Tensors', subheading: 'Creation'} */\nfunction eye_(numRows, numColumns, batchShape, dtype) {\n    if (dtype === void 0) { dtype = 'float32'; }\n    if (numColumns == null) {\n        numColumns = numRows;\n    }\n    var buff = buffer([numRows, numColumns], dtype);\n    var n = numRows <= numColumns ? numRows : numColumns;\n    for (var i = 0; i < n; ++i) {\n        buff.set(1, i, i);\n    }\n    var out = buff.toTensor().as2D(numRows, numColumns);\n    if (batchShape == null) {\n        return out;\n    }\n    else {\n        if (batchShape.length === 1) {\n            return exports.tile(exports.expandDims(out, 0), [batchShape[0], 1, 1]);\n        }\n        else if (batchShape.length === 2) {\n            return exports.tile(exports.expandDims(exports.expandDims(out, 0), 0), [batchShape[0], batchShape[1], 1, 1]);\n        }\n        else if (batchShape.length === 3) {\n            return exports.tile(exports.expandDims(exports.expandDims(exports.expandDims(out, 0), 0), 0), [batchShape[0], batchShape[1], batchShape[2], 1, 1]);\n        }\n        else {\n            throw new Error(\"eye() currently supports only 1D and 2D \" +\n                (\n                // tslint:disable-next-line:no-any\n                \"batchShapes, but received \" + batchShape.length + \"D.\"));\n        }\n    }\n}\n/**\n * Creates a `tf.Tensor` with values sampled from a normal distribution.\n *\n * ```js\n * tf.randomNormal([2, 2]).print();\n * ```\n *\n * @param shape An array of integers defining the output tensor shape.\n * @param mean The mean of the normal distribution.\n * @param stdDev The standard deviation of the normal distribution.\n * @param dtype The data type of the output.\n * @param seed The seed for the random number generator.\n */\n/** @doc {heading: 'Tensors', subheading: 'Random'} */\nfunction randomNormal_(shape, mean, stdDev, dtype, seed) {\n    if (mean === void 0) { mean = 0; }\n    if (stdDev === void 0) { stdDev = 1; }\n    if (dtype != null && dtype === 'bool') {\n        throw new Error(\"Unsupported data type \" + dtype);\n    }\n    var randGauss = new rand_1.MPRandGauss(mean, stdDev, dtype, false /* truncated */, seed);\n    var res = buffer(shape, dtype);\n    for (var i = 0; i < res.values.length; i++) {\n        res.values[i] = randGauss.nextValue();\n    }\n    return res.toTensor();\n}\n/**\n * Creates a `tf.Tensor` with values sampled from a truncated normal\n * distribution.\n *\n * ```js\n * tf.truncatedNormal([2, 2]).print();\n * ```\n *\n * The generated values follow a normal distribution with specified mean and\n * standard deviation, except that values whose magnitude is more than 2\n * standard deviations from the mean are dropped and re-picked.\n *\n * @param shape An array of integers defining the output tensor shape.\n * @param mean The mean of the normal distribution.\n * @param stdDev The standard deviation of the normal distribution.\n * @param dtype The data type of the output tensor.\n * @param seed The seed for the random number generator.\n */\n/** @doc {heading: 'Tensors', subheading: 'Creation'} */\nfunction truncatedNormal_(shape, mean, stdDev, dtype, seed) {\n    if (mean === void 0) { mean = 0; }\n    if (stdDev === void 0) { stdDev = 1; }\n    if (dtype != null && dtype === 'bool') {\n        throw new Error(\"Unsupported data type \" + dtype);\n    }\n    var randGauss = new rand_1.MPRandGauss(mean, stdDev, dtype, true /* truncated */, seed);\n    var res = buffer(shape, dtype);\n    for (var i = 0; i < res.values.length; i++) {\n        res.values[i] = randGauss.nextValue();\n    }\n    return res.toTensor();\n}\n/**\n * Creates a `tf.Tensor` with values sampled from a uniform distribution.\n *\n * The generated values follow a uniform distribution in the range [minval,\n * maxval). The lower bound minval is included in the range, while the upper\n * bound maxval is excluded.\n *\n * ```js\n * tf.randomUniform([2, 2]).print();\n * ```\n *\n * @param shape An array of integers defining the output tensor shape.\n * @param minval The lower bound on the range of random values to generate.\n *   Defaults to 0.\n * @param maxval The upper bound on the range of random values to generate.\n *   Defaults to 1.\n * @param dtype The data type of the output tensor. Defaults to 'float32'.\n */\n/** @doc {heading: 'Tensors', subheading: 'Random'} */\nfunction randomUniform_(shape, minval, maxval, dtype, seed) {\n    if (minval === void 0) { minval = 0; }\n    if (maxval === void 0) { maxval = 1; }\n    if (dtype === void 0) { dtype = 'float32'; }\n    var res = buffer(shape, dtype);\n    var random = new rand_1.UniformRandom(minval, maxval, null, seed);\n    for (var i = 0; i < res.values.length; i++) {\n        res.values[i] = random.nextValue();\n    }\n    return res.toTensor();\n}\n/**\n * Creates a `tf.Tensor` with values sampled from a random number generator\n * function defined by the user.\n *\n * @param shape An array of integers defining the output tensor shape.\n * @param randFunction A random number generator function which is called\n * for each element in the output tensor.\n * @param dtype The data type of the output tensor. Defaults to 'float32'.\n */\nfunction rand_(shape, randFunction, dtype) {\n    var size = util.sizeFromShape(shape);\n    var values = null;\n    if (dtype == null || dtype === 'float32') {\n        values = new Float32Array(size);\n    }\n    else if (dtype === 'int32') {\n        values = new Int32Array(size);\n    }\n    else if (dtype === 'bool') {\n        values = new Uint8Array(size);\n    }\n    else {\n        throw new Error(\"Unknown data type \" + dtype);\n    }\n    for (var i = 0; i < size; i++) {\n        values[i] = randFunction();\n    }\n    return tensor_1.Tensor.make(shape, { values: values }, dtype);\n}\n/**\n * Creates a `tf.Tensor` with values drawn from a multinomial distribution.\n *\n * ```js\n * const probs = tf.tensor([.75, .25]);\n * tf.multinomial(probs, 3).print();\n * ```\n *\n * @param logits 1D array with unnormalized log-probabilities, or\n *     2D array of shape `[batchSize, numOutcomes]`. See the `normalized`\n *     parameter.\n * @param numSamples Number of samples to draw for each row slice.\n * @param seed The seed number.\n * @param normalized Whether the provided `logits` are normalized true\n *     probabilities (sum to 1). Defaults to false.\n * @return 1D array of shape `[numSamples]`, or 2D array of shape\n *     `[batchSize, numSamples]`, depending on the rank of the input.\n */\n/** @doc {heading: 'Tensors', subheading: 'Random'} */\nfunction multinomial_(logits, numSamples, seed, normalized) {\n    if (normalized === void 0) { normalized = false; }\n    var $logits = tensor_util_env_1.convertToTensor(logits, 'logits', 'multinomial');\n    var numOutcomes = $logits.size;\n    var origRank = $logits.rank;\n    if (numOutcomes < 2) {\n        throw new Error(\"Error in multinomial: you need at least 2 outcomes, but got \" +\n            (numOutcomes + \".\"));\n    }\n    if (origRank > 2) {\n        throw new Error(\"Rank of probabilities must be 1 or 2, but is \" + origRank);\n    }\n    seed = seed || Math.random();\n    var logits2D = origRank === 1 ? $logits.as2D(1, -1) : $logits;\n    var res = engine_1.ENGINE.runKernel(function (backend) { return backend.multinomial(logits2D, normalized, numSamples, seed); }, { logits2D: logits2D });\n    return origRank === 1 ? res.as1D() : res;\n}\n/**\n * Creates a one-hot `tf.Tensor`. The locations represented by `indices` take\n * value `onValue` (defaults to 1), while all other locations take value\n * `offValue` (defaults to 0). If `indices` is rank `R`, the output has rank\n * `R+1` with the last axis of size `depth`.\n *\n * ```js\n * tf.oneHot(tf.tensor1d([0, 1], 'int32'), 3).print();\n * ```\n *\n * @param indices `tf.Tensor` of indices with dtype `int32`.\n * @param depth The depth of the one hot dimension.\n * @param onValue A number used to fill in the output when the index matches\n * the location.\n * @param offValue A number used to fill in the output when the index does\n *     not match the location.\n */\n/** @doc {heading: 'Tensors', subheading: 'Creation'} */\nfunction oneHot_(indices, depth, onValue, offValue) {\n    if (onValue === void 0) { onValue = 1; }\n    if (offValue === void 0) { offValue = 0; }\n    if (depth < 2) {\n        throw new Error(\"Error in oneHot: depth must be >=2, but it is \" + depth);\n    }\n    var $indices = tensor_util_env_1.convertToTensor(indices, 'indices', 'oneHot', 'int32');\n    var outShape = $indices.shape.concat([depth]);\n    $indices = $indices.flatten();\n    var grad = function (dy) {\n        return { $indices: function () { return tensor_ops_1.zeros($indices.shape, 'float32'); } };\n    };\n    var result = engine_1.ENGINE.runKernel(function (backend) { return backend.oneHot($indices, depth, onValue, offValue); }, { $indices: $indices }, grad);\n    return result.reshape(outShape);\n}\n/**\n * Reshapes a `tf.Tensor` to a given shape.\n *\n * Given an input tensor, returns a new tensor with the same values as the\n * input tensor with shape `shape`.\n *\n * If one component of shape is the special value -1, the size of that\n * dimension is computed so that the total size remains constant. In\n * particular, a shape of [-1] flattens into 1-D. At most one component of\n * shape can be -1.\n *\n * If shape is 1-D or higher, then the operation returns a tensor with shape\n * shape filled with the values of tensor. In this case, the number of\n * elements implied by shape must be the same as the number of elements in\n * tensor.\n *\n * ```js\n * const x = tf.tensor1d([1, 2, 3, 4]);\n * x.reshape([2, 2]).print();\n * ```\n *\n * @param x The input tensor to be reshaped.\n * @param shape An array of integers defining the output tensor shape.\n */\n/** @doc {heading: 'Tensors', subheading: 'Transformations'} */\nfunction reshape_(x, shape) {\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'reshape', null);\n    shape = util.inferFromImplicitShape(shape, $x.size);\n    util.assert($x.size === util.sizeFromShape(shape), function () { return 'new shape and old shape must have the same number of elements.'; });\n    var grad = function (dy) {\n        return { $x: function () { return dy.reshape($x.shape); } };\n    };\n    return engine_1.ENGINE.runKernel(function (backend) { return backend.reshape($x, shape); }, { $x: $x }, grad);\n}\n/**\n * Removes dimensions of size 1 from the shape of a `tf.Tensor`.\n *\n * ```js\n * const x = tf.tensor([1, 2, 3, 4], [1, 1, 4]);\n * x.squeeze().print();\n * ```\n *\n * @param x The input tensor to be squeezed.\n * @param axis An optional list of numbers. If specified, only\n *     squeezes the dimensions listed. The dimension index starts at 0. It\n * is an error to squeeze a dimension that is not 1.\n */\n/** @doc {heading: 'Tensors', subheading: 'Transformations'} */\nfunction squeeze_(x, axis) {\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'squeeze');\n    return exports.reshape($x, util.squeezeShape($x.shape, axis).newShape);\n}\n/**\n * Casts a `tf.Tensor` to a new dtype.\n *\n * ```js\n * const x = tf.tensor1d([1.5, 2.5, 3]);\n * tf.cast(x, 'int32').print();\n * ```\n * @param x The input tensor to be casted.\n * @param dtype The dtype to cast the input tensor to.\n */\n/** @doc {heading: 'Tensors', subheading: 'Transformations'} */\nfunction cast_(x, dtype) {\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'cast');\n    // Sanity checks.\n    if (!util.isValidDtype(dtype)) {\n        throw new Error(\"Failed to cast to unknown dtype \" + dtype);\n    }\n    if (dtype === 'string' && $x.dtype !== 'string' ||\n        dtype !== 'string' && $x.dtype === 'string') {\n        throw new Error('Only strings can be casted to strings');\n    }\n    var grad = function (dy) {\n        return { $x: function () { return dy.clone(); } };\n    };\n    return engine_1.ENGINE.runKernel(function (backend) { return backend.cast($x, dtype); }, { $x: $x }, grad);\n}\n/**\n * Construct a tensor by repeating it the number of times given by reps.\n *\n * This operation creates a new tensor by replicating `input` `reps`\n * times. The output tensor's i'th dimension has `input.shape[i] *\n * reps[i]` elements, and the values of `input` are replicated\n * `reps[i]` times along the i'th dimension. For example, tiling\n * `[a, b, c, d]` by `[2]` produces `[a, b, c, d, a, b, c, d]`.\n *\n * ```js\n * const a = tf.tensor1d([1, 2]);\n *\n * a.tile([2]).print();    // or a.tile([2])\n * ```\n *\n * ```js\n * const a = tf.tensor2d([1, 2, 3, 4], [2, 2]);\n *\n * a.tile([1, 2]).print();  // or a.tile([1, 2])\n * ```\n * @param x The tensor to tile.\n * @param reps Determines the number of replications per dimension.\n */\n/** @doc {heading: 'Tensors', subheading: 'Slicing and Joining'} */\nfunction tile_(x, reps) {\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'tile');\n    util.assert($x.rank === reps.length, function () { return \"Error in transpose: rank of input \" + $x.rank + \" \" +\n        (\"must match length of reps \" + reps + \".\"); });\n    var grad = function (dy, saved) {\n        var $x = saved[0];\n        var derX = function () {\n            var xGrad = tensor_ops_1.zerosLike($x);\n            // TODO(cais): Maybe reduce memory footprint by avoiding repeated\n            // slicing.\n            if ($x.rank === 1) {\n                for (var i = 0; i < reps[0]; ++i) {\n                    xGrad = xGrad.add(dy.slice([i * $x.shape[0]], [$x.shape[0]]));\n                }\n            }\n            else if ($x.rank === 2) {\n                for (var i = 0; i < reps[0]; ++i) {\n                    for (var j = 0; j < reps[1]; ++j) {\n                        xGrad = xGrad.add(dy.slice([i * $x.shape[0], j * $x.shape[1]], [$x.shape[0], $x.shape[1]]));\n                    }\n                }\n            }\n            else if ($x.rank === 3) {\n                for (var i = 0; i < reps[0]; ++i) {\n                    for (var j = 0; j < reps[1]; ++j) {\n                        for (var k = 0; k < reps[2]; ++k) {\n                            xGrad = xGrad.add(dy.slice([i * $x.shape[0], j * $x.shape[1], k * $x.shape[2]], [$x.shape[0], $x.shape[1], $x.shape[2]]));\n                        }\n                    }\n                }\n            }\n            else if ($x.rank === 4) {\n                for (var i = 0; i < reps[0]; ++i) {\n                    for (var j = 0; j < reps[1]; ++j) {\n                        for (var k = 0; k < reps[2]; ++k) {\n                            for (var l = 0; l < reps[3]; ++l) {\n                                xGrad = xGrad.add(dy.slice([\n                                    i * $x.shape[0], j * $x.shape[1], k * $x.shape[2],\n                                    l * $x.shape[3]\n                                ], [$x.shape[0], $x.shape[1], $x.shape[2], $x.shape[3]]));\n                            }\n                        }\n                    }\n                }\n            }\n            else {\n                throw new Error(\"Gradient for tile operation is not implemented for rank-\" +\n                    ($x.rank + \" tensors yet.\"));\n            }\n            return xGrad;\n        };\n        return { $x: derX };\n    };\n    return engine_1.ENGINE.runKernel(function (backend, save) {\n        var res = backend.tile($x, reps);\n        save([$x]);\n        return res;\n    }, { $x: $x }, grad);\n}\n/**\n * Pads a `tf.Tensor1D` with a given value and paddings. See `pad` for details.\n */\nfunction pad1d_(x, paddings, constantValue) {\n    if (constantValue === void 0) { constantValue = 0; }\n    util.assert(paddings.length === 2, function () { return 'Invalid number of paddings. Must be length of 2.'; });\n    return exports.pad(x, [paddings], constantValue);\n}\n/**\n * Pads a `tf.Tensor2D` with a given value and paddings. See `pad` for details.\n */\nfunction pad2d_(x, paddings, constantValue) {\n    if (constantValue === void 0) { constantValue = 0; }\n    util.assert(paddings.length === 2 && paddings[0].length === 2 &&\n        paddings[1].length === 2, function () { return 'Invalid number of paddings. Must be length of 2 each.'; });\n    return exports.pad(x, paddings, constantValue);\n}\n/**\n * Pads a `tf.Tensor3D` with a given value and paddings. See `pad` for details.\n */\nfunction pad3d_(x, paddings, constantValue) {\n    if (constantValue === void 0) { constantValue = 0; }\n    util.assert(paddings.length === 3 && paddings[0].length === 2 &&\n        paddings[1].length === 2 && paddings[2].length === 2, function () { return 'Invalid number of paddings. Must be length of 2 each.'; });\n    return exports.pad(x, paddings, constantValue);\n}\n/**\n * Pads a `tf.Tensor4D` with a given value and paddings. See `pad` for details.\n */\nfunction pad4d_(x, paddings, constantValue) {\n    if (constantValue === void 0) { constantValue = 0; }\n    util.assert(paddings.length === 4 && paddings[0].length === 2 &&\n        paddings[1].length === 2 && paddings[2].length === 2 &&\n        paddings[3].length === 2, function () { return 'Invalid number of paddings. Must be length of 2 each.'; });\n    return exports.pad(x, paddings, constantValue);\n}\n/**\n * Pads a `tf.Tensor` with a given value and paddings.\n *\n * This operation currently only implements the `CONSTANT` mode.\n *\n * Also available are stricter rank-specific methods with the same signature\n * as this method that assert that `paddings` is of given length.\n *   - `tf.pad1d`\n *   - `tf.pad2d`\n *   - `tf.pad3d`\n *   - `tf.pad4d`\n *\n * ```js\n * const x = tf.tensor1d([1, 2, 3, 4]);\n * x.pad([[1, 2]]).print();\n * ```\n * @param x The tensor to pad.\n * @param paddings An array of length `R` (the rank of the tensor), where\n * each element is a length-2 tuple of ints `[padBefore, padAfter]`,\n * specifying how much to pad along each dimension of the tensor.\n * @param constantValue The pad value to use. Defaults to 0.\n */\n/** @doc {heading: 'Tensors', subheading: 'Transformations'} */\nfunction pad_(x, paddings, constantValue) {\n    if (constantValue === void 0) { constantValue = 0; }\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'pad');\n    if ($x.rank === 0) {\n        throw new Error('pad(scalar) is not defined. Pass non-scalar to pad');\n    }\n    // Pad introduces values around the original tensor, so the gradient\n    // slices the original shape out of the gradient.\n    var begin = paddings.map(function (p) { return p[0]; });\n    var grad = function (dy) {\n        return { $x: function () { return dy.slice(begin, $x.shape); } };\n    };\n    return engine_1.ENGINE.runKernel(function (backend) { return backend.pad($x, paddings, constantValue); }, { $x: $x }, grad);\n}\n/**\n * Stacks a list of rank-`R` `tf.Tensor`s into one rank-`(R+1)` `tf.Tensor`.\n *\n * ```js\n * const a = tf.tensor1d([1, 2]);\n * const b = tf.tensor1d([3, 4]);\n * const c = tf.tensor1d([5, 6]);\n * tf.stack([a, b, c]).print();\n * ```\n *\n * @param tensors A list of tensor objects with the same shape and dtype.\n * @param axis The axis to stack along. Defaults to 0 (the first dim).\n */\n/** @doc {heading: 'Tensors', subheading: 'Slicing and Joining'} */\nfunction stack_(tensors, axis) {\n    if (axis === void 0) { axis = 0; }\n    var $tensors = tensor_util_env_1.convertToTensorArray(tensors, 'tensors', 'stack');\n    util.assert($tensors.length >= 1, function () { return 'Pass at least one tensor to tf.stack'; });\n    if ($tensors.length === 1) {\n        return $tensors[0].expandDims(axis);\n    }\n    var rank = $tensors[0].rank;\n    var shape = $tensors[0].shape;\n    var dtype = $tensors[0].dtype;\n    util.assert(axis <= rank, function () { return 'Axis must be <= rank of the tensor'; });\n    $tensors.forEach(function (t) {\n        util.assertShapesMatch(shape, t.shape, 'All tensors passed to stack must have matching shapes');\n    });\n    $tensors.forEach(function (t) {\n        util.assert(dtype === t.dtype, function () { return 'All tensors passed to stack must have matching dtypes'; });\n    });\n    var expandedTensors = $tensors.map(function (t) { return t.expandDims(axis); });\n    return concat_split_1.concat(expandedTensors, axis);\n}\n/**\n * This operation reshapes the \"batch\" dimension 0 into `M + 1` dimensions of\n * shape `blockShape + [batch]`, interleaves these blocks back into the grid\n * defined by the spatial dimensions `[1, ..., M]`, to obtain a result with\n * the same rank as the input. The spatial dimensions of this intermediate\n * result are then optionally cropped according to `crops` to produce the\n * output. This is the reverse of `tf.spaceToBatchND`. See below for a precise\n * description.\n *\n * ```js\n * const x = tf.tensor4d([1, 2, 3, 4], [4, 1, 1, 1]);\n * const blockShape = [2, 2];\n * const crops = [[0, 0], [0, 0]];\n *\n * x.batchToSpaceND(blockShape, crops).print();\n * ```\n *\n * @param x A `tf.Tensor`. N-D with `x.shape` = `[batch] + spatialShape +\n * remainingShape`, where spatialShape has `M` dimensions.\n * @param blockShape A 1-D array. Must have shape `[M]`, all values must\n * be >= 1.\n * @param crops A 2-D array.  Must have shape `[M, 2]`, all values must be >= 0.\n * `crops[i] = [cropStart, cropEnd]` specifies the amount to crop from input\n * dimension `i + 1`, which corresponds to spatial dimension `i`. It is required\n * that `cropStart[i] + cropEnd[i] <= blockShape[i] * inputShape[i + 1]`\n *\n * This operation is equivalent to the following steps:\n *\n * 1. Reshape `x` to `reshaped` of shape: `[blockShape[0], ...,\n * blockShape[M-1], batch / prod(blockShape), x.shape[1], ...,\n * x.shape[N-1]]`\n *\n * 2. Permute dimensions of `reshaped`to produce `permuted` of shape `[batch /\n * prod(blockShape),x.shape[1], blockShape[0], ..., x.shape[M],\n * blockShape[M-1],x.shape[M+1], ..., x.shape[N-1]]`\n *\n * 3. Reshape `permuted` to produce `reshapedPermuted` of shape `[batch /\n * prod(blockShape),x.shape[1] * blockShape[0], ..., x.shape[M] *\n * blockShape[M-1],x.shape[M+1], ..., x.shape[N-1]]`\n *\n * 4. Crop the start and end of dimensions `[1, ..., M]` of `reshapedPermuted`\n * according to `crops` to produce the output of shape: `[batch /\n * prod(blockShape),x.shape[1] * blockShape[0] - crops[0,0] - crops[0,1],\n * ..., x.shape[M] * blockShape[M-1] - crops[M-1,0] -\n * crops[M-1,1],x.shape[M+1], ..., x.shape[N-1]]`\n */\n/** @doc {heading: 'Tensors', subheading: 'Transformations'} */\nfunction batchToSpaceND_(x, blockShape, crops) {\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'batchToSpaceND');\n    var prod = blockShape.reduce(function (a, b) { return a * b; });\n    util.assert($x.rank >= 1 + blockShape.length, function () { return \"input rank is \" + $x.rank + \" but should be > than blockShape.length \" + blockShape.length; });\n    util.assert(crops.length === blockShape.length, function () { return \"crops.length is \" + crops.length + \" but should be equal to blockShape.length  \" + blockShape.length; });\n    util.assert($x.shape[0] % prod === 0, function () { return \"input tensor batch is \" + $x.shape[0] + \" but is not divisible by the product of \" +\n        (\"the elements of blockShape \" + blockShape.join(' * ') + \" === \" + prod); });\n    var grad = function (dy) {\n        return { $x: function () { return dy.spaceToBatchND(blockShape, crops); } };\n    };\n    return engine_1.ENGINE.runKernel(function (backend) { return backend.batchToSpaceND($x, blockShape, crops); }, { $x: $x }, grad);\n}\n/**\n * This operation divides \"spatial\" dimensions `[1, ..., M]` of the input into\n * a grid of blocks of shape `blockShape`, and interleaves these blocks with\n * the \"batch\" dimension (0) such that in the output, the spatial\n * dimensions `[1, ..., M]` correspond to the position within the grid,\n * and the batch dimension combines both the position within a spatial block\n * and the original batch position. Prior to division into blocks,\n * the spatial dimensions of the input are optionally zero padded\n * according to `paddings`. See below for a precise description.\n *\n * ```js\n * const x = tf.tensor4d([1, 2, 3, 4], [1, 2, 2, 1]);\n * const blockShape = [2, 2];\n * const paddings = [[0, 0], [0, 0]];\n *\n * x.spaceToBatchND(blockShape, paddings).print();\n * ```\n *\n * @param x A `tf.Tensor`. N-D with `x.shape` = `[batch] + spatialShape +\n * remainingShape`, where spatialShape has `M` dimensions.\n * @param blockShape A 1-D array. Must have shape `[M]`, all values must\n * be >= 1.\n * @param paddings A 2-D array. Must have shape `[M, 2]`, all values must be >=\n *     0. `paddings[i] = [padStart, padEnd]` specifies the amount to zero-pad\n * from input dimension `i + 1`, which corresponds to spatial dimension `i`. It\n * is required that\n * `(inputShape[i + 1] + padStart + padEnd) % blockShape[i] === 0`\n *\n * This operation is equivalent to the following steps:\n *\n * 1. Zero-pad the start and end of dimensions `[1, ..., M]` of the input\n * according to `paddings` to produce `padded` of shape paddedShape.\n *\n * 2. Reshape `padded` to `reshapedPadded` of shape:\n * `[batch] + [paddedShape[1] / blockShape[0], blockShape[0], ...,\n * paddedShape[M] / blockShape[M-1], blockShape[M-1]] + remainingShape`\n *\n * 3. Permute dimensions of `reshapedPadded` to produce `permutedReshapedPadded`\n * of shape: `blockShape + [batch] + [paddedShape[1] / blockShape[0], ...,\n * paddedShape[M] / blockShape[M-1]] + remainingShape`\n *\n * 4. Reshape `permutedReshapedPadded` to flatten `blockShape` into the\n * batch dimension, producing an output tensor of shape:\n * `[batch * prod(blockShape)] + [paddedShape[1] / blockShape[0], ...,\n * paddedShape[M] / blockShape[M-1]] + remainingShape`\n */\n/** @doc {heading: 'Tensors', subheading: 'Transformations'} */\nfunction spaceToBatchND_(x, blockShape, paddings) {\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'spaceToBatchND');\n    util.assert($x.rank >= 1 + blockShape.length, function () { return \"input rank \" + $x.rank + \" should be > than [blockShape] \" + blockShape.length; });\n    util.assert(paddings.length === blockShape.length, function () { return \"paddings.shape[0] \" + paddings.length + \" must be equal to [blockShape] \" + blockShape.length; });\n    util.assert($x.shape.reduce(function (a, b, i) {\n        if (i > 0 && i <= blockShape.length) {\n            return a &&\n                ((b + paddings[i - 1][0] + paddings[i - 1][1]) %\n                    blockShape[i - 1] ===\n                    0);\n        }\n        return a;\n    }, true), function () { return \"input spatial dimensions \" + $x.shape.slice(1) + \" with paddings \" + paddings.toString() + \" must be divisible by blockShapes \" + blockShape.toString(); });\n    var grad = function (dy) {\n        return { $x: function () { return dy.batchToSpaceND(blockShape, paddings); } };\n    };\n    return engine_1.ENGINE.runKernel(function (backend) { return backend.spaceToBatchND($x, blockShape, paddings); }, { $x: $x }, grad);\n}\n/**\n * Unstacks a `tf.Tensor` of rank-`R` into a list of rank-`(R-1)` `tf.Tensor`s.\n *\n * ```js\n * const a = tf.tensor2d([1, 2, 3, 4], [2, 2]);\n *\n * tf.unstack(a).forEach(tensor => tensor.print());\n * ```\n *\n * @param x A tensor object.\n * @param axis The axis to unstack along. Defaults to 0 (the first dim).\n */\n/** @doc {heading: 'Tensors', subheading: 'Slicing and Joining'} */\nfunction unstack_(x, axis) {\n    if (axis === void 0) { axis = 0; }\n    axis = axis || 0;\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'unstack');\n    util.assert(axis >= -$x.shape.length && axis < $x.shape.length, function () {\n        return \"Axis = \" + axis + \" is not in [-\" + $x.shape.length + \", \" + $x.shape.length + \")\";\n    });\n    if (axis < 0) {\n        axis += $x.shape.length;\n    }\n    var grad = function (dy) {\n        return { $x: function () { return exports.stack(dy, axis); } };\n    };\n    return engine_1.ENGINE.runKernel(function (backend) { return backend.unstack($x, axis); }, { $x: $x }, grad);\n}\n/**\n * Computes the cumulative sum of a `tf.Tensor` along `axis`.\n *\n * ```js\n * const x = tf.tensor([1, 2, 3, 4]);\n * x.cumsum().print();\n * ```\n * ```js\n * const x = tf.tensor([[1, 2], [3, 4]]);\n * x.cumsum().print();\n * ```\n *\n * @param x The input tensor to be summed.\n * @param axis The axis along which to sum. Optional. Defaults to 0.\n * @param exclusive Whether to perform exclusive cumulative sum. Optional.\n *     Defaults to false. If set to true then the sum of each tensor entry\n *     does not include its own value, but only the values previous to it\n *     along the specified axis.\n * @param reverse Whether to sum in the opposite direction. Optional.\n *     Defaults to false.\n */\n/** @doc {heading: 'Operations', subheading: 'Scan'} */\nfunction cumsum_(x, axis, exclusive, reverse) {\n    if (axis === void 0) { axis = 0; }\n    if (exclusive === void 0) { exclusive = false; }\n    if (reverse === void 0) { reverse = false; }\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'cumsum');\n    axis = axis | 0;\n    var permutation = axis_util_1.getAxesPermutation([axis], $x.rank);\n    var permutedX = $x;\n    if (permutation != null) {\n        permutedX = $x.transpose(permutation);\n    }\n    var permutedAxis = axis_util_1.getInnerMostAxes(1, $x.rank)[0];\n    var grad = function (dy) {\n        return { permutedX: function () { return dy.cumsum(axis, exclusive, !reverse); } };\n    };\n    var value = engine_1.ENGINE.runKernel(function (backend) { return backend.cumsum(permutedX, permutedAxis, exclusive, reverse); }, { permutedX: permutedX }, grad);\n    if (permutation != null) {\n        value = value.transpose(permutation);\n    }\n    return value;\n}\n/**\n * Returns a `tf.Tensor` that has expanded rank, by inserting a dimension\n * into the tensor's shape.\n *\n * ```js\n * const x = tf.tensor1d([1, 2, 3, 4]);\n * const axis = 1;\n * x.expandDims(axis).print();\n * ```\n *\n * @param x The input tensor whose dimensions to be expanded.\n * @param axis The dimension index at which to insert shape of `1`. Defaults\n *     to 0 (the first dimension).\n */\n/** @doc {heading: 'Tensors', subheading: 'Transformations'} */\nfunction expandDims_(x, axis) {\n    if (axis === void 0) { axis = 0; }\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'expandDims');\n    util.assert(axis <= $x.rank, function () { return 'Axis must be <= rank of the tensor'; });\n    var newShape = $x.shape.slice();\n    if (axis < 0) {\n        // Negative value is counted from the tail of rank.\n        util.assert(-($x.rank + 1) <= axis, function () { return \"Axis must be in the interval [\" + -($x.rank + 1) + \", \" + $x.rank + \"]\"; });\n        axis = $x.rank + axis + 1;\n    }\n    newShape.splice(axis, 0, 1);\n    return exports.reshape($x, newShape);\n}\n/**\n * Rearranges data from depth into blocks of spatial data. More specifically,\n * this op outputs a copy of the input tensor where values from the `depth`\n * dimension are moved in spatial blocks to the `height` and `width` dimensions.\n * The attr `blockSize` indicates the input block size and how the data is\n * moved.\n *\n *  - Chunks of data of size `blockSize * blockSize` from depth are rearranged\n * into non-overlapping blocks of size `blockSize x blockSize`\n *\n *  - The width the output tensor is `inputWidth * blockSize`, whereas the\n * height is `inputHeight * blockSize`\n *\n *  - The Y, X coordinates within each block of the output image are determined\n * by the high order component of the input channel index\n *\n *  - The depth of the input tensor must be divisible by `blockSize *\n * blockSize`\n *\n * The `dataFormat` attr specifies the layout of the input and output tensors\n * with the following options: \"NHWC\": [ `batch, height, width, channels` ]\n * \"NCHW\": [ `batch, channels, height, width` ]\n *\n * ```js\n * const x = tf.tensor4d([1, 2, 3, 4], [1, 1, 1, 4]);\n * const blockSize = 2;\n * const dataFormat = \"NHWC\";\n *\n * tf.depthToSpace(x, blockSize, dataFormat).print();\n * ```\n *\n * @param x The input tensor of rank 4\n * @param blockSIze  An `int` that is `>= 2`. The size of the spatial block\n * @param dataFormat An optional string from: \"NHWC\", \"NCHW\". Defaults to \"NHWC\"\n */\n/** @doc {heading: 'Tensors', subheading: 'Transformations'} */\nfunction depthToSpace_(x, blockSize, dataFormat) {\n    if (dataFormat === void 0) { dataFormat = 'NHWC'; }\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'depthToSpace');\n    var inputHeight = (dataFormat === 'NHWC') ? $x.shape[1] : $x.shape[2];\n    var inputWidth = (dataFormat === 'NHWC') ? $x.shape[2] : $x.shape[3];\n    var inputDepth = (dataFormat === 'NHWC') ? $x.shape[3] : $x.shape[1];\n    util.assert(inputHeight * blockSize >= 0, function () { return \"Negative dimension size caused by overflow when multiplying\\n      \" + inputHeight + \" and \" + blockSize + \"  for depthToSpace with input shape\\n      \" + $x.shape; });\n    util.assert(inputWidth * blockSize >= 0, function () { return \"Negative dimension size caused by overflow when multiplying\\n      \" + inputWidth + \" and \" + blockSize + \" for depthToSpace with input shape\\n          \" + $x.shape; });\n    util.assert((inputDepth % (blockSize * blockSize) === 0), function () { return \"Dimension size must be evenly divisible by \" + blockSize * blockSize + \" but is \" + inputDepth + \" for depthToSpace with input shape \" + $x.shape; });\n    return engine_1.ENGINE.runKernel(function (backend) { return backend.depthToSpace($x, blockSize, dataFormat); }, { $x: $x });\n}\n/**\n * Computes the difference between two lists of numbers.\n *\n * Given a Tensor `x` and a Tensor `y`, this operation returns a Tensor `out`\n * that represents all values that are in `x` but not in `y`. The returned\n * Tensor `out` is sorted in the same order that the numbers appear in `x`\n * (duplicates are preserved). This operation also returns a Tensor indices that\n * represents the position of each out element in `x`. In other words:\n *\n * `out[i] = x[idx[i]] for i in [0, 1, ..., out.length - 1]`\n *\n * ```js\n * const x = [1, 2, 3, 4, 5, 6];\n * const y = [1, 3, 5];\n *\n * const [out, indices] = await tf.setdiff1dAsync(x, y);\n * out.print(); // [2, 4, 6]\n * indices.print(); // [1, 3, 5]\n * ```\n *\n * @param x 1-D Tensor. Values to keep.\n * @param y 1-D Tensor. Must have the same type as x. Values to exclude in the\n *     output.\n * @returns Promise of Tensor tuple [out, indices].\n *  out: Tensor with the same type as x.\n *  indices: A Tensor of type int32.\n */\n/** @doc {heading: 'Tensors', subheading: 'Transformations'} */\nfunction setdiff1dAsync_(x, y) {\n    return __awaiter(this, void 0, void 0, function () {\n        var $x, $y, xVals, yVals, ySet, outputSize, i, buffer, indices, i, p;\n        return __generator(this, function (_a) {\n            switch (_a.label) {\n                case 0:\n                    $x = tensor_util_env_1.convertToTensor(x, 'x', 'setdiff1d');\n                    $y = tensor_util_env_1.convertToTensor(y, 'y', 'setdiff1d');\n                    util.assert($x.dtype === $y.dtype, function () { return \"x and y should have the same dtype, but got x (\" + $x.dtype + \") and y (\" + $y.dtype + \").\"; });\n                    util.assert($x.rank === 1, function () { return \"x should be 1D tensor, but got x (\" + $x.shape + \").\"; });\n                    util.assert($y.rank === 1, function () { return \"y should be 1D tensor, but got y (\" + $y.shape + \").\"; });\n                    return [4 /*yield*/, $x.data()];\n                case 1:\n                    xVals = _a.sent();\n                    return [4 /*yield*/, $y.data()];\n                case 2:\n                    yVals = _a.sent();\n                    ySet = new Set(yVals);\n                    outputSize = 0;\n                    for (i = 0; i < xVals.length; i++) {\n                        if (!ySet.has(xVals[i])) {\n                            outputSize++;\n                        }\n                    }\n                    buffer = new tensor_1.TensorBuffer([outputSize], $x.dtype);\n                    indices = new tensor_1.TensorBuffer([outputSize], 'int32');\n                    for (i = 0, p = 0; i < xVals.length; i++) {\n                        if (!ySet.has(xVals[i])) {\n                            buffer.values[p] = xVals[i];\n                            indices.values[p] = i;\n                            p++;\n                        }\n                    }\n                    return [2 /*return*/, [buffer.toTensor(), indices.toTensor()]];\n            }\n        });\n    });\n}\n/**\n * Creates an empty `tf.TensorBuffer` with the specified `shape` and `dtype`.\n *\n * The values are stored in CPU as `TypedArray`. Fill the buffer using\n * `buffer.set()`, or by modifying directly `buffer.values`.\n *\n * When done, call `buffer.toTensor()` to get an immutable `tf.Tensor` with\n * those values.\n *\n * ```js\n * // Create a buffer and set values at particular indices.\n * const buffer = tf.buffer([2, 2]);\n * buffer.set(3, 0, 0);\n * buffer.set(5, 1, 0);\n *\n * // Convert the buffer back to a tensor.\n * buffer.toTensor().print();\n * ```\n *\n * @param shape An array of integers defining the output tensor shape.\n * @param dtype The dtype of the buffer. Defaults to 'float32'.\n * @param values The values of the buffer as `TypedArray`. Defaults to\n * zeros.\n */\n/** @doc {heading: 'Tensors', subheading: 'Creation'} */\nfunction buffer(shape, dtype, values) {\n    if (dtype === void 0) { dtype = 'float32'; }\n    dtype = dtype || 'float32';\n    util.assertNonNegativeIntegerDimensions(shape);\n    return new tensor_1.TensorBuffer(shape, dtype, values);\n}\nexports.buffer = buffer;\n/**\n * Prints information about the `tf.Tensor` including its data.\n *\n * ```js\n * const verbose = true;\n * tf.tensor2d([1, 2, 3, 4], [2, 2]).print(verbose);\n * ```\n * @param x The tensor to be printed.\n * @param verbose Whether to print verbose information about the ` Tensor`,\n * including dtype and size.\n */\n/** @doc {heading: 'Tensors', subheading: 'Creation'} */\nfunction print(x, verbose) {\n    if (verbose === void 0) { verbose = false; }\n    console.log(x.toString(verbose));\n}\nexports.print = print;\nexports.batchToSpaceND = operation_1.op({ batchToSpaceND_: batchToSpaceND_ });\nexports.cast = operation_1.op({ cast_: cast_ });\nexports.clone = operation_1.op({ clone_: clone_ });\nexports.cumsum = operation_1.op({ cumsum_: cumsum_ });\nexports.depthToSpace = operation_1.op({ depthToSpace_: depthToSpace_ });\nexports.expandDims = operation_1.op({ expandDims_: expandDims_ });\nexports.eye = operation_1.op({ eye_: eye_ });\nexports.multinomial = operation_1.op({ multinomial_: multinomial_ });\nexports.oneHot = operation_1.op({ oneHot_: oneHot_ });\nexports.pad = operation_1.op({ pad_: pad_ });\nexports.pad1d = operation_1.op({ pad1d_: pad1d_ });\nexports.pad2d = operation_1.op({ pad2d_: pad2d_ });\nexports.pad3d = operation_1.op({ pad3d_: pad3d_ });\nexports.pad4d = operation_1.op({ pad4d_: pad4d_ });\nexports.rand = operation_1.op({ rand_: rand_ });\nexports.randomNormal = operation_1.op({ randomNormal_: randomNormal_ });\nexports.randomUniform = operation_1.op({ randomUniform_: randomUniform_ });\nexports.reshape = operation_1.op({ reshape_: reshape_ });\nexports.spaceToBatchND = operation_1.op({ spaceToBatchND_: spaceToBatchND_ });\nexports.squeeze = operation_1.op({ squeeze_: squeeze_ });\nexports.stack = operation_1.op({ stack_: stack_ });\nexports.tile = operation_1.op({ tile_: tile_ });\nexports.truncatedNormal = operation_1.op({ truncatedNormal_: truncatedNormal_ });\nexports.unstack = operation_1.op({ unstack_: unstack_ });\nexports.setdiff1dAsync = setdiff1dAsync_;\n//# sourceMappingURL=array_ops.js.map","\n/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar engine_1 = require(\"../engine\");\nvar tensor_util_env_1 = require(\"../tensor_util_env\");\nvar util_1 = require(\"../util\");\nvar util_2 = require(\"../util\");\nvar concat_util_1 = require(\"./concat_util\");\nvar operation_1 = require(\"./operation\");\nvar tensor_ops_1 = require(\"./tensor_ops\");\n/**\n * Concatenates a list of`tf.Tensor1D`s along an axis. See `concat` for details.\n *\n * For example, if:\n * A: shape(3) = |r1, g1, b1|\n * B: shape(2) = |r2, g2|\n * C = tf.concat1d([A, B]) == |r1, g1, b1, r2, g2|\n *\n * @param tensors A list of`tf.Tensor`s to concatenate.\n * @return The concatenated array.\n */\nfunction concat1d_(tensors) {\n    return exports.concat(tensors, 0 /* axis */);\n}\n/**\n * Concatenates a list of`tf.Tensor2D`s along an axis. See `concat` for details.\n *\n * For example, if:\n * A: shape(2, 3) = | r1, g1, b1 |\n *                  | r2, g2, b2 |\n *\n * B: shape(2, 3) = | r3, g3, b3 |\n *                  | r4, g4, b4 |\n *\n * C = tf.concat2d([A, B], axis)\n *\n * if axis = 0:\n * C: shape(4, 3) = | r1, g1, b1 |\n *                  | r2, g2, b2 |\n *                  | r3, g3, b3 |\n *                  | r4, g4, b4 |\n *\n * if axis = 1:\n * C = shape(2, 6) = | r1, g1, b1, r3, g3, b3 |\n *                   | r2, g2, b2, r4, g4, b4 |\n *\n *\n * @param tensors A list of `tf.Tensor`s to concatenate.\n * @param axis The axis to concatenate along.\n * @return The concatenated array.\n */\nfunction concat2d_(tensors, axis) {\n    return exports.concat(tensors, axis);\n}\n/**\n * Concatenates a list of `tf.Tensor3D`s along an axis.\n * See `concat` for details.\n *\n * For example, if:\n * A: shape(2, 1, 3) = | r1, g1, b1 |\n *                     | r2, g2, b2 |\n *\n * B: shape(2, 1, 3) = | r3, g3, b3 |\n *                     | r4, g4, b4 |\n *\n * C = tf.concat3d([A, B], axis)\n *\n * if axis = 0:\n * C: shape(4, 1, 3) = | r1, g1, b1 |\n *                     | r2, g2, b2 |\n *                     | r3, g3, b3 |\n *                     | r4, g4, b4 |\n *\n * if axis = 1:\n * C: shape(2, 2, 3) = | r1, g1, b1, r3, g3, b3 |\n *                     | r2, g2, b2, r4, g4, b4 |\n *\n * if axis = 2:\n * C = shape(2, 1, 6) = | r1, g1, b1, r3, g3, b3 |\n *                      | r2, g2, b2, r4, g4, b4 |\n *\n * @param tensors A list of`tf.Tensor`s to concatenate.\n * @param axis The axis to concate along.\n * @return The concatenated array.\n */\nfunction concat3d_(tensors, axis) {\n    return exports.concat(tensors, axis);\n}\n/**\n * Concatenates a list of `tf.Tensor4D`s along an axis.\n * See `concat` for details.\n *\n * @param tensors A list of `tf.Tensor`s to concatenate.\n * @param axis The axis to concate along.\n * @return The concatenated array.\n */\nfunction concat4d_(tensors, axis) {\n    return exports.concat(tensors, axis);\n}\n/**\n * Concatenates a list of `tf.Tensor`s along a given axis.\n *\n * The tensors ranks and types must match, and their sizes must match in all\n * dimensions except `axis`.\n *\n * Also available are stricter rank-specific methods that assert that\n * `tensors` are of the given rank:\n *   - `tf.concat1d`\n *   - `tf.concat2d`\n *   - `tf.concat3d`\n *   - `tf.concat4d`\n *\n * Except `tf.concat1d` (which does not have axis param), all methods have\n * same signature as this method.\n *\n * ```js\n * const a = tf.tensor1d([1, 2]);\n * const b = tf.tensor1d([3, 4]);\n * a.concat(b).print();  // or a.concat(b)\n * ```\n *\n * ```js\n * const a = tf.tensor1d([1, 2]);\n * const b = tf.tensor1d([3, 4]);\n * const c = tf.tensor1d([5, 6]);\n * tf.concat([a, b, c]).print();\n * ```\n *\n * ```js\n * const a = tf.tensor2d([[1, 2], [10, 20]]);\n * const b = tf.tensor2d([[3, 4], [30, 40]]);\n * const axis = 1;\n * tf.concat([a, b], axis).print();\n * ```\n * @param tensors A list of tensors to concatenate.\n * @param axis The axis to concate along. Defaults to 0 (the first dim).\n */\n/** @doc {heading: 'Tensors', subheading: 'Slicing and Joining'} */\nfunction concat_(tensors, axis) {\n    if (axis === void 0) { axis = 0; }\n    util_1.assert(tensors.length >= 1, function () { return 'Pass at least one tensor to concat'; });\n    var $tensors = tensor_util_env_1.convertToTensorArray(tensors, 'tensors', 'concat');\n    axis = util_2.parseAxisParam(axis, $tensors[0].shape)[0];\n    var outShape = concat_util_1.computeOutShape($tensors.map(function (t) { return t.shape; }), axis);\n    if (util_1.sizeFromShape(outShape) === 0) {\n        return tensor_ops_1.tensor([], outShape);\n    }\n    // Keep only non-empty tensors (ignore tensors with 0 in their shape).\n    $tensors = $tensors.filter(function (t) { return t.size > 0; });\n    if ($tensors.length === 1) {\n        return $tensors[0];\n    }\n    var shapes = $tensors.map(function (t) { return t.shape; });\n    concat_util_1.assertParamsConsistent(shapes, axis);\n    var der = function (dy) {\n        var sizeSplits = shapes.map(function (s) { return s[axis]; });\n        var derTensors = exports.split(dy, sizeSplits, axis);\n        return derTensors.map(function (t) { return function () { return t; }; });\n    };\n    var inputs = $tensors;\n    return engine_1.ENGINE.runKernel(function (backend) { return backend.concat($tensors, axis); }, inputs, der);\n}\n/**\n * Splits a `tf.Tensor` into sub tensors.\n *\n * If `numOrSizeSplits` is a number, splits `x` along dimension `axis`\n * into `numOrSizeSplits` smaller tensors.\n * Requires that `numOrSizeSplits` evenly divides `x.shape[axis]`.\n *\n * If `numOrSizeSplits` is a number array, splits `x` into\n * `numOrSizeSplits.length` pieces. The shape of the `i`-th piece has the\n * same size as `x` except along dimension `axis` where the size is\n * `numOrSizeSplits[i]`.\n *\n * ```js\n * const x = tf.tensor2d([1, 2, 3, 4, 5, 6, 7, 8], [2, 4]);\n * const [a, b] = tf.split(x, 2, 1);\n * a.print();\n * b.print();\n *\n * const [c, d, e] = tf.split(x, [1, 2, 1], 1);\n * c.print();\n * d.print();\n * e.print();\n * ```\n *\n * @param x The input tensor to split.\n * @param numOrSizeSplits Either an integer indicating the number of\n * splits along the axis or an array of integers containing the sizes of\n * each output tensor along the axis. If a number then it must evenly divide\n * `x.shape[axis]`; otherwise the sum of sizes must match `x.shape[axis]`.\n * @param axis The dimension along which to split. Defaults to 0 (the first\n * dim).\n */\n/** @doc {heading: 'Tensors', subheading: 'Slicing and Joining'} */\nfunction split_(x, numOrSizeSplits, axis) {\n    if (axis === void 0) { axis = 0; }\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'split');\n    axis = util_2.parseAxisParam(axis, $x.shape)[0];\n    var splitSizes;\n    if (typeof (numOrSizeSplits) === 'number') {\n        util_1.assert($x.shape[axis] % numOrSizeSplits === 0, function () { return 'Number of splits must evenly divide the axis.'; });\n        splitSizes =\n            new Array(numOrSizeSplits).fill($x.shape[axis] / numOrSizeSplits);\n    }\n    else {\n        util_1.assert($x.shape[axis] === numOrSizeSplits.reduce(function (a, b) { return a + b; }), function () { return 'The sum of sizes must match the size of the axis dimension.'; });\n        splitSizes = numOrSizeSplits;\n    }\n    var der = function (dy) { return ({ $x: function () { return exports.concat(dy, axis); } }); };\n    return engine_1.ENGINE.runKernel(function (backend) { return backend.split($x, splitSizes, axis); }, { $x: $x }, der);\n}\nexports.concat = operation_1.op({ concat_: concat_ });\nexports.concat1d = operation_1.op({ concat1d_: concat1d_ });\nexports.concat2d = operation_1.op({ concat2d_: concat2d_ });\nexports.concat3d = operation_1.op({ concat3d_: concat3d_ });\nexports.concat4d = operation_1.op({ concat4d_: concat4d_ });\nexports.split = operation_1.op({ split_: split_ });\n//# sourceMappingURL=concat_split.js.map","\n/**\n * @license\n * Copyright 2017 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar seedrandom = require(\"seedrandom\");\n// https://en.wikipedia.org/wiki/Marsaglia_polar_method\nvar MPRandGauss = /** @class */ (function () {\n    function MPRandGauss(mean, stdDeviation, dtype, truncated, seed) {\n        this.mean = mean;\n        this.stdDev = stdDeviation;\n        this.dtype = dtype;\n        this.nextVal = NaN;\n        this.truncated = truncated;\n        if (this.truncated) {\n            this.upper = this.mean + this.stdDev * 2;\n            this.lower = this.mean - this.stdDev * 2;\n        }\n        var seedValue = seed ? seed : Math.random();\n        this.random = seedrandom.alea(seedValue.toString());\n    }\n    /** Returns next sample from a gaussian distribution. */\n    MPRandGauss.prototype.nextValue = function () {\n        if (!isNaN(this.nextVal)) {\n            var value = this.nextVal;\n            this.nextVal = NaN;\n            return value;\n        }\n        var resultX, resultY;\n        var isValid = false;\n        while (!isValid) {\n            var v1 = void 0, v2 = void 0, s = void 0;\n            do {\n                v1 = 2 * this.random() - 1;\n                v2 = 2 * this.random() - 1;\n                s = v1 * v1 + v2 * v2;\n            } while (s >= 1 || s === 0);\n            var mul = Math.sqrt(-2.0 * Math.log(s) / s);\n            resultX = this.mean + this.stdDev * v1 * mul;\n            resultY = this.mean + this.stdDev * v2 * mul;\n            if (!this.truncated || this.isValidTruncated(resultX)) {\n                isValid = true;\n            }\n        }\n        if (!this.truncated || this.isValidTruncated(resultY)) {\n            this.nextVal = this.convertValue(resultY);\n        }\n        return this.convertValue(resultX);\n    };\n    /** Handles proper rounding for non floating point numbers. */\n    MPRandGauss.prototype.convertValue = function (value) {\n        if (this.dtype == null || this.dtype === 'float32') {\n            return value;\n        }\n        return Math.round(value);\n    };\n    /** Returns true if less than 2-standard-deviations from the mean. */\n    MPRandGauss.prototype.isValidTruncated = function (value) {\n        return value <= this.upper && value >= this.lower;\n    };\n    return MPRandGauss;\n}());\nexports.MPRandGauss = MPRandGauss;\nvar UniformRandom = /** @class */ (function () {\n    function UniformRandom(min, max, dtype, seed) {\n        if (min === void 0) { min = 0; }\n        if (max === void 0) { max = 1; }\n        if (seed === void 0) { seed = Math.random(); }\n        var _this = this;\n        /** Handles proper rounding for non floating point numbers. */\n        this.canReturnFloat = function () {\n            return (_this.dtype == null || _this.dtype === 'float32');\n        };\n        this.min = min;\n        this.range = max - min;\n        this.dtype = dtype;\n        if (!this.canReturnFloat() && this.range <= 1) {\n            throw new Error(\"The difference between \" + min + \" - \" + max + \" <= 1 and dtype is not float\");\n        }\n        this.random = seedrandom.alea(seed.toString());\n    }\n    UniformRandom.prototype.convertValue = function (value) {\n        if (this.canReturnFloat()) {\n            return value;\n        }\n        return Math.round(value);\n    };\n    UniformRandom.prototype.nextValue = function () {\n        return this.convertValue(this.min + this.range * this.random());\n    };\n    return UniformRandom;\n}());\nexports.UniformRandom = UniformRandom;\n//# sourceMappingURL=rand.js.map","\n/**\n * @license\n * Copyright 2019 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar AddNProgram = /** @class */ (function () {\n    function AddNProgram(outputShape, shapes) {\n        this.outputShape = [];\n        this.outputShape = outputShape;\n        this.variableNames = shapes.map(function (_, i) { return \"T\" + i; });\n        var snippets = [];\n        // Get target elements from every input tensor.\n        this.variableNames.forEach(function (variable) {\n            snippets.push(\"float v\" + variable + \" = get\" + variable + \"AtOutCoords();\");\n        });\n        // Calculate the sum of all elements.\n        var operation = this.variableNames.map(function (variable) {\n            return \"v\" + variable;\n        }).join(' + ');\n        this.userCode = \"\\n      void main() {\\n        \" + snippets.join('\\n        ') + \"\\n\\n        float result = \" + operation + \";\\n        setOutput(result);\\n      }\\n    \";\n    }\n    return AddNProgram;\n}());\nexports.AddNProgram = AddNProgram;\n//# sourceMappingURL=addn_gpu.js.map","\n/**\n * @license\n * Copyright 2019 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar AddNPackedProgram = /** @class */ (function () {\n    function AddNPackedProgram(outputShape, shapes) {\n        this.outputShape = [];\n        this.usesPackedTextures = true;\n        this.outputShape = outputShape;\n        this.variableNames = shapes.map(function (_, i) { return \"T\" + i; });\n        var snippets = [];\n        // Get target elements from every input tensor.\n        this.variableNames.forEach(function (variable) {\n            snippets.push(\"vec4 v\" + variable + \" = get\" + variable + \"AtOutCoords();\");\n        });\n        // Calculate the sum of all elements.\n        var operation = this.variableNames.map(function (variable) {\n            return \"v\" + variable;\n        }).join(' + ');\n        this.userCode = \"\\n      void main() {\\n        \" + snippets.join('\\n        ') + \"\\n\\n        vec4 result = \" + operation + \";\\n        setOutput(result);\\n      }\\n    \";\n    }\n    return AddNPackedProgram;\n}());\nexports.AddNPackedProgram = AddNPackedProgram;\n//# sourceMappingURL=addn_packed_gpu.js.map","\n/**\n * @license\n * Copyright 2017 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar ArgMinMaxProgram = /** @class */ (function () {\n    function ArgMinMaxProgram(reduceInfo, op, firstPass) {\n        this.variableNames = ['A'];\n        var windowSize = reduceInfo.windowSize;\n        var batchSize = reduceInfo.batchSize;\n        var inSize = reduceInfo.inSize;\n        var outSize = Math.ceil(inSize / windowSize);\n        if (!firstPass) {\n            this.variableNames.push('bestIndicesA');\n        }\n        this.outputShape = [batchSize, outSize];\n        var compOp = (op === 'max') ? '>' : '<';\n        var indexSnippet = firstPass ?\n            'inOffset + i;' :\n            'round(getBestIndicesA(batch, inOffset + i));';\n        this.userCode = \"\\n      void main() {\\n        ivec2 coords = getOutputCoords();\\n        int batch = coords[0];\\n        int outIdx = coords[1];\\n        int inOffset = outIdx * \" + windowSize + \";\\n\\n        int bestIndex = inOffset;\\n        float bestValue = getA(batch, bestIndex);\\n\\n        for (int i = 0; i < \" + windowSize + \"; i++) {\\n          int inIdx = \" + indexSnippet + \";\\n          float candidate = getA(batch, inIdx);\\n          if (candidate \" + compOp + \" bestValue) {\\n            bestValue = candidate;\\n            bestIndex = inIdx;\\n          }\\n        }\\n        setOutput(float(bestIndex));\\n      }\\n    \";\n    }\n    return ArgMinMaxProgram;\n}());\nexports.ArgMinMaxProgram = ArgMinMaxProgram;\n//# sourceMappingURL=argminmax_gpu.js.map","\n/**\n * @license\n * Copyright 2019 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar util_1 = require(\"../../util\");\nvar packing_util_1 = require(\"../packing_util\");\nvar shader_compiler_1 = require(\"./shader_compiler\");\nvar ArgMinMaxPackedProgram = /** @class */ (function () {\n    function ArgMinMaxPackedProgram(shape, windowSize, op, firstPass) {\n        this.variableNames = ['A'];\n        this.usesPackedTextures = true;\n        util_1.assert(shape.length > 2, function () { return \"Packed arg\" + (op.charAt(0).toUpperCase() +\n            op.slice(1)) + \" supports only inputs with rank above 2.\"; });\n        var inSize = shape[shape.length - 1];\n        var outSize = Math.ceil(inSize / windowSize);\n        this.outputShape = shape.slice(0, -1);\n        if (outSize > 1) {\n            this.outputShape.push(outSize);\n        }\n        if (!firstPass) {\n            this.variableNames.push('bestIndicesA');\n        }\n        var outShape = this.outputShape;\n        var rank = outShape.length;\n        var dtype = shader_compiler_1.getCoordsDataType(rank);\n        var coords = packing_util_1.getChannels('coords', rank);\n        var sourceLocSetup;\n        var sourceRank;\n        if (outSize === 1) {\n            sourceRank = rank + 1;\n            var sourceLocDType = shader_compiler_1.getCoordsDataType(sourceRank);\n            sourceLocSetup = \"\\n        \" + sourceLocDType + \" sourceLocR = \" + sourceLocDType + \"(\" + coords.join() + \", 0);\\n        ++\" + coords[rank - 1] + \";\\n        \" + sourceLocDType + \" sourceLocG = \" + sourceLocDType + \"(\" + coords.join() + \", 0);\\n        ++\" + coords[rank - 2] + \";\\n        \" + sourceLocDType + \" sourceLocA = \" + sourceLocDType + \"(\" + coords.join() + \", 0);\\n        --\" + coords[rank - 1] + \";\\n        \" + sourceLocDType + \" sourceLocB = \" + sourceLocDType + \"(\" + coords.join() + \", 0);\\n        --\" + coords[rank - 2] + \";\";\n        }\n        else {\n            sourceRank = rank;\n            sourceLocSetup = \"\\n        \" + dtype + \" sourceLocR = coords;\\n        ++\" + coords[rank - 1] + \";\\n        \" + dtype + \" sourceLocG = coords;\\n        ++\" + coords[rank - 2] + \";\\n        \" + dtype + \" sourceLocA = coords;\\n        --\" + coords[rank - 1] + \";\\n        \" + dtype + \" sourceLocB = coords;\\n        --\" + coords[rank - 2] + \";\";\n        }\n        var channels = ['x', 'y', 'z', 'w', 'u', 'v'].slice(0, sourceRank);\n        var inChannel = '.' + channels[sourceRank - 1]; // e.g. \".b\" for rank 3.\n        var intChannels = channels.map(function (x) { return 'int ' + x; });\n        var srcRCoords = packing_util_1.getChannels('sourceLocR', sourceRank - 1).concat('inIdx.r');\n        var srcGCoords = packing_util_1.getChannels('sourceLocG', sourceRank - 1).concat('inIdx.g');\n        var srcBCoords = packing_util_1.getChannels('sourceLocB', sourceRank - 1).concat('inIdx.b');\n        var srcACoords = packing_util_1.getChannels('sourceLocA', sourceRank - 1).concat('inIdx.a');\n        var compOp = (op === 'max') ? 'greaterThan' : 'lessThan';\n        var fetchCandidateIdx = firstPass ? '' : \"\\n          inIdx = round(vec4(getBestIndicesAChannel(\" + srcRCoords.join() + \"),\\n                             getBestIndicesAChannel(\" + srcGCoords.join() + \"),\\n                             getBestIndicesAChannel(\" + srcBCoords.join() + \"),\\n                             getBestIndicesAChannel(\" + srcACoords.join() + \")));\";\n        var fetchValue = \"vec4(\\n            getAChannel(\" + srcRCoords.join() + \"),\\n            hasNextCol ? getAChannel(\" + srcGCoords.join() + \") : 0.,\\n            hasNextRow ? getAChannel(\" + srcBCoords.join() + \") : 0.,\\n            hasNextRow && hasNextCol ? getAChannel(\" + srcACoords.join() + \") : 0.)\";\n        var getBestIndicesAChannelSnippet = firstPass ? '' : \"\\n      float getBestIndicesAChannel(\" + intChannels.join() + \") {\\n        return getChannel(getBestIndicesA(\" + channels.join() + \"),\\n                                          vec2(\" + channels.slice(-2).join() + \"));\\n      }\";\n        this.userCode = \"\\n      float getAChannel(\" + intChannels.join() + \") {\\n        return getChannel(getA(\" + channels.join() + \"),\\n                               vec2(\" + channels.slice(-2).join() + \"));\\n      }\\n      \" + getBestIndicesAChannelSnippet + \"\\n      void main() {\\n        \" + dtype + \" coords = getOutputCoords();\\n        bool hasNextCol = \" + coords[rank - 1] + \" < \" + (outShape[rank - 1] - 1) + \";\\n        bool hasNextRow = \" + coords[rank - 2] + \" < \" + (outShape[rank - 2] - 1) + \";\\n        \" + sourceLocSetup + \"\\n        ivec4 srcIdx = ivec4(sourceLocR\" + inChannel + \", sourceLocG\" + inChannel + \",\\n          sourceLocB\" + inChannel + \", sourceLocA\" + inChannel + \") * \" + windowSize + \";\\n        ivec4 inIdx = srcIdx;\\n        vec4 bestIndex = vec4(inIdx);\\n        vec4 bestValue = \" + fetchValue + \";\\n\\n        for (int i = 0; i < \" + windowSize + \"; i++) {\\n          inIdx = srcIdx;\\n          \" + fetchCandidateIdx + \"\\n          vec4 candidate = \" + fetchValue + \";\\n          bvec4 nan = isnan(candidate);\\n          bvec4 replace = bvec4(\\n            vec4(\" + compOp + \"(candidate, bestValue)) * (vec4(1.0) - vec4(nan)));\\n\\n          bestValue = vec4(replace.x  ? candidate.x : bestValue.x,\\n                           replace.y  ? candidate.y : bestValue.y,\\n                           replace.z  ? candidate.z : bestValue.z,\\n                           replace.w  ? candidate.w : bestValue.w);\\n          bestIndex = mix(bestIndex, vec4(inIdx), vec4(replace));\\n          srcIdx++;\\n        }\\n        setOutput(bestIndex);\\n      }\\n    \";\n    }\n    return ArgMinMaxPackedProgram;\n}());\nexports.ArgMinMaxPackedProgram = ArgMinMaxPackedProgram;\n//# sourceMappingURL=argminmax_packed_gpu.js.map","\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nfunction getVecChannels(name, rank) {\n    return ['x', 'y', 'z', 'w', 'u', 'v'].slice(0, rank).map(function (d) { return name + \".\" + d; });\n}\nexports.getVecChannels = getVecChannels;\nfunction getChannels(name, rank) {\n    if (rank === 1) {\n        return [name];\n    }\n    return getVecChannels(name, rank);\n}\nexports.getChannels = getChannels;\nfunction getSourceCoords(rank, dims) {\n    if (rank === 1) {\n        return 'rc';\n    }\n    var coords = '';\n    for (var i = 0; i < rank; i++) {\n        coords += dims[i];\n        if (i < rank - 1) {\n            coords += ',';\n        }\n    }\n    return coords;\n}\nexports.getSourceCoords = getSourceCoords;\n//# sourceMappingURL=packing_util.js.map","\n/**\n * @license\n * Copyright 2017 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar broadcast_util_1 = require(\"../../ops/broadcast_util\");\nvar util = require(\"../../util\");\nvar glsl_version_1 = require(\"./glsl_version\");\nvar shader_util = require(\"./shader_compiler_util\");\nfunction makeShader(inputsInfo, outputShape, userCode, usesPackedTextures) {\n    var prefixSnippets = [];\n    inputsInfo.forEach(function (x) {\n        var size = util.sizeFromShape(x.shapeInfo.logicalShape);\n        // Snippet when we decided to upload the values as uniform.\n        if (x.shapeInfo.isUniform) {\n            prefixSnippets.push(\"uniform float \" + x.name + (size > 1 ? \"[\" + size + \"]\" : '') + \";\");\n        }\n        else {\n            prefixSnippets.push(\"uniform sampler2D \" + x.name + \";\");\n            prefixSnippets.push(\"uniform int offset\" + x.name + \";\");\n        }\n    });\n    var inputPrefixSnippet = prefixSnippets.join('\\n');\n    var inputSamplingSnippet = inputsInfo\n        .map(function (x) { return getInputSamplingSnippet(x, outputShape, usesPackedTextures); })\n        .join('\\n');\n    var outTexShape = outputShape.texShape;\n    var glsl = glsl_version_1.getGlslDifferences();\n    var floatTextureSampleSnippet = getFloatTextureSampleSnippet(glsl);\n    var outputSamplingSnippet;\n    var floatTextureSetOutputSnippet;\n    var shaderPrefix = getShaderPrefix(glsl);\n    if (outputShape.isPacked) {\n        outputSamplingSnippet =\n            getPackedOutputSamplingSnippet(outputShape.logicalShape, outTexShape);\n        floatTextureSetOutputSnippet = getFloatTextureSetRGBASnippet(glsl);\n    }\n    else {\n        outputSamplingSnippet =\n            getOutputSamplingSnippet(outputShape.logicalShape, outTexShape);\n        floatTextureSetOutputSnippet = getFloatTextureSetRSnippet(glsl);\n    }\n    if (usesPackedTextures) {\n        shaderPrefix += SHADER_PACKED_PREFIX;\n    }\n    var source = [\n        shaderPrefix, floatTextureSampleSnippet, floatTextureSetOutputSnippet,\n        inputPrefixSnippet, outputSamplingSnippet, inputSamplingSnippet, userCode\n    ].join('\\n');\n    return source;\n}\nexports.makeShader = makeShader;\nfunction getSamplerFromInInfo(inInfo) {\n    var shape = inInfo.shapeInfo.logicalShape;\n    switch (shape.length) {\n        case 0:\n            return getSamplerScalar(inInfo);\n        case 1:\n            return getSampler1D(inInfo);\n        case 2:\n            return getSampler2D(inInfo);\n        case 3:\n            return getSampler3D(inInfo);\n        case 4:\n            return getSampler4D(inInfo);\n        case 5:\n            return getSampler5D(inInfo);\n        case 6:\n            return getSampler6D(inInfo);\n        default:\n            throw new Error(shape.length + \"-D input sampling\" +\n                \" is not yet supported\");\n    }\n}\nfunction getPackedSamplerFromInInfo(inInfo) {\n    var shape = inInfo.shapeInfo.logicalShape;\n    switch (shape.length) {\n        case 0:\n            return getPackedSamplerScalar(inInfo);\n        case 1:\n            return getPackedSampler1D(inInfo);\n        case 2:\n            return getPackedSampler2D(inInfo);\n        case 3:\n            return getPackedSampler3D(inInfo);\n        default:\n            return getPackedSamplerND(inInfo);\n    }\n}\nfunction getInputSamplingSnippet(inInfo, outShapeInfo, usesPackedTextures) {\n    if (usesPackedTextures === void 0) { usesPackedTextures = false; }\n    var res = '';\n    if (usesPackedTextures) {\n        res += getPackedSamplerFromInInfo(inInfo);\n    }\n    else {\n        res += getSamplerFromInInfo(inInfo);\n    }\n    var inShape = inInfo.shapeInfo.logicalShape;\n    var outShape = outShapeInfo.logicalShape;\n    if (inShape.length <= outShape.length) {\n        if (usesPackedTextures) {\n            res += getPackedSamplerAtOutputCoords(inInfo, outShapeInfo);\n        }\n        else {\n            res += getSamplerAtOutputCoords(inInfo, outShapeInfo);\n        }\n    }\n    return res;\n}\nfunction getPackedOutputSamplingSnippet(outShape, outTexShape) {\n    switch (outShape.length) {\n        case 0:\n            return getOutputScalarCoords();\n        case 1:\n            return getOutputPacked1DCoords(outShape, outTexShape);\n        case 2:\n            return getOutputPacked2DCoords(outShape, outTexShape);\n        case 3:\n            return getOutputPacked3DCoords(outShape, outTexShape);\n        default:\n            return getOutputPackedNDCoords(outShape, outTexShape);\n    }\n}\nfunction getOutputSamplingSnippet(outShape, outTexShape) {\n    switch (outShape.length) {\n        case 0:\n            return getOutputScalarCoords();\n        case 1:\n            return getOutput1DCoords(outShape, outTexShape);\n        case 2:\n            return getOutput2DCoords(outShape, outTexShape);\n        case 3:\n            return getOutput3DCoords(outShape, outTexShape);\n        case 4:\n            return getOutput4DCoords(outShape, outTexShape);\n        case 5:\n            return getOutput5DCoords(outShape, outTexShape);\n        case 6:\n            return getOutput6DCoords(outShape, outTexShape);\n        default:\n            throw new Error(outShape.length + \"-D output sampling is not yet supported\");\n    }\n}\nfunction getFloatTextureSampleSnippet(glsl) {\n    return \"\\n    float sampleTexture(sampler2D textureSampler, vec2 uv) {\\n      return \" + glsl.texture2D + \"(textureSampler, uv).r;\\n    }\\n  \";\n}\nfunction getFloatTextureSetRSnippet(glsl) {\n    return \"\\n    void setOutput(float val) {\\n      \" + glsl.output + \" = vec4(val, 0, 0, 0);\\n    }\\n  \";\n}\nfunction getFloatTextureSetRGBASnippet(glsl) {\n    return \"\\n    void setOutput(vec4 val) {\\n      \" + glsl.output + \" = val;\\n    }\\n  \";\n}\nfunction getShaderPrefix(glsl) {\n    var SHADER_PREFIX = glsl.version + \"\\n    precision highp float;\\n    precision highp int;\\n    precision highp sampler2D;\\n    \" + glsl.varyingFs + \" vec2 resultUV;\\n    \" + glsl.defineOutput + \"\\n    const vec2 halfCR = vec2(0.5, 0.5);\\n\\n    struct ivec5\\n    {\\n      int x;\\n      int y;\\n      int z;\\n      int w;\\n      int u;\\n    };\\n\\n    struct ivec6\\n    {\\n      int x;\\n      int y;\\n      int z;\\n      int w;\\n      int u;\\n      int v;\\n    };\\n\\n    uniform float NAN;\\n    #define isnan(value) isnan_custom(value)\\n    \" + glsl.defineSpecialNaN + \"\\n    bvec4 isnan_custom(vec4 val) {\\n      return bvec4(isnan(val.x), isnan(val.y), isnan(val.z), isnan(val.w));\\n    }\\n\\n    \" + glsl.defineSpecialInf + \"\\n    \" + glsl.defineRound + \"\\n\\n    int imod(int x, int y) {\\n      return x - y * (x / y);\\n    }\\n\\n    int idiv(int a, int b, float sign) {\\n      int res = a / b;\\n      int mod = imod(a, b);\\n      if (sign < 0. && mod != 0) {\\n        res -= 1;\\n      }\\n      return res;\\n    }\\n\\n    //Based on the work of Dave Hoskins\\n    //https://www.shadertoy.com/view/4djSRW\\n    #define HASHSCALE1 443.8975\\n    float random(float seed){\\n      vec2 p = resultUV * seed;\\n      vec3 p3  = fract(vec3(p.xyx) * HASHSCALE1);\\n      p3 += dot(p3, p3.yzx + 19.19);\\n      return fract((p3.x + p3.y) * p3.z);\\n    }\\n\\n    \" + SAMPLE_1D_SNIPPET + \"\\n    \" + SAMPLE_2D_SNIPPET + \"\\n    \" + SAMPLE_3D_SNIPPET + \"\\n  \";\n    return SHADER_PREFIX;\n}\nvar SAMPLE_1D_SNIPPET = \"\\nvec2 uvFromFlat(int texNumR, int texNumC, int index) {\\n  int texR = index / texNumC;\\n  int texC = index - texR * texNumC;\\n  return (vec2(texC, texR) + halfCR) / vec2(texNumC, texNumR);\\n}\\nvec2 packedUVfrom1D(int texNumR, int texNumC, int index) {\\n  int texelIndex = index / 2;\\n  int texR = texelIndex / texNumC;\\n  int texC = texelIndex - texR * texNumC;\\n  return (vec2(texC, texR) + halfCR) / vec2(texNumC, texNumR);\\n}\\n\";\nvar SAMPLE_2D_SNIPPET = \"\\nvec2 packedUVfrom2D(int texelsInLogicalRow, int texNumR,\\n  int texNumC, int row, int col) {\\n  int texelIndex = (row / 2) * texelsInLogicalRow + (col / 2);\\n  int texR = texelIndex / texNumC;\\n  int texC = texelIndex - texR * texNumC;\\n  return (vec2(texC, texR) + halfCR) / vec2(texNumC, texNumR);\\n}\\n\";\nvar SAMPLE_3D_SNIPPET = \"\\nvec2 packedUVfrom3D(int texNumR, int texNumC,\\n    int texelsInBatch, int texelsInLogicalRow, int b,\\n    int row, int col) {\\n  int index = b * texelsInBatch + (row / 2) * texelsInLogicalRow + (col / 2);\\n  int texR = index / texNumC;\\n  int texC = index - texR * texNumC;\\n  return (vec2(texC, texR) + halfCR) / vec2(texNumC, texNumR);\\n}\\n\";\nvar SHADER_PACKED_PREFIX = \"\\n  float getChannel(vec4 frag, vec2 innerDims) {\\n    vec2 modCoord = mod(innerDims, 2.);\\n    return modCoord.x == 0. ?\\n      (modCoord.y == 0. ? frag.r : frag.g) :\\n      (modCoord.y == 0. ? frag.b : frag.a);\\n  }\\n  float getChannel(vec4 frag, int dim) {\\n    float modCoord = mod(float(dim), 2.);\\n    return modCoord == 0. ? frag.r : frag.g;\\n  }\\n\";\nfunction getOutputScalarCoords() {\n    return \"\\n    int getOutputCoords() {\\n      return 0;\\n    }\\n  \";\n}\nfunction getOutputPacked1DCoords(shape, texShape) {\n    var packedTexShape = [Math.ceil(texShape[0] / 2), Math.ceil(texShape[1] / 2)];\n    if (packedTexShape[0] === 1) {\n        return \"\\n      int getOutputCoords() {\\n        return 2 * int(resultUV.x * \" + packedTexShape[1] + \".0);\\n      }\\n    \";\n    }\n    if (packedTexShape[1] === 1) {\n        return \"\\n      int getOutputCoords() {\\n        return 2 * int(resultUV.y * \" + packedTexShape[0] + \".0);\\n      }\\n    \";\n    }\n    return \"\\n    int getOutputCoords() {\\n      ivec2 resTexRC = ivec2(resultUV.yx *\\n                             vec2(\" + packedTexShape[0] + \", \" + packedTexShape[1] + \"));\\n      return resTexRC.x * \" + packedTexShape[1] + \" + resTexRC.y;\\n    }\\n  \";\n}\nfunction getOutput1DCoords(shape, texShape) {\n    if (texShape[0] === 1) {\n        return \"\\n      int getOutputCoords() {\\n        return int(resultUV.x * \" + texShape[1] + \".0);\\n      }\\n    \";\n    }\n    if (texShape[1] === 1) {\n        return \"\\n      int getOutputCoords() {\\n        return int(resultUV.y * \" + texShape[0] + \".0);\\n      }\\n    \";\n    }\n    return \"\\n    int getOutputCoords() {\\n      ivec2 resTexRC = ivec2(resultUV.yx *\\n                             vec2(\" + texShape[0] + \", \" + texShape[1] + \"));\\n      return resTexRC.x * \" + texShape[1] + \" + resTexRC.y;\\n    }\\n  \";\n}\nfunction getOutputPacked3DCoords(shape, texShape) {\n    var packedTexShape = [Math.ceil(texShape[0] / 2), Math.ceil(texShape[1] / 2)];\n    var texelsInLogicalRow = Math.ceil(shape[2] / 2);\n    var texelsInBatch = texelsInLogicalRow * Math.ceil(shape[1] / 2);\n    return \"\\n    ivec3 getOutputCoords() {\\n      ivec2 resTexRC = ivec2(resultUV.yx *\\n                             vec2(\" + packedTexShape[0] + \", \" + packedTexShape[1] + \"));\\n      int index = resTexRC.x * \" + packedTexShape[1] + \" + resTexRC.y;\\n\\n      int b = index / \" + texelsInBatch + \";\\n      index -= b * \" + texelsInBatch + \";\\n\\n      int r = 2 * (index / \" + texelsInLogicalRow + \");\\n      int c = imod(index, \" + texelsInLogicalRow + \") * 2;\\n\\n      return ivec3(b, r, c);\\n    }\\n  \";\n}\nfunction getOutput3DCoords(shape, texShape) {\n    var coordsFromIndexSnippet = shader_util.getLogicalCoordinatesFromFlatIndex(['r', 'c', 'd'], shape);\n    return \"\\n    ivec3 getOutputCoords() {\\n      ivec2 resTexRC = ivec2(resultUV.yx *\\n                             vec2(\" + texShape[0] + \", \" + texShape[1] + \"));\\n      int index = resTexRC.x * \" + texShape[1] + \" + resTexRC.y;\\n      \" + coordsFromIndexSnippet + \"\\n      return ivec3(r, c, d);\\n    }\\n  \";\n}\nfunction getOutputPackedNDCoords(shape, texShape) {\n    var packedTexShape = [Math.ceil(texShape[0] / 2), Math.ceil(texShape[1] / 2)];\n    var texelsInLogicalRow = Math.ceil(shape[shape.length - 1] / 2);\n    var texelsInBatch = texelsInLogicalRow * Math.ceil(shape[shape.length - 2] / 2);\n    var texelsInBatchN = texelsInBatch;\n    var batches = \"\";\n    var coords = 'b, r, c';\n    for (var b = 2; b < shape.length - 1; b++) {\n        texelsInBatchN *= shape[shape.length - b - 1];\n        batches = \"\\n      int b\" + b + \" = index / \" + texelsInBatchN + \";\\n      index -= b\" + b + \" * \" + texelsInBatchN + \";\\n    \" + batches;\n        coords = \"b\" + b + \", \" + coords;\n    }\n    return \"\\n    ivec\" + shape.length + \" getOutputCoords() {\\n      ivec2 resTexRC = ivec2(resultUV.yx *\\n                             vec2(\" + packedTexShape[0] + \", \" + packedTexShape[1] + \"));\\n      int index = resTexRC.x * \" + packedTexShape[1] + \" + resTexRC.y;\\n\\n      \" + batches + \"\\n\\n      int b = index / \" + texelsInBatch + \";\\n      index -= b * \" + texelsInBatch + \";\\n\\n      int r = 2 * (index / \" + texelsInLogicalRow + \");\\n      int c = imod(index, \" + texelsInLogicalRow + \") * 2;\\n\\n      return ivec\" + shape.length + \"(\" + coords + \");\\n    }\\n  \";\n}\nfunction getOutput4DCoords(shape, texShape) {\n    var coordsFromIndexSnippet = shader_util.getLogicalCoordinatesFromFlatIndex(['r', 'c', 'd', 'd2'], shape);\n    return \"\\n    ivec4 getOutputCoords() {\\n      ivec2 resTexRC = ivec2(resultUV.yx *\\n        vec2(\" + texShape[0] + \", \" + texShape[1] + \"));\\n      int index = resTexRC.x * \" + texShape[1] + \" + resTexRC.y;\\n      \" + coordsFromIndexSnippet + \"\\n      return ivec4(r, c, d, d2);\\n    }\\n  \";\n}\nfunction getOutput5DCoords(shape, texShape) {\n    var coordsFromIndexSnippet = shader_util.getLogicalCoordinatesFromFlatIndex(['r', 'c', 'd', 'd2', 'd3'], shape);\n    return \"\\n    ivec5 getOutputCoords() {\\n      ivec2 resTexRC = ivec2(resultUV.yx * vec2(\" + texShape[0] + \",\\n                             \" + texShape[1] + \"));\\n\\n      int index = resTexRC.x * \" + texShape[1] + \" + resTexRC.y;\\n\\n      \" + coordsFromIndexSnippet + \"\\n\\n      ivec5 outShape = ivec5(r, c, d, d2, d3);\\n      return outShape;\\n    }\\n  \";\n}\nfunction getOutput6DCoords(shape, texShape) {\n    var coordsFromIndexSnippet = shader_util.getLogicalCoordinatesFromFlatIndex(['r', 'c', 'd', 'd2', 'd3', 'd4'], shape);\n    return \"\\n    ivec6 getOutputCoords() {\\n      ivec2 resTexRC = ivec2(resultUV.yx *\\n        vec2(\" + texShape[0] + \", \" + texShape[1] + \"));\\n      int index = resTexRC.x * \" + texShape[1] + \" + resTexRC.y;\\n\\n      \" + coordsFromIndexSnippet + \"\\n\\n      ivec6 result = ivec6(r, c, d, d2, d3, d4);\\n      return result;\\n    }\\n  \";\n}\nfunction getOutputPacked2DCoords(shape, texShape) {\n    var packedTexShape = [Math.ceil(texShape[0] / 2), Math.ceil(texShape[1] / 2)];\n    if (util.arraysEqual(shape, texShape)) {\n        return \"\\n      ivec2 getOutputCoords() {\\n        return 2 * ivec2(resultUV.yx * vec2(\" + packedTexShape[0] + \", \" + packedTexShape[1] + \"));\\n      }\\n    \";\n    }\n    // texels needed to accommodate a logical row\n    var texelsInLogicalRow = Math.ceil(shape[1] / 2);\n    /**\n     * getOutputCoords\n     *\n     * resTexRC: The rows and columns of the texels. If you move over one\n     * texel to the right in the packed texture, you are moving over one column\n     * (not two).\n     *\n     * index: The texel index\n     */\n    return \"\\n    ivec2 getOutputCoords() {\\n      ivec2 resTexRC = ivec2(resultUV.yx *\\n                             vec2(\" + packedTexShape[0] + \", \" + packedTexShape[1] + \"));\\n\\n      int index = resTexRC.x * \" + packedTexShape[1] + \" + resTexRC.y;\\n      int r = 2 * (index / \" + texelsInLogicalRow + \");\\n      int c = imod(index, \" + texelsInLogicalRow + \") * 2;\\n\\n      return ivec2(r, c);\\n    }\\n  \";\n}\nfunction getOutput2DCoords(shape, texShape) {\n    if (util.arraysEqual(shape, texShape)) {\n        return \"\\n      ivec2 getOutputCoords() {\\n        return ivec2(resultUV.yx * vec2(\" + texShape[0] + \", \" + texShape[1] + \"));\\n      }\\n    \";\n    }\n    if (shape[1] === 1) {\n        return \"\\n      ivec2 getOutputCoords() {\\n        ivec2 resTexRC = ivec2(resultUV.yx *\\n                               vec2(\" + texShape[0] + \", \" + texShape[1] + \"));\\n        int index = resTexRC.x * \" + texShape[1] + \" + resTexRC.y;\\n        return ivec2(index, 0);\\n      }\\n    \";\n    }\n    if (shape[0] === 1) {\n        return \"\\n      ivec2 getOutputCoords() {\\n        ivec2 resTexRC = ivec2(resultUV.yx *\\n                               vec2(\" + texShape[0] + \", \" + texShape[1] + \"));\\n        int index = resTexRC.x * \" + texShape[1] + \" + resTexRC.y;\\n        return ivec2(0, index);\\n      }\\n    \";\n    }\n    return \"\\n    ivec2 getOutputCoords() {\\n      ivec2 resTexRC = ivec2(resultUV.yx *\\n                             vec2(\" + texShape[0] + \", \" + texShape[1] + \"));\\n      int index = resTexRC.x * \" + texShape[1] + \" + resTexRC.y;\\n      int r = index / \" + shape[1] + \";\\n      int c = index - r * \" + shape[1] + \";\\n      return ivec2(r, c);\\n    }\\n  \";\n}\nfunction getFlatOffsetUniformName(texName) {\n    return \"offset\" + texName;\n}\nfunction getPackedSamplerScalar(inputInfo) {\n    var texName = inputInfo.name;\n    var funcName = 'get' + texName.charAt(0).toUpperCase() + texName.slice(1);\n    var glsl = glsl_version_1.getGlslDifferences();\n    return \"\\n    vec4 \" + funcName + \"() {\\n      return \" + glsl.texture2D + \"(\" + texName + \", halfCR);\\n    }\\n  \";\n}\nfunction getSamplerScalar(inputInfo) {\n    var texName = inputInfo.name;\n    var funcName = 'get' + texName.charAt(0).toUpperCase() + texName.slice(1);\n    if (inputInfo.shapeInfo.isUniform) {\n        return \"float \" + funcName + \"() {return \" + texName + \";}\";\n    }\n    var _a = inputInfo.shapeInfo.texShape, texNumR = _a[0], texNumC = _a[1];\n    if (texNumR === 1 && texNumC === 1) {\n        return \"\\n      float \" + funcName + \"() {\\n        return sampleTexture(\" + texName + \", halfCR);\\n      }\\n    \";\n    }\n    var _b = inputInfo.shapeInfo.texShape, tNumR = _b[0], tNumC = _b[1];\n    var offset = getFlatOffsetUniformName(texName);\n    return \"\\n    float \" + funcName + \"() {\\n      vec2 uv = uvFromFlat(\" + tNumR + \", \" + tNumC + \", \" + offset + \");\\n      return sampleTexture(\" + texName + \", uv);\\n    }\\n  \";\n}\nfunction getPackedSampler1D(inputInfo) {\n    var texName = inputInfo.name;\n    var funcName = 'get' + texName.charAt(0).toUpperCase() + texName.slice(1);\n    var texShape = inputInfo.shapeInfo.texShape;\n    var packedTexShape = [Math.ceil(texShape[0] / 2), Math.ceil(texShape[1] / 2)];\n    var glsl = glsl_version_1.getGlslDifferences();\n    return \"\\n    vec4 \" + funcName + \"(int index) {\\n      vec2 uv = packedUVfrom1D(\\n        \" + packedTexShape[0] + \", \" + packedTexShape[1] + \", index);\\n      return \" + glsl.texture2D + \"(\" + texName + \", uv);\\n    }\\n  \";\n}\nfunction getSampler1D(inputInfo) {\n    var texName = inputInfo.name;\n    var funcName = 'get' + texName.charAt(0).toUpperCase() + texName.slice(1);\n    if (inputInfo.shapeInfo.isUniform) {\n        // Uniform arrays will be less than 65505 (no risk of float16 overflow).\n        return \"\\n      float \" + funcName + \"(int index) {\\n        \" + getUniformSampler(inputInfo) + \"\\n      }\\n    \";\n    }\n    var texShape = inputInfo.shapeInfo.texShape;\n    var tNumR = texShape[0];\n    var tNumC = texShape[1];\n    if (tNumC === 1 && tNumR === 1) {\n        return \"\\n      float \" + funcName + \"(int index) {\\n        return sampleTexture(\" + texName + \", halfCR);\\n      }\\n    \";\n    }\n    var offset = getFlatOffsetUniformName(texName);\n    if (tNumC === 1) {\n        return \"\\n      float \" + funcName + \"(int index) {\\n        vec2 uv = vec2(0.5, (float(index + \" + offset + \") + 0.5) / \" + tNumR + \".0);\\n        return sampleTexture(\" + texName + \", uv);\\n      }\\n    \";\n    }\n    if (tNumR === 1) {\n        return \"\\n      float \" + funcName + \"(int index) {\\n        vec2 uv = vec2((float(index + \" + offset + \") + 0.5) / \" + tNumC + \".0, 0.5);\\n        return sampleTexture(\" + texName + \", uv);\\n      }\\n    \";\n    }\n    return \"\\n    float \" + funcName + \"(int index) {\\n      vec2 uv = uvFromFlat(\" + tNumR + \", \" + tNumC + \", index + \" + offset + \");\\n      return sampleTexture(\" + texName + \", uv);\\n    }\\n  \";\n}\nfunction getPackedSampler2D(inputInfo) {\n    var shape = inputInfo.shapeInfo.logicalShape;\n    var texName = inputInfo.name;\n    var funcName = 'get' + texName.charAt(0).toUpperCase() + texName.slice(1);\n    var texShape = inputInfo.shapeInfo.texShape;\n    var texNumR = texShape[0];\n    var texNumC = texShape[1];\n    var glsl = glsl_version_1.getGlslDifferences();\n    if (texShape != null && util.arraysEqual(shape, texShape)) {\n        return \"\\n      vec4 \" + funcName + \"(int row, int col) {\\n        vec2 uv = (vec2(col, row) + halfCR) / vec2(\" + texNumC + \".0, \" + texNumR + \".0);\\n\\n        return \" + glsl.texture2D + \"(\" + texName + \", uv);\\n      }\\n    \";\n    }\n    var packedTexShape = [Math.ceil(texShape[0] / 2), Math.ceil(texShape[1] / 2)];\n    var valuesPerRow = Math.ceil(shape[1] / 2);\n    return \"\\n    vec4 \" + funcName + \"(int row, int col) {\\n      vec2 uv = packedUVfrom2D(\" + valuesPerRow + \", \" + packedTexShape[0] + \", \" + packedTexShape[1] + \", row, col);\\n      return \" + glsl.texture2D + \"(\" + texName + \", uv);\\n    }\\n  \";\n}\nfunction getSampler2D(inputInfo) {\n    var shape = inputInfo.shapeInfo.logicalShape;\n    var texName = inputInfo.name;\n    var funcName = 'get' + texName.charAt(0).toUpperCase() + texName.slice(1);\n    var texShape = inputInfo.shapeInfo.texShape;\n    if (texShape != null && util.arraysEqual(shape, texShape)) {\n        var texNumR_1 = texShape[0];\n        var texNumC_1 = texShape[1];\n        return \"\\n    float \" + funcName + \"(int row, int col) {\\n      vec2 uv = (vec2(col, row) + halfCR) / vec2(\" + texNumC_1 + \".0, \" + texNumR_1 + \".0);\\n      return sampleTexture(\" + texName + \", uv);\\n    }\\n  \";\n    }\n    var _a = util.squeezeShape(shape), newShape = _a.newShape, keptDims = _a.keptDims;\n    var squeezedShape = newShape;\n    if (squeezedShape.length < shape.length) {\n        var newInputInfo = squeezeInputInfo(inputInfo, squeezedShape);\n        var params = ['row', 'col'];\n        return \"\\n      \" + getSamplerFromInInfo(newInputInfo) + \"\\n      float \" + funcName + \"(int row, int col) {\\n        return \" + funcName + \"(\" + getSqueezedParams(params, keptDims) + \");\\n      }\\n    \";\n    }\n    if (inputInfo.shapeInfo.isUniform) {\n        // Uniform arrays will be less than 65505 (no risk of float16 overflow).\n        return \"\\n      float \" + funcName + \"(int row, int col) {\\n        int index = round(dot(vec2(row, col), vec2(\" + shape[1] + \", 1)));\\n        \" + getUniformSampler(inputInfo) + \"\\n      }\\n    \";\n    }\n    var texNumR = texShape[0];\n    var texNumC = texShape[1];\n    var offset = getFlatOffsetUniformName(texName);\n    if (texNumC === 1) {\n        // index is used directly as physical (no risk of float16 overflow).\n        return \"\\n    float \" + funcName + \"(int row, int col) {\\n      float index = dot(vec3(row, col, \" + offset + \"), vec3(\" + shape[1] + \", 1, 1));\\n      vec2 uv = vec2(0.5, (index + 0.5) / \" + texNumR + \".0);\\n      return sampleTexture(\" + texName + \", uv);\\n    }\\n  \";\n    }\n    if (texNumR === 1) {\n        // index is used directly as physical (no risk of float16 overflow).\n        return \"\\n    float \" + funcName + \"(int row, int col) {\\n      float index = dot(vec3(row, col, \" + offset + \"), vec3(\" + shape[1] + \", 1, 1));\\n      vec2 uv = vec2((index + 0.5) / \" + texNumC + \".0, 0.5);\\n      return sampleTexture(\" + texName + \", uv);\\n    }\\n  \";\n    }\n    return \"\\n  float \" + funcName + \"(int row, int col) {\\n    // Explicitly use integer operations as dot() only works on floats.\\n    int index = row * \" + shape[1] + \" + col + \" + offset + \";\\n    vec2 uv = uvFromFlat(\" + texNumR + \", \" + texNumC + \", index);\\n    return sampleTexture(\" + texName + \", uv);\\n  }\\n\";\n}\nfunction getPackedSampler3D(inputInfo) {\n    var shape = inputInfo.shapeInfo.logicalShape;\n    var texName = inputInfo.name;\n    var funcName = 'get' + texName.charAt(0).toUpperCase() + texName.slice(1);\n    var texShape = inputInfo.shapeInfo.texShape;\n    var packedTexShape = [Math.ceil(texShape[0] / 2), Math.ceil(texShape[1] / 2)];\n    if (shape[0] === 1) {\n        var squeezedShape = shape.slice(1);\n        var keptDims = [1, 2];\n        var newInputInfo = squeezeInputInfo(inputInfo, squeezedShape);\n        var params = ['b', 'row', 'col'];\n        return \"\\n        \" + getPackedSamplerFromInInfo(newInputInfo) + \"\\n        vec4 \" + funcName + \"(int b, int row, int col) {\\n          return \" + funcName + \"(\" + getSqueezedParams(params, keptDims) + \");\\n        }\\n      \";\n    }\n    var texNumR = packedTexShape[0];\n    var texNumC = packedTexShape[1];\n    var valuesPerRow = Math.ceil(shape[2] / 2);\n    var texelsInBatch = valuesPerRow * Math.ceil(shape[1] / 2);\n    var glsl = glsl_version_1.getGlslDifferences();\n    return \"\\n    vec4 \" + funcName + \"(int b, int row, int col) {\\n      vec2 uv = packedUVfrom3D(\\n        \" + texNumR + \", \" + texNumC + \", \" + texelsInBatch + \", \" + valuesPerRow + \", b, row, col);\\n      return \" + glsl.texture2D + \"(\" + texName + \", uv);\\n    }\\n  \";\n}\nfunction getSampler3D(inputInfo) {\n    var shape = inputInfo.shapeInfo.logicalShape;\n    var texName = inputInfo.name;\n    var funcName = 'get' + texName.charAt(0).toUpperCase() + texName.slice(1);\n    var stride0 = shape[1] * shape[2];\n    var stride1 = shape[2];\n    var _a = util.squeezeShape(shape), newShape = _a.newShape, keptDims = _a.keptDims;\n    var squeezedShape = newShape;\n    if (squeezedShape.length < shape.length) {\n        var newInputInfo = squeezeInputInfo(inputInfo, squeezedShape);\n        var params = ['row', 'col', 'depth'];\n        return \"\\n        \" + getSamplerFromInInfo(newInputInfo) + \"\\n        float \" + funcName + \"(int row, int col, int depth) {\\n          return \" + funcName + \"(\" + getSqueezedParams(params, keptDims) + \");\\n        }\\n      \";\n    }\n    if (inputInfo.shapeInfo.isUniform) {\n        // Uniform arrays will be less than 65505 (no risk of float16 overflow).\n        return \"\\n      float \" + funcName + \"(int row, int col, int depth) {\\n        int index = round(dot(vec3(row, col, depth),\\n                          vec3(\" + stride0 + \", \" + stride1 + \", 1)));\\n        \" + getUniformSampler(inputInfo) + \"\\n      }\\n    \";\n    }\n    var texShape = inputInfo.shapeInfo.texShape;\n    var texNumR = texShape[0];\n    var texNumC = texShape[1];\n    var flatOffset = inputInfo.shapeInfo.flatOffset;\n    if (texNumC === stride0 && flatOffset == null) {\n        // texC is used directly as physical (no risk of float16 overflow).\n        return \"\\n        float \" + funcName + \"(int row, int col, int depth) {\\n          float texR = float(row);\\n          float texC = dot(vec2(col, depth), vec2(\" + stride1 + \", 1));\\n          vec2 uv = (vec2(texC, texR) + halfCR) /\\n                     vec2(\" + texNumC + \".0, \" + texNumR + \".0);\\n          return sampleTexture(\" + texName + \", uv);\\n        }\\n      \";\n    }\n    if (texNumC === stride1 && flatOffset == null) {\n        // texR is used directly as physical (no risk of float16 overflow).\n        return \"\\n    float \" + funcName + \"(int row, int col, int depth) {\\n      float texR = dot(vec2(row, col), vec2(\" + shape[1] + \", 1));\\n      float texC = float(depth);\\n      vec2 uv = (vec2(texC, texR) + halfCR) / vec2(\" + texNumC + \".0, \" + texNumR + \".0);\\n      return sampleTexture(\" + texName + \", uv);\\n    }\\n  \";\n    }\n    var offset = getFlatOffsetUniformName(texName);\n    return \"\\n      float \" + funcName + \"(int row, int col, int depth) {\\n        // Explicitly use integer operations as dot() only works on floats.\\n        int index = row * \" + stride0 + \" + col * \" + stride1 + \" + depth + \" + offset + \";\\n        vec2 uv = uvFromFlat(\" + texNumR + \", \" + texNumC + \", index);\\n        return sampleTexture(\" + texName + \", uv);\\n      }\\n  \";\n}\nfunction getPackedSamplerND(inputInfo) {\n    var shape = inputInfo.shapeInfo.logicalShape;\n    var rank = shape.length;\n    var texName = inputInfo.name;\n    var funcName = 'get' + texName.charAt(0).toUpperCase() + texName.slice(1);\n    var texShape = inputInfo.shapeInfo.texShape;\n    var packedTexShape = [Math.ceil(texShape[0] / 2), Math.ceil(texShape[1] / 2)];\n    var texNumR = packedTexShape[0];\n    var texNumC = packedTexShape[1];\n    var valuesPerRow = Math.ceil(shape[rank - 1] / 2);\n    var texelsInBatch = valuesPerRow * Math.ceil(shape[rank - 2] / 2);\n    var params = \"int b, int row, int col\";\n    var index = \"b * \" + texelsInBatch + \" + (row / 2) * \" + valuesPerRow + \" + (col / 2)\";\n    for (var b = 2; b < rank - 1; b++) {\n        params = \"int b\" + b + \", \" + params;\n        texelsInBatch *= shape[rank - b - 1];\n        index = \"b\" + b + \" * \" + texelsInBatch + \" + \" + index;\n    }\n    var glsl = glsl_version_1.getGlslDifferences();\n    return \"\\n    vec4 \" + funcName + \"(\" + params + \") {\\n      int index = \" + index + \";\\n      int texR = index / \" + texNumC + \";\\n      int texC = index - texR * \" + texNumC + \";\\n      vec2 uv = (vec2(texC, texR) + halfCR) / vec2(\" + texNumC + \", \" + texNumR + \");\\n      return \" + glsl.texture2D + \"(\" + texName + \", uv);\\n    }\\n  \";\n}\nfunction getSampler4D(inputInfo) {\n    var shape = inputInfo.shapeInfo.logicalShape;\n    var texName = inputInfo.name;\n    var funcName = 'get' + texName.charAt(0).toUpperCase() + texName.slice(1);\n    var stride2 = shape[3];\n    var stride1 = shape[2] * stride2;\n    var stride0 = shape[1] * stride1;\n    var _a = util.squeezeShape(shape), newShape = _a.newShape, keptDims = _a.keptDims;\n    if (newShape.length < shape.length) {\n        var newInputInfo = squeezeInputInfo(inputInfo, newShape);\n        var params = ['row', 'col', 'depth', 'depth2'];\n        return \"\\n      \" + getSamplerFromInInfo(newInputInfo) + \"\\n      float \" + funcName + \"(int row, int col, int depth, int depth2) {\\n        return \" + funcName + \"(\" + getSqueezedParams(params, keptDims) + \");\\n      }\\n    \";\n    }\n    if (inputInfo.shapeInfo.isUniform) {\n        // Uniform arrays will be less than 65505 (no risk of float16 overflow).\n        return \"\\n      float \" + funcName + \"(int row, int col, int depth, int depth2) {\\n        int index = round(dot(vec4(row, col, depth, depth2),\\n                          vec4(\" + stride0 + \", \" + stride1 + \", \" + stride2 + \", 1)));\\n        \" + getUniformSampler(inputInfo) + \"\\n      }\\n    \";\n    }\n    var flatOffset = inputInfo.shapeInfo.flatOffset;\n    var texShape = inputInfo.shapeInfo.texShape;\n    var texNumR = texShape[0];\n    var texNumC = texShape[1];\n    if (texNumC === stride0 && flatOffset == null) {\n        // texC is used directly as physical (no risk of float16 overflow).\n        return \"\\n      float \" + funcName + \"(int row, int col, int depth, int depth2) {\\n        float texR = float(row);\\n        float texC =\\n            dot(vec3(col, depth, depth2),\\n                vec3(\" + stride1 + \", \" + stride2 + \", 1));\\n        vec2 uv = (vec2(texC, texR) + halfCR) /\\n                   vec2(\" + texNumC + \".0, \" + texNumR + \".0);\\n        return sampleTexture(\" + texName + \", uv);\\n      }\\n    \";\n    }\n    if (texNumC === stride2 && flatOffset == null) {\n        // texR is used directly as physical (no risk of float16 overflow).\n        return \"\\n      float \" + funcName + \"(int row, int col, int depth, int depth2) {\\n        float texR = dot(vec3(row, col, depth),\\n                         vec3(\" + shape[1] * shape[2] + \", \" + shape[2] + \", 1));\\n        float texC = float(depth2);\\n        vec2 uv = (vec2(texC, texR) + halfCR) /\\n                  vec2(\" + texNumC + \".0, \" + texNumR + \".0);\\n        return sampleTexture(\" + texName + \", uv);\\n      }\\n    \";\n    }\n    var offset = getFlatOffsetUniformName(texName);\n    return \"\\n    float \" + funcName + \"(int row, int col, int depth, int depth2) {\\n      // Explicitly use integer operations as dot() only works on floats.\\n      int index = row * \" + stride0 + \" + col * \" + stride1 + \" +\\n          depth * \" + stride2 + \" + depth2;\\n      vec2 uv = uvFromFlat(\" + texNumR + \", \" + texNumC + \", index + \" + offset + \");\\n      return sampleTexture(\" + texName + \", uv);\\n    }\\n  \";\n}\nfunction getSampler5D(inputInfo) {\n    var shape = inputInfo.shapeInfo.logicalShape;\n    var texName = inputInfo.name;\n    var funcName = 'get' + texName.charAt(0).toUpperCase() + texName.slice(1);\n    var stride3 = shape[4];\n    var stride2 = shape[3] * stride3;\n    var stride1 = shape[2] * stride2;\n    var stride0 = shape[1] * stride1;\n    var _a = util.squeezeShape(shape), newShape = _a.newShape, keptDims = _a.keptDims;\n    if (newShape.length < shape.length) {\n        var newInputInfo = squeezeInputInfo(inputInfo, newShape);\n        var params = ['row', 'col', 'depth', 'depth2', 'depth3'];\n        return \"\\n      \" + getSamplerFromInInfo(newInputInfo) + \"\\n      float \" + funcName + \"(int row, int col, int depth, int depth2, int depth3) {\\n        return \" + funcName + \"(\" + getSqueezedParams(params, keptDims) + \");\\n      }\\n    \";\n    }\n    if (inputInfo.shapeInfo.isUniform) {\n        // Uniform arrays will be less than 65505 (no risk of float16 overflow).\n        return \"\\n      float \" + funcName + \"(int row, int col, int depth, int depth2, int depth3) {\\n        float index = dot(\\n          vec4(row, col, depth, depth2),\\n          vec4(\" + stride0 + \", \" + stride1 + \", \" + stride2 + \", \" + stride3 + \")) +\\n          depth3;\\n        \" + getUniformSampler(inputInfo) + \"\\n      }\\n    \";\n    }\n    var flatOffset = inputInfo.shapeInfo.flatOffset;\n    var texShape = inputInfo.shapeInfo.texShape;\n    var texNumR = texShape[0];\n    var texNumC = texShape[1];\n    if (texNumC === stride0 && flatOffset == null) {\n        // texC is used directly as physical (no risk of float16 overflow).\n        return \"\\n      float \" + funcName + \"(int row, int col, int depth, int depth2, int depth3) {\\n        int texR = row;\\n        float texC = dot(vec4(col, depth, depth2, depth3),\\n                         vec4(\" + stride1 + \", \" + stride2 + \", \" + stride3 + \", 1));\\n        vec2 uv = (vec2(texC, texR) + halfCR) /\\n                   vec2(\" + texNumC + \".0, \" + texNumR + \".0);\\n        return sampleTexture(\" + texName + \", uv);\\n      }\\n    \";\n    }\n    if (texNumC === stride3 && flatOffset == null) {\n        // texR is used directly as physical (no risk of float16 overflow).\n        return \"\\n      float \" + funcName + \"(int row, int col, int depth, int depth2, int depth3) {\\n        float texR = dot(\\n          vec4(row, col, depth, depth2),\\n          vec4(\" + shape[1] * shape[2] * shape[3] + \",\\n               \" + shape[2] * shape[3] + \", \" + shape[3] + \", 1));\\n        int texC = depth3;\\n        vec2 uv = (vec2(texC, texR) + halfCR) /\\n                  vec2(\" + texNumC + \".0, \" + texNumR + \".0);\\n        return sampleTexture(\" + texName + \", uv);\\n      }\\n    \";\n    }\n    var offset = getFlatOffsetUniformName(texName);\n    return \"\\n    float \" + funcName + \"(int row, int col, int depth, int depth2, int depth3) {\\n      // Explicitly use integer operations as dot() only works on floats.\\n      int index = row * \" + stride0 + \" + col * \" + stride1 + \" + depth * \" + stride2 + \" +\\n          depth2 * \" + stride3 + \" + depth3 + \" + offset + \";\\n      vec2 uv = uvFromFlat(\" + texNumR + \", \" + texNumC + \", index);\\n      return sampleTexture(\" + texName + \", uv);\\n    }\\n  \";\n}\nfunction getSampler6D(inputInfo) {\n    var shape = inputInfo.shapeInfo.logicalShape;\n    var texName = inputInfo.name;\n    var funcName = 'get' + texName.charAt(0).toUpperCase() + texName.slice(1);\n    var _a = util.squeezeShape(shape), newShape = _a.newShape, keptDims = _a.keptDims;\n    if (newShape.length < shape.length) {\n        var newInputInfo = squeezeInputInfo(inputInfo, newShape);\n        var params = ['row', 'col', 'depth', 'depth2', 'depth3', 'depth4'];\n        return \"\\n      \" + getSamplerFromInInfo(newInputInfo) + \"\\n      float \" + funcName + \"(int row, int col, int depth,\\n                    int depth2, int depth3, int depth4) {\\n        return \" + funcName + \"(\" + getSqueezedParams(params, keptDims) + \");\\n      }\\n    \";\n    }\n    var stride4 = shape[5];\n    var stride3 = shape[4] * stride4;\n    var stride2 = shape[3] * stride3;\n    var stride1 = shape[2] * stride2;\n    var stride0 = shape[1] * stride1;\n    if (inputInfo.shapeInfo.isUniform) {\n        // Uniform arrays will be less than 65505 (no risk of float16 overflow).\n        return \"\\n      float \" + funcName + \"(int row, int col, int depth,\\n                  int depth2, int depth3, int depth4) {\\n        int index = round(dot(\\n          vec4(row, col, depth, depth2),\\n          vec4(\" + stride0 + \", \" + stride1 + \", \" + stride2 + \", \" + stride3 + \")) +\\n          dot(\\n            vec2(depth3, depth4),\\n            vec2(\" + stride4 + \", 1)));\\n        \" + getUniformSampler(inputInfo) + \"\\n      }\\n    \";\n    }\n    var flatOffset = inputInfo.shapeInfo.flatOffset;\n    var texShape = inputInfo.shapeInfo.texShape;\n    var texNumR = texShape[0];\n    var texNumC = texShape[1];\n    if (texNumC === stride0 && flatOffset == null) {\n        // texC is used directly as physical (no risk of float16 overflow).\n        return \"\\n      float \" + funcName + \"(int row, int col, int depth,\\n                    int depth2, int depth3, int depth4) {\\n        int texR = row;\\n        float texC = dot(vec4(col, depth, depth2, depth3),\\n          vec4(\" + stride1 + \", \" + stride2 + \", \" + stride3 + \", \" + stride4 + \")) +\\n               float(depth4);\\n        vec2 uv = (vec2(texC, texR) + halfCR) /\\n                   vec2(\" + texNumC + \".0, \" + texNumR + \".0);\\n        return sampleTexture(\" + texName + \", uv);\\n      }\\n    \";\n    }\n    if (texNumC === stride4 && flatOffset == null) {\n        // texR is used directly as physical (no risk of float16 overflow).\n        return \"\\n      float \" + funcName + \"(int row, int col, int depth,\\n                    int depth2, int depth3, int depth4) {\\n        float texR = dot(vec4(row, col, depth, depth2),\\n          vec4(\" + shape[1] * shape[2] * shape[3] * shape[4] + \",\\n               \" + shape[2] * shape[3] * shape[4] + \",\\n               \" + shape[3] * shape[4] + \",\\n               \" + shape[4] + \")) + float(depth3);\\n        int texC = depth4;\\n        vec2 uv = (vec2(texC, texR) + halfCR) /\\n                  vec2(\" + texNumC + \".0, \" + texNumR + \".0);\\n        return sampleTexture(\" + texName + \", uv);\\n      }\\n    \";\n    }\n    var offset = getFlatOffsetUniformName(texName);\n    return \"\\n    float \" + funcName + \"(int row, int col, int depth,\\n                  int depth2, int depth3, int depth4) {\\n      // Explicitly use integer operations as dot() only works on floats.\\n      int index = row * \" + stride0 + \" + col * \" + stride1 + \" + depth * \" + stride2 + \" +\\n          depth2 * \" + stride3 + \" + depth3 * \" + stride4 + \" + depth4 + \" + offset + \";\\n      vec2 uv = uvFromFlat(\" + texNumR + \", \" + texNumC + \", index);\\n      return sampleTexture(\" + texName + \", uv);\\n    }\\n  \";\n}\nfunction getUniformSampler(inputInfo) {\n    var texName = inputInfo.name;\n    var inSize = util.sizeFromShape(inputInfo.shapeInfo.logicalShape);\n    if (inSize < 2) {\n        return \"return \" + texName + \";\";\n    }\n    return \"\\n    for (int i = 0; i < \" + inSize + \"; i++) {\\n      if (i == index) {\\n        return \" + texName + \"[i];\\n      }\\n    }\\n  \";\n}\nfunction getPackedSamplerAtOutputCoords(inputInfo, outShapeInfo) {\n    var texName = inputInfo.name;\n    var texFuncSnippet = texName.charAt(0).toUpperCase() + texName.slice(1);\n    var funcName = 'get' + texFuncSnippet + 'AtOutCoords';\n    var inRank = inputInfo.shapeInfo.logicalShape.length;\n    var outRank = outShapeInfo.logicalShape.length;\n    var broadcastDims = broadcast_util_1.getBroadcastDims(inputInfo.shapeInfo.logicalShape, outShapeInfo.logicalShape);\n    var type = getCoordsDataType(outRank);\n    var rankDiff = outRank - inRank;\n    var coordsSnippet;\n    var fields = ['x', 'y', 'z', 'w', 'u', 'v'];\n    if (inRank === 0) {\n        coordsSnippet = '';\n    }\n    else if (outRank < 2 && broadcastDims.length >= 1) {\n        coordsSnippet = 'coords = 0;';\n    }\n    else {\n        coordsSnippet =\n            broadcastDims.map(function (d) { return \"coords.\" + fields[d + rankDiff] + \" = 0;\"; })\n                .join('\\n');\n    }\n    var unpackedCoordsSnippet = '';\n    if (outRank < 2 && inRank > 0) {\n        unpackedCoordsSnippet = 'coords';\n    }\n    else {\n        unpackedCoordsSnippet = inputInfo.shapeInfo.logicalShape\n            .map(function (s, i) { return \"coords.\" + fields[i + rankDiff]; })\n            .join(', ');\n    }\n    var output = \"return outputValue;\";\n    var inSize = util.sizeFromShape(inputInfo.shapeInfo.logicalShape);\n    var isInputScalar = inSize === 1;\n    var outSize = util.sizeFromShape(outShapeInfo.logicalShape);\n    var isOutputScalar = outSize === 1;\n    if (inRank === 1 && !isInputScalar && !isOutputScalar) {\n        output = \"\\n      return vec4(outputValue.xy, outputValue.xy);\\n    \";\n    }\n    else if (isInputScalar && !isOutputScalar) {\n        if (outRank === 1) {\n            output = \"\\n        return vec4(outputValue.x, outputValue.x, 0., 0.);\\n      \";\n        }\n        else {\n            output = \"\\n        return vec4(outputValue.x);\\n      \";\n        }\n    }\n    else if (broadcastDims.length) {\n        var rows = inRank - 2;\n        var cols = inRank - 1;\n        if (broadcastDims.indexOf(rows) > -1 && broadcastDims.indexOf(cols) > -1) {\n            output = \"return vec4(outputValue.x);\";\n        }\n        else if (broadcastDims.indexOf(rows) > -1) {\n            output = \"return vec4(outputValue.x, outputValue.y, \" +\n                \"outputValue.x, outputValue.y);\";\n        }\n        else if (broadcastDims.indexOf(cols) > -1) {\n            output = \"return vec4(outputValue.xx, outputValue.zz);\";\n        }\n    }\n    return \"\\n    vec4 \" + funcName + \"() {\\n      \" + type + \" coords = getOutputCoords();\\n      \" + coordsSnippet + \"\\n      vec4 outputValue = get\" + texFuncSnippet + \"(\" + unpackedCoordsSnippet + \");\\n      \" + output + \"\\n    }\\n  \";\n}\nfunction getSamplerAtOutputCoords(inputInfo, outShapeInfo) {\n    var texName = inputInfo.name;\n    var texFuncSnippet = texName.charAt(0).toUpperCase() + texName.slice(1);\n    var funcName = 'get' + texFuncSnippet + 'AtOutCoords';\n    var outTexShape = outShapeInfo.texShape;\n    var inTexShape = inputInfo.shapeInfo.texShape;\n    var inRank = inputInfo.shapeInfo.logicalShape.length;\n    var outRank = outShapeInfo.logicalShape.length;\n    if (!inputInfo.shapeInfo.isUniform && inRank === outRank &&\n        inputInfo.shapeInfo.flatOffset == null &&\n        util.arraysEqual(inTexShape, outTexShape)) {\n        return \"\\n      float \" + funcName + \"() {\\n        return sampleTexture(\" + texName + \", resultUV);\\n      }\\n    \";\n    }\n    var type = getCoordsDataType(outRank);\n    var broadcastDims = broadcast_util_1.getBroadcastDims(inputInfo.shapeInfo.logicalShape, outShapeInfo.logicalShape);\n    var rankDiff = outRank - inRank;\n    var coordsSnippet;\n    var fields = ['x', 'y', 'z', 'w', 'u', 'v'];\n    if (inRank === 0) {\n        coordsSnippet = '';\n    }\n    else if (outRank < 2 && broadcastDims.length >= 1) {\n        coordsSnippet = 'coords = 0;';\n    }\n    else {\n        coordsSnippet =\n            broadcastDims.map(function (d) { return \"coords.\" + fields[d + rankDiff] + \" = 0;\"; })\n                .join('\\n');\n    }\n    var unpackedCoordsSnippet = '';\n    if (outRank < 2 && inRank > 0) {\n        unpackedCoordsSnippet = 'coords';\n    }\n    else {\n        unpackedCoordsSnippet = inputInfo.shapeInfo.logicalShape\n            .map(function (s, i) { return \"coords.\" + fields[i + rankDiff]; })\n            .join(', ');\n    }\n    return \"\\n    float \" + funcName + \"() {\\n      \" + type + \" coords = getOutputCoords();\\n      \" + coordsSnippet + \"\\n      return get\" + texFuncSnippet + \"(\" + unpackedCoordsSnippet + \");\\n    }\\n  \";\n}\nfunction getCoordsDataType(rank) {\n    if (rank <= 1) {\n        return 'int';\n    }\n    else if (rank === 2) {\n        return 'ivec2';\n    }\n    else if (rank === 3) {\n        return 'ivec3';\n    }\n    else if (rank === 4) {\n        return 'ivec4';\n    }\n    else if (rank === 5) {\n        return 'ivec5';\n    }\n    else if (rank === 6) {\n        return 'ivec6';\n    }\n    else {\n        throw Error(\"GPU for rank \" + rank + \" is not yet supported\");\n    }\n}\nexports.getCoordsDataType = getCoordsDataType;\n/** Returns a new input info (a copy) that has a squeezed logical shape. */\nfunction squeezeInputInfo(inInfo, squeezedShape) {\n    // Deep copy.\n    var newInputInfo = JSON.parse(JSON.stringify(inInfo));\n    newInputInfo.shapeInfo.logicalShape = squeezedShape;\n    return newInputInfo;\n}\nfunction getSqueezedParams(params, keptDims) {\n    return keptDims.map(function (d) { return params[d]; }).join(', ');\n}\n//# sourceMappingURL=shader_compiler.js.map","\n/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar environment_1 = require(\"../../environment\");\nfunction getGlslDifferences() {\n    var version;\n    var attribute;\n    var varyingVs;\n    var varyingFs;\n    var texture2D;\n    var output;\n    var defineOutput;\n    var defineSpecialNaN;\n    var defineSpecialInf;\n    var defineRound;\n    if (environment_1.ENV.getNumber('WEBGL_VERSION') === 2) {\n        version = '#version 300 es';\n        attribute = 'in';\n        varyingVs = 'out';\n        varyingFs = 'in';\n        texture2D = 'texture';\n        output = 'outputColor';\n        defineOutput = 'out vec4 outputColor;';\n        defineSpecialNaN = \"\\n      bool isnan_custom(float val) {\\n        return (val > 0. || val < 0. || val == 0.) ? false : true;\\n      }\\n    \";\n        defineSpecialInf = \"\\n      const float INFINITY = uintBitsToFloat(uint(0x7f800000));\\n    \";\n        defineRound = \"\\n      #define round(value) newRound(value)\\n      int newRound(float value) {\\n        return int(floor(value + 0.5));\\n      }\\n\\n      ivec4 newRound(vec4 value) {\\n        return ivec4(floor(value + vec4(0.5)));\\n      }\\n    \";\n    }\n    else {\n        version = '';\n        attribute = 'attribute';\n        varyingVs = 'varying';\n        varyingFs = 'varying';\n        texture2D = 'texture2D';\n        output = 'gl_FragColor';\n        defineOutput = '';\n        defineSpecialNaN = \"\\n      bool isnan_custom(float val) {\\n        return (val > 0. || val < 1. || val == 0.) ? false : true;\\n      }\\n    \";\n        defineSpecialInf = \"\\n      uniform float INFINITY;\\n\\n      bool isinf(float val) {\\n        return abs(val) == INFINITY;\\n      }\\n      bvec4 isinf(vec4 val) {\\n        return equal(abs(val), vec4(INFINITY));\\n      }\\n    \";\n        defineRound = \"\\n      int round(float value) {\\n        return int(floor(value + 0.5));\\n      }\\n\\n      ivec4 round(vec4 value) {\\n        return ivec4(floor(value + vec4(0.5)));\\n      }\\n    \";\n    }\n    return {\n        version: version,\n        attribute: attribute,\n        varyingVs: varyingVs,\n        varyingFs: varyingFs,\n        texture2D: texture2D,\n        output: output,\n        defineOutput: defineOutput,\n        defineSpecialNaN: defineSpecialNaN,\n        defineSpecialInf: defineSpecialInf,\n        defineRound: defineRound\n    };\n}\nexports.getGlslDifferences = getGlslDifferences;\n//# sourceMappingURL=glsl_version.js.map","\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar util = require(\"../../util\");\n/**\n * Produces GLSL code that derives logical coordinates from a flat\n * index. The code performs integer division with each stride and decrements\n * the index until the index equals the final dimension coordinate.\n */\nfunction getLogicalCoordinatesFromFlatIndex(coords, shape, index) {\n    if (index === void 0) { index = 'index'; }\n    var strides = util.computeStrides(shape);\n    return strides\n        .map(function (stride, i) {\n        var line1 = \"int \" + coords[i] + \" = \" + index + \" / \" + stride;\n        var line2 = i === strides.length - 1 ?\n            \"int \" + coords[i + 1] + \" = \" + index + \" - \" + coords[i] + \" * \" + stride :\n            \"index -= \" + coords[i] + \" * \" + stride;\n        return line1 + \"; \" + line2 + \";\";\n    })\n        .join('');\n}\nexports.getLogicalCoordinatesFromFlatIndex = getLogicalCoordinatesFromFlatIndex;\nfunction buildVec(x) {\n    if (x.length === 1) {\n        return \"\" + x[0];\n    }\n    return \"vec\" + x.length + \"(\" + x.join(',') + \")\";\n}\n/**\n * Produces GLSL code that computes the dot product of the input x and y\n * vectors. Handles splitting inputs into increments of vec4s when necessary.\n */\nfunction dotify(x, y) {\n    if (x.length !== y.length) {\n        throw new Error(\"Vectors to be dotted must be of the same length -\" +\n            (\"got \" + x.length + \" and \" + y.length));\n    }\n    var slices = [];\n    var nearestVec4 = Math.floor(x.length / 4);\n    var nearestVec4Remainder = x.length % 4;\n    for (var i = 0; i < nearestVec4; i++) {\n        var xSlice = x.slice(i * 4, i * 4 + 4);\n        var ySlice = y.slice(i * 4, i * 4 + 4);\n        slices.push(buildVec(xSlice) + \", \" + buildVec(ySlice));\n    }\n    if (nearestVec4Remainder !== 0) {\n        var xSlice = x.slice(nearestVec4 * 4);\n        var ySlice = y.slice(nearestVec4 * 4);\n        if (xSlice.length === 1) {\n            xSlice = xSlice.map(function (d) { return \"float(\" + d + \")\"; });\n            ySlice = ySlice.map(function (d) { return \"float(\" + d + \")\"; });\n        }\n        slices.push(buildVec(xSlice) + \", \" + buildVec(ySlice));\n    }\n    return slices.map(function (d, i) { return \"dot(\" + d + \")\"; }).join('+');\n}\nexports.dotify = dotify;\n//# sourceMappingURL=shader_compiler_util.js.map","\n/**\n * @license\n * Copyright 2017 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar AvgPool2DBackpropProgram = /** @class */ (function () {\n    function AvgPool2DBackpropProgram(convInfo) {\n        this.variableNames = ['dy'];\n        this.outputShape = convInfo.inShape;\n        var filterHeight = convInfo.filterHeight;\n        var filterWidth = convInfo.filterWidth;\n        var strideHeight = convInfo.strideHeight;\n        var strideWidth = convInfo.strideWidth;\n        var dilationHeight = convInfo.dilationHeight;\n        var dilationWidth = convInfo.dilationWidth;\n        var effectiveFilterHeight = convInfo.effectiveFilterHeight;\n        var effectiveFilterWidth = convInfo.effectiveFilterWidth;\n        var padTop = effectiveFilterHeight - 1 - convInfo.padInfo.top;\n        var padLeft = effectiveFilterWidth - 1 - convInfo.padInfo.left;\n        var avgMultiplier = 1 / (filterHeight * filterWidth);\n        this.userCode = \"\\n      const ivec2 pads = ivec2(\" + padTop + \", \" + padLeft + \");\\n      const float avgMultiplier = float(\" + avgMultiplier + \");\\n\\n      void main() {\\n        ivec4 coords = getOutputCoords();\\n        int b = coords[0];\\n        int d = coords[3];\\n\\n        ivec2 dyRCCorner = coords.yz - pads;\\n        int dyRCorner = dyRCCorner.x;\\n        int dyCCorner = dyRCCorner.y;\\n\\n        // Convolve dy(?, ?, d) with pos mask(:, :, d) to get dx(xR, xC, d).\\n        // ? = to be determined. : = across all values in that axis.\\n        float dotProd = 0.0;\\n        for (int wR = 0; wR < \" + effectiveFilterHeight + \";\\n            wR += \" + dilationHeight + \") {\\n          float dyR = float(dyRCorner + wR) / \" + strideHeight + \".0;\\n\\n          if (dyR < 0.0 || dyR >= \" + convInfo.outHeight + \".0 || fract(dyR) > 0.0) {\\n            continue;\\n          }\\n          int idyR = int(dyR);\\n\\n          for (int wC = 0; wC < \" + effectiveFilterWidth + \";\\n            wC+= \" + dilationWidth + \") {\\n            float dyC = float(dyCCorner + wC) / \" + strideWidth + \".0;\\n\\n            if (dyC < 0.0 || dyC >= \" + convInfo.outWidth + \".0 ||\\n                fract(dyC) > 0.0) {\\n              continue;\\n            }\\n            int idyC = int(dyC);\\n\\n            float dyValue = getDy(b, idyR, idyC, d);\\n\\n            dotProd += dyValue * avgMultiplier;\\n          }\\n        }\\n        setOutput(dotProd);\\n      }\\n    \";\n    }\n    return AvgPool2DBackpropProgram;\n}());\nexports.AvgPool2DBackpropProgram = AvgPool2DBackpropProgram;\n//# sourceMappingURL=avg_pool_backprop_gpu.js.map","\n/**\n * @license\n * Copyright 2017 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar broadcast_util = require(\"../../ops/broadcast_util\");\nvar BatchNormProgram = /** @class */ (function () {\n    function BatchNormProgram(xShape, meanShape, varianceShape, offsetShape, scaleShape, varianceEpsilon) {\n        this.outputShape = [];\n        this.variableNames = ['x', 'mean', 'variance'];\n        broadcast_util.assertAndGetBroadcastShape(xShape, meanShape);\n        broadcast_util.assertAndGetBroadcastShape(xShape, varianceShape);\n        var offsetSnippet = '0.0';\n        if (offsetShape != null) {\n            broadcast_util.assertAndGetBroadcastShape(xShape, offsetShape);\n            this.variableNames.push('offset');\n            offsetSnippet = 'getOffsetAtOutCoords()';\n        }\n        var scaleSnippet = '1.0';\n        if (scaleShape != null) {\n            broadcast_util.assertAndGetBroadcastShape(xShape, scaleShape);\n            this.variableNames.push('scale');\n            scaleSnippet = 'getScaleAtOutCoords()';\n        }\n        this.outputShape = xShape;\n        this.userCode = \"\\n      void main() {\\n        float x = getXAtOutCoords();\\n        float mean = getMeanAtOutCoords();\\n        float variance = getVarianceAtOutCoords();\\n        float offset = \" + offsetSnippet + \";\\n        float scale = \" + scaleSnippet + \";\\n        float inv = scale * inversesqrt(variance + float(\" + varianceEpsilon + \"));\\n        setOutput(dot(vec3(x, -mean, offset), vec3(inv, inv, 1)));\\n      }\\n    \";\n    }\n    return BatchNormProgram;\n}());\nexports.BatchNormProgram = BatchNormProgram;\n//# sourceMappingURL=batchnorm_gpu.js.map","\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar broadcast_util = require(\"../../ops/broadcast_util\");\nvar BatchNormPackedProgram = /** @class */ (function () {\n    function BatchNormPackedProgram(xShape, meanShape, varianceShape, offsetShape, scaleShape, varianceEpsilon) {\n        this.usesPackedTextures = true;\n        this.variableNames = ['x', 'mean', 'variance'];\n        broadcast_util.assertAndGetBroadcastShape(xShape, meanShape);\n        broadcast_util.assertAndGetBroadcastShape(xShape, varianceShape);\n        var offsetSnippet = 'vec4(0.0)';\n        if (offsetShape != null) {\n            broadcast_util.assertAndGetBroadcastShape(xShape, offsetShape);\n            this.variableNames.push('offset');\n            offsetSnippet = 'getOffsetAtOutCoords()';\n        }\n        var scaleSnippet = 'vec4(1.0)';\n        if (scaleShape != null) {\n            broadcast_util.assertAndGetBroadcastShape(xShape, scaleShape);\n            this.variableNames.push('scale');\n            scaleSnippet = 'getScaleAtOutCoords()';\n        }\n        this.outputShape = xShape;\n        this.userCode = \"\\n      void main() {\\n        vec4 offset = \" + offsetSnippet + \";\\n        vec4 scale = \" + scaleSnippet + \";\\n\\n        vec4 x = getXAtOutCoords();\\n        vec4 mean = getMeanAtOutCoords();\\n        vec4 variance = getVarianceAtOutCoords();\\n\\n        vec4 inv = scale * inversesqrt(variance + vec4(\" + varianceEpsilon + \"));\\n\\n        setOutput((x - mean) * inv + offset);\\n      }\\n    \";\n    }\n    return BatchNormPackedProgram;\n}());\nexports.BatchNormPackedProgram = BatchNormPackedProgram;\n//# sourceMappingURL=batchnorm_packed_gpu.js.map","\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar broadcast_util = require(\"../../ops/broadcast_util\");\n// (Ar + Ai)(Br + Bi) =\n// ArBr + ArBi + AiBr + AiBi = ArBr - AB + ArBi + AiBr\n// Yr = ArBr - AB\n// Yi = ArBi + AiBr\nexports.COMPLEX_MULTIPLY = {\n    REAL: 'return areal * breal - aimag * bimag;',\n    IMAG: 'return areal * bimag + aimag * breal;'\n};\nvar BinaryOpComplexProgram = /** @class */ (function () {\n    function BinaryOpComplexProgram(op, aShape, bShape) {\n        this.variableNames = ['AReal', 'AImag', 'BReal', 'BImag'];\n        this.outputShape =\n            broadcast_util.assertAndGetBroadcastShape(aShape, bShape);\n        this.userCode = \"\\n      float binaryOpComplex(\\n          float areal, float aimag, float breal, float bimag) {\\n        \" + op + \"\\n      }\\n\\n      void main() {\\n        float areal = getARealAtOutCoords();\\n        float aimag = getAImagAtOutCoords();\\n        float breal = getBRealAtOutCoords();\\n        float bimag = getBImagAtOutCoords();\\n        setOutput(binaryOpComplex(areal, aimag, breal, bimag));\\n      }\\n    \";\n    }\n    return BinaryOpComplexProgram;\n}());\nexports.BinaryOpComplexProgram = BinaryOpComplexProgram;\n//# sourceMappingURL=binaryop_complex_gpu.js.map","\n/**\n * @license\n * Copyright 2017 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar broadcast_util = require(\"../../ops/broadcast_util\");\nvar CHECK_NAN_SNIPPET = \"\\n  if (isnan(a)) return a;\\n  if (isnan(b)) return b;\\n\";\nexports.ADD = 'return a + b;';\nexports.SUB = 'return a - b;';\nexports.MUL = 'return a * b;';\n// Without the equality check div produces 0.9999 for a = b, which when\n// floored can cause errors.\nexports.DIV = \"\\nif (b == 0.0) {\\n  return NAN;\\n} \\nif (a == b) {\\n  return 1.0;\\n};\\nreturn a / b;\";\n// We use native integer division to deal with floating point imprecision. Since\n// we implement floor division and glsl implements truncated division, we\n// correct for this by subtracting 1 from result when the result is negative and\n// there is a remainder.\nexports.INT_DIV = \"\\n  float s = sign(a) * sign(b);\\n  int ia = round(a);\\n  int ib = round(b);\\n  if (ib != 0) {\\n    // Windows (D3D) wants guaranteed non-zero int division at compile-time.\\n    return float(idiv(ia, ib, s));\\n  } else {\\n    return NAN;\\n  }\\n\";\nexports.POW = \"\\nif(a < 0.0 && floor(b) < b){\\n  return NAN;\\n}\\nreturn (round(mod(b, 2.0)) != 1) ?\\n    pow(abs(a), b) : sign(a) * pow(abs(a), b);\\n\";\nexports.SQUARED_DIFFERENCE = 'return (a - b) * (a - b);';\nexports.EQUAL = \"return float(a == b);\";\nexports.NOT_EQUAL = \"return float(a != b);\";\nexports.LESS = \"return float(a < b);\";\nexports.LESS_EQUAL = \"return float(a <= b);\";\nexports.GREATER = \"return float(a > b);\";\nexports.GREATER_EQUAL = \"return float(a >= b);\";\nexports.LOGICAL_AND = \"return float(a >= 1.0 && b >= 1.0);\";\nexports.LOGICAL_OR = \"return float(a >= 1.0 || b >= 1.0);\";\nexports.MAX = CHECK_NAN_SNIPPET + \"\\n  return max(a, b);\\n\";\nexports.MIN = CHECK_NAN_SNIPPET + \"\\n  return min(a, b);\\n\";\nexports.MOD = \"if (b == 0.0) return NAN;\\n  return mod(a, b);\";\nexports.ATAN2 = CHECK_NAN_SNIPPET + \"\\n  return atan(a, b);\\n\";\nexports.ELU_DER = \"return (b >= 1.0) ? a : a * (b + 1.0);\";\nexports.PRELU = \"return (a < 0.) ? b * a : a;\";\nvar BinaryOpProgram = /** @class */ (function () {\n    function BinaryOpProgram(op, aShape, bShape) {\n        this.variableNames = ['A', 'B'];\n        this.outputShape =\n            broadcast_util.assertAndGetBroadcastShape(aShape, bShape);\n        this.userCode = \"\\n      float binaryOperation(float a, float b) {\\n        \" + op + \"\\n      }\\n\\n      void main() {\\n        float a = getAAtOutCoords();\\n        float b = getBAtOutCoords();\\n        setOutput(binaryOperation(a, b));\\n      }\\n    \";\n    }\n    return BinaryOpProgram;\n}());\nexports.BinaryOpProgram = BinaryOpProgram;\n//# sourceMappingURL=binaryop_gpu.js.map","\n/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar broadcast_util = require(\"../../ops/broadcast_util\");\nvar util_1 = require(\"../../util\");\nvar packing_util_1 = require(\"../packing_util\");\nvar shader_compiler_1 = require(\"./shader_compiler\");\nvar CHECK_NAN_SNIPPET = \"\\n  result.r = isNaN.r > 0. ? NAN : result.r;\\n  result.g = isNaN.g > 0. ? NAN : result.g;\\n  result.b = isNaN.b > 0. ? NAN : result.b;\\n  result.a = isNaN.a > 0. ? NAN : result.a;\\n\";\n// We do the same as in ./binaryop_gpu, with vec4 and ivec4.\n// On Linux, the vectorized implementation produces NaNs when a and b are 0.\nexports.DIV = \"\\n  // vec4 one = vec4(equal(a, b));\\n  // return one + (vec4(1.0) - one) * a / b;\\n  vec4 result = a / b;\\n  if(b.x == 0.0) {\\n    result.x = NAN;\\n  } else if(a.x == b.x) {\\n    result.x = 1.;\\n  }\\n  if(b.y == 0.0) {\\n    result.y = NAN;\\n  } else if(a.y == b.y) {\\n    result.y = 1.;\\n  }\\n  if(b.z == 0.0) {\\n    result.z = NAN;\\n  } else if(a.z == b.z) {\\n    result.z = 1.;\\n  }\\n  if(b.w == 0.0) {\\n    result.w = NAN;\\n  } else if(a.w == b.w) {\\n    result.w = 1.;\\n  }\\n  \\n  return result;\\n\";\nexports.INT_DIV = \"\\n  ivec4 ia = round(a);\\n  ivec4 ib = round(b);\\n  bvec4 cond = notEqual(ib, ivec4(0));\\n  ivec4 result = ivec4(0);\\n  vec4 s = sign(a) * sign(b);\\n\\n  // Windows (D3D) wants guaranteed non-zero int division at compile-time.\\n  if (cond[0]) {\\n    result[0] = idiv(ia[0], ib[0], s[0]);\\n  }\\n  if (cond[1]) {\\n    result[1] = idiv(ia[1], ib[1], s[1]);\\n  }\\n  if (cond[2]) {\\n    result[2] = idiv(ia[2], ib[2], s[2]);\\n  }\\n  if (cond[3]) {\\n    result[3] = idiv(ia[3], ib[3], s[3]);\\n  }\\n  return vec4(result);\\n\";\nexports.POW = \"\\n  // isModRound1 has 1 for components with round(mod(b, 2.0)) == 1, 0 otherwise.\\n  vec4 isModRound1 = vec4(equal(round(mod(b, 2.0)), ivec4(1)));\\n  vec4 multiplier = sign(a) * isModRound1 + (vec4(1.0) - isModRound1);\\n  vec4 result = multiplier * pow(abs(a), b);\\n\\n  vec4 isNaN = vec4(lessThan(a, vec4(0.0))) * vec4(lessThan(floor(b), b));\\n  \" +\n    CHECK_NAN_SNIPPET + \"\\n  return result;\\n\";\nexports.PRELU = \"\\n  vec4 aLessThanZero = vec4(lessThan(a, vec4(0.)));\\n  return (aLessThanZero * (b * a)) + ((vec4(1.0) - aLessThanZero) * a);\\n\";\nexports.ELU_DER = \"\\n  vec4 bGTEZero = vec4(greaterThanEqual(b, vec4(0.)));\\n  return (bGTEZero * a) + ((vec4(1.0) - bGTEZero) * (a * (b + vec4(1.0))));\\n\";\nexports.ATAN2 = \"\\n  vec4 result = atan(a, b);\\n  vec4 isNaN = min(vec4(isnan(a)) + vec4(isnan(b)), vec4(1.0));\\n  \" +\n    CHECK_NAN_SNIPPET + \"\\n  return result;\\n\";\nexports.EQUAL = \"\\n  return vec4(equal(a, b));\\n\";\nexports.NOT_EQUAL = \"\\n  return vec4(notEqual(a, b));\\n\";\nexports.LESS = \"\\n  return vec4(lessThan(a, b));\\n\";\nexports.LESS_EQUAL = \"\\n  return vec4(lessThanEqual(a, b));\\n\";\nexports.GREATER = \"\\n  return vec4(greaterThan(a, b));\\n\";\nexports.GREATER_EQUAL = \"\\n  return vec4(greaterThanEqual(a, b));\\n\";\nexports.LOGICAL_AND = \"\\n  return vec4(\\n    vec4(greaterThanEqual(a, vec4(1.0))) *\\n    vec4(greaterThanEqual(b, vec4(1.0))));\\n\";\nexports.LOGICAL_OR = \"\\n  return min(\\n    vec4(greaterThanEqual(a, vec4(1.0))) +\\n    vec4(greaterThanEqual(b, vec4(1.0))),\\n    vec4(1.0));\\n\";\nexports.MAX = \"\\n  vec4 result = vec4(max(a, b));\\n  vec4 isNaN = min(vec4(isnan(a)) + vec4(isnan(b)), vec4(1.0));\\n  \" +\n    CHECK_NAN_SNIPPET + \"\\n  return result;\\n\";\nexports.MIN = \"\\n  vec4 result = vec4(min(a, b));\\n  vec4 isNaN = min(vec4(isnan(a)) + vec4(isnan(b)), vec4(1.0));\\n  \" +\n    CHECK_NAN_SNIPPET + \"\\n  return result;\\n\";\nexports.MOD = \"\\n  vec4 result = mod(a, b);\\n  vec4 isNaN = vec4(equal(b, vec4(0.0)));\\n  \" +\n    CHECK_NAN_SNIPPET + \"\\n  return result;\\n\";\nvar BinaryOpPackedProgram = /** @class */ (function () {\n    function BinaryOpPackedProgram(op, aShape, bShape, checkOutOfBounds) {\n        if (checkOutOfBounds === void 0) { checkOutOfBounds = false; }\n        this.variableNames = ['A', 'B'];\n        this.supportsBroadcasting = true;\n        this.usesPackedTextures = true;\n        this.outputShape =\n            broadcast_util.assertAndGetBroadcastShape(aShape, bShape);\n        var rank = this.outputShape.length;\n        var checkOutOfBoundsString = '';\n        if (checkOutOfBounds) {\n            if (rank === 0 || util_1.sizeFromShape(this.outputShape) === 1) {\n                checkOutOfBoundsString = \"\\n          result.y = 0.;\\n          result.z = 0.;\\n          result.w = 0.;\\n        \";\n            }\n            else {\n                var dtype = shader_compiler_1.getCoordsDataType(rank);\n                checkOutOfBoundsString = \"\\n          \" + dtype + \" coords = getOutputCoords();\\n        \";\n                if (rank === 1) {\n                    checkOutOfBoundsString += \"\\n            result.y = (coords + 1) >= \" + this.outputShape[0] + \" ? 0. : result.y;\\n            result.z = 0.;\\n            result.w = 0.;\\n          \";\n                }\n                else {\n                    var channels = packing_util_1.getChannels('coords', rank);\n                    checkOutOfBoundsString += \"\\n            bool nextRowOutOfBounds =\\n              (\" + channels[rank - 2] + \" + 1) >= \" + this.outputShape[rank - 2] + \";\\n            bool nextColOutOfBounds =\\n              (\" + channels[rank - 1] + \" + 1) >= \" + this.outputShape[rank - 1] + \";\\n            result.y = nextColOutOfBounds ? 0. : result.y;\\n            result.z = nextRowOutOfBounds ? 0. : result.z;\\n            result.w = nextColOutOfBounds || nextRowOutOfBounds ? 0. : result.w;\\n          \";\n                }\n            }\n        }\n        this.userCode = \"\\n      vec4 binaryOperation(vec4 a, vec4 b) {\\n        \" + op + \"\\n      }\\n\\n      void main() {\\n        vec4 a = getAAtOutCoords();\\n        vec4 b = getBAtOutCoords();\\n\\n        vec4 result = binaryOperation(a, b);\\n        \" + checkOutOfBoundsString + \"\\n\\n        setOutput(result);\\n      }\\n    \";\n    }\n    return BinaryOpPackedProgram;\n}());\nexports.BinaryOpPackedProgram = BinaryOpPackedProgram;\n//# sourceMappingURL=binaryop_packed_gpu.js.map","\n/**\n * @license\n * Copyright 2017 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar ClipProgram = /** @class */ (function () {\n    function ClipProgram(aShape) {\n        this.variableNames = ['A'];\n        this.outputShape = aShape;\n        this.userCode = \"\\n      uniform float min;\\n      uniform float max;\\n\\n      void main() {\\n        float value = getAAtOutCoords();\\n        if (isnan(value)) {\\n          setOutput(value);\\n          return;\\n        }\\n\\n        setOutput(clamp(value, min, max));\\n      }\\n    \";\n    }\n    ClipProgram.prototype.getCustomSetupFunc = function (min, max) {\n        var _this = this;\n        return function (gpgpu, webGLProgram) {\n            if (_this.minLoc == null) {\n                _this.minLoc = gpgpu.getUniformLocationNoThrow(webGLProgram, 'min');\n                _this.maxLoc = gpgpu.getUniformLocationNoThrow(webGLProgram, 'max');\n            }\n            gpgpu.gl.uniform1f(_this.minLoc, min);\n            gpgpu.gl.uniform1f(_this.maxLoc, max);\n        };\n    };\n    return ClipProgram;\n}());\nexports.ClipProgram = ClipProgram;\n//# sourceMappingURL=clip_gpu.js.map","\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar ClipPackedProgram = /** @class */ (function () {\n    function ClipPackedProgram(aShape) {\n        this.variableNames = ['A'];\n        this.usesPackedTextures = true;\n        this.outputShape = aShape;\n        this.userCode = \"\\n      uniform float min;\\n      uniform float max;\\n\\n      void main() {\\n        vec4 value = getAAtOutCoords();\\n\\n        if (any(isnan(value))) {\\n          setOutput(value);\\n          return;\\n        }\\n\\n        setOutput(clamp(value, vec4(min), vec4(max)));\\n      }\\n    \";\n    }\n    ClipPackedProgram.prototype.getCustomSetupFunc = function (min, max) {\n        var _this = this;\n        return function (gpgpu, webGLProgram) {\n            if (_this.minLoc == null) {\n                _this.minLoc = gpgpu.getUniformLocationNoThrow(webGLProgram, 'min');\n                _this.maxLoc = gpgpu.getUniformLocationNoThrow(webGLProgram, 'max');\n            }\n            gpgpu.gl.uniform1f(_this.minLoc, min);\n            gpgpu.gl.uniform1f(_this.maxLoc, max);\n        };\n    };\n    return ClipPackedProgram;\n}());\nexports.ClipPackedProgram = ClipPackedProgram;\n//# sourceMappingURL=clip_packed_gpu.js.map","\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar ComplexAbsProgram = /** @class */ (function () {\n    function ComplexAbsProgram(shape) {\n        this.variableNames = ['real', 'imag'];\n        this.outputShape = shape;\n        this.userCode = \"\\n      void main() {\\n        float re = abs(getRealAtOutCoords());\\n        float im = abs(getImagAtOutCoords());\\n        float mx = max(re, im);\\n\\n        // sadly the length function in glsl is not underflow-safe\\n        // (at least not on Intel GPUs). So the safe solution is\\n        // to ensure underflow-safety in all cases.\\n        setOutput(\\n          mx == 0.0 ? 0.0 : mx * length(vec2(1, min(re, im)/mx))\\n        );\\n      }\\n    \";\n    }\n    return ComplexAbsProgram;\n}());\nexports.ComplexAbsProgram = ComplexAbsProgram;\n//# sourceMappingURL=complex_abs_gpu.js.map","\n/**\n * @license\n * Copyright 2017 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar concat_util = require(\"../../ops/concat_util\");\nvar ConcatProgram = /** @class */ (function () {\n    // Concats 2d tensors along axis=1. See comments in MathBackendWebGL.concat().\n    function ConcatProgram(shapes) {\n        this.outputShape = [];\n        this.outputShape = concat_util.computeOutShape(shapes, 1 /* axis */);\n        this.variableNames = shapes.map(function (_, i) { return \"T\" + i; });\n        var offsets = new Array(shapes.length - 1);\n        offsets[0] = shapes[0][1];\n        for (var i = 1; i < offsets.length; i++) {\n            offsets[i] = offsets[i - 1] + shapes[i][1];\n        }\n        var snippets = [\"if (yC < \" + offsets[0] + \") setOutput(getT0(yR, yC));\"];\n        for (var i = 1; i < offsets.length; i++) {\n            var shift = offsets[i - 1];\n            snippets.push(\"else if (yC < \" + offsets[i] + \") \" +\n                (\"setOutput(getT\" + i + \"(yR, yC-\" + shift + \"));\"));\n        }\n        var lastIndex = offsets.length;\n        var lastShift = offsets[offsets.length - 1];\n        snippets.push(\"else setOutput(getT\" + lastIndex + \"(yR, yC-\" + lastShift + \"));\");\n        this.userCode = \"\\n      void main() {\\n        ivec2 coords = getOutputCoords();\\n        int yR = coords.x;\\n        int yC = coords.y;\\n\\n        \" + snippets.join('\\n        ') + \"\\n      }\\n    \";\n    }\n    return ConcatProgram;\n}());\nexports.ConcatProgram = ConcatProgram;\n//# sourceMappingURL=concat_gpu.js.map","\n/**\n * @license\n * Copyright 2019 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar concat_util = require(\"../../ops/concat_util\");\nvar packing_util_1 = require(\"../packing_util\");\nvar shader_compiler_1 = require(\"./shader_compiler\");\nvar ConcatPackedProgram = /** @class */ (function () {\n    function ConcatPackedProgram(shapes, axis) {\n        this.usesPackedTextures = true;\n        this.outputShape = [];\n        this.outputShape = concat_util.computeOutShape(shapes, axis);\n        var shape = this.outputShape;\n        var rank = shape.length;\n        var dtype = shader_compiler_1.getCoordsDataType(rank);\n        var coords = packing_util_1.getChannels('coords', rank);\n        var channels = ['x', 'y', 'z', 'w', 'u', 'v'].slice(0, rank);\n        this.variableNames = shapes.map(function (_, i) { return \"T\" + i; });\n        var offsets = new Array(shapes.length - 1);\n        offsets[0] = shapes[0][axis];\n        for (var i = 1; i < offsets.length; i++) {\n            offsets[i] = offsets[i - 1] + shapes[i][axis];\n        }\n        var channel = channels[axis];\n        var lastChannels = 'vec2(' + channels.slice(-2).join() + ')';\n        var allChannels = channels.join();\n        var getValueSnippet = \"if (\" + channel + \" < \" + offsets[0] + \")\\n          return getChannel(getT0(\" + allChannels + \"), \" + lastChannels + \");\";\n        for (var i = 1; i < offsets.length; i++) {\n            var shift_1 = offsets[i - 1];\n            getValueSnippet += \"\\n        else if (\" + channel + \" < \" + offsets[i] + \") {\\n          \" + channel + \" -= \" + shift_1 + \";\\n          return getChannel(getT\" + i + \"(\" + allChannels + \"), \" + lastChannels + \");\\n        }\";\n        }\n        var lastIndex = offsets.length;\n        var shift = offsets[offsets.length - 1];\n        getValueSnippet += \"\\n        else {\\n          \" + channel + \" -= \" + shift + \";\\n          return getChannel(getT\" + lastIndex + \"(\" + allChannels + \"), \" + lastChannels + \");\\n        }\";\n        this.userCode = \"\\n      float getValue(\" + channels.map(function (x) { return 'int ' + x; }) + \") {\\n        \" + getValueSnippet + \"\\n      }\\n\\n      void main() {\\n        \" + dtype + \" coords = getOutputCoords();\\n        vec4 result = vec4(getValue(\" + coords + \"), 0., 0., 0.);\\n        if (++\" + coords[rank - 1] + \" < \" + shape[rank - 1] + \") {\\n          result.g = getValue(\" + coords + \");\\n        }\\n        if (++\" + coords[rank - 2] + \" < \" + shape[rank - 2] + \") {\\n          result.a = getValue(\" + coords + \");\\n        }\\n        if (\" + coords[rank - 2] + \" < \" + shape[rank - 2] + \" &&\\n            --\" + coords[rank - 1] + \" < \" + shape[rank - 1] + \") {\\n          result.b = getValue(\" + coords + \");\\n        }\\n        setOutput(result);\\n      }\\n    \";\n    }\n    return ConcatPackedProgram;\n}());\nexports.ConcatPackedProgram = ConcatPackedProgram;\n//# sourceMappingURL=concat_packed_gpu.js.map","\n/**\n * @license\n * Copyright 2017 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar Conv2DDerFilterProgram = /** @class */ (function () {\n    function Conv2DDerFilterProgram(convInfo) {\n        this.variableNames = ['x', 'dy'];\n        this.outputShape = convInfo.filterShape;\n        var strideHeight = convInfo.strideHeight;\n        var strideWidth = convInfo.strideWidth;\n        var padTop = convInfo.padInfo.top;\n        var padLeft = convInfo.padInfo.left;\n        this.userCode = \"\\n      void main() {\\n        ivec4 coords = getOutputCoords();\\n        int wR = coords.x;\\n        int wC = coords.y;\\n        int d1 = coords.z;\\n        int d2 = coords.w;\\n\\n        // Convolve x(?, ?, d1) with dy(:, :, d2) to get dw(wR, wC, d1, d2).\\n        // ? = to be determined. : = across all values in that axis.\\n        float dotProd = 0.0;\\n\\n        for (int b = 0; b < \" + convInfo.batchSize + \"; b++) {\\n          for (int yR = 0; yR < \" + convInfo.outHeight + \"; yR++) {\\n            int xR = wR + yR * \" + strideHeight + \" - \" + padTop + \";\\n\\n            if (xR < 0 || xR >= \" + convInfo.inHeight + \") {\\n              continue;\\n            }\\n\\n            for (int yC = 0; yC < \" + convInfo.outWidth + \"; yC++) {\\n              int xC = wC + yC * \" + strideWidth + \" - \" + padLeft + \";\\n\\n              if (xC < 0 || xC >= \" + convInfo.inWidth + \") {\\n                continue;\\n              }\\n\\n              float dyValue = getDy(b, yR, yC, d2);\\n              float xValue = getX(b, xR, xC, d1);\\n              dotProd += (xValue * dyValue);\\n            }\\n          }\\n        }\\n        setOutput(dotProd);\\n      }\\n    \";\n    }\n    return Conv2DDerFilterProgram;\n}());\nexports.Conv2DDerFilterProgram = Conv2DDerFilterProgram;\nvar Conv2DDerInputProgram = /** @class */ (function () {\n    function Conv2DDerInputProgram(convInfo) {\n        this.variableNames = ['dy', 'W'];\n        this.outputShape = convInfo.inShape;\n        var filterHeight = convInfo.filterHeight;\n        var filterWidth = convInfo.filterWidth;\n        var strideHeight = convInfo.strideHeight;\n        var strideWidth = convInfo.strideWidth;\n        var padTop = filterHeight - 1 - convInfo.padInfo.top;\n        var padLeft = filterWidth - 1 - convInfo.padInfo.left;\n        this.userCode = \"\\n      const ivec2 pads = ivec2(\" + padTop + \", \" + padLeft + \");\\n\\n      void main() {\\n        ivec4 coords = getOutputCoords();\\n        int batch = coords[0];\\n        int d1 = coords[3];\\n\\n        ivec2 dyCorner = coords.yz - pads;\\n        int dyRCorner = dyCorner.x;\\n        int dyCCorner = dyCorner.y;\\n\\n        // Convolve dy(?, ?, d2) with w(:, :, d1, d2) to compute dx(xR, xC, d1).\\n        // ? = to be determined. : = across all values in that axis.\\n        float dotProd = 0.0;\\n        for (int wR = 0; wR < \" + filterHeight + \"; wR++) {\\n          float dyR = float(dyRCorner + wR) / \" + strideHeight + \".0;\\n\\n          if (dyR < 0.0 || dyR >= \" + convInfo.outHeight + \".0 || fract(dyR) > 0.0) {\\n            continue;\\n          }\\n          int idyR = int(dyR);\\n\\n          int wRPerm = \" + filterHeight + \" - 1 - wR;\\n\\n          for (int wC = 0; wC < \" + filterWidth + \"; wC++) {\\n            float dyC = float(dyCCorner + wC) / \" + strideWidth + \".0;\\n\\n            if (dyC < 0.0 || dyC >= \" + convInfo.outWidth + \".0 ||\\n                fract(dyC) > 0.0) {\\n              continue;\\n            }\\n            int idyC = int(dyC);\\n\\n            int wCPerm = \" + filterWidth + \" - 1 - wC;\\n\\n            for (int d2 = 0; d2 < \" + convInfo.outChannels + \"; d2++) {\\n              float xValue = getDy(batch, idyR, idyC, d2);\\n              float wValue = getW(wRPerm, wCPerm, d1, d2);\\n              dotProd += xValue * wValue;\\n            }\\n          }\\n        }\\n        setOutput(dotProd);\\n      }\\n    \";\n    }\n    return Conv2DDerInputProgram;\n}());\nexports.Conv2DDerInputProgram = Conv2DDerInputProgram;\nvar Conv3DDerFilterProgram = /** @class */ (function () {\n    function Conv3DDerFilterProgram(convInfo) {\n        this.variableNames = ['x', 'dy'];\n        this.outputShape = convInfo.filterShape;\n        var strideDepth = convInfo.strideDepth;\n        var strideHeight = convInfo.strideHeight;\n        var strideWidth = convInfo.strideWidth;\n        var padFront = convInfo.padInfo.front;\n        var padTop = convInfo.padInfo.top;\n        var padLeft = convInfo.padInfo.left;\n        this.userCode = \"\\n      void main() {\\n        ivec5 coords = getOutputCoords();\\n        int wF = coords.x;\\n        int wR = coords.y;\\n        int wC = coords.z;\\n        int d1 = coords.w;\\n        int d2 = coords.u;\\n\\n        float dotProd = 0.0;\\n\\n        for (int b = 0; b < \" + convInfo.batchSize + \"; b++) {\\n          for (int yF = 0; yF < \" + convInfo.outDepth + \"; yF++) {\\n            int xF = wF + yF * \" + strideDepth + \" - \" + padFront + \";\\n\\n            if (xF < 0 || xF >= \" + convInfo.inDepth + \") {\\n              continue;\\n            }\\n\\n            for (int yR = 0; yR < \" + convInfo.outHeight + \"; yR++) {\\n              int xR = wR + yR * \" + strideHeight + \" - \" + padTop + \";\\n\\n              if (xR < 0 || xR >= \" + convInfo.inHeight + \") {\\n                continue;\\n              }\\n\\n              for (int yC = 0; yC < \" + convInfo.outWidth + \"; yC++) {\\n                int xC = wC + yC * \" + strideWidth + \" - \" + padLeft + \";\\n\\n                if (xC < 0 || xC >= \" + convInfo.inWidth + \") {\\n                  continue;\\n                }\\n\\n                float dyValue = getDy(b, yF, yR, yC, d2);\\n                float xValue = getX(b, xF, xR, xC, d1);\\n                dotProd += (xValue * dyValue);\\n              }\\n            }\\n          }\\n        }\\n        setOutput(dotProd);\\n      }\\n    \";\n    }\n    return Conv3DDerFilterProgram;\n}());\nexports.Conv3DDerFilterProgram = Conv3DDerFilterProgram;\nvar Conv3DDerInputProgram = /** @class */ (function () {\n    function Conv3DDerInputProgram(convInfo) {\n        this.variableNames = ['dy', 'W'];\n        this.outputShape = convInfo.inShape;\n        var filterDepth = convInfo.filterDepth;\n        var filterHeight = convInfo.filterHeight;\n        var filterWidth = convInfo.filterWidth;\n        var strideDepth = convInfo.strideDepth;\n        var strideHeight = convInfo.strideHeight;\n        var strideWidth = convInfo.strideWidth;\n        var padFront = filterDepth - 1 - convInfo.padInfo.front;\n        var padTop = filterHeight - 1 - convInfo.padInfo.top;\n        var padLeft = filterWidth - 1 - convInfo.padInfo.left;\n        this.userCode = \"\\n      const ivec3 pads = ivec3(\" + padFront + \", \" + padTop + \", \" + padLeft + \");\\n\\n      void main() {\\n        ivec5 coords = getOutputCoords();\\n        int batch = coords.x;\\n        int d1 = coords.u;\\n\\n\\n        ivec3 dyCorner = ivec3(coords.y, coords.z, coords.w) - pads;\\n        int dyFCorner = dyCorner.x;\\n        int dyRCorner = dyCorner.y;\\n        int dyCCorner = dyCorner.z;\\n\\n        float dotProd = 0.0;\\n        for (int wF = 0; wF < \" + filterDepth + \"; wF++) {\\n          float dyF = float(dyFCorner + wF) / \" + strideDepth + \".0;\\n\\n          if (dyF < 0.0 || dyF >= \" + convInfo.outDepth + \".0 || fract(dyF) > 0.0) {\\n            continue;\\n          }\\n          int idyF = int(dyF);\\n\\n          int wFPerm = \" + filterDepth + \" - 1 - wF;\\n\\n          for (int wR = 0; wR < \" + filterHeight + \"; wR++) {\\n            float dyR = float(dyRCorner + wR) / \" + strideHeight + \".0;\\n\\n            if (dyR < 0.0 || dyR >= \" + convInfo.outHeight + \".0 ||\\n              fract(dyR) > 0.0) {\\n              continue;\\n            }\\n            int idyR = int(dyR);\\n\\n            int wRPerm = \" + filterHeight + \" - 1 - wR;\\n\\n            for (int wC = 0; wC < \" + filterWidth + \"; wC++) {\\n              float dyC = float(dyCCorner + wC) / \" + strideWidth + \".0;\\n\\n              if (dyC < 0.0 || dyC >= \" + convInfo.outWidth + \".0 ||\\n                  fract(dyC) > 0.0) {\\n                continue;\\n              }\\n              int idyC = int(dyC);\\n\\n              int wCPerm = \" + filterWidth + \" - 1 - wC;\\n\\n              for (int d2 = 0; d2 < \" + convInfo.outChannels + \"; d2++) {\\n                float xValue = getDy(batch, idyF, idyR, idyC, d2);\\n                float wValue = getW(wFPerm, wRPerm, wCPerm, d1, d2);\\n                dotProd += xValue * wValue;\\n              }\\n            }\\n          }\\n        }\\n        setOutput(dotProd);\\n      }\\n    \";\n    }\n    return Conv3DDerInputProgram;\n}());\nexports.Conv3DDerInputProgram = Conv3DDerInputProgram;\n//# sourceMappingURL=conv_backprop_gpu.js.map","\n/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar DepthwiseConv2DDerFilterProgram = /** @class */ (function () {\n    function DepthwiseConv2DDerFilterProgram(convInfo) {\n        this.variableNames = ['x', 'dy'];\n        this.outputShape = convInfo.filterShape;\n        var strideHeight = convInfo.strideHeight;\n        var strideWidth = convInfo.strideWidth;\n        var padTop = convInfo.padInfo.top;\n        var padLeft = convInfo.padInfo.left;\n        var channelMul = convInfo.outChannels / convInfo.inChannels;\n        this.userCode = \"\\n      void main() {\\n        ivec4 coords = getOutputCoords();\\n        int wR = coords.x;\\n        int wC = coords.y;\\n        int d1 = coords.z;\\n        int dm = coords.w;\\n        int d2 = d1 * \" + channelMul + \" + dm;\\n\\n        float dotProd = 0.0;\\n\\n        // TODO: Vec4 over the batch size\\n        for (int b = 0; b < \" + convInfo.batchSize + \"; b++) {\\n          for (int yR = 0; yR < \" + convInfo.outHeight + \"; yR++) {\\n            int xR = wR + yR * \" + strideHeight + \" - \" + padTop + \";\\n\\n            if (xR < 0 || xR >= \" + convInfo.inHeight + \") {\\n              continue;\\n            }\\n\\n            for (int yC = 0; yC < \" + convInfo.outWidth + \"; yC++) {\\n              int xC = wC + yC * \" + strideWidth + \" - \" + padLeft + \";\\n\\n              if (xC < 0 || xC >= \" + convInfo.inWidth + \") {\\n                continue;\\n              }\\n\\n              float dyValue = getDy(b, yR, yC, d2);\\n              float xValue = getX(b, xR, xC, d1);\\n              dotProd += (xValue * dyValue);\\n            }\\n          }\\n        }\\n        setOutput(dotProd);\\n      }\\n    \";\n    }\n    return DepthwiseConv2DDerFilterProgram;\n}());\nexports.DepthwiseConv2DDerFilterProgram = DepthwiseConv2DDerFilterProgram;\nvar DepthwiseConv2DDerInputProgram = /** @class */ (function () {\n    function DepthwiseConv2DDerInputProgram(convInfo) {\n        this.variableNames = ['dy', 'W'];\n        this.outputShape = convInfo.inShape;\n        var filterHeight = convInfo.filterHeight;\n        var filterWidth = convInfo.filterWidth;\n        var strideHeight = convInfo.strideHeight;\n        var strideWidth = convInfo.strideWidth;\n        var padTop = filterHeight - 1 - convInfo.padInfo.top;\n        var padLeft = filterWidth - 1 - convInfo.padInfo.left;\n        var channelMul = convInfo.outChannels / convInfo.inChannels;\n        this.userCode = \"\\n      const ivec2 pads = ivec2(\" + padTop + \", \" + padLeft + \");\\n\\n      void main() {\\n        ivec4 coords = getOutputCoords();\\n        int batch = coords[0];\\n        int d1 = coords[3];\\n        ivec2 dyCorner = coords.yz - pads;\\n        int dyRCorner = dyCorner.x;\\n        int dyCCorner = dyCorner.y;\\n\\n        float dotProd = 0.0;\\n\\n        for (int wR = 0; wR < \" + filterHeight + \"; wR++) {\\n          float dyR = float(dyRCorner + wR) / \" + strideHeight + \".0;\\n\\n          if (dyR < 0.0 || dyR >= \" + convInfo.outHeight + \".0 || fract(dyR) > 0.0) {\\n            continue;\\n          }\\n          int idyR = int(dyR);\\n\\n          int wRPerm = \" + filterHeight + \" - 1 - wR;\\n\\n          for (int wC = 0; wC < \" + filterWidth + \"; wC++) {\\n            float dyC = float(dyCCorner + wC) / \" + strideWidth + \".0;\\n\\n            if (dyC < 0.0 || dyC >= \" + convInfo.outWidth + \".0 ||\\n                fract(dyC) > 0.0) {\\n              continue;\\n            }\\n            int idyC = int(dyC);\\n\\n            int wCPerm = \" + filterWidth + \" - 1 - wC;\\n\\n            // TODO: Vec4 over the channelMul\\n            for (int dm = 0; dm < \" + channelMul + \"; dm++) {\\n              int d2 = d1 * \" + channelMul + \" + dm;\\n              float xValue = getDy(batch, idyR, idyC, d2);\\n              float wValue = getW(wRPerm, wCPerm, d1, dm);\\n              dotProd += xValue * wValue;\\n            }\\n          }\\n        }\\n        setOutput(dotProd);\\n      }\\n    \";\n    }\n    return DepthwiseConv2DDerInputProgram;\n}());\nexports.DepthwiseConv2DDerInputProgram = DepthwiseConv2DDerInputProgram;\n//# sourceMappingURL=conv_backprop_gpu_depthwise.js.map","\n/**\n * @license\n * Copyright 2017 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar Conv2DProgram = /** @class */ (function () {\n    function Conv2DProgram(convInfo) {\n        this.variableNames = ['x', 'W'];\n        this.outputShape = convInfo.outShape;\n        var padTop = convInfo.padInfo.top;\n        var padLeft = convInfo.padInfo.left;\n        var strideHeight = convInfo.strideHeight;\n        var strideWidth = convInfo.strideWidth;\n        var dilationHeight = convInfo.dilationHeight;\n        var dilationWidth = convInfo.dilationWidth;\n        var filterHeight = convInfo.filterHeight;\n        var filterWidth = convInfo.filterWidth;\n        var inputDepthNearestVec4 = Math.floor(convInfo.inChannels / 4) * 4;\n        var inputDepthVec4Remainder = convInfo.inChannels % 4;\n        this.userCode = \"\\n      const ivec2 strides = ivec2(\" + strideHeight + \", \" + strideWidth + \");\\n      const ivec2 pads = ivec2(\" + padTop + \", \" + padLeft + \");\\n\\n      void main() {\\n        ivec4 coords = getOutputCoords();\\n        int batch = coords[0];\\n        int d2 = coords[3];\\n\\n        ivec2 xRCCorner = coords.yz * strides - pads;\\n        int xRCorner = xRCCorner.x;\\n        int xCCorner = xRCCorner.y;\\n\\n        // Convolve x(?, ?, d1) with w(:, :, d1, d2) to get y(yR, yC, d2).\\n        // ? = to be determined. : = across all values in that axis.\\n        float dotProd = 0.0;\\n        for (int wR = 0; wR < \" + filterHeight + \"; wR++) {\\n          int xR = xRCorner + wR * \" + dilationHeight + \";\\n\\n          if (xR < 0 || xR >= \" + convInfo.inHeight + \") {\\n            continue;\\n          }\\n\\n          for (int wC = 0; wC < \" + filterWidth + \"; wC++) {\\n            int xC = xCCorner + wC * \" + dilationWidth + \";\\n\\n            if (xC < 0 || xC >= \" + convInfo.inWidth + \") {\\n              continue;\\n            }\\n\\n            for (int d1 = 0; d1 < \" + inputDepthNearestVec4 + \"; d1 += 4) {\\n              vec4 xValues = vec4(\\n                getX(batch, xR, xC, d1),\\n                getX(batch, xR, xC, d1 + 1),\\n                getX(batch, xR, xC, d1 + 2),\\n                getX(batch, xR, xC, d1 + 3)\\n              );\\n              vec4 wValues = vec4(\\n                getW(wR, wC, d1, d2),\\n                getW(wR, wC, d1 + 1, d2),\\n                getW(wR, wC, d1 + 2, d2),\\n                getW(wR, wC, d1 + 3, d2)\\n              );\\n\\n              dotProd += dot(xValues, wValues);\\n            }\\n\\n            if (\" + (inputDepthVec4Remainder === 1) + \") {\\n              dotProd +=\\n                getX(batch, xR, xC, \" + inputDepthNearestVec4 + \") *\\n                getW(wR, wC, \" + inputDepthNearestVec4 + \", d2);\\n            } else if (\" + (inputDepthVec4Remainder === 2) + \") {\\n              vec2 xValues = vec2(\\n                getX(batch, xR, xC, \" + inputDepthNearestVec4 + \"),\\n                getX(batch, xR, xC, \" + inputDepthNearestVec4 + \" + 1)\\n              );\\n              vec2 wValues = vec2(\\n                getW(wR, wC, \" + inputDepthNearestVec4 + \", d2),\\n                getW(wR, wC, \" + inputDepthNearestVec4 + \" + 1, d2)\\n              );\\n              dotProd += dot(xValues, wValues);\\n            } else if (\" + (inputDepthVec4Remainder === 3) + \") {\\n              vec3 xValues = vec3(\\n                getX(batch, xR, xC, \" + inputDepthNearestVec4 + \"),\\n                getX(batch, xR, xC, \" + inputDepthNearestVec4 + \" + 1),\\n                getX(batch, xR, xC, \" + inputDepthNearestVec4 + \" + 2)\\n              );\\n              vec3 wValues = vec3(\\n                getW(wR, wC, \" + inputDepthNearestVec4 + \", d2),\\n                getW(wR, wC, \" + inputDepthNearestVec4 + \" + 1, d2),\\n                getW(wR, wC, \" + inputDepthNearestVec4 + \" + 2, d2)\\n              );\\n              dotProd += dot(xValues, wValues);\\n            }\\n          }\\n        }\\n        setOutput(dotProd);\\n      }\\n    \";\n    }\n    return Conv2DProgram;\n}());\nexports.Conv2DProgram = Conv2DProgram;\nvar Conv3DProgram = /** @class */ (function () {\n    function Conv3DProgram(convInfo) {\n        this.variableNames = ['x', 'W'];\n        this.outputShape = convInfo.outShape;\n        var padFront = convInfo.padInfo.front;\n        var padTop = convInfo.padInfo.top;\n        var padLeft = convInfo.padInfo.left;\n        var strideDepth = convInfo.strideDepth;\n        var strideHeight = convInfo.strideHeight;\n        var strideWidth = convInfo.strideWidth;\n        var dilationDepth = convInfo.dilationDepth;\n        var dilationHeight = convInfo.dilationHeight;\n        var dilationWidth = convInfo.dilationWidth;\n        var filterDepth = convInfo.filterDepth;\n        var filterHeight = convInfo.filterHeight;\n        var filterWidth = convInfo.filterWidth;\n        var inputDepthNearestVec4 = Math.floor(convInfo.inChannels / 4) * 4;\n        var inputDepthVec4Remainder = convInfo.inChannels % 4;\n        this.userCode = \"\\n      const ivec3 strides = ivec3(\" + strideDepth + \", \" + strideHeight + \", \" + strideWidth + \");\\n      const ivec3 pads = ivec3(\" + padFront + \", \" + padTop + \", \" + padLeft + \");\\n\\n      void main() {\\n        ivec5 coords = getOutputCoords();\\n        int batch = coords.x;\\n        int d2 = coords.u;\\n\\n        ivec3 xFRCCorner = ivec3(coords.y, coords.z, coords.w) * strides - pads;\\n        int xFCorner = xFRCCorner.x;\\n        int xRCorner = xFRCCorner.y;\\n        int xCCorner = xFRCCorner.z;\\n\\n        // Convolve x(?, ?, ?, d1) with w(:, :, :, d1, d2) to get\\n        // y(yF, yR, yC, d2). ? = to be determined. : = across all\\n        // values in that axis.\\n        float dotProd = 0.0;\\n        for (int wF = 0; wF < \" + filterDepth + \"; wF++) {\\n          int xF = xFCorner + wF * \" + dilationDepth + \";\\n\\n          if (xF < 0 || xF >= \" + convInfo.inDepth + \") {\\n            continue;\\n          }\\n\\n          for (int wR = 0; wR < \" + filterHeight + \"; wR++) {\\n            int xR = xRCorner + wR * \" + dilationHeight + \";\\n\\n            if (xR < 0 || xR >= \" + convInfo.inHeight + \") {\\n              continue;\\n            }\\n\\n            for (int wC = 0; wC < \" + filterWidth + \"; wC++) {\\n              int xC = xCCorner + wC * \" + dilationWidth + \";\\n\\n              if (xC < 0 || xC >= \" + convInfo.inWidth + \") {\\n                continue;\\n              }\\n\\n              for (int d1 = 0; d1 < \" + inputDepthNearestVec4 + \"; d1 += 4) {\\n                vec4 xValues = vec4(\\n                  getX(batch, xF, xR, xC, d1),\\n                  getX(batch, xF, xR, xC, d1 + 1),\\n                  getX(batch, xF, xR, xC, d1 + 2),\\n                  getX(batch, xF, xR, xC, d1 + 3)\\n                );\\n                vec4 wValues = vec4(\\n                  getW(wF, wR, wC, d1, d2),\\n                  getW(wF, wR, wC, d1 + 1, d2),\\n                  getW(wF, wR, wC, d1 + 2, d2),\\n                  getW(wF, wR, wC, d1 + 3, d2)\\n                );\\n\\n                dotProd += dot(xValues, wValues);\\n              }\\n\\n              if (\" + (inputDepthVec4Remainder === 1) + \") {\\n                dotProd +=\\n                  getX(batch, xF, xR, xC, \" + inputDepthNearestVec4 + \") *\\n                  getW(wF, wR, wC, \" + inputDepthNearestVec4 + \", d2);\\n              } else if (\" + (inputDepthVec4Remainder === 2) + \") {\\n                vec2 xValues = vec2(\\n                  getX(batch, xF, xR, xC, \" + inputDepthNearestVec4 + \"),\\n                  getX(batch, xF, xR, xC, \" + inputDepthNearestVec4 + \" + 1)\\n                );\\n                vec2 wValues = vec2(\\n                  getW(wF, wR, wC, \" + inputDepthNearestVec4 + \", d2),\\n                  getW(wF, wR, wC, \" + inputDepthNearestVec4 + \" + 1, d2)\\n                );\\n                dotProd += dot(xValues, wValues);\\n              } else if (\" + (inputDepthVec4Remainder === 3) + \") {\\n                vec3 xValues = vec3(\\n                  getX(batch, xF, xR, xC, \" + inputDepthNearestVec4 + \"),\\n                  getX(batch, xF, xR, xC, \" + inputDepthNearestVec4 + \" + 1),\\n                  getX(batch, xF, xR, xC, \" + inputDepthNearestVec4 + \" + 2)\\n                );\\n                vec3 wValues = vec3(\\n                  getW(wF, wR, wC, \" + inputDepthNearestVec4 + \", d2),\\n                  getW(wF, wR, wC, \" + inputDepthNearestVec4 + \" + 1, d2),\\n                  getW(wF, wR, wC, \" + inputDepthNearestVec4 + \" + 2, d2)\\n                );\\n                dotProd += dot(xValues, wValues);\\n              }\\n            }\\n          }\\n        }\\n        setOutput(dotProd);\\n      }\\n    \";\n    }\n    return Conv3DProgram;\n}());\nexports.Conv3DProgram = Conv3DProgram;\n//# sourceMappingURL=conv_gpu.js.map","\n/**\n * @license\n * Copyright 2017 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar DepthwiseConv2DProgram = /** @class */ (function () {\n    function DepthwiseConv2DProgram(convInfo) {\n        this.variableNames = ['x', 'W'];\n        this.outputShape = convInfo.outShape;\n        var xNumRows = convInfo.inHeight;\n        var xNumCols = convInfo.inWidth;\n        var padTop = convInfo.padInfo.top;\n        var padLeft = convInfo.padInfo.left;\n        var strideHeight = convInfo.strideHeight;\n        var strideWidth = convInfo.strideWidth;\n        var dilationHeight = convInfo.dilationHeight;\n        var dilationWidth = convInfo.dilationWidth;\n        var filterHeight = convInfo.filterHeight;\n        var filterWidth = convInfo.filterWidth;\n        var channelMul = convInfo.outChannels / convInfo.inChannels;\n        this.userCode = \"\\n      const ivec2 strides = ivec2(\" + strideHeight + \", \" + strideWidth + \");\\n      const ivec2 pads = ivec2(\" + padTop + \", \" + padLeft + \");\\n\\n      void main() {\\n        ivec4 coords = getOutputCoords();\\n        int batch = coords.x;\\n        ivec2 xRCCorner = coords.yz * strides - pads;\\n        int d2 = coords.w;\\n        int d1 = d2 / \" + channelMul + \";\\n        int q = d2 - d1 * \" + channelMul + \";\\n\\n        int xRCorner = xRCCorner.x;\\n        int xCCorner = xRCCorner.y;\\n\\n        // Convolve x(?, ?, d1) with w(:, :, d1, q) to get y(yR, yC, d2).\\n        // ? = to be determined. : = across all values in that axis.\\n        float dotProd = 0.0;\\n        // TODO(dsmilkov): Flatten the two for loops and vec4 the operations.\\n        for (int wR = 0; wR < \" + filterHeight + \"; wR++) {\\n          int xR = xRCorner + wR * \" + dilationHeight + \";\\n\\n          if (xR < 0 || xR >= \" + xNumRows + \") {\\n            continue;\\n          }\\n\\n          for (int wC = 0; wC < \" + filterWidth + \"; wC++) {\\n            int xC = xCCorner + wC * \" + dilationWidth + \";\\n\\n            if (xC < 0 || xC >= \" + xNumCols + \") {\\n              continue;\\n            }\\n\\n            float xVal = getX(batch, xR, xC, d1);\\n            float wVal = getW(wR, wC, d1, q);\\n            dotProd += xVal * wVal;\\n          }\\n        }\\n        setOutput(dotProd);\\n      }\\n    \";\n    }\n    return DepthwiseConv2DProgram;\n}());\nexports.DepthwiseConv2DProgram = DepthwiseConv2DProgram;\n//# sourceMappingURL=conv_gpu_depthwise.js.map","\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar util = require(\"../../util\");\nvar DepthwiseConvPacked2DProgram = /** @class */ (function () {\n    function DepthwiseConvPacked2DProgram(convInfo) {\n        this.variableNames = ['x', 'W'];\n        this.usesPackedTextures = true;\n        this.outputShape = convInfo.outShape;\n        var xNumRows = convInfo.inHeight;\n        var xNumCols = convInfo.inWidth;\n        var padTop = convInfo.padInfo.top;\n        var padLeft = convInfo.padInfo.left;\n        var strideHeight = convInfo.strideHeight;\n        var strideWidth = convInfo.strideWidth;\n        var dilationHeight = convInfo.dilationHeight;\n        var dilationWidth = convInfo.dilationWidth;\n        var filterHeight = convInfo.filterHeight;\n        var filterWidth = convInfo.filterWidth;\n        var texelsAcross = filterWidth;\n        var mainLoop = \"int xR; int xC; int xCOffset;\";\n        for (var r = 0; r < filterHeight; r++) {\n            for (var c = 0; c < filterWidth; c++) {\n                mainLoop += \"\\n          vec4 xTexelR\" + r + \"C\" + c * 2 + \" = vec4(0.);\\n          vec4 wR\" + r + \"C\" + c + \" = vec4(0.);\\n          vec4 xR\" + r + \"C\" + c + \" = vec4(0.);\";\n            }\n        }\n        /**\n         * This vectorized implementation works by gathering the values needed for\n         * each output channel's dot product into vec4's and then multiplying them\n         * all together (this happens in the final double for-loop below). Most of\n         * the main loop consists of constructing these vec4's with the minimum\n         * number of texture2D calls, which means making use of all four returned\n         * values from a texture2D call at once.\n         */\n        for (var r = 0; r < filterHeight; r++) {\n            for (var texelC = 0; texelC < texelsAcross; texelC++) {\n                var c = texelC * 2;\n                mainLoop += \"\\n          xR = xRCorner + \" + r * dilationHeight + \";\\n          xC = xCCorner + \" + c * dilationWidth + \";\\n        \";\n                if (strideWidth === 1) {\n                    if (c < filterWidth) {\n                        // If padding is odd, the outer texels have to be composed.\n                        if (padLeft % 2 === 1) {\n                            // TODO: Ensure vec4 previous does not result in redundant sample,\n                            // and avoid setting xTexelRC's that exceed the boundary in the\n                            // first place rather than resetting them to vec4(0)).\n                            // To compute xCOffset:\n                            // - If padding is odd, we must add 1 to ensure we ask for an\n                            // even-numbered row.\n                            // - We subtract 2 to access the previous texel.\n                            mainLoop += \"\\n                xCOffset = xC + 1;\\n                if(xR >= 0 && xR < \" + xNumRows + \" && xCOffset >= 0 && xCOffset < \" + xNumCols + \") {\\n                  xTexelR\" + r + \"C\" + c + \" = getX(batch, xR, xCOffset, d1);\\n                } else {\\n                  xTexelR\" + r + \"C\" + c + \" = vec4(0.);\\n                }\\n\\n                xCOffset = xC + 1 - 2;\\n                if(xR >= 0 && xR < \" + xNumRows + \" && xCOffset >= 0 && xCOffset < \" + xNumCols + \") {\\n                  vec4 previous = getX(batch, xR, xCOffset, d1);\\n                  xR\" + r + \"C\" + c + \" = vec4(previous.zw, xTexelR\" + r + \"C\" + c + \".xy);\\n                } else {\\n                  xR\" + r + \"C\" + c + \" = vec4(0, 0, xTexelR\" + r + \"C\" + c + \".xy);\\n                }\\n              \";\n                        }\n                        else {\n                            // Padding is even, so xRC corresponds to a single texel.\n                            mainLoop += \"\\n                if(xR >= 0 && xR < \" + xNumRows + \" && xC >= 0 && xC < \" + xNumCols + \") {\\n                  xTexelR\" + r + \"C\" + c + \" = getX(batch, xR, xC, d1);\\n                } else {\\n                  xTexelR\" + r + \"C\" + c + \" = vec4(0.);\\n                }\\n\\n                xR\" + r + \"C\" + c + \" = xTexelR\" + r + \"C\" + c + \";\\n              \";\n                        }\n                        if (c + 1 < filterWidth) {\n                            // If dilation is even, the second entry should match the first\n                            // (either both are composed or both are single samples). But if\n                            // dilation is odd, then the second entry should be the opposite\n                            // of the first (if the first is composed, the second is a single\n                            // sample, and vice versa.)\n                            var nextTexelOffset = padLeft % 2 === 0 ?\n                                util.nearestLargerEven(dilationWidth) :\n                                dilationWidth;\n                            if ((dilationWidth % 2 === 0 && padLeft % 2 === 1) ||\n                                (dilationWidth % 2 !== 0 && padLeft % 2 !== 1)) {\n                                mainLoop += \"\\n                  xCOffset = xC + \" + padLeft % 2 + \" + \" + nextTexelOffset + \";\\n\\n                  if(xR >= 0 && xR < \" + xNumRows + \" &&\\n                    xCOffset >= 0 && xCOffset < \" + xNumCols + \") {\\n                    xTexelR\" + r + \"C\" + (c + 2) + \" = getX(batch, xR, xCOffset, d1);\\n                  }\\n                \";\n                                // If dilation > 1 then the xRC's will not be able to share any\n                                // values, so each xRC will require two unique calls to getX.\n                                if (dilationWidth > 1) {\n                                    mainLoop += \"\\n                    xCOffset -= 2;\\n                    if(xR >= 0 && xR < \" + xNumRows + \" &&\\n                      xCOffset >= 0 && xCOffset < \" + xNumCols + \") {\\n                      xTexelR\" + r + \"C\" + c + \" = getX(batch, xR, xCOffset, d1);\\n                    } else {\\n                      xTexelR\" + r + \"C\" + c + \" = vec4(0.);\\n                    }\\n                  \";\n                                }\n                                mainLoop += \"\\n                  xR\" + r + \"C\" + (c + 1) + \" = vec4(\\n                    xTexelR\" + r + \"C\" + c + \".zw, xTexelR\" + r + \"C\" + (c + 2) + \".xy);\\n                \";\n                            }\n                            else {\n                                mainLoop += \"\\n                  xCOffset = xC + \" + nextTexelOffset + \";\\n\\n                  if(xR >= 0 && xR < \" + xNumRows + \" &&\\n                    xCOffset >= 0 && xCOffset < \" + xNumCols + \") {\\n                    xTexelR\" + r + \"C\" + (c + 2) + \" = getX(batch, xR, xCOffset, d1);\\n                  }\\n\\n                  xR\" + r + \"C\" + (c + 1) + \" = xTexelR\" + r + \"C\" + (c + 2) + \";\\n                \";\n                            }\n                        }\n                    }\n                }\n                else { // stride > 1\n                    if (c < filterWidth) {\n                        mainLoop += \"\\n              if(xR >= 0 && xR < \" + xNumRows + \") {\\n            \";\n                        // Depending on whether padLeft is even or odd, we want either the\n                        // xy or zw channels from X texels for xR${r}C${c}. If padLeft is\n                        // even, xR${r}C${c + 1} is simply the zw channels of texels we've\n                        // already sampled. But if padLeft is odd, xR${r}C{$c + 1}.zw will\n                        // need to come from the xy channels of a new texel, hence the `vec4\n                        // final` initialized below.\n                        if (padLeft % 2 === 1) {\n                            mainLoop += \"\\n                xCOffset = xC + 1 - \" + strideWidth + \";\\n                if(xCOffset >= 0 && xCOffset < \" + xNumCols + \") {\\n                  xTexelR\" + r + \"C\" + c + \" = getX(batch, xR, xCOffset, d1);\\n                } else {\\n                  xTexelR\" + r + \"C\" + c + \" = vec4(0.);\\n                }\\n\\n                if(xC + 1 >= 0 && xC + 1 < \" + xNumCols + \") {\\n                  xTexelR\" + r + \"C\" + (c + 2) + \" = getX(batch, xR, xC + 1, d1);\\n                } else {\\n                  xTexelR\" + r + \"C\" + (c + 2) + \" = vec4(0.);\\n                }\\n\\n                xR\" + r + \"C\" + c + \" = vec4(\\n                  xTexelR\" + r + \"C\" + c + \".zw, xTexelR\" + r + \"C\" + (c + 2) + \".zw);\\n              \";\n                            if (c + 1 < filterWidth) {\n                                mainLoop += \"\\n                  vec4 final = vec4(0.);\\n                  xCOffset = xC + 1 + \" + strideWidth + \";\\n                  if(xCOffset >= 0 && xCOffset < \" + xNumCols + \") {\\n                    final = getX(batch, xR, xCOffset, d1);\\n                  }\\n                  xR\" + r + \"C\" + (c + 1) + \" = vec4(xTexelR\" + r + \"C\" + (c + 2) + \".xy, final.xy);\\n                \";\n                            }\n                        }\n                        else {\n                            mainLoop += \"\\n                if(xC >= 0 && xC < \" + xNumCols + \") {\\n                  xTexelR\" + r + \"C\" + c + \" = getX(batch, xR, xC, d1);\\n                } else {\\n                  xTexelR\" + r + \"C\" + c + \" = vec4(0.);\\n                }\\n\\n                xCOffset = xC + \" + strideWidth + \";\\n                if(xCOffset >= 0 && xCOffset < \" + xNumCols + \") {\\n                  xTexelR\" + r + \"C\" + (c + 2) + \" = getX(batch, xR, xCOffset, d1);\\n                } else {\\n                  xTexelR\" + r + \"C\" + (c + 2) + \" = vec4(0.);\\n                }\\n\\n                xR\" + r + \"C\" + c + \" = vec4(\\n                  xTexelR\" + r + \"C\" + c + \".xy, xTexelR\" + r + \"C\" + (c + 2) + \".xy);\\n              \";\n                            if (c + 1 < filterWidth) {\n                                mainLoop += \"\\n                  xR\" + r + \"C\" + (c + 1) + \" = vec4(\\n                    xTexelR\" + r + \"C\" + c + \".zw, xTexelR\" + r + \"C\" + (c + 2) + \".zw);\\n                \";\n                            }\n                        }\n                        mainLoop += \"}\";\n                    }\n                }\n                if (c < filterWidth) {\n                    mainLoop += \"\\n            vec4 wTexelR\" + r + \"C\" + c + \" = getW(\" + r + \", \" + c + \", d1, q);\\n            wR\" + r + \"C\" + c + \" = vec4(wTexelR\" + r + \"C\" + c + \".xz, wTexelR\" + r + \"C\" + c + \".xz);\\n          \";\n                    if (c + 1 < filterWidth) {\n                        mainLoop += \"\\n              vec4 wTexelR\" + r + \"C\" + (c + 1) + \" = getW(\" + r + \", \" + (c + 1) + \", d1, q);\\n              wR\" + r + \"C\" + (c + 1) + \" =\\n                vec4(wTexelR\" + r + \"C\" + (c + 1) + \".xz, wTexelR\" + r + \"C\" + (c + 1) + \".xz);\";\n                    }\n                }\n            }\n        }\n        for (var r = 0; r < filterHeight; r++) {\n            for (var c = 0; c < filterWidth; c++) {\n                mainLoop += \"result += xR\" + r + \"C\" + c + \" * wR\" + r + \"C\" + c + \";\";\n            }\n        }\n        this.userCode = \"\\n      const ivec2 strides = ivec2(\" + strideHeight + \", \" + strideWidth + \");\\n      const ivec2 pads = ivec2(\" + padTop + \", \" + padLeft + \");\\n\\n      void main() {\\n\\n        ivec4 coords = getOutputCoords();\\n        int batch = coords.x;\\n        ivec2 xRCCorner = coords.yz * strides - pads;\\n        int d2 = coords.w;\\n        int d1 = d2;\\n        int q = 0;\\n        int xRCorner = xRCCorner.x;\\n        int xCCorner = xRCCorner.y;\\n\\n        vec4 result = vec4(0.);\\n\\n        \" + mainLoop + \"\\n\\n        setOutput(result);\\n      }\\n    \";\n    }\n    return DepthwiseConvPacked2DProgram;\n}());\nexports.DepthwiseConvPacked2DProgram = DepthwiseConvPacked2DProgram;\n//# sourceMappingURL=conv_packed_gpu_depthwise.js.map","\n/**\n * @license\n * Copyright 2017 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar CropAndResizeProgram = /** @class */ (function () {\n    function CropAndResizeProgram(imageShape, boxShape, cropSize, method, extrapolationValue) {\n        this.variableNames = ['Image', 'Boxes', 'BoxInd'];\n        this.outputShape = [];\n        var batch = imageShape[0], imageHeight = imageShape[1], imageWidth = imageShape[2], depth = imageShape[3];\n        var numBoxes = boxShape[0];\n        var cropHeight = cropSize[0], cropWidth = cropSize[1];\n        this.outputShape = [numBoxes, cropHeight, cropWidth, depth];\n        var methodId = method === 'bilinear' ? 1 : 0;\n        var _a = [imageHeight - 1 + \".0\", imageWidth - 1 + \".0\"], inputHeightFloat = _a[0], inputWidthFloat = _a[1];\n        var _b = cropHeight > 1 ?\n            [\n                \"\" + (imageHeight - 1) / (cropHeight - 1),\n                '(y2-y1) * height_ratio',\n                \"y1*\" + inputHeightFloat + \" + float(y)*(height_scale)\",\n            ] :\n            [\n                '0.0',\n                '0.0',\n                \"0.5 * (y1+y2) * \" + inputHeightFloat,\n            ], heightRatio = _b[0], heightScale = _b[1], inY = _b[2];\n        var _c = cropWidth > 1 ?\n            [\n                \"\" + (imageWidth - 1) / (cropWidth - 1),\n                '(x2-x1) * width_ratio',\n                \"x1*\" + inputWidthFloat + \" + float(x)*(width_scale)\",\n            ] :\n            [\n                '0.0',\n                '0.0',\n                \"0.5 * (x1+x2) * \" + inputWidthFloat,\n            ], widthRatio = _c[0], widthScale = _c[1], inX = _c[2];\n        // Reference implementation\n        // tslint:disable-next-line:max-line-length\n        // https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/crop_and_resize_op_gpu.cu.cc\n        this.userCode = \"\\n      const float height_ratio = float(\" + heightRatio + \");\\n      const float width_ratio = float(\" + widthRatio + \");\\n      void main() {\\n        ivec4 coords = getOutputCoords();\\n        int b = coords[0];\\n        int y = coords[1];\\n        int x = coords[2];\\n        int d = coords[3];\\n\\n        // get box vals\\n        float y1 = getBoxes(b,0);\\n        float x1 = getBoxes(b,1);\\n        float y2 = getBoxes(b,2);\\n        float x2 = getBoxes(b,3);\\n\\n        // get image in batch index\\n        int bInd = round(getBoxInd(b));\\n        if(bInd < 0 || bInd >= \" + batch + \") {\\n          return;\\n        }\\n\\n        float height_scale = \" + heightScale + \";\\n        float width_scale = \" + widthScale + \";\\n\\n        float in_y = \" + inY + \";\\n        if( in_y < 0.0 || in_y > \" + inputHeightFloat + \" ) {\\n          setOutput(float(\" + extrapolationValue + \"));\\n          return;\\n        }\\n        float in_x = \" + inX + \";\\n        if( in_x < 0.0 || in_x > \" + inputWidthFloat + \" ) {\\n          setOutput(float(\" + extrapolationValue + \"));\\n          return;\\n        }\\n\\n        vec2 sourceFracIndexCR = vec2(in_x,in_y);\\n        if(\" + methodId + \" == 1) {\\n          // Compute the four integer indices.\\n          ivec2 sourceFloorCR = ivec2(sourceFracIndexCR);\\n          ivec2 sourceCeilCR = ivec2(ceil(sourceFracIndexCR));\\n\\n          float topLeft = getImage(b, sourceFloorCR.y, sourceFloorCR.x, d);\\n          float bottomLeft = getImage(b, sourceCeilCR.y, sourceFloorCR.x, d);\\n          float topRight = getImage(b, sourceFloorCR.y, sourceCeilCR.x, d);\\n          float bottomRight = getImage(b, sourceCeilCR.y, sourceCeilCR.x, d);\\n\\n          vec2 fracCR = sourceFracIndexCR - vec2(sourceFloorCR);\\n\\n          float top = topLeft + (topRight - topLeft) * fracCR.x;\\n          float bottom = bottomLeft + (bottomRight - bottomLeft) * fracCR.x;\\n          float newValue = top + (bottom - top) * fracCR.y;\\n          setOutput(newValue);\\n        } else {\\n          // Compute the coordinators of nearest neighbor point.\\n          ivec2 sourceNearestCR = ivec2(floor(\\n            sourceFracIndexCR + vec2(0.5,0.5)));\\n          float newValue = getImage(b, sourceNearestCR.y, sourceNearestCR.x, d);\\n          setOutput(newValue);\\n        }\\n      }\\n    \";\n    }\n    return CropAndResizeProgram;\n}());\nexports.CropAndResizeProgram = CropAndResizeProgram;\n//# sourceMappingURL=crop_and_resize_gpu.js.map","\n/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar shader_compiler_1 = require(\"./shader_compiler\");\nvar CumSumProgram = /** @class */ (function () {\n    function CumSumProgram(shape, exclusive, reverse) {\n        this.variableNames = ['x'];\n        this.outputShape = shape;\n        var rank = shape.length;\n        var finalDim = shape[shape.length - 1];\n        var comparator = reverse ? '<' : '>';\n        this.userCode = \"\\n      int getIndex(int i) {\\n        \" + (reverse ? \"return \" + finalDim + \" -i - 1;\" : 'return i;') + \"\\n      }\\n\\n      void main() {\\n        \" + shader_compiler_1.getCoordsDataType(rank) + \" coords = getOutputCoords();\\n        int end = \" + getFinalCoord(rank, 'coords') + \";\\n        float val = 0.0;\\n        for (int i = \" + finalDim + \" - 1; i >= 0; i -= 1) {\\n          int idx = getIndex(i);\\n          if (idx \" + comparator + \" end) {\\n            continue;\\n          }\\n          if (idx == end && \" + exclusive + \") {\\n            continue;\\n          }\\n          \" + getFinalCoord(rank, 'coords') + \" = idx;\\n          val += getX(\" + getCoords(rank, 'coords') + \");\\n        }\\n        setOutput(val);\\n      }\\n    \";\n    }\n    return CumSumProgram;\n}());\nexports.CumSumProgram = CumSumProgram;\nfunction getCoords(rank, name) {\n    if (rank === 1) {\n        return \"\" + name;\n    }\n    else if (rank === 2) {\n        return name + \".x, \" + name + \".y\";\n    }\n    else if (rank === 3) {\n        return name + \".x, \" + name + \".y, \" + name + \".z\";\n    }\n    else if (rank === 4) {\n        return name + \".x, \" + name + \".y, \" + name + \".z, \" + name + \".w\";\n    }\n    else {\n        throw Error(\"Cumulative sum for rank \" + rank + \" is not yet supported\");\n    }\n}\nfunction getFinalCoord(rank, name) {\n    if (rank === 1) {\n        return \"\" + name;\n    }\n    else if (rank === 2) {\n        return name + \".y\";\n    }\n    else if (rank === 3) {\n        return name + \".z\";\n    }\n    else if (rank === 4) {\n        return name + \".w\";\n    }\n    else {\n        throw Error(\"Cumulative sum for rank \" + rank + \" is not yet supported\");\n    }\n}\n//# sourceMappingURL=cumsum_gpu.js.map","\n/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar DepthToSpaceProgram = /** @class */ (function () {\n    function DepthToSpaceProgram(outputShape, blockSize, dataFormat) {\n        this.variableNames = ['x'];\n        this.outputShape = [];\n        this.outputShape = outputShape;\n        this.blockSize = blockSize;\n        this.dataFormat = dataFormat;\n        this.userCode = \"\\n    void main() {\\n      ivec4 coords = getOutputCoords();\\n      int b = coords[0];\\n      int h = \" + this.getHeightCoordString() + \";\\n      int w = \" + this.getWidthCoordString() + \";\\n      int d = \" + this.getDepthCoordString() + \";\\n\\n      int in_h = h / \" + blockSize + \";\\n      int offset_h = imod(h, \" + blockSize + \");\\n      int in_w = w / \" + blockSize + \";\\n      int offset_w = imod(w, \" + blockSize + \");\\n      int offset_d = (offset_h * \" + blockSize + \" + offset_w) *\\n        \" + this.getOutputDepthSize() + \";\\n      int in_d = d + offset_d;\\n\\n      float result = \" + this.getInputSamplingString() + \";\\n      setOutput(result);\\n    }\\n  \";\n    }\n    DepthToSpaceProgram.prototype.getHeightCoordString = function () {\n        if (this.dataFormat === 'NHWC') {\n            return \"coords[1]\";\n        }\n        else {\n            return \"coords[2]\";\n        }\n    };\n    DepthToSpaceProgram.prototype.getWidthCoordString = function () {\n        if (this.dataFormat === 'NHWC') {\n            return \"coords[2]\";\n        }\n        else {\n            return \"coords[3]\";\n        }\n    };\n    DepthToSpaceProgram.prototype.getDepthCoordString = function () {\n        if (this.dataFormat === 'NHWC') {\n            return \"coords[3]\";\n        }\n        else {\n            return \"coords[1]\";\n        }\n    };\n    DepthToSpaceProgram.prototype.getOutputDepthSize = function () {\n        if (this.dataFormat === 'NHWC') {\n            return this.outputShape[3];\n        }\n        else {\n            return this.outputShape[1];\n        }\n    };\n    DepthToSpaceProgram.prototype.getInputSamplingString = function () {\n        if (this.dataFormat === 'NHWC') {\n            return \"getX(b, in_h, in_w, in_d)\";\n        }\n        else {\n            return \"getX(b, in_d, in_h, in_w)\";\n        }\n    };\n    return DepthToSpaceProgram;\n}());\nexports.DepthToSpaceProgram = DepthToSpaceProgram;\n//# sourceMappingURL=depth_to_space_gpu.js.map","\n/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar glsl_version_1 = require(\"./glsl_version\");\nvar EncodeFloatProgram = /** @class */ (function () {\n    function EncodeFloatProgram(outputShape) {\n        this.variableNames = ['A'];\n        var glsl = glsl_version_1.getGlslDifferences();\n        this.outputShape = outputShape;\n        this.userCode = \"\\n      const float FLOAT_MAX = 1.70141184e38;\\n      const float FLOAT_MIN = 1.17549435e-38;\\n\\n      lowp vec4 encode_float(highp float v) {\\n        if (isnan(v)) {\\n          return vec4(255, 255, 255, 255);\\n        }\\n\\n        highp float av = abs(v);\\n\\n        if(av < FLOAT_MIN) {\\n          return vec4(0.0, 0.0, 0.0, 0.0);\\n        } else if(v > FLOAT_MAX) {\\n          return vec4(0.0, 0.0, 128.0, 127.0) / 255.0;\\n        } else if(v < -FLOAT_MAX) {\\n          return vec4(0.0, 0.0,  128.0, 255.0) / 255.0;\\n        }\\n\\n        highp vec4 c = vec4(0,0,0,0);\\n\\n        highp float e = floor(log2(av));\\n        highp float m = exp2(fract(log2(av))) - 1.0;\\n\\n        c[2] = floor(128.0 * m);\\n        m -= c[2] / 128.0;\\n        c[1] = floor(32768.0 * m);\\n        m -= c[1] / 32768.0;\\n        c[0] = floor(8388608.0 * m);\\n\\n        highp float ebias = e + 127.0;\\n        c[3] = floor(ebias / 2.0);\\n        ebias -= c[3] * 2.0;\\n        c[2] += floor(ebias) * 128.0;\\n\\n        c[3] += 128.0 * step(0.0, -v);\\n\\n        return c / 255.0;\\n      }\\n\\n      void main() {\\n        float x = getAAtOutCoords();\\n        \" + glsl.output + \" = encode_float(x);\\n      }\\n    \";\n    }\n    return EncodeFloatProgram;\n}());\nexports.EncodeFloatProgram = EncodeFloatProgram;\n//# sourceMappingURL=encode_float_gpu.js.map","\n/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.COMPLEX_FFT = {\n    REAL: 'return real * expR - imag * expI;',\n    IMAG: 'return real * expI + imag * expR;'\n};\nvar FFTProgram = /** @class */ (function () {\n    function FFTProgram(op, inputShape, inverse) {\n        this.variableNames = ['real', 'imag'];\n        var innerDim = inputShape[1];\n        this.outputShape = inputShape;\n        var exponentMultiplierSnippet = inverse ? \"2.0 * \" + Math.PI : \"-2.0 * \" + Math.PI;\n        var resultDenominator = inverse ? innerDim + \".0\" : '1.0';\n        this.userCode = \"\\n      const float exponentMultiplier = \" + exponentMultiplierSnippet + \";\\n\\n      float unaryOpComplex(float real, float expR, float imag, float expI) {\\n        \" + op + \"\\n      }\\n\\n      float mulMatDFT(int batch, int index) {\\n        float indexRatio = float(index) / float(\" + innerDim + \");\\n        float exponentMultiplierTimesIndexRatio =\\n            exponentMultiplier * indexRatio;\\n\\n        float result = 0.0;\\n\\n        for (int i = 0; i < \" + innerDim + \"; i++) {\\n          // x = (-2|2 * PI / N) * index * i;\\n          float x = exponentMultiplierTimesIndexRatio * float(i);\\n          float expR = cos(x);\\n          float expI = sin(x);\\n          float real = getReal(batch, i);\\n          float imag = getImag(batch, i);\\n\\n          result +=\\n              unaryOpComplex(real, expR, imag, expI) / \" + resultDenominator + \";\\n        }\\n\\n        return result;\\n      }\\n\\n      void main() {\\n        ivec2 coords = getOutputCoords();\\n        setOutput(mulMatDFT(coords[0], coords[1]));\\n      }\\n    \";\n    }\n    return FFTProgram;\n}());\nexports.FFTProgram = FFTProgram;\n//# sourceMappingURL=fft_gpu.js.map","\n/**\n * @license\n * Copyright 2019 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar FillProgram = /** @class */ (function () {\n    function FillProgram(shape, value) {\n        this.outputShape = [];\n        this.variableNames = ['x'];\n        this.outputShape = shape;\n        this.userCode = \"\\n      uniform float value;\\n      void main() {\\n        // Input can be obtained from uniform value.\\n        setOutput(value);\\n      }\\n    \";\n    }\n    FillProgram.prototype.getCustomSetupFunc = function (value) {\n        var _this = this;\n        return function (gpgpu, webGLProgram) {\n            if (_this.valueLoc == null) {\n                _this.valueLoc = gpgpu.getUniformLocationNoThrow(webGLProgram, 'value');\n            }\n            gpgpu.gl.uniform1f(_this.valueLoc, value);\n        };\n    };\n    return FillProgram;\n}());\nexports.FillProgram = FillProgram;\n//# sourceMappingURL=fill_gpu.js.map","\n/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar glsl_version_1 = require(\"./glsl_version\");\nvar FromPixelsProgram = /** @class */ (function () {\n    function FromPixelsProgram(outputShape) {\n        this.variableNames = ['A'];\n        var glsl = glsl_version_1.getGlslDifferences();\n        var height = outputShape[0], width = outputShape[1];\n        this.outputShape = outputShape;\n        this.userCode = \"\\n      void main() {\\n        ivec3 coords = getOutputCoords();\\n        int texR = coords[0];\\n        int texC = coords[1];\\n        int depth = coords[2];\\n        vec2 uv = (vec2(texC, texR) + halfCR) / vec2(\" + width + \".0, \" + height + \".0);\\n\\n        vec4 values = \" + glsl.texture2D + \"(A, uv);\\n        float value;\\n        if (depth == 0) {\\n          value = values.r;\\n        } else if (depth == 1) {\\n          value = values.g;\\n        } else if (depth == 2) {\\n          value = values.b;\\n        } else if (depth == 3) {\\n          value = values.a;\\n        }\\n\\n        setOutput(floor(value * 255.0 + 0.5));\\n      }\\n    \";\n    }\n    return FromPixelsProgram;\n}());\nexports.FromPixelsProgram = FromPixelsProgram;\n//# sourceMappingURL=from_pixels_gpu.js.map","\n/**\n * @license\n * Copyright 2017 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar shader_compiler_1 = require(\"./shader_compiler\");\nvar GatherProgram = /** @class */ (function () {\n    function GatherProgram(aShape, indicesLength, axis) {\n        this.variableNames = ['A', 'indices'];\n        var outputShape = aShape.slice();\n        outputShape[axis] = indicesLength;\n        this.outputShape = outputShape;\n        this.rank = outputShape.length;\n        var dtype = shader_compiler_1.getCoordsDataType(this.rank);\n        var sourceCoords = getSourceCoords(aShape, axis);\n        this.userCode = \"\\n      void main() {\\n        \" + dtype + \" resRC = getOutputCoords();\\n        setOutput(getA(\" + sourceCoords + \"));\\n      }\\n    \";\n    }\n    return GatherProgram;\n}());\nexports.GatherProgram = GatherProgram;\nfunction getSourceCoords(aShape, axis) {\n    var rank = aShape.length;\n    if (rank > 4) {\n        throw Error(\"Gather for rank \" + rank + \" is not yet supported\");\n    }\n    if (rank === 1) {\n        return \"int(getIndices(resRC))\";\n    }\n    var currentCoords = ['resRC.x', 'resRC.y', 'resRC.z', 'resRC.w'];\n    var sourceCoords = [];\n    for (var i = 0; i < aShape.length; i++) {\n        if (i === axis) {\n            sourceCoords.push(\"int(getIndices(\" + currentCoords[i] + \"))\");\n        }\n        else {\n            sourceCoords.push(\"\" + currentCoords[i]);\n        }\n    }\n    return sourceCoords.join();\n}\n//# sourceMappingURL=gather_gpu.js.map","\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar shader_compiler_1 = require(\"./shader_compiler\");\nvar GatherNDProgram = /** @class */ (function () {\n    function GatherNDProgram(sliceDim, strides, shape) {\n        this.sliceDim = sliceDim;\n        this.strides = strides;\n        this.variableNames = ['x', 'indices'];\n        this.outputShape = shape;\n        var stridesType = shader_compiler_1.getCoordsDataType(strides.length);\n        var dtype = shader_compiler_1.getCoordsDataType(shape.length);\n        var strideString = this.sliceDim > 1 ? 'strides[j]' : 'strides';\n        this.userCode = \"\\n        \" + stridesType + \" strides = \" + stridesType + \"(\" + this.strides + \");\\n         void main() {\\n          \" + dtype + \" coords = getOutputCoords();\\n          int flattenIndex = 0;\\n          for (int j = 0; j < \" + this.sliceDim + \"; j++) {\\n            int index = round(getIndices(coords[0], j));\\n            flattenIndex += index * \" + strideString + \";\\n          }\\n          setOutput(getX(flattenIndex, coords[1]));\\n        }\\n      \";\n    }\n    return GatherNDProgram;\n}());\nexports.GatherNDProgram = GatherNDProgram;\n//# sourceMappingURL=gather_nd_gpu.js.map","\n/**\n * @license\n * Copyright 2017 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : new P(function (resolve) { resolve(result.value); }).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nvar __generator = (this && this.__generator) || function (thisArg, body) {\n    var _ = { label: 0, sent: function() { if (t[0] & 1) throw t[1]; return t[1]; }, trys: [], ops: [] }, f, y, t, g;\n    return g = { next: verb(0), \"throw\": verb(1), \"return\": verb(2) }, typeof Symbol === \"function\" && (g[Symbol.iterator] = function() { return this; }), g;\n    function verb(n) { return function (v) { return step([n, v]); }; }\n    function step(op) {\n        if (f) throw new TypeError(\"Generator is already executing.\");\n        while (_) try {\n            if (f = 1, y && (t = op[0] & 2 ? y[\"return\"] : op[0] ? y[\"throw\"] || ((t = y[\"return\"]) && t.call(y), 0) : y.next) && !(t = t.call(y, op[1])).done) return t;\n            if (y = 0, t) op = [op[0] & 2, t.value];\n            switch (op[0]) {\n                case 0: case 1: t = op; break;\n                case 4: _.label++; return { value: op[1], done: false };\n                case 5: _.label++; y = op[1]; op = [0]; continue;\n                case 7: op = _.ops.pop(); _.trys.pop(); continue;\n                default:\n                    if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) { _ = 0; continue; }\n                    if (op[0] === 3 && (!t || (op[1] > t[0] && op[1] < t[3]))) { _.label = op[1]; break; }\n                    if (op[0] === 6 && _.label < t[1]) { _.label = t[1]; t = op; break; }\n                    if (t && _.label < t[2]) { _.label = t[2]; _.ops.push(op); break; }\n                    if (t[2]) _.ops.pop();\n                    _.trys.pop(); continue;\n            }\n            op = body.call(thisArg, _);\n        } catch (e) { op = [6, e]; y = 0; } finally { f = t = 0; }\n        if (op[0] & 5) throw op[1]; return { value: op[0] ? op[1] : void 0, done: true };\n    }\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar environment_1 = require(\"../../environment\");\nvar util = require(\"../../util\");\nvar canvas_util_1 = require(\"./canvas_util\");\nvar gpgpu_util = require(\"./gpgpu_util\");\nvar tex_util = require(\"./tex_util\");\nvar webgl_util = require(\"./webgl_util\");\nvar GPGPUContext = /** @class */ (function () {\n    function GPGPUContext(gl) {\n        this.outputTexture = null;\n        this.program = null;\n        this.disposed = false;\n        this.vertexAttrsAreBound = false;\n        this.itemsToPoll = [];\n        var glVersion = environment_1.ENV.getNumber('WEBGL_VERSION');\n        if (gl != null) {\n            this.gl = gl;\n            canvas_util_1.setWebGLContext(glVersion, gl);\n        }\n        else {\n            this.gl = canvas_util_1.getWebGLContext(glVersion);\n        }\n        // WebGL 2.0 enables texture floats without an extension.\n        if (environment_1.ENV.getNumber('WEBGL_VERSION') === 1) {\n            this.textureFloatExtension = webgl_util.getExtensionOrThrow(this.gl, this.debug, 'OES_texture_float');\n            this.colorBufferFloatExtension =\n                this.gl.getExtension('WEBGL_color_buffer_float');\n            if (!environment_1.ENV.getBool('WEBGL_RENDER_FLOAT32_ENABLED')) {\n                this.textureHalfFloatExtension = webgl_util.getExtensionOrThrow(this.gl, this.debug, 'OES_texture_half_float');\n                this.colorBufferHalfFloatExtension =\n                    this.gl.getExtension('EXT_color_buffer_half_float');\n            }\n        }\n        else {\n            this.colorBufferFloatExtension = webgl_util.getExtensionOrThrow(this.gl, this.debug, 'EXT_color_buffer_float');\n        }\n        this.vertexBuffer = gpgpu_util.createVertexBuffer(this.gl, this.debug);\n        this.indexBuffer = gpgpu_util.createIndexBuffer(this.gl, this.debug);\n        this.framebuffer = webgl_util.createFramebuffer(this.gl, this.debug);\n        this.textureConfig =\n            gpgpu_util.getTextureConfig(this.gl, this.textureHalfFloatExtension);\n    }\n    Object.defineProperty(GPGPUContext.prototype, \"debug\", {\n        get: function () {\n            return environment_1.ENV.getBool('DEBUG');\n        },\n        enumerable: true,\n        configurable: true\n    });\n    GPGPUContext.prototype.dispose = function () {\n        var _this = this;\n        if (this.disposed) {\n            return;\n        }\n        if (this.program != null) {\n            console.warn('Disposing a GPGPUContext that still has a bound WebGLProgram.' +\n                ' This is probably a resource leak, delete the program with ' +\n                'GPGPUContext.deleteProgram before disposing.');\n        }\n        if (this.outputTexture != null) {\n            console.warn('Disposing a GPGPUContext that still has a bound output matrix ' +\n                'texture.  This is probably a resource leak, delete the output ' +\n                'matrix texture with GPGPUContext.deleteMatrixTexture before ' +\n                'disposing.');\n        }\n        var gl = this.gl;\n        webgl_util.callAndCheck(gl, this.debug, function () { return gl.finish(); });\n        webgl_util.callAndCheck(gl, this.debug, function () { return gl.bindFramebuffer(gl.FRAMEBUFFER, null); });\n        webgl_util.callAndCheck(gl, this.debug, function () { return gl.deleteFramebuffer(_this.framebuffer); });\n        webgl_util.callAndCheck(gl, this.debug, function () { return gl.bindBuffer(gl.ARRAY_BUFFER, null); });\n        webgl_util.callAndCheck(gl, this.debug, function () { return gl.bindBuffer(gl.ELEMENT_ARRAY_BUFFER, null); });\n        webgl_util.callAndCheck(gl, this.debug, function () { return gl.deleteBuffer(_this.indexBuffer); });\n        this.disposed = true;\n    };\n    GPGPUContext.prototype.createFloat32MatrixTexture = function (rows, columns) {\n        this.throwIfDisposed();\n        return gpgpu_util.createFloat32MatrixTexture(this.gl, this.debug, rows, columns, this.textureConfig);\n    };\n    GPGPUContext.prototype.createFloat16MatrixTexture = function (rows, columns) {\n        this.throwIfDisposed();\n        return gpgpu_util.createFloat16MatrixTexture(this.gl, this.debug, rows, columns, this.textureConfig);\n    };\n    GPGPUContext.prototype.createUnsignedBytesMatrixTexture = function (rows, columns) {\n        this.throwIfDisposed();\n        return gpgpu_util.createUnsignedBytesMatrixTexture(this.gl, this.debug, rows, columns, this.textureConfig);\n    };\n    GPGPUContext.prototype.uploadPixelDataToTexture = function (texture, pixels) {\n        this.throwIfDisposed();\n        gpgpu_util.uploadPixelDataToTexture(this.gl, this.debug, texture, pixels);\n    };\n    GPGPUContext.prototype.createFloat16PackedMatrixTexture = function (rows, columns) {\n        this.throwIfDisposed();\n        return gpgpu_util.createFloat16PackedMatrixTexture(this.gl, this.debug, rows, columns, this.textureConfig);\n    };\n    GPGPUContext.prototype.createPackedMatrixTexture = function (rows, columns) {\n        this.throwIfDisposed();\n        return gpgpu_util.createPackedMatrixTexture(this.gl, this.debug, rows, columns, this.textureConfig);\n    };\n    GPGPUContext.prototype.deleteMatrixTexture = function (texture) {\n        var _this = this;\n        this.throwIfDisposed();\n        if (this.outputTexture === texture) {\n            webgl_util.unbindColorTextureFromFramebuffer(this.gl, this.debug, this.framebuffer);\n            this.outputTexture = null;\n        }\n        webgl_util.callAndCheck(this.gl, this.debug, function () { return _this.gl.deleteTexture(texture); });\n    };\n    GPGPUContext.prototype.uploadMatrixToTexture = function (texture, rows, columns, matrix) {\n        this.throwIfDisposed();\n        var numChannels = webgl_util.getNumChannels();\n        return gpgpu_util.uploadMatrixToTexture(this.gl, this.debug, texture, rows, columns, matrix, numChannels, this.textureConfig);\n    };\n    GPGPUContext.prototype.uploadMatrixToPackedTexture = function (texture, batch, rows, columns, physicalRows, physicalCols, matrix) {\n        this.throwIfDisposed();\n        return gpgpu_util.uploadMatrixToPackedTexture(this.gl, this.debug, texture, batch, rows, columns, physicalRows, physicalCols, matrix, this.textureConfig);\n    };\n    GPGPUContext.prototype.downloadFloat32MatrixFromOutputTexture = function (texture, rows, columns) {\n        var _this = this;\n        return this.downloadMatrixDriver(texture, function () { return gpgpu_util.downloadFloat32MatrixFromOutputTexture(_this.gl, _this.debug, rows, columns, _this.textureConfig); });\n    };\n    GPGPUContext.prototype.downloadByteEncodedFloatMatrixFromOutputTexture = function (texture, rows, columns) {\n        var _this = this;\n        return this.downloadMatrixDriver(texture, function () { return gpgpu_util.downloadByteEncodedFloatMatrixFromOutputTexture(_this.gl, _this.debug, rows, columns, _this.textureConfig); });\n    };\n    GPGPUContext.prototype.downloadPackedMatrixFromBuffer = function (buffer, batch, rows, columns, physicalRows, physicalCols) {\n        return gpgpu_util.downloadPackedMatrixFromBuffer(this.gl, buffer, batch, rows, columns, physicalRows, physicalCols, this.textureConfig);\n    };\n    GPGPUContext.prototype.downloadFloat32MatrixFromBuffer = function (buffer, rows, columns) {\n        return gpgpu_util.downloadFloat32MatrixFromBuffer(this.gl, buffer, rows, columns, this.textureConfig);\n    };\n    GPGPUContext.prototype.createBufferFromTexture = function (texture, rows, columns) {\n        this.bindTextureToFrameBuffer(texture);\n        var result = gpgpu_util.createBufferFromOutputTexture(this.gl, this.debug, rows, columns, this.textureConfig);\n        this.unbindTextureToFrameBuffer();\n        return result;\n    };\n    GPGPUContext.prototype.createAndWaitForFence = function () {\n        var fenceContext = this.createFence(this.gl);\n        return this.pollFence(fenceContext);\n    };\n    GPGPUContext.prototype.createFence = function (gl) {\n        var _this = this;\n        var query;\n        var isFencePassed;\n        if (environment_1.ENV.getBool('WEBGL_FENCE_API_ENABLED')) {\n            var gl2_1 = gl;\n            var sync_1 = gl2_1.fenceSync(gl2_1.SYNC_GPU_COMMANDS_COMPLETE, 0);\n            gl.flush();\n            isFencePassed = function () {\n                var status = gl2_1.clientWaitSync(sync_1, 0, 0);\n                return status === gl2_1.ALREADY_SIGNALED ||\n                    status === gl2_1.CONDITION_SATISFIED;\n            };\n            query = sync_1;\n        }\n        else if (environment_1.ENV.getNumber('WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION') > 0) {\n            query = this.beginQuery();\n            this.endQuery();\n            isFencePassed = function () { return _this.isQueryAvailable(query, environment_1.ENV.getNumber('WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION')); };\n        }\n        else {\n            // If we have no way to fence, return true immediately. This will fire in\n            // WebGL 1.0 when there is no disjoint query timer. In this case, because\n            // the fence passes immediately, we'll immediately ask for a download of\n            // the texture, which will cause the UI thread to hang.\n            isFencePassed = function () { return true; };\n        }\n        return { query: query, isFencePassed: isFencePassed };\n    };\n    GPGPUContext.prototype.downloadMatrixFromPackedTexture = function (texture, batch, rows, columns, physicalRows, physicalCols) {\n        var _this = this;\n        return this.downloadMatrixDriver(texture, function () { return gpgpu_util.downloadMatrixFromPackedOutputTexture(_this.gl, _this.debug, batch, rows, columns, physicalRows, physicalCols, _this.textureConfig); });\n    };\n    GPGPUContext.prototype.createProgram = function (fragmentShaderSource) {\n        this.throwIfDisposed();\n        var gl = this.gl;\n        var fragmentShader = webgl_util.createFragmentShader(gl, this.debug, fragmentShaderSource);\n        var vertexShader = gpgpu_util.createVertexShader(gl, this.debug);\n        var program = webgl_util.createProgram(gl, this.debug);\n        webgl_util.callAndCheck(gl, this.debug, function () { return gl.attachShader(program, vertexShader); });\n        webgl_util.callAndCheck(gl, this.debug, function () { return gl.attachShader(program, fragmentShader); });\n        webgl_util.linkProgram(gl, this.debug, program);\n        if (this.debug) {\n            webgl_util.validateProgram(gl, this.debug, program);\n        }\n        if (!this.vertexAttrsAreBound) {\n            this.setProgram(program);\n            this.vertexAttrsAreBound = gpgpu_util.bindVertexProgramAttributeStreams(gl, this.debug, this.program, this.vertexBuffer);\n        }\n        return program;\n    };\n    GPGPUContext.prototype.deleteProgram = function (program) {\n        var _this = this;\n        this.throwIfDisposed();\n        if (program === this.program) {\n            this.program = null;\n        }\n        if (program != null) {\n            webgl_util.callAndCheck(this.gl, this.debug, function () { return _this.gl.deleteProgram(program); });\n        }\n    };\n    GPGPUContext.prototype.setProgram = function (program) {\n        var _this = this;\n        this.throwIfDisposed();\n        this.program = program;\n        if ((this.program != null) && this.debug) {\n            webgl_util.validateProgram(this.gl, this.debug, this.program);\n        }\n        webgl_util.callAndCheck(this.gl, this.debug, function () { return _this.gl.useProgram(program); });\n    };\n    GPGPUContext.prototype.getUniformLocation = function (program, uniformName, shouldThrow) {\n        if (shouldThrow === void 0) { shouldThrow = true; }\n        this.throwIfDisposed();\n        if (shouldThrow) {\n            return webgl_util.getProgramUniformLocationOrThrow(this.gl, this.debug, program, uniformName);\n        }\n        else {\n            return webgl_util.getProgramUniformLocation(this.gl, program, uniformName);\n        }\n    };\n    GPGPUContext.prototype.getAttributeLocation = function (program, attribute) {\n        var _this = this;\n        this.throwIfDisposed();\n        return webgl_util.callAndCheck(this.gl, this.debug, function () { return _this.gl.getAttribLocation(program, attribute); });\n    };\n    GPGPUContext.prototype.getUniformLocationNoThrow = function (program, uniformName) {\n        this.throwIfDisposed();\n        return this.gl.getUniformLocation(program, uniformName);\n    };\n    GPGPUContext.prototype.setInputMatrixTexture = function (inputMatrixTexture, uniformLocation, textureUnit) {\n        this.throwIfDisposed();\n        this.throwIfNoProgram();\n        webgl_util.bindTextureToProgramUniformSampler(this.gl, this.debug, this.program, inputMatrixTexture, uniformLocation, textureUnit);\n    };\n    GPGPUContext.prototype.setOutputMatrixTexture = function (outputMatrixTexture, rows, columns) {\n        this.setOutputMatrixTextureDriver(outputMatrixTexture, columns, rows);\n    };\n    GPGPUContext.prototype.setOutputPackedMatrixTexture = function (outputPackedMatrixTexture, rows, columns) {\n        this.throwIfDisposed();\n        var _a = tex_util.getPackedMatrixTextureShapeWidthHeight(rows, columns), width = _a[0], height = _a[1];\n        this.setOutputMatrixTextureDriver(outputPackedMatrixTexture, width, height);\n    };\n    GPGPUContext.prototype.setOutputMatrixWriteRegion = function (startRow, numRows, startColumn, numColumns) {\n        this.setOutputMatrixWriteRegionDriver(startColumn, startRow, numColumns, numRows);\n    };\n    GPGPUContext.prototype.setOutputPackedMatrixWriteRegion = function (startRow, numRows, startColumn, numColumns) {\n        throw new Error('setOutputPackedMatrixWriteRegion not implemented.');\n    };\n    GPGPUContext.prototype.debugValidate = function () {\n        if (this.program != null) {\n            webgl_util.validateProgram(this.gl, this.debug, this.program);\n        }\n        webgl_util.validateFramebuffer(this.gl);\n    };\n    GPGPUContext.prototype.executeProgram = function () {\n        this.throwIfDisposed();\n        this.throwIfNoProgram();\n        var gl = this.gl;\n        if (this.debug) {\n            this.debugValidate();\n        }\n        webgl_util.callAndCheck(gl, this.debug, function () { return gl.drawElements(gl.TRIANGLES, 6, gl.UNSIGNED_SHORT, 0); });\n    };\n    GPGPUContext.prototype.blockUntilAllProgramsCompleted = function () {\n        var _this = this;\n        this.throwIfDisposed();\n        webgl_util.callAndCheck(this.gl, this.debug, function () { return _this.gl.finish(); });\n    };\n    GPGPUContext.prototype.getQueryTimerExtension = function () {\n        if (this.disjointQueryTimerExtension == null) {\n            this.disjointQueryTimerExtension =\n                webgl_util.getExtensionOrThrow(this.gl, this.debug, environment_1.ENV.getNumber('WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION') ===\n                    2 ?\n                    'EXT_disjoint_timer_query_webgl2' :\n                    'EXT_disjoint_timer_query');\n        }\n        return this.disjointQueryTimerExtension;\n    };\n    GPGPUContext.prototype.getQueryTimerExtensionWebGL2 = function () {\n        return this.getQueryTimerExtension();\n    };\n    GPGPUContext.prototype.getQueryTimerExtensionWebGL1 = function () {\n        return this.getQueryTimerExtension();\n    };\n    GPGPUContext.prototype.beginQuery = function () {\n        if (environment_1.ENV.getNumber('WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION') === 2) {\n            var gl2 = this.gl;\n            var ext_1 = this.getQueryTimerExtensionWebGL2();\n            var query_1 = gl2.createQuery();\n            gl2.beginQuery(ext_1.TIME_ELAPSED_EXT, query_1);\n            return query_1;\n        }\n        var ext = this.getQueryTimerExtensionWebGL1();\n        var query = ext.createQueryEXT();\n        ext.beginQueryEXT(ext.TIME_ELAPSED_EXT, query);\n        return query;\n    };\n    GPGPUContext.prototype.endQuery = function () {\n        if (environment_1.ENV.getNumber('WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION') === 2) {\n            var gl2 = this.gl;\n            var ext_2 = this.getQueryTimerExtensionWebGL2();\n            gl2.endQuery(ext_2.TIME_ELAPSED_EXT);\n            return;\n        }\n        var ext = this.getQueryTimerExtensionWebGL1();\n        ext.endQueryEXT(ext.TIME_ELAPSED_EXT);\n    };\n    GPGPUContext.prototype.waitForQueryAndGetTime = function (query) {\n        return __awaiter(this, void 0, void 0, function () {\n            var _this = this;\n            return __generator(this, function (_a) {\n                switch (_a.label) {\n                    case 0: return [4 /*yield*/, util.repeatedTry(function () { return _this.disposed || // while testing contexts are created / disposed\n                            // in rapid succession, so without this check we\n                            // may poll for the query timer indefinitely\n                            _this.isQueryAvailable(query, environment_1.ENV.getNumber('WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION')); })];\n                    case 1:\n                        _a.sent();\n                        return [2 /*return*/, this.getQueryTime(query, environment_1.ENV.getNumber('WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION'))];\n                }\n            });\n        });\n    };\n    GPGPUContext.prototype.getQueryTime = function (query, queryTimerVersion) {\n        if (queryTimerVersion === 0) {\n            return null;\n        }\n        if (queryTimerVersion === 2) {\n            var gl2 = this.gl;\n            var timeElapsedNanos = gl2.getQueryParameter(query, gl2.QUERY_RESULT);\n            // Return milliseconds.\n            return timeElapsedNanos / 1000000;\n        }\n        else {\n            var ext = this.getQueryTimerExtensionWebGL1();\n            var timeElapsedNanos = ext.getQueryObjectEXT(query, ext.QUERY_RESULT_EXT);\n            // Return milliseconds.\n            return timeElapsedNanos / 1000000;\n        }\n    };\n    GPGPUContext.prototype.isQueryAvailable = function (query, queryTimerVersion) {\n        if (queryTimerVersion === 0) {\n            return true;\n        }\n        if (queryTimerVersion === 2) {\n            var gl2 = this.gl;\n            var ext = this.getQueryTimerExtensionWebGL2();\n            var available = gl2.getQueryParameter(query, gl2.QUERY_RESULT_AVAILABLE);\n            if (this.disjoint == null) {\n                this.disjoint = this.gl.getParameter(ext.GPU_DISJOINT_EXT);\n            }\n            return available && !this.disjoint;\n        }\n        else {\n            var ext = this.getQueryTimerExtensionWebGL1();\n            var available = ext.getQueryObjectEXT(query, ext.QUERY_RESULT_AVAILABLE_EXT);\n            if (this.disjoint == null) {\n                this.disjoint = this.gl.getParameter(ext.GPU_DISJOINT_EXT);\n            }\n            return available && !this.disjoint;\n        }\n    };\n    GPGPUContext.prototype.pollFence = function (fenceContext) {\n        var _this = this;\n        return new Promise(function (resolve) {\n            _this.addItemToPoll(function () { return fenceContext.isFencePassed(); }, function () { return resolve(); });\n        });\n    };\n    GPGPUContext.prototype.pollItems = function () {\n        // Find the last query that has finished.\n        var index = linearSearchLastTrue(this.itemsToPoll.map(function (x) { return x.isDoneFn; }));\n        for (var i = 0; i <= index; ++i) {\n            var resolveFn = this.itemsToPoll[i].resolveFn;\n            resolveFn();\n        }\n        this.itemsToPoll = this.itemsToPoll.slice(index + 1);\n    };\n    GPGPUContext.prototype.addItemToPoll = function (isDoneFn, resolveFn) {\n        var _this = this;\n        this.itemsToPoll.push({ isDoneFn: isDoneFn, resolveFn: resolveFn });\n        if (this.itemsToPoll.length > 1) {\n            // We already have a running loop that polls.\n            return;\n        }\n        // Start a new loop that polls.\n        util.repeatedTry(function () {\n            _this.pollItems();\n            // End the loop if no more items to poll.\n            return _this.itemsToPoll.length === 0;\n        });\n    };\n    GPGPUContext.prototype.bindTextureToFrameBuffer = function (texture) {\n        this.throwIfDisposed();\n        webgl_util.bindColorTextureToFramebuffer(this.gl, this.debug, texture, this.framebuffer);\n        if (this.debug) {\n            webgl_util.validateFramebuffer(this.gl);\n        }\n    };\n    GPGPUContext.prototype.unbindTextureToFrameBuffer = function () {\n        if (this.outputTexture != null) {\n            webgl_util.bindColorTextureToFramebuffer(this.gl, this.debug, this.outputTexture, this.framebuffer);\n            if (this.debug) {\n                webgl_util.validateFramebuffer(this.gl);\n            }\n        }\n        else {\n            webgl_util.unbindColorTextureFromFramebuffer(this.gl, this.debug, this.framebuffer);\n        }\n    };\n    GPGPUContext.prototype.downloadMatrixDriver = function (texture, downloadAndDecode) {\n        this.bindTextureToFrameBuffer(texture);\n        var result = downloadAndDecode();\n        this.unbindTextureToFrameBuffer();\n        return result;\n    };\n    GPGPUContext.prototype.setOutputMatrixTextureDriver = function (outputMatrixTextureMaybePacked, width, height) {\n        this.throwIfDisposed();\n        var gl = this.gl;\n        webgl_util.bindColorTextureToFramebuffer(gl, this.debug, outputMatrixTextureMaybePacked, this.framebuffer);\n        if (this.debug) {\n            webgl_util.validateFramebuffer(gl);\n        }\n        this.outputTexture = outputMatrixTextureMaybePacked;\n        webgl_util.callAndCheck(gl, this.debug, function () { return gl.viewport(0, 0, width, height); });\n        webgl_util.callAndCheck(gl, this.debug, function () { return gl.scissor(0, 0, width, height); });\n    };\n    GPGPUContext.prototype.setOutputMatrixWriteRegionDriver = function (x, y, width, height) {\n        var _this = this;\n        this.throwIfDisposed();\n        webgl_util.callAndCheck(this.gl, this.debug, function () { return _this.gl.scissor(x, y, width, height); });\n    };\n    GPGPUContext.prototype.throwIfDisposed = function () {\n        if (this.disposed) {\n            throw new Error('Attempted to use disposed GPGPUContext.');\n        }\n    };\n    GPGPUContext.prototype.throwIfNoProgram = function () {\n        if (this.program == null) {\n            throw new Error('No GPU program is currently set.');\n        }\n    };\n    return GPGPUContext;\n}());\nexports.GPGPUContext = GPGPUContext;\n/**\n * Finds the index of the last true element using linear search.\n * Note: We can't do binary search because Chrome expects us to explicitly\n * test all fences before download:\n * https://github.com/tensorflow/tfjs/issues/1145\n */\nfunction linearSearchLastTrue(arr) {\n    var i = 0;\n    for (; i < arr.length; ++i) {\n        var isDone = arr[i]();\n        if (!isDone) {\n            break;\n        }\n    }\n    return i - 1;\n}\nexports.linearSearchLastTrue = linearSearchLastTrue;\n//# sourceMappingURL=gpgpu_context.js.map","\n/**\n * @license\n * Copyright 2017 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar environment_1 = require(\"../../environment\");\nvar util = require(\"../../util\");\nvar glsl_version_1 = require(\"./glsl_version\");\nvar tex_util = require(\"./tex_util\");\nvar webgl_util = require(\"./webgl_util\");\nfunction createVertexShader(gl, debug) {\n    var glsl = glsl_version_1.getGlslDifferences();\n    var vertexShaderSource = glsl.version + \"\\n    precision highp float;\\n    \" + glsl.attribute + \" vec3 clipSpacePos;\\n    \" + glsl.attribute + \" vec2 uv;\\n    \" + glsl.varyingVs + \" vec2 resultUV;\\n\\n    void main() {\\n      gl_Position = vec4(clipSpacePos, 1);\\n      resultUV = uv;\\n    }\";\n    return webgl_util.createVertexShader(gl, debug, vertexShaderSource);\n}\nexports.createVertexShader = createVertexShader;\nfunction createVertexBuffer(gl, debug) {\n    // [x y z u v] * [upper-left, lower-left, upper-right, lower-right]\n    var vertexArray = new Float32Array([-1, 1, 0, 0, 1, -1, -1, 0, 0, 0, 1, 1, 0, 1, 1, 1, -1, 0, 1, 0]);\n    return webgl_util.createStaticVertexBuffer(gl, debug, vertexArray);\n}\nexports.createVertexBuffer = createVertexBuffer;\nfunction createIndexBuffer(gl, debug) {\n    // OpenGL (and WebGL) have \"CCW == front\" winding\n    var triangleVertexIndices = new Uint16Array([0, 1, 2, 2, 1, 3]);\n    return webgl_util.createStaticIndexBuffer(gl, debug, triangleVertexIndices);\n}\nexports.createIndexBuffer = createIndexBuffer;\nfunction getTextureConfig(\n// tslint:disable-next-line:no-any\ngl, textureHalfFloatExtension) {\n    // tslint:disable-next-line:no-any\n    var glany = gl;\n    var internalFormatFloat;\n    var internalFormatHalfFloat;\n    var internalFormatPackedHalfFloat;\n    var internalFormatPackedFloat;\n    var textureFormatFloat;\n    var downloadTextureFormat;\n    var downloadUnpackNumChannels;\n    var defaultNumChannels;\n    var textureTypeHalfFloat;\n    if (environment_1.ENV.getNumber('WEBGL_VERSION') === 2) {\n        internalFormatFloat = glany.R32F;\n        internalFormatHalfFloat = glany.R16F;\n        internalFormatPackedHalfFloat = glany.RGBA16F;\n        internalFormatPackedFloat = glany.RGBA32F;\n        textureFormatFloat = glany.RED;\n        downloadUnpackNumChannels = 4;\n        defaultNumChannels = 1;\n        textureTypeHalfFloat = glany.HALF_FLOAT;\n    }\n    else {\n        internalFormatFloat = gl.RGBA;\n        internalFormatHalfFloat = gl.RGBA;\n        internalFormatPackedHalfFloat = gl.RGBA;\n        internalFormatPackedFloat = glany.RGBA;\n        textureFormatFloat = gl.RGBA;\n        downloadUnpackNumChannels = 4;\n        defaultNumChannels = 4;\n        textureTypeHalfFloat = textureHalfFloatExtension != null ?\n            textureHalfFloatExtension.HALF_FLOAT_OES :\n            null;\n    }\n    downloadTextureFormat = gl.RGBA;\n    return {\n        internalFormatFloat: internalFormatFloat,\n        internalFormatHalfFloat: internalFormatHalfFloat,\n        internalFormatPackedHalfFloat: internalFormatPackedHalfFloat,\n        internalFormatPackedFloat: internalFormatPackedFloat,\n        textureFormatFloat: textureFormatFloat,\n        downloadTextureFormat: downloadTextureFormat,\n        downloadUnpackNumChannels: downloadUnpackNumChannels,\n        defaultNumChannels: defaultNumChannels,\n        textureTypeHalfFloat: textureTypeHalfFloat\n    };\n}\nexports.getTextureConfig = getTextureConfig;\nfunction createAndConfigureTexture(gl, debug, width, height, internalFormat, textureFormat, textureType) {\n    webgl_util.validateTextureSize(width, height);\n    var texture = webgl_util.createTexture(gl, debug);\n    var tex2d = gl.TEXTURE_2D;\n    webgl_util.callAndCheck(gl, debug, function () { return gl.bindTexture(tex2d, texture); });\n    webgl_util.callAndCheck(gl, debug, function () { return gl.texParameteri(tex2d, gl.TEXTURE_WRAP_S, gl.CLAMP_TO_EDGE); });\n    webgl_util.callAndCheck(gl, debug, function () { return gl.texParameteri(tex2d, gl.TEXTURE_WRAP_T, gl.CLAMP_TO_EDGE); });\n    webgl_util.callAndCheck(gl, debug, function () { return gl.texParameteri(tex2d, gl.TEXTURE_MIN_FILTER, gl.NEAREST); });\n    webgl_util.callAndCheck(gl, debug, function () { return gl.texParameteri(tex2d, gl.TEXTURE_MAG_FILTER, gl.NEAREST); });\n    webgl_util.callAndCheck(gl, debug, function () { return gl.texImage2D(tex2d, 0, internalFormat, width, height, 0, textureFormat, textureType, null); });\n    webgl_util.callAndCheck(gl, debug, function () { return gl.bindTexture(gl.TEXTURE_2D, null); });\n    return texture;\n}\nfunction createFloat32MatrixTexture(gl, debug, rows, columns, textureConfig) {\n    var _a = tex_util.getUnpackedMatrixTextureShapeWidthHeight(rows, columns), width = _a[0], height = _a[1];\n    return createAndConfigureTexture(gl, debug, width, height, textureConfig.internalFormatFloat, textureConfig.textureFormatFloat, gl.FLOAT);\n}\nexports.createFloat32MatrixTexture = createFloat32MatrixTexture;\nfunction createFloat16MatrixTexture(gl, debug, rows, columns, textureConfig) {\n    var _a = tex_util.getUnpackedMatrixTextureShapeWidthHeight(rows, columns), width = _a[0], height = _a[1];\n    return createAndConfigureTexture(gl, debug, width, height, textureConfig.internalFormatHalfFloat, textureConfig.textureFormatFloat, textureConfig.textureTypeHalfFloat);\n}\nexports.createFloat16MatrixTexture = createFloat16MatrixTexture;\nfunction createUnsignedBytesMatrixTexture(gl, debug, rows, columns, textureConfig) {\n    var _a = tex_util.getUnpackedMatrixTextureShapeWidthHeight(rows, columns), width = _a[0], height = _a[1];\n    return createAndConfigureTexture(gl, debug, width, height, gl.RGBA, gl.RGBA, gl.UNSIGNED_BYTE);\n}\nexports.createUnsignedBytesMatrixTexture = createUnsignedBytesMatrixTexture;\nfunction createPackedMatrixTexture(gl, debug, rows, columns, textureConfig) {\n    var _a = tex_util.getPackedMatrixTextureShapeWidthHeight(rows, columns), width = _a[0], height = _a[1];\n    return createAndConfigureTexture(gl, debug, width, height, textureConfig.internalFormatPackedFloat, gl.RGBA, gl.FLOAT);\n}\nexports.createPackedMatrixTexture = createPackedMatrixTexture;\nfunction createFloat16PackedMatrixTexture(gl, debug, rows, columns, textureConfig) {\n    var _a = tex_util.getPackedMatrixTextureShapeWidthHeight(rows, columns), width = _a[0], height = _a[1];\n    return createAndConfigureTexture(gl, debug, width, height, textureConfig.internalFormatPackedHalfFloat, gl.RGBA, textureConfig.textureTypeHalfFloat);\n}\nexports.createFloat16PackedMatrixTexture = createFloat16PackedMatrixTexture;\nfunction bindVertexProgramAttributeStreams(gl, debug, program, vertexBuffer) {\n    var posOffset = 0; // x is the first buffer element\n    var uvOffset = 3 * 4; // uv comes after [x y z]\n    var stride = (3 * 4) + (2 * 4); // xyz + uv, each entry is 4-byte float.\n    webgl_util.callAndCheck(gl, debug, function () { return gl.bindBuffer(gl.ARRAY_BUFFER, vertexBuffer); });\n    var success = webgl_util.bindVertexBufferToProgramAttribute(gl, debug, program, 'clipSpacePos', vertexBuffer, 3, stride, posOffset);\n    return success &&\n        webgl_util.bindVertexBufferToProgramAttribute(gl, debug, program, 'uv', vertexBuffer, 2, stride, uvOffset);\n}\nexports.bindVertexProgramAttributeStreams = bindVertexProgramAttributeStreams;\nfunction uploadPixelDataToTexture(gl, debug, texture, pixels) {\n    webgl_util.callAndCheck(gl, debug, function () { return gl.bindTexture(gl.TEXTURE_2D, texture); });\n    if (pixels.data instanceof Uint8Array) {\n        webgl_util.callAndCheck(gl, debug, function () { return gl.texImage2D(gl.TEXTURE_2D, 0, gl.RGBA, pixels.width, pixels.height, 0, gl.RGBA, gl.UNSIGNED_BYTE, pixels.data); });\n    }\n    else {\n        webgl_util.callAndCheck(gl, debug, function () { return gl.texImage2D(gl.TEXTURE_2D, 0, gl.RGBA, gl.RGBA, gl.UNSIGNED_BYTE, pixels); });\n    }\n    webgl_util.callAndCheck(gl, debug, function () { return gl.bindTexture(gl.TEXTURE_2D, null); });\n}\nexports.uploadPixelDataToTexture = uploadPixelDataToTexture;\nfunction uploadDataToTexture(gl, debug, texture, width, height, data, textureFormat) {\n    webgl_util.validateTextureSize(width, height);\n    webgl_util.callAndCheck(gl, debug, function () { return gl.bindTexture(gl.TEXTURE_2D, texture); });\n    webgl_util.callAndCheck(gl, debug, function () { return gl.texSubImage2D(gl.TEXTURE_2D, 0, 0, 0, width, height, textureFormat, gl.FLOAT, data); });\n    webgl_util.callAndCheck(gl, debug, function () { return gl.bindTexture(gl.TEXTURE_2D, null); });\n}\nfunction uploadMatrixToTexture(gl, debug, texture, rows, columns, matrix, numChannels, textureConfig) {\n    var _a = tex_util.getUnpackedMatrixTextureShapeWidthHeight(rows, columns), w = _a[0], h = _a[1];\n    var unpackedArray;\n    var numTexels = rows * columns;\n    if (textureConfig.defaultNumChannels === 1 && numTexels === matrix.length) {\n        // No need to allocate a temporary array.\n        unpackedArray = matrix;\n    }\n    else {\n        unpackedArray = new Float32Array(numTexels * numChannels);\n        tex_util.encodeMatrixToUnpackedArray(matrix, unpackedArray, numChannels);\n    }\n    uploadDataToTexture(gl, debug, texture, w, h, unpackedArray, textureConfig.textureFormatFloat);\n}\nexports.uploadMatrixToTexture = uploadMatrixToTexture;\n/**\n * This method writes a tensor to a packed texture in a way that respects how we\n * represent data using each texel's r,g,b,a channels. Specifically, we lay\n * out the four channels in two rows each containing two channels, so a single\n * texel can represent up to four values from the tensor. That means a texture\n * that has a channel width of 11 and channel height of 4 will have a texel\n * width of 6 and texel height of 2.\n *\n * rows, columns: Logical number of rows and columns in the tensor to be\n * uploaded.\n *\n * physicalRows, physicalCols: Channel dimensions of the texture that will hold\n * the tensor.\n *\n * width, height (internal parameters): Texel dimensions of the texture.\n */\nfunction uploadMatrixToPackedTexture(gl, debug, texture, batch, rows, columns, physicalRows, physicalCols, matrix, textureConfig) {\n    var _a = tex_util.getPackedMatrixTextureShapeWidthHeight(physicalRows, physicalCols), w = _a[0], h = _a[1];\n    var packedRGBA = new Float32Array(tex_util.getPackedRGBAArraySizeFromMatrixShape(physicalRows, physicalCols));\n    tex_util.encodeMatrixToPackedRGBA(matrix, batch, rows, columns, packedRGBA);\n    uploadDataToTexture(gl, debug, texture, w, h, packedRGBA, gl.RGBA);\n}\nexports.uploadMatrixToPackedTexture = uploadMatrixToPackedTexture;\nfunction createBufferFromOutputTexture(gl2, debug, rows, columns, textureConfig) {\n    // Create and bind the buffer.\n    var buffer = gl2.createBuffer();\n    webgl_util.callAndCheck(gl2, debug, function () { return gl2.bindBuffer(gl2.PIXEL_PACK_BUFFER, buffer); });\n    // Initialize the buffer to the size of the texture in bytes.\n    var bytesPerFloat = 4;\n    var bufferSizeBytes = bytesPerFloat *\n        tex_util.getUnpackedArraySizeFromMatrixSize(rows * columns, textureConfig.downloadUnpackNumChannels);\n    webgl_util.callAndCheck(gl2, debug, function () { return gl2.bufferData(gl2.PIXEL_PACK_BUFFER, bufferSizeBytes, gl2.STREAM_READ); });\n    // Enqueue a command on the GPU command queue to copy of texture into the\n    // buffer.\n    webgl_util.callAndCheck(gl2, debug, function () { return gl2.readPixels(0, 0, columns, rows, gl2.RGBA, gl2.FLOAT, 0); });\n    webgl_util.callAndCheck(gl2, debug, function () { return gl2.bindBuffer(gl2.PIXEL_PACK_BUFFER, null); });\n    return buffer;\n}\nexports.createBufferFromOutputTexture = createBufferFromOutputTexture;\nfunction downloadFloat32MatrixFromBuffer(gl, buffer, rows, columns, textureConfig) {\n    var gl2 = gl;\n    var downloadTarget = new Float32Array(tex_util.getUnpackedArraySizeFromMatrixSize(rows * columns, textureConfig.downloadUnpackNumChannels));\n    gl2.bindBuffer(gl2.PIXEL_PACK_BUFFER, buffer);\n    gl2.getBufferSubData(gl2.PIXEL_PACK_BUFFER, 0, downloadTarget);\n    gl2.bindBuffer(gl2.PIXEL_PACK_BUFFER, null);\n    var matrix = new Float32Array(rows * columns);\n    tex_util.decodeMatrixFromUnpackedArray(downloadTarget, matrix, textureConfig.downloadUnpackNumChannels);\n    return matrix;\n}\nexports.downloadFloat32MatrixFromBuffer = downloadFloat32MatrixFromBuffer;\nfunction downloadFloat32MatrixFromOutputTexture(gl, debug, rows, columns, textureConfig) {\n    var _a = tex_util.getUnpackedMatrixTextureShapeWidthHeight(rows, columns), w = _a[0], h = _a[1];\n    var downloadTarget = new Float32Array(tex_util.getUnpackedArraySizeFromMatrixSize(rows * columns, textureConfig.downloadUnpackNumChannels));\n    webgl_util.callAndCheck(gl, debug, function () { return gl.readPixels(0, 0, w, h, textureConfig.downloadTextureFormat, gl.FLOAT, downloadTarget); });\n    var matrix = new Float32Array(rows * columns);\n    tex_util.decodeMatrixFromUnpackedArray(downloadTarget, matrix, textureConfig.downloadUnpackNumChannels);\n    return matrix;\n}\nexports.downloadFloat32MatrixFromOutputTexture = downloadFloat32MatrixFromOutputTexture;\nfunction downloadByteEncodedFloatMatrixFromOutputTexture(gl, debug, rows, columns, textureConfig) {\n    var _a = tex_util.getUnpackedMatrixTextureShapeWidthHeight(rows, columns), w = _a[0], h = _a[1];\n    var numChannels = 4;\n    var downloadTarget = new Uint8Array(tex_util.getUnpackedArraySizeFromMatrixSize(rows * columns, numChannels));\n    webgl_util.callAndCheck(gl, debug, function () { return gl.readPixels(0, 0, w, h, textureConfig.downloadTextureFormat, gl.UNSIGNED_BYTE, downloadTarget); });\n    // By wrapping the buffer in a Float32Array, we use native browser IEEE 754\n    // decoding of the 4 bytes that back each 32 bit float.\n    return new Float32Array(downloadTarget.buffer);\n}\nexports.downloadByteEncodedFloatMatrixFromOutputTexture = downloadByteEncodedFloatMatrixFromOutputTexture;\nfunction downloadPackedMatrixFromBuffer(gl, buffer, batch, rows, cols, physicalRows, physicalCols, textureConfig) {\n    var gl2 = gl;\n    var downloadTarget = new Float32Array(tex_util.getPackedRGBAArraySizeFromMatrixShape(physicalRows, physicalCols));\n    gl2.bindBuffer(gl2.PIXEL_PACK_BUFFER, buffer);\n    gl2.getBufferSubData(gl2.PIXEL_PACK_BUFFER, 0, downloadTarget);\n    gl2.bindBuffer(gl2.PIXEL_PACK_BUFFER, null);\n    var matrix = new Float32Array(util.sizeFromShape([batch, rows, cols]));\n    tex_util.decodeMatrixFromPackedRGBA(downloadTarget, batch, rows, cols, matrix);\n    return matrix;\n}\nexports.downloadPackedMatrixFromBuffer = downloadPackedMatrixFromBuffer;\nfunction downloadMatrixFromPackedOutputTexture(gl, debug, batch, rows, cols, physicalRows, physicalCols, textureConfig) {\n    var _a = tex_util.getPackedMatrixTextureShapeWidthHeight(physicalRows, physicalCols), w = _a[0], h = _a[1];\n    var packedRGBA = new Float32Array(tex_util.getPackedRGBAArraySizeFromMatrixShape(physicalRows, physicalCols));\n    webgl_util.callAndCheck(gl, debug, function () { return gl.readPixels(0, 0, w, h, gl.RGBA, gl.FLOAT, packedRGBA); });\n    var matrix = new Float32Array(util.sizeFromShape([batch, rows, cols]));\n    return tex_util.decodeMatrixFromPackedRGBA(packedRGBA, batch, rows, cols, matrix);\n}\nexports.downloadMatrixFromPackedOutputTexture = downloadMatrixFromPackedOutputTexture;\n//# sourceMappingURL=gpgpu_util.js.map","\n/**\n * @license\n * Copyright 2017 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar util = require(\"../../util\");\nvar TextureUsage;\n(function (TextureUsage) {\n    TextureUsage[TextureUsage[\"RENDER\"] = 0] = \"RENDER\";\n    TextureUsage[TextureUsage[\"UPLOAD\"] = 1] = \"UPLOAD\";\n    TextureUsage[TextureUsage[\"PIXELS\"] = 2] = \"PIXELS\";\n    TextureUsage[TextureUsage[\"DOWNLOAD\"] = 3] = \"DOWNLOAD\";\n})(TextureUsage = exports.TextureUsage || (exports.TextureUsage = {}));\nvar PhysicalTextureType;\n(function (PhysicalTextureType) {\n    PhysicalTextureType[PhysicalTextureType[\"UNPACKED_FLOAT16\"] = 0] = \"UNPACKED_FLOAT16\";\n    PhysicalTextureType[PhysicalTextureType[\"UNPACKED_FLOAT32\"] = 1] = \"UNPACKED_FLOAT32\";\n    PhysicalTextureType[PhysicalTextureType[\"PACKED_4X1_UNSIGNED_BYTE\"] = 2] = \"PACKED_4X1_UNSIGNED_BYTE\";\n    PhysicalTextureType[PhysicalTextureType[\"PACKED_2X2_FLOAT32\"] = 3] = \"PACKED_2X2_FLOAT32\";\n    PhysicalTextureType[PhysicalTextureType[\"PACKED_2X2_FLOAT16\"] = 4] = \"PACKED_2X2_FLOAT16\";\n})(PhysicalTextureType = exports.PhysicalTextureType || (exports.PhysicalTextureType = {}));\nfunction getUnpackedMatrixTextureShapeWidthHeight(rows, columns) {\n    return [columns, rows];\n}\nexports.getUnpackedMatrixTextureShapeWidthHeight = getUnpackedMatrixTextureShapeWidthHeight;\nfunction getUnpackedArraySizeFromMatrixSize(matrixSize, channelsPerTexture) {\n    return matrixSize * channelsPerTexture;\n}\nexports.getUnpackedArraySizeFromMatrixSize = getUnpackedArraySizeFromMatrixSize;\nfunction getColorMatrixTextureShapeWidthHeight(rows, columns) {\n    return [columns * 4, rows];\n}\nexports.getColorMatrixTextureShapeWidthHeight = getColorMatrixTextureShapeWidthHeight;\nfunction getMatrixSizeFromUnpackedArraySize(unpackedSize, channelsPerTexture) {\n    if (unpackedSize % channelsPerTexture !== 0) {\n        throw new Error(\"unpackedSize (\" + unpackedSize + \") must be a multiple of \" +\n            (\"\" + channelsPerTexture));\n    }\n    return unpackedSize / channelsPerTexture;\n}\nexports.getMatrixSizeFromUnpackedArraySize = getMatrixSizeFromUnpackedArraySize;\nfunction encodeMatrixToUnpackedArray(matrix, unpackedArray, channelsPerTexture) {\n    var requiredSize = getUnpackedArraySizeFromMatrixSize(matrix.length, channelsPerTexture);\n    if (unpackedArray.length < requiredSize) {\n        throw new Error(\"unpackedArray length (\" + unpackedArray.length + \") must be >= \" +\n            (\"\" + requiredSize));\n    }\n    var dst = 0;\n    for (var src = 0; src < matrix.length; ++src) {\n        unpackedArray[dst] = matrix[src];\n        dst += channelsPerTexture;\n    }\n}\nexports.encodeMatrixToUnpackedArray = encodeMatrixToUnpackedArray;\nfunction decodeMatrixFromUnpackedArray(unpackedArray, matrix, channelsPerTexture) {\n    var requiredSize = getMatrixSizeFromUnpackedArraySize(unpackedArray.length, channelsPerTexture);\n    if (matrix.length < requiredSize) {\n        throw new Error(\"matrix length (\" + matrix.length + \") must be >= \" + requiredSize);\n    }\n    var dst = 0;\n    for (var src = 0; src < unpackedArray.length; src += channelsPerTexture) {\n        matrix[dst++] = unpackedArray[src];\n    }\n}\nexports.decodeMatrixFromUnpackedArray = decodeMatrixFromUnpackedArray;\nfunction decodeMatrixFromUnpackedColorRGBAArray(unpackedArray, matrix, channels) {\n    var requiredSize = unpackedArray.length * channels / 4;\n    if (matrix.length < requiredSize) {\n        throw new Error(\"matrix length (\" + matrix.length + \") must be >= \" + requiredSize);\n    }\n    var dst = 0;\n    for (var src = 0; src < unpackedArray.length; src += 4) {\n        for (var c = 0; c < channels; c++) {\n            matrix[dst++] = unpackedArray[src + c];\n        }\n    }\n}\nexports.decodeMatrixFromUnpackedColorRGBAArray = decodeMatrixFromUnpackedColorRGBAArray;\nfunction getPackedMatrixTextureShapeWidthHeight(rows, columns) {\n    return [\n        Math.max(1, Math.ceil(columns / 2)), Math.max(1, Math.ceil(rows / 2))\n    ];\n}\nexports.getPackedMatrixTextureShapeWidthHeight = getPackedMatrixTextureShapeWidthHeight;\nfunction getPackedRGBAArraySizeFromMatrixShape(rows, columns) {\n    var _a = getPackedMatrixTextureShapeWidthHeight(rows, columns), w = _a[0], h = _a[1];\n    return w * h * 4;\n}\nexports.getPackedRGBAArraySizeFromMatrixShape = getPackedRGBAArraySizeFromMatrixShape;\n/*\nThis is how encodeMatrixToPackedRGBA encodes a tensor with shape = [2, 3, 5]\n(indices are [batch, row, col]).\n\n000|001   002|003   004|xxx   020|021   022|023   024|xxx\n-------   -------   -------   -------   -------   -------\n010|011   012|013   014|xxx   xxx|xxx   xxx|xxx   xxx|xxx\n\n100|101   102|103   104|xxx   120|121   122|123   124|xxx\n-------   -------   -------   -------   -------   -------\n110|111   112|113   114|xxx   xxx|xxx   xxx|xxx   xxx|xxx\n\nSingle texels contain only values from the same batch, and from adjacent rows\nand columns.\n\nNote the batch dimension is needed so xxx's are inserted below 020, 021, 022,\n023, and 024.\n */\nfunction encodeMatrixToPackedRGBA(matrix, batches, rows, columns, packedRGBA) {\n    var oddWidth = (columns % 2) === 1;\n    var oddHeight = (rows % 2) === 1;\n    var widthInFullBlocks = Math.floor(columns / 2);\n    var heightInFullBlocks = Math.floor(rows / 2);\n    var texelsPerRow = Math.ceil(columns / 2);\n    var texelsPerBatch = texelsPerRow * Math.ceil(rows / 2);\n    var flattenedMatrixSize = util.nearestLargerEven(rows) * util.nearestLargerEven(columns);\n    for (var batch = 0; batch < batches; batch++) {\n        var sourceOffset = batch * rows * columns;\n        var batchOffset = batch * flattenedMatrixSize;\n        // loop over full 2x2 blocks\n        {\n            var dstStride = (oddWidth ? 4 : 0);\n            var oneRow = columns;\n            var dst = batchOffset;\n            for (var blockY = 0; blockY < heightInFullBlocks; ++blockY) {\n                var matrixSrcRow = (blockY * 2 * columns);\n                for (var blockX = 0; blockX < widthInFullBlocks; ++blockX) {\n                    var matrixSrcCol = blockX * 2;\n                    var src = sourceOffset + matrixSrcRow + matrixSrcCol;\n                    packedRGBA[dst] = matrix[src];\n                    packedRGBA[dst + 1] = matrix[src + 1];\n                    packedRGBA[dst + 2] = matrix[src + oneRow];\n                    packedRGBA[dst + 3] = matrix[src + oneRow + 1];\n                    dst += 4;\n                }\n                dst += dstStride;\n            }\n        }\n        // loop down final odd column\n        if (oddWidth) {\n            var src = sourceOffset + columns - 1;\n            var dst = batchOffset + (texelsPerRow - 1) * 4;\n            var srcStride = 2 * columns;\n            var dstStride = texelsPerRow * 4;\n            for (var blockY = 0; blockY < heightInFullBlocks; ++blockY) {\n                packedRGBA[dst] = matrix[src];\n                packedRGBA[dst + 2] = matrix[src + columns];\n                src += srcStride;\n                dst += dstStride;\n            }\n        }\n        // loop across final row\n        if (oddHeight) {\n            var src = sourceOffset + (rows - 1) * columns;\n            var dst = batchOffset + (texelsPerBatch - texelsPerRow) * 4;\n            for (var blockX = 0; blockX < widthInFullBlocks; ++blockX) {\n                packedRGBA[dst++] = matrix[src++];\n                packedRGBA[dst++] = matrix[src++];\n                dst += 2;\n            }\n            // fill in bottom-right texel\n            if (oddWidth && oddHeight) {\n                packedRGBA[batchOffset + flattenedMatrixSize - 4] = matrix[src];\n            }\n        }\n    }\n    return packedRGBA;\n}\nexports.encodeMatrixToPackedRGBA = encodeMatrixToPackedRGBA;\nfunction decodeMatrixFromPackedRGBA(packedRGBA, batches, rows, columns, matrix) {\n    var requiredSize = rows * columns;\n    if (matrix.length < requiredSize) {\n        throw new Error(\"matrix length (\" + matrix.length + \") must be >= \" + requiredSize);\n    }\n    var oddWidth = (columns % 2) === 1;\n    var oddHeight = (rows % 2) === 1;\n    var widthInFullBlocks = Math.floor(columns / 2);\n    var heightInFullBlocks = Math.floor(rows / 2);\n    var texelsPerRow = Math.ceil(columns / 2);\n    var texelsPerBatch = texelsPerRow * Math.ceil(rows / 2);\n    var flattenedMatrixSize = util.nearestLargerEven(rows) * util.nearestLargerEven(columns);\n    for (var batch = 0; batch < batches; batch++) {\n        var batchOffset = batch * rows * columns;\n        var sourceOffset = batch * flattenedMatrixSize;\n        // loop over full 2x2 blocks\n        {\n            var srcStride = oddWidth ? 4 : 0;\n            var dstStride = columns + (oddWidth ? 1 : 0);\n            var src = sourceOffset;\n            var dstRow1 = batchOffset;\n            var dstRow2 = batchOffset + columns;\n            for (var blockY = 0; blockY < heightInFullBlocks; ++blockY) {\n                for (var blockX = 0; blockX < widthInFullBlocks; ++blockX) {\n                    matrix[dstRow1++] = packedRGBA[src++];\n                    matrix[dstRow1++] = packedRGBA[src++];\n                    matrix[dstRow2++] = packedRGBA[src++];\n                    matrix[dstRow2++] = packedRGBA[src++];\n                }\n                src += srcStride;\n                dstRow1 += dstStride;\n                dstRow2 += dstStride;\n            }\n        }\n        // loop down final column\n        if (oddWidth) {\n            var src = sourceOffset + (texelsPerRow - 1) * 4;\n            var dst = batchOffset + columns - 1;\n            var srcStride = texelsPerRow * 4;\n            var dstStride = 2 * columns;\n            for (var blockY = 0; blockY < heightInFullBlocks; ++blockY) {\n                matrix[dst] = packedRGBA[src];\n                matrix[dst + columns] = packedRGBA[src + 2];\n                src += srcStride;\n                dst += dstStride;\n            }\n        }\n        // loop across final row\n        if (oddHeight) {\n            var src = sourceOffset + (texelsPerBatch - texelsPerRow) * 4;\n            var dst = batchOffset + (rows - 1) * columns;\n            for (var blockX = 0; blockX < widthInFullBlocks; ++blockX) {\n                matrix[dst++] = packedRGBA[src++];\n                matrix[dst++] = packedRGBA[src++];\n                src += 2;\n            }\n            // fill in bottom-right cell\n            if (oddWidth) {\n                matrix[batchOffset + (rows * columns) - 1] = packedRGBA[src];\n            }\n        }\n    }\n    return matrix;\n}\nexports.decodeMatrixFromPackedRGBA = decodeMatrixFromPackedRGBA;\n//# sourceMappingURL=tex_util.js.map","\n/**\n * @license\n * Copyright 2017 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar environment_1 = require(\"../../environment\");\nvar util = require(\"../../util\");\nvar shader_compiler = require(\"./shader_compiler\");\nfunction compileProgram(gpgpu, program, inputs, output) {\n    var userCode = program.userCode;\n    var inputInfos = inputs.map(function (input, i) {\n        var shapeInfo = {\n            logicalShape: input.shape,\n            texShape: input.isUniform ? null : input.texData.texShape,\n            isUniform: input.isUniform,\n            isPacked: input.isUniform ? false : input.texData.isPacked,\n            flatOffset: null\n        };\n        if (input.texData != null && input.texData.slice != null &&\n            input.texData.slice.flatOffset > 0) {\n            shapeInfo.flatOffset = input.texData.slice.flatOffset;\n        }\n        return { name: program.variableNames[i], shapeInfo: shapeInfo };\n    });\n    var inShapeInfos = inputInfos.map(function (x) { return x.shapeInfo; });\n    var outShapeInfo = {\n        logicalShape: output.shape,\n        texShape: output.texData.texShape,\n        isUniform: false,\n        isPacked: output.texData.isPacked,\n        flatOffset: null\n    };\n    var source = shader_compiler.makeShader(inputInfos, outShapeInfo, userCode, program.usesPackedTextures);\n    var webGLProgram = gpgpu.createProgram(source);\n    // Add special uniforms (NAN, INFINITY)\n    var infLoc = null;\n    var nanLoc = gpgpu.getUniformLocation(webGLProgram, 'NAN', false);\n    if (environment_1.ENV.getNumber('WEBGL_VERSION') === 1) {\n        infLoc = gpgpu.getUniformLocation(webGLProgram, 'INFINITY', false);\n    }\n    // Add user-defined uniforms\n    var uniformLocations = {};\n    for (var i = 0; i < program.variableNames.length; i++) {\n        var varName = program.variableNames[i];\n        var shouldThrow = false;\n        uniformLocations[varName] =\n            gpgpu.getUniformLocation(webGLProgram, varName, shouldThrow);\n        uniformLocations[\"offset\" + varName] =\n            gpgpu.getUniformLocation(webGLProgram, \"offset\" + varName, shouldThrow);\n    }\n    return {\n        program: program,\n        source: source,\n        webGLProgram: webGLProgram,\n        uniformLocations: uniformLocations,\n        inShapeInfos: inShapeInfos,\n        outShapeInfo: outShapeInfo,\n        infLoc: infLoc,\n        nanLoc: nanLoc,\n    };\n}\nexports.compileProgram = compileProgram;\nfunction validateBinaryAndProgram(shapeInfos, inputs) {\n    if (shapeInfos.length !== inputs.length) {\n        throw Error(\"Binary was compiled with \" + shapeInfos.length + \" inputs, but \" +\n            (\"was executed with \" + inputs.length + \" inputs\"));\n    }\n    shapeInfos.forEach(function (s, i) {\n        var shapeA = s.logicalShape;\n        var input = inputs[i];\n        var shapeB = input.shape;\n        if (!util.arraysEqual(shapeA, shapeB)) {\n            throw Error(\"Binary was compiled with different shapes than \" +\n                (\"the current args. Shapes \" + shapeA + \" and \" + shapeB + \" must match\"));\n        }\n        // The input is uploaded as uniform.\n        if (s.isUniform && input.isUniform) {\n            return;\n        }\n        var texShapeA = s.texShape;\n        var texShapeB = input.isUniform ? null : input.texData.texShape;\n        if (!util.arraysEqual(texShapeA, texShapeB)) {\n            throw Error(\"Binary was compiled with different texture shapes than the\" +\n                (\" current args. Shape \" + texShapeA + \" and \" + texShapeB + \" must match\"));\n        }\n    });\n}\nfunction runProgram(gpgpu, binary, inputs, output, customSetup) {\n    validateBinaryAndProgram(binary.inShapeInfos, inputs);\n    validateBinaryAndProgram([binary.outShapeInfo], [output]);\n    var outTex = output.texData.texture;\n    var outTexShape = output.texData.texShape;\n    if (output.texData.isPacked) {\n        gpgpu.setOutputPackedMatrixTexture(outTex, outTexShape[0], outTexShape[1]);\n    }\n    else {\n        gpgpu.setOutputMatrixTexture(outTex, outTexShape[0], outTexShape[1]);\n    }\n    gpgpu.setProgram(binary.webGLProgram);\n    // Set special uniforms (NAN, INFINITY)\n    if (environment_1.ENV.getNumber('WEBGL_VERSION') === 1) {\n        if (binary.infLoc !== null) {\n            gpgpu.gl.uniform1f(binary.infLoc, Infinity);\n        }\n    }\n    if (binary.nanLoc !== null) {\n        gpgpu.gl.uniform1f(binary.nanLoc, NaN);\n    }\n    // Set user-defined inputs\n    inputs.forEach(function (input, i) {\n        var varName = binary.program.variableNames[i];\n        var varLoc = binary.uniformLocations[varName];\n        var varOffsetLoc = binary.uniformLocations[\"offset\" + varName];\n        if (varLoc == null) {\n            // The compiler inferred that this variable is not used in this shader.\n            return;\n        }\n        if (input.isUniform) {\n            // Upload the values of the tensor as uniform.\n            if (util.sizeFromShape(input.shape) < 2) {\n                gpgpu.gl.uniform1f(varLoc, input.uniformValues[0]);\n            }\n            else {\n                var vals = input.uniformValues;\n                if (!(vals instanceof Float32Array)) {\n                    vals = new Float32Array(vals);\n                }\n                gpgpu.gl.uniform1fv(varLoc, vals);\n            }\n            return;\n        }\n        // If the input was sliced, upload the flat offset index.\n        if (input.texData.slice != null && varOffsetLoc != null) {\n            gpgpu.gl.uniform1i(varOffsetLoc, input.texData.slice.flatOffset);\n        }\n        gpgpu.setInputMatrixTexture(input.texData.texture, varLoc, i);\n    });\n    if (customSetup != null) {\n        customSetup(gpgpu, binary.webGLProgram);\n    }\n    gpgpu.executeProgram();\n}\nexports.runProgram = runProgram;\nfunction makeShaderKey(program, inputs, output) {\n    var keyInputs = '';\n    inputs.concat(output).forEach(function (x) {\n        var hasOffset = x.texData != null && x.texData.slice != null &&\n            x.texData.slice.flatOffset > 0;\n        var texShape = x.isUniform ? 'uniform' : x.texData.texShape;\n        keyInputs += x.shape + \"_\" + texShape + \"_\" + hasOffset;\n    });\n    var keyUserCode = program.userCode;\n    var key = program.constructor.name;\n    // Fast string concat. See https://jsperf.com/string-concatenation/14.\n    key += '_' + keyInputs + '_' + keyUserCode;\n    return key;\n}\nexports.makeShaderKey = makeShaderKey;\n//# sourceMappingURL=gpgpu_math.js.map","\n/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar glsl_version_1 = require(\"./glsl_version\");\nvar Im2ColPackedProgram = /** @class */ (function () {\n    function Im2ColPackedProgram(outputShape, inputShape, convInfo) {\n        this.variableNames = ['A'];\n        this.usesPackedTextures = true;\n        this.outputShape = outputShape;\n        var filterWidth = convInfo.filterWidth, inChannels = convInfo.inChannels, strideWidth = convInfo.strideWidth, strideHeight = convInfo.strideHeight, padInfo = convInfo.padInfo, outWidth = convInfo.outWidth, dilationWidth = convInfo.dilationWidth, dilationHeight = convInfo.dilationHeight;\n        var left = padInfo.left, top = padInfo.top;\n        var itemsPerBlockRow = inChannels * filterWidth;\n        var glsl = glsl_version_1.getGlslDifferences();\n        this.userCode = \"\\n      void main() {\\n        ivec2 rc = getOutputCoords();\\n\\n        vec4 result = vec4(0);\\n\\n        for(int row=0; row<=1; row++) {\\n          for(int col=0; col<=1; col++) {\\n            int blockIndex = rc.y + col;\\n            int pos = rc.x + row;\\n\\n            if(blockIndex >= \" + outputShape[1] + \" || pos >= \" + outputShape[0] + \") continue;\\n\\n            int offsetY = int(blockIndex / (\" + outWidth + \")) * \" + strideHeight + \" - \" + top + \";\\n            int d0 = offsetY + \" + dilationHeight + \" * (pos / \" + itemsPerBlockRow + \");\\n\\n            if(d0 >= \" + inputShape[0] + \" || d0 < 0) continue;\\n\\n            int offsetX = int(mod(float(blockIndex), \" + outWidth + \".) * \" + strideWidth + \". - \" + left + \".);\\n            int d1 = offsetX + \" + dilationWidth + \" * (int(mod(float(pos), \" + itemsPerBlockRow + \".) / \" + inChannels + \".));\\n\\n            if(d1 >= \" + inputShape[1] + \" || d1 < 0) continue;\\n\\n            vec2 innerDims = vec2(d1, int(mod(float(pos), \" + inChannels + \".)));\\n            result[row * 2 + col] = getChannel(getA(d0, int(innerDims.x),\\n                                              int(innerDims.y)), innerDims);\\n          }\\n        }\\n\\n        \" + glsl.output + \" = result;\\n      }\\n    \";\n    }\n    return Im2ColPackedProgram;\n}());\nexports.Im2ColPackedProgram = Im2ColPackedProgram;\n//# sourceMappingURL=im2col_packed_gpu.js.map","\n/**\n * @license\n * Copyright 2017 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar LRNProgram = /** @class */ (function () {\n    function LRNProgram(xShape, radius, bias, alpha, beta) {\n        this.variableNames = ['x'];\n        this.outputShape = [];\n        var rad = radius;\n        var maxD = xShape[3] - 1;\n        this.outputShape = xShape;\n        // optimize pow(bias + alpha * sum, -beta)\n        // src: https://github.com/tensorflow/tensorflow/..\n        // blob/26033a1644a9c4a5fbe3170ab2e864b6a4ccd4ca/..\n        // tensorflow/core/kernels/mkl_lrn_op.cc#L320\n        var powOperator;\n        var basis = \"float(\" + bias + \") + float(\" + alpha + \") * sum\";\n        if (beta === 0.5) {\n            powOperator = \"inversesqrt(\" + basis + \")\";\n        }\n        else if (beta === 1.0) {\n            powOperator = \"1.0/(\" + basis + \")\";\n        }\n        else {\n            powOperator = \"exp(log(\" + basis + \") * float(-\" + beta + \"));\";\n        }\n        this.userCode = \"\\n      void main() {\\n        ivec4 coords = getOutputCoords();\\n        int b = coords[0];\\n        int r = coords[1];\\n        int c = coords[2];\\n        int d = coords[3];\\n        float x = getX(b, r, c, d);\\n        float sum = 0.0;\\n        for (int j = -\" + rad + \"; j <= \" + rad + \"; j++) {\\n          int idx = d + j;\\n          if (idx >= 0 && idx <=  \" + maxD + \") {\\n            float z = getX(b, r, c, idx);\\n            sum += z * z;\\n          }\\n        }\\n        float val = x * \" + powOperator + \";\\n        setOutput(val);\\n      }\\n    \";\n    }\n    return LRNProgram;\n}());\nexports.LRNProgram = LRNProgram;\n//# sourceMappingURL=lrn_gpu.js.map","\n/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar LRNGradProgram = /** @class */ (function () {\n    function LRNGradProgram(inputShape, depthRadius, bias, alpha, beta) {\n        this.variableNames = ['inputImage', 'outputImage', 'dy'];\n        this.outputShape = [];\n        this.outputShape = inputShape;\n        this.depth = inputShape[3];\n        this.depthRadius = depthRadius;\n        this.bias = bias;\n        this.alpha = alpha;\n        this.beta = beta;\n        this.userCode = \"\\n      void main() {\\n        ivec4 coords = getOutputCoords();\\n        int b = coords[0];\\n        int r = coords[1];\\n        int c = coords[2];\\n\\n        float result = 0.0;\\n        for (int d = 0; d < \" + this.depth + \"; ++d) {\\n          int depthBegin = int(max(0.0, float(d - \" + depthRadius + \")));\\n          int depthEnd = int(min(float(\" + this.depth + \"),\\n              float(d + \" + depthRadius + \" + 1)));\\n\\n          const int MIN_DEPTH_BEGIN = 0;\\n          const int MAX_DEPTH_END = \" + this.depth + \";\\n\\n          float norm = 0.0;\\n          for (int k = MIN_DEPTH_BEGIN; k < MAX_DEPTH_END; ++k) {\\n            if (k < depthBegin){\\n              continue;\\n            }\\n            else if (k >= depthBegin && k < depthEnd) {\\n              norm += getInputImage(b, r, c, k) * getInputImage(b, r, c, k);\\n            }\\n            else {\\n              break;\\n            }\\n          }\\n\\n          norm = float(\" + alpha + \") * norm + float(\" + bias + \");\\n\\n          for(int k = MIN_DEPTH_BEGIN; k < MAX_DEPTH_END; ++k){\\n            if (k < depthBegin){\\n              continue;\\n            }\\n            else if (k >= depthBegin && k < depthEnd){\\n              float dyi = -2.0 * float(\" + alpha + \")\\n                * float(\" + beta + \")\\n                * getInputImage(b ,r ,c, k) * getOutputImage(b, r, c, d)\\n                / norm;\\n              if (k == d) {\\n                dyi += pow(norm, -1.0 * \" + beta + \");\\n              }\\n              if (k == coords[3]) {\\n                dyi *= getDy(b, r, c, d);\\n                result += dyi;\\n              }\\n            }\\n            else {\\n              break;\\n            }\\n          }\\n      }\\n      setOutput(result);\\n      }\\n    \";\n    }\n    return LRNGradProgram;\n}());\nexports.LRNGradProgram = LRNGradProgram;\n//# sourceMappingURL=lrn_grad_gpu.js.map","\n/**\n * @license\n * Copyright 2019 Google LLC All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar LRNPackedProgram = /** @class */ (function () {\n    function LRNPackedProgram(xShape, radius, bias, alpha, beta) {\n        this.variableNames = ['x'];\n        this.outputShape = [];\n        this.usesPackedTextures = true;\n        var rad = radius;\n        var maxD = xShape[3] - 1;\n        this.outputShape = xShape;\n        // optimize pow(bias + alpha * sum, -beta)\n        // src: https://github.com/tensorflow/tensorflow/..\n        // blob/26033a1644a9c4a5fbe3170ab2e864b6a4ccd4ca/..\n        // tensorflow/core/kernels/mkl_lrn_op.cc#L320\n        var powOperator;\n        var basis = \"float(\" + bias + \") + float(\" + alpha + \") * sum\";\n        if (beta === 0.5) {\n            powOperator = \"inversesqrt(\" + basis + \")\";\n        }\n        else if (beta === 1.0) {\n            powOperator = \"1.0/(\" + basis + \")\";\n        }\n        else {\n            powOperator = \"exp(log(\" + basis + \") * float(-\" + beta + \"));\";\n        }\n        this.userCode = \"\\n      void main() {\\n        ivec4 coords = getOutputCoords();\\n        int b = coords.x;\\n        int r = coords.y;\\n        int c = coords.z;\\n        int d = coords.w;\\n\\n        bool hasNextCol = d < \" + this.outputShape[3] + \";\\n        bool hasNextRow = c < \" + this.outputShape[2] + \";\\n\\n        vec4 sum = vec4(0.);\\n        vec4 xFragAtOutputCoords = getX(b, r, c, d);\\n\\n        vec4 xAtOutputCoords = vec4(\\n          getChannel(xFragAtOutputCoords, vec2(c, d)),\\n          hasNextCol ?\\n            getChannel(xFragAtOutputCoords, vec2(c, d + 1)) : 0.0,\\n          hasNextRow ?\\n            getChannel(xFragAtOutputCoords , vec2(c + 1, d)) : 0.0,\\n          (hasNextRow && hasNextCol) ?\\n            getChannel(xFragAtOutputCoords, vec2(c + 1, d + 1)) : 0.0\\n        );\\n\\n        int firstChannel = d - \" + rad + \";\\n        vec2 cache = vec2(0.);\\n        if(firstChannel >= 0){\\n          vec4 firstChannelFrag = getX(b, r, c, firstChannel);\\n          cache.x = getChannel(firstChannelFrag, vec2(c, firstChannel));\\n            if(hasNextRow){\\n              cache.y = getChannel(firstChannelFrag, vec2(c + 1, firstChannel));\\n            }\\n        }\\n\\n        ivec2 depth = ivec2(d, d + 1);\\n        for (int j = - \" + rad + \"; j <= \" + rad + \"; j++) {\\n          ivec2 idx = depth + j;\\n          bvec2 aboveLowerBound = greaterThanEqual(idx, ivec2(0));\\n          bvec2 belowUpperBound = lessThanEqual(idx, ivec2(\" + maxD + \"));\\n\\n          bool depthInRange = aboveLowerBound.x && belowUpperBound.x;\\n          bool depthPlusOneInRange = aboveLowerBound.y && belowUpperBound.y;\\n\\n          if(depthInRange || depthPlusOneInRange){\\n            vec4 z = vec4(0.);\\n            vec4 xFragAtCurrentDepth;\\n            z.xz = cache.xy;\\n            if(depthPlusOneInRange && hasNextCol){\\n              xFragAtCurrentDepth = idx.y != d ?\\n                getX(b, r, c, idx.y) : xFragAtOutputCoords;\\n              z.y = getChannel(xFragAtCurrentDepth, vec2(c, idx.y));\\n              if(hasNextRow){\\n                z.w = getChannel(xFragAtCurrentDepth, vec2(c + 1, idx.y));\\n              }\\n            }\\n            cache.xy = z.yw;\\n            sum += z * z;\\n          }\\n        }\\n        vec4 result = xAtOutputCoords * \" + powOperator + \";\\n        setOutput(result);\\n      }\\n    \";\n    }\n    return LRNPackedProgram;\n}());\nexports.LRNPackedProgram = LRNPackedProgram;\n//# sourceMappingURL=lrn_packed_gpu.js.map","\n/**\n * @license\n * Copyright 2017 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar MaxPool2DBackpropProgram = /** @class */ (function () {\n    function MaxPool2DBackpropProgram(convInfo) {\n        this.variableNames = ['dy', 'maxPos'];\n        this.outputShape = convInfo.inShape;\n        var strideHeight = convInfo.strideHeight;\n        var strideWidth = convInfo.strideWidth;\n        var dilationHeight = convInfo.dilationHeight;\n        var effectiveFilterHeight = convInfo.effectiveFilterHeight;\n        var effectiveFilterWidth = convInfo.effectiveFilterWidth;\n        var padTop = effectiveFilterHeight - 1 - convInfo.padInfo.top;\n        var padLeft = effectiveFilterWidth - 1 - convInfo.padInfo.left;\n        var lastIndex = effectiveFilterHeight * effectiveFilterWidth - 1;\n        this.userCode = \"\\n      const ivec2 pads = ivec2(\" + padTop + \", \" + padLeft + \");\\n\\n      void main() {\\n        ivec4 coords = getOutputCoords();\\n        int b = coords[0];\\n        int d = coords[3];\\n\\n        ivec2 dyRCCorner = coords.yz - pads;\\n        int dyRCorner = dyRCCorner.x;\\n        int dyCCorner = dyRCCorner.y;\\n\\n        // Convolve dy(?, ?, d) with pos mask(:, :, d) to get dx(xR, xC, d).\\n        // ? = to be determined. : = across all values in that axis.\\n        float dotProd = 0.0;\\n        for (int wR = 0; wR < \" + effectiveFilterHeight + \";\\n          wR += \" + dilationHeight + \") {\\n          float dyR = float(dyRCorner + wR) / \" + strideHeight + \".0;\\n\\n          if (dyR < 0.0 || dyR >= \" + convInfo.outHeight + \".0 || fract(dyR) > 0.0) {\\n            continue;\\n          }\\n          int idyR = int(dyR);\\n\\n          for (int wC = 0; wC < \" + effectiveFilterWidth + \"; wC++) {\\n            float dyC = float(dyCCorner + wC) / \" + strideWidth + \".0;\\n\\n            if (dyC < 0.0 || dyC >= \" + convInfo.outWidth + \".0 ||\\n                fract(dyC) > 0.0) {\\n              continue;\\n            }\\n            int idyC = int(dyC);\\n\\n            float dyValue = getDy(b, idyR, idyC, d);\\n            int maxPosValue = \" + lastIndex + \" - int(getMaxPos(b, idyR, idyC, d));\\n\\n            // Get the current value, check it against the value from the\\n            // position matrix.\\n            int curPosValue = wR * \" + effectiveFilterWidth + \" + wC;\\n            float mask = float(maxPosValue == curPosValue ? 1.0 : 0.0);\\n\\n            dotProd += dyValue * mask;\\n          }\\n        }\\n        setOutput(dotProd);\\n      }\\n    \";\n    }\n    return MaxPool2DBackpropProgram;\n}());\nexports.MaxPool2DBackpropProgram = MaxPool2DBackpropProgram;\n//# sourceMappingURL=max_pool_backprop_gpu.js.map","\n/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar MatMulPackedProgram = /** @class */ (function () {\n    function MatMulPackedProgram(aShape, outputShape, transposeA, transposeB, addBias, activation) {\n        if (transposeA === void 0) { transposeA = false; }\n        if (transposeB === void 0) { transposeB = false; }\n        if (addBias === void 0) { addBias = false; }\n        if (activation === void 0) { activation = null; }\n        this.variableNames = ['matrixA', 'matrixB'];\n        this.usesPackedTextures = true;\n        this.outputShape = outputShape;\n        var sharedDim = transposeA ? aShape[1] : aShape[2];\n        var sharedDimensionPacked = Math.ceil(sharedDim / 2);\n        var aSample = transposeA ? 'i * 2, rc.y' : 'rc.y, i * 2';\n        var bSample = transposeB ? 'rc.z, i * 2' : 'i * 2, rc.z';\n        var aSwizzle = transposeA ? ['a.xxyy', 'a.zzww'] : ['a.xxzz', 'a.yyww'];\n        var bSwizzle = transposeB ? ['b.xzxz', 'b.ywyw'] : ['b.xyxy', 'b.zwzw'];\n        var activationSnippet = '', applyActivationSnippet = '';\n        if (activation) {\n            activationSnippet = \"vec4 activation(vec4 x) {\\n        \" + activation + \"\\n      }\";\n            applyActivationSnippet = \"result = activation(result);\";\n        }\n        var addBiasSnippet = addBias ? 'result += getBiasAtOutCoords();' : '';\n        if (addBias) {\n            this.variableNames.push('bias');\n        }\n        this.userCode = \"\\n      \" + activationSnippet + \"\\n\\n      const float sharedDimension = \" + sharedDimensionPacked + \".0;\\n\\n      vec4 dot2x2ARowBCol(ivec3 rc) {\\n        vec4 result = vec4(0);\\n        for (int i = 0; i < \" + sharedDimensionPacked + \"; i++) {\\n          vec4 a = getMatrixA(rc.x, \" + aSample + \");\\n          vec4 b = getMatrixB(rc.x, \" + bSample + \");\\n\\n          result += (\" + aSwizzle[0] + \" * \" + bSwizzle[0] + \") + (\" + aSwizzle[1] + \" * \" + bSwizzle[1] + \");\\n        }\\n        return result;\\n      }\\n\\n      void main() {\\n        ivec3 rc = getOutputCoords();\\n        vec4 result = dot2x2ARowBCol(rc);\\n\\n        \" + addBiasSnippet + \"\\n\\n        \" + applyActivationSnippet + \"\\n\\n        setOutput(result);\\n      }\\n    \";\n    }\n    return MatMulPackedProgram;\n}());\nexports.MatMulPackedProgram = MatMulPackedProgram;\n//# sourceMappingURL=mulmat_packed_gpu.js.map","\n/**\n * @license\n * Copyright 2017 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar MultinomialProgram = /** @class */ (function () {\n    function MultinomialProgram(batchSize, numOutcomes, numSamples) {\n        this.variableNames = ['probs'];\n        this.outputShape = [batchSize, numSamples];\n        this.userCode = \"\\n      uniform float seed;\\n\\n      void main() {\\n        ivec2 coords = getOutputCoords();\\n        int batch = coords[0];\\n\\n        float r = random(seed);\\n        float cdf = 0.0;\\n\\n        for (int i = 0; i < \" + (numOutcomes - 1) + \"; i++) {\\n          cdf += getProbs(batch, i);\\n\\n          if (r < cdf) {\\n            setOutput(float(i));\\n            return;\\n          }\\n        }\\n\\n        // If no other event happened, last event happened.\\n        setOutput(float(\" + (numOutcomes - 1) + \"));\\n      }\\n    \";\n    }\n    MultinomialProgram.prototype.getCustomSetupFunc = function (seed) {\n        var _this = this;\n        return function (gpgpu, webGLProgram) {\n            if (_this.seedLoc == null) {\n                _this.seedLoc = gpgpu.getUniformLocation(webGLProgram, 'seed');\n            }\n            gpgpu.gl.uniform1f(_this.seedLoc, seed);\n        };\n    };\n    return MultinomialProgram;\n}());\nexports.MultinomialProgram = MultinomialProgram;\n//# sourceMappingURL=multinomial_gpu.js.map","\n/**\n * @license\n * Copyright 2017 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar OneHotProgram = /** @class */ (function () {\n    function OneHotProgram(numIndices, depth, onValue, offValue) {\n        this.variableNames = ['indices'];\n        this.outputShape = [numIndices, depth];\n        this.userCode = \"\\n      void main() {\\n        ivec2 coords = getOutputCoords();\\n        int index = round(getIndices(coords.x));\\n        setOutput(mix(float(\" + offValue + \"), float(\" + onValue + \"),\\n                      float(index == coords.y)));\\n      }\\n    \";\n    }\n    return OneHotProgram;\n}());\nexports.OneHotProgram = OneHotProgram;\n//# sourceMappingURL=onehot_gpu.js.map","\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar packing_util_1 = require(\"../packing_util\");\nvar shader_compiler_1 = require(\"./shader_compiler\");\nvar PackProgram = /** @class */ (function () {\n    function PackProgram(outputShape) {\n        this.variableNames = ['A'];\n        this.isPackShader = true;\n        // Only input / output 3D tensors.\n        this.outputShape = outputShape;\n        var rank = outputShape.length;\n        if (rank === 0) {\n            this.userCode = \"\\n        void main() {\\n          setOutput(vec4(getA(), 0., 0., 0.));\\n        }\\n      \";\n        }\n        else {\n            var channels = packing_util_1.getChannels('rc', rank);\n            var dtype = shader_compiler_1.getCoordsDataType(rank);\n            var outOfBoundsCondition = getOutOfBoundsCondition(rank, outputShape, channels);\n            var setup = getSetup(rank, outputShape[outputShape.length - 1], outputShape[outputShape.length - 2], channels);\n            var output = getOutput(outputShape, channels);\n            this.userCode = \"\\n        void main() {\\n          \" + dtype + \" rc = getOutputCoords();\\n\\n          if(\" + outOfBoundsCondition + \") {\\n            setOutput(vec4(0));\\n          } else {\\n            \" + setup + \"\\n\\n            setOutput(vec4(\" + output + \"));\\n          }\\n        }\\n      \";\n        }\n    }\n    return PackProgram;\n}());\nexports.PackProgram = PackProgram;\nfunction getSourceCoordsArr(rank, dims) {\n    var coords = [];\n    for (var row = 0; row <= 1; row++) {\n        for (var col = 0; col <= 1; col++) {\n            var coord = (row === 0 ? 'r' : 'rp1') + \", \" + (col === 0 ? 'c' : 'cp1');\n            for (var d = 2; d < rank; d++) {\n                coord = dims[dims.length - 1 - d] + \",\" + coord;\n            }\n            coords.push(coord);\n        }\n    }\n    return coords;\n}\nfunction getOutOfBoundsCondition(rank, shape, dims) {\n    if (rank === 1) {\n        return \"rc > \" + shape[0];\n    }\n    var cond = '';\n    for (var i = rank - 2; i < rank; i++) {\n        cond += dims[i] + \" >= \" + shape[i];\n        if (i < rank - 1) {\n            cond += '||';\n        }\n    }\n    return cond;\n}\nfunction getSetup(rank, cols, rows, dims) {\n    if (rank === 1) {\n        return '';\n    }\n    var innerDims = dims.slice(-2);\n    return \"\\n    int r = \" + innerDims[0] + \";\\n    int c = \" + innerDims[1] + \";\\n    int rp1 = r + 1;\\n    int cp1 = c + 1;\\n\\n    bool cEdge = cp1 >= \" + cols + \";\\n    bool rEdge = rp1 >= \" + rows + \";\\n  \";\n}\nfunction getOutput(shape, dims) {\n    var rank = shape.length;\n    var sourceCoords = getSourceCoordsArr(rank, dims);\n    if (rank === 1) {\n        return \"getA(rc),\\n            rc + 1 >= \" + shape[0] + \" ? 0. : getA(rc + 1),\\n            0, 0\";\n    }\n    return \"getA(\" + sourceCoords[0] + \"),\\n          cEdge ? 0. : getA(\" + sourceCoords[1] + \"),\\n          rEdge ? 0. : getA(\" + sourceCoords[2] + \"),\\n          rEdge || cEdge ? 0. : getA(\" + sourceCoords[3] + \")\";\n}\n//# sourceMappingURL=pack_gpu.js.map","\n/**\n * @license\n * Copyright 2017 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar shader_compiler_1 = require(\"./shader_compiler\");\nvar PadProgram = /** @class */ (function () {\n    function PadProgram(xShape, paddings, constantValue) {\n        this.variableNames = ['x'];\n        this.outputShape = paddings.map(function (p, i) { return p[0] /* beforePad */ + xShape[i] + p[1]; } /* afterPad */);\n        var rank = xShape.length;\n        var type = shader_compiler_1.getCoordsDataType(rank);\n        var start = paddings.map(function (p) { return p[0]; }).join(',');\n        var end = paddings.map(function (p, i) { return p[0] + xShape[i]; }).join(',');\n        var unpackedCoords = ['coords[0]', 'coords[1]', 'coords[2]', 'coords[3]'].slice(0, rank);\n        if (rank === 1) {\n            this.userCode = \"\\n        int start = \" + start + \";\\n        int end = \" + end + \";\\n\\n        void main() {\\n          int outC = getOutputCoords();\\n          if (outC < start || outC >= end) {\\n            setOutput(float(\" + constantValue + \"));\\n          } else {\\n            setOutput(getX(outC - start));\\n          }\\n        }\\n      \";\n            return;\n        }\n        this.userCode = \"\\n      \" + type + \" start = \" + type + \"(\" + start + \");\\n      \" + type + \" end = \" + type + \"(\" + end + \");\\n\\n      void main() {\\n        \" + type + \" outC = getOutputCoords();\\n        if (any(lessThan(outC, start)) || any(greaterThanEqual(outC, end))) {\\n          setOutput(float(\" + constantValue + \"));\\n        } else {\\n          \" + type + \" coords = outC - start;\\n          setOutput(getX(\" + unpackedCoords + \"));\\n        }\\n      }\\n    \";\n    }\n    return PadProgram;\n}());\nexports.PadProgram = PadProgram;\n//# sourceMappingURL=pad_gpu.js.map","\n/**\n * @license\n * Copyright 2019 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar shader_compiler_1 = require(\"./shader_compiler\");\nvar packing_util_1 = require(\"../packing_util\");\nvar PadPackedProgram = /** @class */ (function () {\n    function PadPackedProgram(xShape, paddings, constantValue) {\n        this.variableNames = ['x'];\n        this.usesPackedTextures = true;\n        this.outputShape = paddings.map(function (p, i) { return p[0] /* beforePad */ + xShape[i] + p[1]; } /* afterPad */);\n        var rank = xShape.length;\n        var dtype = shader_compiler_1.getCoordsDataType(rank);\n        var start = paddings.map(function (p) { return p[0]; }).join(',');\n        var end = paddings.map(function (p, i) { return p[0] + xShape[i]; }).join(',');\n        var coords = packing_util_1.getChannels('rc', rank);\n        var source = packing_util_1.getChannels('source', rank);\n        var cLimit = coords[rank - 1] + \" < \" + this.outputShape[rank - 1];\n        var innerDims = rank === 1 ? 'source' : \"vec2(\" + source.slice(-2).join() + \")\";\n        var componentSetup = [\n            dtype + \" rc = outputLoc;\",\n            coords[rank - 1] + \" += 1;\\n       if(\" + cLimit + \") {\\n      \",\n            rank === 1 ? '' :\n                \"}\\n       rc = outputLoc;\\n       \" + coords[rank - 2] + \" += 1;\\n       if(\" + coords[rank - 2] + \" < \" + this.outputShape[rank - 2] + \") {\",\n            rank === 1 ? '' :\n                \"  \" + coords[rank - 1] + \" += 1;\\n         if(\" + cLimit + \") {\"\n        ];\n        var paddingArea = rank === 1 ?\n            'rc < start || rc >= end' :\n            'any(lessThan(rc, start)) || any(greaterThanEqual(rc, end))';\n        var mainLoop = '';\n        for (var i = 0, j = rank === 1 ? 2 : 4; i < j; i++) {\n            mainLoop += \"\\n        \" + componentSetup[i] + \"\\n        if (\" + paddingArea + \") {\\n          result[\" + i + \"] = float(\" + constantValue + \");\\n        } else {\\n          \" + dtype + \" source = rc - start;\\n          result[\" + i + \"] = getChannel(getX(\" + source.join() + \"), \" + innerDims + \");\\n        }\\n      \";\n        }\n        mainLoop += (rank === 1 ? \"} \" : \"}}\");\n        this.userCode = \"\\n      const \" + dtype + \" start = \" + dtype + \"(\" + start + \");\\n      const \" + dtype + \" end = \" + dtype + \"(\" + end + \");\\n\\n      void main() {\\n        \" + dtype + \" outputLoc = getOutputCoords();\\n        vec4 result = vec4(0.);\\n        \" + mainLoop + \"\\n        setOutput(result);\\n      }\\n    \";\n    }\n    return PadPackedProgram;\n}());\nexports.PadPackedProgram = PadPackedProgram;\n//# sourceMappingURL=pad_packed_gpu.js.map","\n/**\n * @license\n * Copyright 2017 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar Pool2DProgram = /** @class */ (function () {\n    function Pool2DProgram(convInfo, poolType, computePositions) {\n        this.variableNames = ['x'];\n        if (poolType === 'avg' && computePositions) {\n            throw new Error('Cannot compute positions for average pool.');\n        }\n        var filterWidth = convInfo.filterWidth;\n        var strideHeight = convInfo.strideHeight;\n        var strideWidth = convInfo.strideWidth;\n        var dilationHeight = convInfo.dilationHeight;\n        var dilationWidth = convInfo.dilationWidth;\n        var effectiveFilterHeight = convInfo.effectiveFilterHeight;\n        var effectiveFilterWidth = convInfo.effectiveFilterWidth;\n        var padTop = convInfo.padInfo.top;\n        var padLeft = convInfo.padInfo.left;\n        this.outputShape = convInfo.outShape;\n        var isAvgPool = poolType === 'avg';\n        var initializationValue = '0.0';\n        if (!isAvgPool) {\n            // WebGL on Firefox Linux can't compile 1/0 so we do 1/eps.\n            initializationValue = '-1.0 / 1e-20';\n        }\n        if (computePositions) {\n            var compareOp_1 = '>=';\n            this.userCode = \"\\n        const ivec2 strides = ivec2(\" + strideHeight + \", \" + strideWidth + \");\\n        const ivec2 pads = ivec2(\" + padTop + \", \" + padLeft + \");\\n\\n        void main() {\\n          ivec4 coords = getOutputCoords();\\n          int batch = coords[0];\\n          int d = coords[3];\\n\\n          ivec2 xRCCorner = coords.yz * strides - pads;\\n          int xRCorner = xRCCorner.x;\\n          int xCCorner = xRCCorner.y;\\n\\n          // max/min x(?, ?, d) to get y(yR, yC, d).\\n          // ? = to be determined\\n          float minMaxValue = 0.0;\\n          float minMaxValueFound = 0.0;\\n          int minMaxPosition = 0;\\n          float avgValue = 0.0;\\n\\n          for (int wR = 0; wR < \" + effectiveFilterHeight + \";\\n              wR += \" + dilationHeight + \") {\\n            int xR = xRCorner + wR;\\n\\n            if (xR < 0 || xR >= \" + convInfo.inHeight + \") {\\n              continue;\\n            }\\n\\n            for (int wC = 0; wC < \" + effectiveFilterWidth + \";\\n                wC += \" + dilationWidth + \") {\\n              int xC = xCCorner + wC;\\n\\n              if (xC < 0 || xC >= \" + convInfo.inWidth + \") {\\n                continue;\\n              }\\n\\n              float value = getX(batch, xR, xC, d);\\n\\n              // If a min / max value has already been found, use it. If not,\\n              // use the current value.\\n              float currMinMaxValue = mix(\\n                  value, minMaxValue, minMaxValueFound);\\n              if (value \" + compareOp_1 + \" currMinMaxValue) {\\n                minMaxValue = value;\\n                minMaxValueFound = 1.0;\\n                minMaxPosition = wR * \" + effectiveFilterWidth + \" + wC;\\n              }\\n            }\\n          }\\n          setOutput(float(minMaxPosition));\\n        }\\n      \";\n            return;\n        }\n        var compareOp = 'max';\n        var returnValue = poolType + \"(\" + poolType + \"(\" + poolType + \"(\" +\n            'minMaxValue[0], minMaxValue[1]), minMaxValue[2]), minMaxValue[3])';\n        if (poolType === 'avg') {\n            returnValue = \"avgValue / count\";\n        }\n        var filterWidthNearestVec4 = Math.floor(filterWidth / 4) * 4;\n        var filterWidthVec4Remainder = filterWidth % 4;\n        var updateSnippet = \"\\n      if (\" + isAvgPool + \") {\\n        avgValue += dot(values, ones);\\n      } else {\\n        minMaxValue = \" + compareOp + \"(values, minMaxValue);\\n      }\\n    \";\n        this.userCode = \"\\n      const ivec2 strides = ivec2(\" + strideHeight + \", \" + strideWidth + \");\\n      const ivec2 pads = ivec2(\" + padTop + \", \" + padLeft + \");\\n      const float initializationValue = \" + initializationValue + \";\\n      const vec4 ones = vec4(1.0, 1.0, 1.0, 1.0);\\n\\n      float count = 0.0;\\n\\n      float getValue(int batch, int xR, int xC, int d) {\\n        if (xC < 0 || xC >= \" + convInfo.inWidth + \") {\\n          return initializationValue;\\n        }\\n        count += 1.0;\\n        return getX(batch, xR, xC, d);\\n      }\\n\\n      void main() {\\n        ivec4 coords = getOutputCoords();\\n        int batch = coords[0];\\n        int d = coords[3];\\n\\n        ivec2 xRCCorner = coords.yz * strides - pads;\\n        int xRCorner = xRCCorner.x;\\n        int xCCorner = xRCCorner.y;\\n\\n        // max/min x(?, ?, d) to get y(yR, yC, d).\\n        // ? = to be determined\\n        vec4 minMaxValue = vec4(\" + initializationValue + \");\\n        float avgValue = 0.0;\\n        count = 0.0;\\n\\n        for (int wR = 0; wR < \" + effectiveFilterHeight + \";\\n            wR += \" + dilationHeight + \") {\\n          int xR = xRCorner + wR;\\n\\n          if (xR < 0 || xR >= \" + convInfo.inHeight + \") {\\n            continue;\\n          }\\n\\n          for (int wC = 0; wC < \" + filterWidthNearestVec4 + \"; wC += 4) {\\n            int xC = xCCorner + wC * \" + dilationWidth + \";\\n\\n            vec4 values = vec4(\\n              getValue(batch, xR, xC, d),\\n              getValue(batch, xR, xC + \" + dilationWidth + \", d),\\n              getValue(batch, xR, xC + 2 * \" + dilationWidth + \", d),\\n              getValue(batch, xR, xC + 3 * \" + dilationWidth + \", d)\\n            );\\n\\n            \" + updateSnippet + \"\\n          }\\n\\n          int xC = xCCorner + \" + filterWidthNearestVec4 + \";\\n          if (\" + (filterWidthVec4Remainder === 1) + \") {\\n            vec4 values = vec4(\\n              getValue(batch, xR, xC, d),\\n              initializationValue,\\n              initializationValue,\\n              initializationValue\\n            );\\n\\n            \" + updateSnippet + \"\\n          } else if (\" + (filterWidthVec4Remainder === 2) + \") {\\n            vec4 values = vec4(\\n              getValue(batch, xR, xC, d),\\n              getValue(batch, xR, xC + \" + dilationWidth + \", d),\\n              initializationValue,\\n              initializationValue\\n            );\\n\\n            \" + updateSnippet + \"\\n          } else if (\" + (filterWidthVec4Remainder === 3) + \") {\\n            vec4 values = vec4(\\n              getValue(batch, xR, xC, d),\\n              getValue(batch, xR, xC + \" + dilationWidth + \", d),\\n              getValue(batch, xR, xC + 2 * \" + dilationWidth + \", d),\\n              initializationValue\\n            );\\n\\n            \" + updateSnippet + \"\\n          }\\n        }\\n        setOutput(\" + returnValue + \");\\n      }\\n    \";\n    }\n    return Pool2DProgram;\n}());\nexports.Pool2DProgram = Pool2DProgram;\n//# sourceMappingURL=pool_gpu.js.map","\n/**\n * @license\n * Copyright 2017 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar ReduceProgram = /** @class */ (function () {\n    function ReduceProgram(reduceInfo, reduceType) {\n        this.variableNames = ['x'];\n        var windowSize = reduceInfo.windowSize;\n        var batchSize = reduceInfo.batchSize;\n        var inSize = reduceInfo.inSize;\n        var outSize = Math.ceil(inSize / windowSize);\n        this.outputShape = [batchSize, outSize];\n        var initializationValue = '0.0';\n        var compareOp = \"\";\n        if (reduceType === 'prod') {\n            initializationValue = '1.0';\n        }\n        else if (reduceType === 'min') {\n            // WebGL on Firefox Linux can't compile 1/0 so we do 1/eps.\n            initializationValue = '1.0 / 1e-20';\n            compareOp = \"min\";\n        }\n        else if (reduceType === 'max') {\n            // WebGL on Firefox Linux can't compile 1/0 so we do 1/eps.\n            initializationValue = '-1.0 / 1e-20';\n            compareOp = \"max\";\n        }\n        var returnValue = reduceType + \"(\" + reduceType + \"(\" + reduceType + \"(\" +\n            'minMaxValue[0], minMaxValue[1]), minMaxValue[2]), minMaxValue[3])';\n        if (reduceType === 'sum') {\n            returnValue = \"sumValue\";\n        }\n        else if (reduceType === 'prod') {\n            returnValue = \"prodValue\";\n        }\n        else if (reduceType === 'all') {\n            returnValue = \"allValue\";\n        }\n        else if (reduceType === 'any') {\n            returnValue = \"anyValue\";\n        }\n        var windowSizeNearestVec4 = Math.floor(windowSize / 4) * 4;\n        var windowSizeVec4Remainder = windowSize % 4;\n        var updateSnippet = \"\\n      if (\" + (reduceType === 'sum') + \") {\\n        sumValue += dot(values, ones);\\n      } else if (\" + (reduceType === 'prod') + \") {\\n        vec2 tmp = vec2(values[0], values[1]) * vec2(values[2], values[3]);\\n        prodValue *= tmp[0] * tmp[1];\\n      } else {\\n        minMaxValue = \" + compareOp + \"(values, minMaxValue);\\n      }\\n    \";\n        var vecType = \"vec4\";\n        if (reduceType === 'all') {\n            initializationValue = '1.0';\n            updateSnippet = \"\\n        bool reducedAllValue = all(values);\\n        float floatedReducedAllValue = float(reducedAllValue);\\n        allValue = float(allValue >= 1.0 && floatedReducedAllValue >= 1.0);\\n      \";\n            vecType = \"bvec4\";\n        }\n        else if (reduceType === 'any') {\n            initializationValue = '0.0';\n            updateSnippet = \"\\n        bool reducedAnyValue = any(values);\\n        float floatedReducedAnyValue = float(reducedAnyValue);\\n        anyValue = float(anyValue >= 1.0 || floatedReducedAnyValue >= 1.0);\\n      \";\n            vecType = \"bvec4\";\n        }\n        var checkOutOfBounds = '';\n        if (inSize % windowSize > 0) {\n            checkOutOfBounds = \"\\n        if (inIdx < 0 || inIdx >= \" + inSize + \") {\\n          return initializationValue;\\n        }\\n      \";\n        }\n        this.userCode = \"\\n      const float initializationValue = \" + initializationValue + \";\\n      const vec4 ones = vec4(1.0, 1.0, 1.0, 1.0);\\n\\n      float getValue(int batch, int inIdx) {\\n        \" + checkOutOfBounds + \"\\n        return getX(batch, inIdx);\\n      }\\n\\n      void main() {\\n        ivec2 coords = getOutputCoords();\\n        int batch = coords[0];\\n        int outIdx = coords[1];\\n        int inOffset = outIdx * \" + windowSize + \";\\n\\n        vec4 minMaxValue = vec4(\" + initializationValue + \");\\n        float prodValue = 1.0;\\n        float sumValue = 0.0;\\n        float allValue = 1.0;\\n        float anyValue = 0.0;\\n\\n        for (int i = 0; i < \" + windowSizeNearestVec4 + \"; i += 4) {\\n          int inIdx = inOffset + i;\\n          \" + vecType + \" values = \" + vecType + \"(\\n            getValue(batch, inIdx),\\n            getValue(batch, inIdx + 1),\\n            getValue(batch, inIdx + 2),\\n            getValue(batch, inIdx + 3)\\n          );\\n\\n          \" + updateSnippet + \"\\n        }\\n\\n        int inIdx = inOffset + \" + windowSizeNearestVec4 + \";\\n        if (\" + (windowSizeVec4Remainder === 1) + \") {\\n          \" + vecType + \" values = \" + vecType + \"(\\n            getValue(batch, inIdx),\\n            initializationValue,\\n            initializationValue,\\n            initializationValue\\n          );\\n\\n          \" + updateSnippet + \"\\n        } else if (\" + (windowSizeVec4Remainder === 2) + \") {\\n          \" + vecType + \" values = \" + vecType + \"(\\n            getValue(batch, inIdx),\\n            getValue(batch, inIdx + 1),\\n            initializationValue,\\n            initializationValue\\n          );\\n\\n          \" + updateSnippet + \"\\n        } else if (\" + (windowSizeVec4Remainder === 3) + \") {\\n          \" + vecType + \" values = \" + vecType + \"(\\n            getValue(batch, inIdx),\\n            getValue(batch, inIdx + 1),\\n            getValue(batch, inIdx + 2),\\n            initializationValue\\n          );\\n\\n          \" + updateSnippet + \"\\n        }\\n        setOutput(\" + returnValue + \");\\n      }\\n    \";\n    }\n    return ReduceProgram;\n}());\nexports.ReduceProgram = ReduceProgram;\n//# sourceMappingURL=reduce_gpu.js.map","\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar util = require(\"../../util\");\nvar shader_util = require(\"./shader_compiler_util\");\nvar ReshapePackedProgram = /** @class */ (function () {\n    function ReshapePackedProgram(outputShape, inputShape) {\n        this.variableNames = ['A'];\n        this.usesPackedTextures = true;\n        this.outputShape = outputShape;\n        var mainLoop = \"\";\n        for (var i = 0; i < 4; i++) {\n            var thisRC = \"thisRC = rc;\";\n            if (i % 2 === 1) {\n                thisRC += \"thisRC.z += 1;\";\n            }\n            if (i > 1) {\n                thisRC += \"thisRC.y += 1;\";\n            }\n            mainLoop += \"\\n        \" + thisRC + \"\\n        \" + (i > 0 ? \"if(thisRC.y < rows && thisRC.z < cols){\" : '') + \"\\n          int flatIndex = getFlatIndex(thisRC);\\n\\n          ivec3 inputRC = inputCoordsFromReshapedOutCoords(flatIndex);\\n          vec2 inputRCInnerDims = vec2(float(inputRC.y),float(inputRC.z));\\n\\n          result[\" + i + \"] =\\n            getChannel(getA(inputRC.x, inputRC.y, inputRC.z), inputRCInnerDims);\\n        \" + (i > 0 ? '}' : '') + \"\\n      \";\n        }\n        this.userCode = \"\\n      \" + getReshapedInputCoords(inputShape) + \"\\n      \" + getFlatIndex(outputShape) + \"\\n\\n      void main() {\\n        ivec3 rc = getOutputCoords();\\n\\n        vec4 result = vec4(0.);\\n\\n        ivec3 thisRC;\\n        int rows = \" + outputShape[1] + \";\\n        int cols = \" + outputShape[2] + \";\\n\\n        \" + mainLoop + \"\\n\\n        setOutput(result);\\n      }\\n    \";\n    }\n    return ReshapePackedProgram;\n}());\nexports.ReshapePackedProgram = ReshapePackedProgram;\nfunction getFlatIndex(shape) {\n    var dotCoordsWithStrides = shader_util.dotify(['coords.x', 'coords.y', 'coords.z'], util.computeStrides(shape).map(function (d) { return d.toString(); }).concat(['1.']));\n    return \"\\n    int getFlatIndex(ivec3 coords) {\\n      return round(\" + dotCoordsWithStrides + \");\\n    }\\n  \";\n}\nfunction getReshapedInputCoords(shape) {\n    var coordsFromIndexSnippet = shader_util.getLogicalCoordinatesFromFlatIndex(['r', 'c', 'd'], shape);\n    return \"\\n    ivec3 inputCoordsFromReshapedOutCoords(int index) {\\n      \" + coordsFromIndexSnippet + \"\\n      return ivec3(r, c, d);\\n    }\\n  \";\n}\n//# sourceMappingURL=reshape_packed_gpu.js.map","\n/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar ResizeBilinearBackpropProgram = /** @class */ (function () {\n    function ResizeBilinearBackpropProgram(dy, x, alignCorners) {\n        this.variableNames = ['dy'];\n        this.outputShape = [];\n        this.outputShape = x.shape;\n        var _a = x.shape, xHeight = _a[1], xWidth = _a[2];\n        var _b = dy.shape, yHeight = _b[1], yWidth = _b[2];\n        // In the backwards pass, we want to find the pixels that were generated for\n        // each pixel in the input image the forward pass and add the corresponding\n        // coefficient from dy to the gradient (with some interpolation).\n        var effectiveXSize = [\n            (alignCorners && yHeight > 1) ? xHeight - 1 : xHeight,\n            (alignCorners && yWidth > 1) ? xWidth - 1 : xWidth\n        ];\n        var effectiveYSize = [\n            (alignCorners && yHeight > 1) ? yHeight - 1 : yHeight,\n            (alignCorners && yWidth > 1) ? yWidth - 1 : yWidth\n        ];\n        var heightScale = effectiveXSize[0] / effectiveYSize[0];\n        var widthScale = effectiveXSize[1] / effectiveYSize[1];\n        var invHeightScale = 1 / heightScale;\n        var invWidthScale = 1 / widthScale;\n        // This defines the size of the window of values around a particular\n        // index in dy that we want to search for contributions to dx.\n        var winHeight = (Math.ceil(invHeightScale) * 2) + 2;\n        var winWidth = (Math.ceil(invWidthScale) * 2) + 2;\n        this.userCode = \"\\n      void main() {\\n        ivec4 coords = getOutputCoords();\\n        int b = coords[0];\\n        int d = coords[3];\\n        int r = coords[1];\\n        int c = coords[2];\\n\\n        float accumulator = 0.0;\\n\\n        const float heightScale = float(\" + heightScale + \");\\n        const float widthScale = float(\" + widthScale + \");\\n\\n        const float invHeightScale = float(\" + invHeightScale + \");\\n        const float invWidthScale = float(\" + invWidthScale + \");\\n\\n        const int winHeight = int(\" + winHeight + \");\\n        const int winWidth = int(\" + winWidth + \");\\n\\n        // Compute bounds for where in dy we will look\\n        float startRLerp = floor(float(r) * invHeightScale);\\n        int startDyR = int(startRLerp - float(winHeight / 2));\\n\\n        float startCLerp = floor(float(c) * invWidthScale);\\n        int startDyC = int(startCLerp - float(winWidth / 2));\\n\\n        // Loop over dy\\n        for (int dyROffset = 0; dyROffset < winHeight; dyROffset++) {\\n          int dyR = dyROffset + startDyR;\\n\\n          // Guard against the window exceeding the bounds of dy\\n          if (dyR < 0 || dyR >= \" + yHeight + \") {\\n            continue;\\n          }\\n\\n          for (int dyCOffset = 0; dyCOffset < winWidth; dyCOffset++) {\\n            int dyC = dyCOffset + startDyC;\\n\\n            // Guard against the window exceeding the bounds of dy\\n            if (dyC < 0 || dyC >= \" + yWidth + \") {\\n              continue;\\n            }\\n\\n            float dxR = float(dyR) * heightScale;\\n            int topDxRIndex = int(floor(dxR));\\n            int bottomDxRIndex = int(min(ceil(dxR), \" + (xHeight - 1) + \".0));\\n            float dxRLerp = dxR - float(topDxRIndex);\\n            float inverseDxRLerp = 1.0 - dxRLerp;\\n\\n            float dxC = float(dyC) * widthScale;\\n            int leftDxCIndex = int(floor(dxC));\\n            int rightDxCIndex = int(min(ceil(dxC), \" + (xWidth - 1) + \".0));\\n            float dxCLerp = dxC - float(leftDxCIndex);\\n            float inverseDxCLerp = 1.0 - dxCLerp;\\n\\n            if (r == topDxRIndex && c == leftDxCIndex) {\\n              // topLeft\\n              accumulator +=\\n                getDy(b, dyR, dyC, d) * inverseDxRLerp * inverseDxCLerp;\\n            }\\n\\n            if (r == topDxRIndex && c == rightDxCIndex) {\\n              // topRight\\n              accumulator += getDy(b, dyR, dyC, d) * inverseDxRLerp * dxCLerp;\\n            }\\n\\n            if (r == bottomDxRIndex && c == leftDxCIndex) {\\n              // bottomLeft\\n              accumulator += getDy(b, dyR, dyC, d) * dxRLerp * inverseDxCLerp;\\n            }\\n\\n            if (r == bottomDxRIndex && c == rightDxCIndex) {\\n              // bottomRight\\n              accumulator += getDy(b, dyR, dyC, d) * dxRLerp * dxCLerp;\\n            }\\n          }\\n        }\\n        // End loop over dy\\n\\n        setOutput(accumulator);\\n      }\\n    \";\n    }\n    return ResizeBilinearBackpropProgram;\n}());\nexports.ResizeBilinearBackpropProgram = ResizeBilinearBackpropProgram;\n//# sourceMappingURL=resize_bilinear_backprop_gpu.js.map","\n/**\n * @license\n * Copyright 2017 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar ResizeBilinearProgram = /** @class */ (function () {\n    function ResizeBilinearProgram(inputShape, newHeight, newWidth, alignCorners) {\n        this.variableNames = ['A'];\n        this.outputShape = [];\n        var batch = inputShape[0], oldHeight = inputShape[1], oldWidth = inputShape[2], depth = inputShape[3];\n        this.outputShape = [batch, newHeight, newWidth, depth];\n        var effectiveInSize = [\n            (alignCorners && newHeight > 1) ? oldHeight - 1 : oldHeight,\n            (alignCorners && newWidth > 1) ? oldWidth - 1 : oldWidth\n        ];\n        var effectiveOutSize = [\n            (alignCorners && newHeight > 1) ? newHeight - 1 : newHeight,\n            (alignCorners && newWidth > 1) ? newWidth - 1 : newWidth\n        ];\n        this.userCode = \"\\n      const vec2 effectiveInputOverOutputRatioRC = vec2(\\n          \" + effectiveInSize[0] / effectiveOutSize[0] + \",\\n          \" + effectiveInSize[1] / effectiveOutSize[1] + \");\\n      const vec2 inputShapeRC = vec2(\" + oldHeight + \".0, \" + oldWidth + \".0);\\n\\n      void main() {\\n        ivec4 coords = getOutputCoords();\\n        int b = coords[0];\\n        int d = coords[3];\\n        ivec2 yRC = coords.yz;\\n\\n        // Fractional source index.\\n        vec2 sourceFracIndexRC = vec2(yRC) * effectiveInputOverOutputRatioRC;\\n\\n        // Compute the four integer indices.\\n        ivec2 sourceFloorRC = ivec2(sourceFracIndexRC);\\n        ivec2 sourceCeilRC = ivec2(\\n          min(inputShapeRC - 1.0, ceil(sourceFracIndexRC)));\\n\\n        float topLeft = getA(b, sourceFloorRC.x, sourceFloorRC.y, d);\\n        float bottomLeft = getA(b, sourceCeilRC.x, sourceFloorRC.y, d);\\n        float topRight = getA(b, sourceFloorRC.x, sourceCeilRC.y, d);\\n        float bottomRight = getA(b, sourceCeilRC.x, sourceCeilRC.y, d);\\n\\n        vec2 fracRC = sourceFracIndexRC - vec2(sourceFloorRC);\\n\\n        float top = topLeft + (topRight - topLeft) * fracRC.y;\\n        float bottom = bottomLeft + (bottomRight - bottomLeft) * fracRC.y;\\n        float newValue = top + (bottom - top) * fracRC.x;\\n\\n        setOutput(newValue);\\n      }\\n    \";\n    }\n    return ResizeBilinearProgram;\n}());\nexports.ResizeBilinearProgram = ResizeBilinearProgram;\n//# sourceMappingURL=resize_bilinear_gpu.js.map","\n/**\n * @license\n * Copyright 2019 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar ResizeBilinearPackedProgram = /** @class */ (function () {\n    function ResizeBilinearPackedProgram(inputShape, newHeight, newWidth, alignCorners) {\n        this.variableNames = ['A'];\n        this.usesPackedTextures = true;\n        this.outputShape = [];\n        var batch = inputShape[0], oldHeight = inputShape[1], oldWidth = inputShape[2], depth = inputShape[3];\n        this.outputShape = [batch, newHeight, newWidth, depth];\n        var effectiveInSize = [\n            (alignCorners && newHeight > 1) ? oldHeight - 1 : oldHeight,\n            (alignCorners && newWidth > 1) ? oldWidth - 1 : oldWidth\n        ];\n        var effectiveOutSize = [\n            (alignCorners && newHeight > 1) ? newHeight - 1 : newHeight,\n            (alignCorners && newWidth > 1) ? newWidth - 1 : newWidth\n        ];\n        this.userCode = \"\\n      const vec3 effectiveInputOverOutputRatioRC = vec3(\\n          \" + effectiveInSize[0] / effectiveOutSize[0] + \",\\n          \" + effectiveInSize[1] / effectiveOutSize[1] + \",\\n          \" + effectiveInSize[1] / effectiveOutSize[1] + \");\\n      const vec3 inputShapeRC = vec3(\" + oldHeight + \".0, \" + oldWidth + \".0,\\n                                     \" + oldWidth + \".0);\\n\\n      float getAValue(int b, int r, int c, int d) {\\n        return getChannel(getA(b, r, c, d), vec2(c, d));\\n      }\\n\\n      void main() {\\n        ivec4 coords = getOutputCoords();\\n        int b = coords[0];\\n        int d = coords[3];\\n        // Calculate values for next column in yRC.z.\\n        ivec3 yRC = coords.yzz + ivec3(0, 0, 1);\\n\\n        // Fractional source index.\\n        vec3 sourceFracIndexRC = vec3(yRC) * effectiveInputOverOutputRatioRC;\\n\\n        // Compute the four integer indices.\\n        ivec3 sourceFloorRC = ivec3(sourceFracIndexRC);\\n        ivec3 sourceCeilRC = ivec3(\\n          min(inputShapeRC - 1.0, ceil(sourceFracIndexRC)));\\n        \\n        // Should we calculate next column and row elements in 2x2 packed cell.\\n        bool hasNextCol = d < \" + (depth - 1) + \"; \\n        bool hasNextRow = coords.z < \" + (newWidth - 1) + \";\\n\\n        // In parallel, construct four corners for all four components in\\n        // packed 2x2 cell.\\n        vec4 topLeft = vec4(\\n          getAValue(b, sourceFloorRC.x, sourceFloorRC.y, d),\\n          hasNextCol ? getAValue(b, sourceFloorRC.x, sourceFloorRC.y, d + 1)\\n                     : 0.0,\\n          hasNextRow ? getAValue(b, sourceFloorRC.x, sourceFloorRC.z, d)\\n                     : 0.0,\\n          (hasNextRow && hasNextCol) ?\\n            getAValue(b, sourceFloorRC.x, sourceFloorRC.z, d + 1) : 0.0);\\n\\n        vec4 bottomLeft = vec4(\\n          getAValue(b, sourceCeilRC.x, sourceFloorRC.y, d),\\n          hasNextCol ? getAValue(b, sourceCeilRC.x, sourceFloorRC.y, d + 1)\\n                     : 0.0,\\n          hasNextRow ? getAValue(b, sourceCeilRC.x, sourceFloorRC.z, d)\\n                     : 0.0,\\n          (hasNextRow && hasNextCol) ?\\n            getAValue(b, sourceCeilRC.x, sourceFloorRC.z, d + 1) : 0.0);\\n\\n        vec4 topRight = vec4(\\n          getAValue(b, sourceFloorRC.x, sourceCeilRC.y, d),\\n          hasNextCol ? getAValue(b, sourceFloorRC.x, sourceCeilRC.y, d + 1)\\n                     : 0.0,\\n          hasNextRow ? getAValue(b, sourceFloorRC.x, sourceCeilRC.z, d)\\n                     : 0.0,\\n          (hasNextRow && hasNextCol) ?\\n            getAValue(b, sourceFloorRC.x, sourceCeilRC.z, d + 1) : 0.0);\\n\\n        vec4 bottomRight = vec4(\\n          getAValue(b, sourceCeilRC.x, sourceCeilRC.y, d),\\n          hasNextCol ? getAValue(b, sourceCeilRC.x, sourceCeilRC.y, d + 1)\\n                     : 0.0,\\n          hasNextRow ? getAValue(b, sourceCeilRC.x, sourceCeilRC.z, d)\\n                     : 0.0,\\n          (hasNextRow && hasNextCol) ?\\n            getAValue(b, sourceCeilRC.x, sourceCeilRC.z, d + 1) : 0.0);\\n\\n        vec3 fracRC = sourceFracIndexRC - vec3(sourceFloorRC);\\n\\n        vec4 top = mix(topLeft, topRight, fracRC.yyzz);\\n        vec4 bottom = mix(bottomLeft, bottomRight, fracRC.yyzz);\\n        vec4 newValue = mix(top, bottom, fracRC.x);\\n\\n        setOutput(newValue);\\n      }\\n    \";\n    }\n    return ResizeBilinearPackedProgram;\n}());\nexports.ResizeBilinearPackedProgram = ResizeBilinearPackedProgram;\n//# sourceMappingURL=resize_bilinear_packed_gpu.js.map","\n/**\n * @license\n * Copyright 2018 Google LLC All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar ResizeNearestNeigborBackpropProgram = /** @class */ (function () {\n    function ResizeNearestNeigborBackpropProgram(dy, x, alignCorners) {\n        this.variableNames = ['dy'];\n        this.outputShape = [];\n        this.outputShape = x.shape;\n        var _a = x.shape, xHeight = _a[1], xWidth = _a[2];\n        var _b = dy.shape, yHeight = _b[1], yWidth = _b[2];\n        // In the backwards pass, we want to find the pixels that were generated for\n        // each pixel in the input image the forward pass and add the corresponding\n        // coefficient from dy to the gradient (with some interpolation).\n        var effectiveXSize = [\n            (alignCorners && yHeight > 1) ? xHeight - 1 : xHeight,\n            (alignCorners && yWidth > 1) ? xWidth - 1 : xWidth\n        ];\n        var effectiveYSize = [\n            (alignCorners && yHeight > 1) ? yHeight - 1 : yHeight,\n            (alignCorners && yWidth > 1) ? yWidth - 1 : yWidth\n        ];\n        var heightScale = effectiveXSize[0] / effectiveYSize[0];\n        var widthScale = effectiveXSize[1] / effectiveYSize[1];\n        var invHeightScale = 1 / heightScale;\n        var invWidthScale = 1 / widthScale;\n        // This defines the size of the window of values around a particular\n        // index in dy that we want to search for contributions to dx.\n        var winHeight = (Math.ceil(invHeightScale) * 2) + 2;\n        var winWidth = (Math.ceil(invWidthScale) * 2) + 2;\n        this.userCode = \"\\n      void main() {\\n        ivec4 coords = getOutputCoords();\\n        int b = coords[0];\\n        int d = coords[3];\\n        int r = coords[1];\\n        int c = coords[2];\\n\\n        float accumulator = 0.0;\\n\\n        const float heightScale = float(\" + heightScale + \");\\n        const float widthScale = float(\" + widthScale + \");\\n\\n        const float invHeightScale = float(\" + invHeightScale + \");\\n        const float invWidthScale = float(\" + invWidthScale + \");\\n\\n        const int winHeight = int(\" + winHeight + \");\\n        const int winWidth = int(\" + winWidth + \");\\n\\n        // Compute bounds for where in dy we will look\\n        float startRLerp = floor(float(r) * invHeightScale);\\n        int startDyR = int(floor(startRLerp - float(winHeight / 2)));\\n\\n        float startCLerp = floor(float(c) * invWidthScale);\\n        int startDyC = int(floor(startCLerp - float(winWidth / 2)));\\n\\n        // Loop over dy\\n        for (int dyROffset = 0; dyROffset < winHeight; dyROffset++) {\\n          int dyR = dyROffset + startDyR;\\n\\n          // Guard against the window exceeding the bounds of dy\\n          if (dyR < 0 || dyR >= \" + yHeight + \") {\\n            continue;\\n          }\\n\\n          for (int dyCOffset = 0; dyCOffset < winWidth; dyCOffset++) {\\n            int dyC = dyCOffset + startDyC;\\n\\n            // Guard against the window exceeding the bounds of dy\\n            if (dyC < 0 || dyC >= \" + yWidth + \") {\\n              continue;\\n            }\\n\\n            float sourceFracRow =\\n              float(\" + effectiveXSize[0] + \") *\\n                (float(dyR) / float(\" + effectiveYSize[0] + \"));\\n\\n            float sourceFracCol =\\n                float(\" + effectiveXSize[1] + \") *\\n                  (float(dyC) / float(\" + effectiveYSize[1] + \"));\\n\\n            int sourceNearestRow = int(min(\\n                float(int(\" + xHeight + \") - 1),\\n                \" + alignCorners + \" ? float(round(sourceFracRow)) :\\n                                  float(floor(sourceFracRow))));\\n\\n            int sourceNearestCol = int(min(\\n                float(int(\" + xWidth + \") - 1),\\n                \" + alignCorners + \" ? float(round(sourceFracCol)) :\\n                                  float(floor(sourceFracCol))));\\n\\n            if (r == sourceNearestRow && c == sourceNearestCol) {\\n              accumulator += getDy(b, dyR, dyC, d);\\n            }\\n          }\\n        }\\n        // End loop over dy\\n\\n        setOutput(accumulator);\\n      }\\n    \";\n    }\n    return ResizeNearestNeigborBackpropProgram;\n}());\nexports.ResizeNearestNeigborBackpropProgram = ResizeNearestNeigborBackpropProgram;\n//# sourceMappingURL=resize_nearest_neighbor_backprop_gpu.js.map","\n/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar ResizeNearestNeighborProgram = /** @class */ (function () {\n    function ResizeNearestNeighborProgram(inputShape, newHeight, newWidth, alignCorners) {\n        this.variableNames = ['A'];\n        this.outputShape = [];\n        var batch = inputShape[0], oldHeight = inputShape[1], oldWidth = inputShape[2], depth = inputShape[3];\n        this.outputShape = [batch, newHeight, newWidth, depth];\n        var effectiveInSize = [\n            (alignCorners && newHeight > 1) ? oldHeight - 1 : oldHeight,\n            (alignCorners && newWidth > 1) ? oldWidth - 1 : oldWidth\n        ];\n        var effectiveOutSize = [\n            (alignCorners && newHeight > 1) ? newHeight - 1 : newHeight,\n            (alignCorners && newWidth > 1) ? newWidth - 1 : newWidth\n        ];\n        // When align corners is false, we rounds the value with floor.\n        var roundBase = alignCorners ? '0.5' : '0.0';\n        this.userCode = \"\\n      const vec2 effectiveInputOverOutputRatioRC = vec2(\\n          \" + effectiveInSize[0] / effectiveOutSize[0] + \",\\n          \" + effectiveInSize[1] / effectiveOutSize[1] + \");\\n      const vec2 inputShapeRC = vec2(\" + oldHeight + \".0, \" + oldWidth + \".0);\\n\\n      void main() {\\n        ivec4 coords = getOutputCoords();\\n        int b = coords[0];\\n        int d = coords[3];\\n        ivec2 yRC = coords.yz;\\n\\n        // Fractional source index.\\n        vec2 sourceFracIndexRC = vec2(yRC) * effectiveInputOverOutputRatioRC;\\n\\n        // Compute the coordinators of nearest neighbor point.\\n        ivec2 sourceNearestRC = ivec2(\\n          min(inputShapeRC - 1.0, floor(sourceFracIndexRC + \" + roundBase + \")));\\n\\n        float newValue = getA(b, sourceNearestRC.x, sourceNearestRC.y, d);\\n\\n        setOutput(newValue);\\n      }\\n    \";\n    }\n    return ResizeNearestNeighborProgram;\n}());\nexports.ResizeNearestNeighborProgram = ResizeNearestNeighborProgram;\n//# sourceMappingURL=resize_nearest_neighbor_gpu.js.map","\n/**\n * @license\n * Copyright 2017 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar shader_compiler_1 = require(\"./shader_compiler\");\nvar ReverseProgram = /** @class */ (function () {\n    function ReverseProgram(xShape, axis) {\n        this.variableNames = ['x'];\n        var rank = xShape.length;\n        if (rank > 4) {\n            throw new Error(\"WebGL backend: Reverse of rank-\" + rank + \" tensor is not yet supported\");\n        }\n        this.outputShape = xShape;\n        if (rank === 1) {\n            this.userCode = \"\\n        void main() {\\n          int coord = getOutputCoords();\\n          setOutput(getX(\" + xShape[0] + \" - coord - 1));\\n        }\\n      \";\n            return;\n        }\n        var getInCoord = function (i) {\n            if (axis.indexOf(i) !== -1 && xShape[i] !== 1) {\n                return xShape[i] + \" - coords[\" + i + \"] - 1\";\n            }\n            return \"coords[\" + i + \"]\";\n        };\n        var inCoords = xShape.map(function (_, i) { return getInCoord(i); }).join(',');\n        var type = shader_compiler_1.getCoordsDataType(rank);\n        this.userCode = \"\\n      void main() {\\n        \" + type + \" coords = getOutputCoords();\\n        setOutput(getX(\" + inCoords + \"));\\n      }\\n    \";\n    }\n    return ReverseProgram;\n}());\nexports.ReverseProgram = ReverseProgram;\n//# sourceMappingURL=reverse_gpu.js.map","\n/**\n * @license\n * Copyright 2019 Google LLC All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar packing_util_1 = require(\"../packing_util\");\nvar shader_compiler_1 = require(\"./shader_compiler\");\nvar ReversePackedProgram = /** @class */ (function () {\n    function ReversePackedProgram(xShape, axis) {\n        this.variableNames = ['x'];\n        this.usesPackedTextures = true;\n        var rank = xShape.length;\n        if (rank > 4) {\n            throw new Error(\"WebGL backend: Reverse of rank-\" + rank + \" tensor is not yet supported\");\n        }\n        this.outputShape = xShape;\n        var channels = packing_util_1.getChannels('rc', rank);\n        var nextColumn = channels[rank - 1] + \" + 1 < \" + this.outputShape[rank - 1];\n        var nextRow = channels[rank - 2] + \" + 1 < \" + this.outputShape[rank - 2];\n        var type = shader_compiler_1.getCoordsDataType(rank);\n        if (rank === 1) {\n            this.userCode = \"\\n        void main(){\\n          int rc = getOutputCoords();\\n          vec4 result = vec4(0.);\\n          result.r = getChannel(getX(\" + xShape[0] + \" - rc - 1),\\n            \" + xShape[0] + \" - rc - 1);\\n          if(\" + nextColumn + \"){\\n              result.g = getChannel(getX(\" + xShape[0] + \" - (rc  + 1) - 1),\\n                \" + xShape[0] + \" - (rc  + 1) - 1);\\n          }\\n          setOutput(result);\\n        }\\n      \";\n        }\n        else {\n            this.userCode = \"\\n        void main() {\\n          \" + type + \" rc = getOutputCoords();\\n          vec4 result = vec4(0.);\\n          result.r = \" + getR(channels.slice()) + \";\\n          if(\" + nextColumn + \"){\\n            result.g = \" + getG(channels.slice()) + \";\\n          }\\n          if(\" + nextRow + \") {\\n            result.b = \" + getB(channels.slice()) + \";\\n            if(\" + nextColumn + \") {\\n              result.a = \" + getA(channels.slice()) + \";\\n            }\\n          }\\n          setOutput(result);\\n        }\\n    \";\n        }\n        function getR(channels) {\n            return getChannel(channels);\n        }\n        function getG(channels) {\n            channels[rank - 1] = '(' + channels[rank - 1] + \" + 1)\";\n            return getChannel(channels);\n        }\n        function getB(channels) {\n            channels[rank - 2] = '(' + channels[rank - 2] + \" + 1)\";\n            return getChannel(channels);\n        }\n        function getA(channels) {\n            channels[rank - 1] = '(' + channels[rank - 1] + \" + 1)\";\n            channels[rank - 2] = '(' + channels[rank - 2] + \" + 1)\";\n            return getChannel(channels);\n        }\n        function getChannel(channels) {\n            var inCoordsArray = xShape.map(function (_, i) { return getInCoord(i, channels); });\n            var inCoords = inCoordsArray.join(',');\n            var innerDims = inCoordsArray.slice(-2).join(',');\n            return \"getChannel(getX(\" + inCoords + \"), vec2(\" + innerDims + \"))\";\n        }\n        function getInCoord(i, channels1) {\n            if (axis.indexOf(i) !== -1 && xShape[i] !== 1) {\n                return xShape[i] + \" - \" + channels1[i] + \" - 1\";\n            }\n            else {\n                return \"\" + channels1[i];\n            }\n        }\n    }\n    return ReversePackedProgram;\n}());\nexports.ReversePackedProgram = ReversePackedProgram;\n//# sourceMappingURL=reverse_packed_gpu.js.map","\n/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar shader_compiler_1 = require(\"./shader_compiler\");\nvar ScatterProgram = /** @class */ (function () {\n    function ScatterProgram(updateSize, sliceDim, indicesRank, updatesRank, strides, shape, summingDupeIndex) {\n        if (summingDupeIndex === void 0) { summingDupeIndex = true; }\n        this.variableNames = ['updates', 'indices', 'defaultValue'];\n        this.outputShape = shape;\n        var stridesType = shader_compiler_1.getCoordsDataType(strides.length);\n        var dtype = shader_compiler_1.getCoordsDataType(shape.length);\n        var indicesString = '';\n        if (indicesRank === 1) {\n            indicesString = 'i';\n        }\n        else if (indicesRank === 2) {\n            indicesString = 'i, j';\n        }\n        var indicesSnippet = \"getIndices(\" + indicesString + \")\";\n        var updatesString = '';\n        if (updatesRank === 1) {\n            updatesString = 'i';\n        }\n        else if (updatesRank === 2) {\n            updatesString = 'i, coords[1]';\n        }\n        var updatesSnippet = \"getUpdates(\" + updatesString + \")\";\n        var strideString = sliceDim > 1 ? 'strides[j]' : 'strides';\n        this.userCode = \"\\n        \" + stridesType + \" strides = \" + stridesType + \"(\" + strides + \");\\n\\n        void main() {\\n          \" + dtype + \" coords = getOutputCoords();\\n          float sum = 0.0;\\n          bool found = false;\\n          for (int i = 0; i < \" + updateSize + \"; i++) {\\n            int flattenedIndex = 0;\\n            for (int j = 0; j < \" + sliceDim + \"; j++) {\\n              int index = round(\" + indicesSnippet + \");\\n              flattenedIndex += index * \" + strideString + \";\\n            }\\n            if (flattenedIndex == coords[0]) {\\n              sum += \" + updatesSnippet + \";\\n              found = true;\\n            }\\n          }\\n          setOutput(mix(getDefaultValue(), sum, float(found)));\\n        }\\n      \";\n    }\n    return ScatterProgram;\n}());\nexports.ScatterProgram = ScatterProgram;\n//# sourceMappingURL=scatter_gpu.js.map","\n/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar SegmentOpProgram = /** @class */ (function () {\n    function SegmentOpProgram(segOpInfo, segOpType) {\n        this.variableNames = ['x', 'segmentIds'];\n        var windowSize = segOpInfo.windowSize;\n        var batchSize = segOpInfo.batchSize;\n        var inSize = segOpInfo.inSize;\n        var numSegments = segOpInfo.numSegments;\n        var outSize = numSegments * Math.ceil(inSize / windowSize);\n        this.outputShape = [batchSize, outSize];\n        var initializationValue = '0.0';\n        var returnValue = \"sumValue\";\n        var windowSizeNearestVec4 = Math.floor(windowSize / 4) * 4;\n        var windowSizeVec4Remainder = windowSize % 4;\n        var updateSnippet = \"\\n        sumValue += dot(values, segFilter);\\n    \";\n        var checkValueOutOfBounds = '';\n        if (inSize % windowSize > 0) {\n            checkValueOutOfBounds = \"\\n        if (inIdx < 0 || inIdx >= \" + inSize + \") {\\n          return initializationValue;\\n        }\\n      \";\n        }\n        var checkSegmentIdOutOfBounds = '';\n        if (inSize % windowSize > 0) {\n            checkSegmentIdOutOfBounds = \"\\n        if (inIdx < 0 || inIdx >= \" + inSize + \") {\\n          return -1.0;\\n        }\\n      \";\n        }\n        this.userCode = \"\\n      const float initializationValue = \" + initializationValue + \";\\n\\n      float getValue(int batch, int inIdx) {\\n        \" + checkValueOutOfBounds + \"\\n        return getX(batch, inIdx);\\n      }\\n\\n      float getSegmentIdAtIndex(int inIdx) {\\n        \" + checkSegmentIdOutOfBounds + \"\\n        return getSegmentIds(inIdx);\\n      }\\n\\n      void main() {\\n        ivec2 coords = getOutputCoords();\\n        int batch = coords[0];\\n        int outIdx = coords[1];\\n        int inOffset = int(floor(float(outIdx) / float(\\n          \" + numSegments + \")) * float(\" + windowSize + \"));\\n        int currentSeg = int(mod(float(outIdx), float(\" + numSegments + \")));\\n\\n        float sumValue = 0.0;\\n\\n        for (int i = 0; i < \" + windowSizeNearestVec4 + \"; i += 4) {\\n          int inIdx = inOffset + i;\\n          vec4 values = vec4(\\n            getValue(batch, inIdx),\\n            getValue(batch, inIdx + 1),\\n            getValue(batch, inIdx + 2),\\n            getValue(batch, inIdx + 3)\\n          );\\n\\n          vec4 segFilter = vec4(\\n            int(getSegmentIdAtIndex(inIdx)) == currentSeg ? 1 : 0,\\n            int(getSegmentIdAtIndex(inIdx + 1)) == currentSeg ? 1 : 0,\\n            int(getSegmentIdAtIndex(inIdx + 2)) == currentSeg ? 1 : 0,\\n            int(getSegmentIdAtIndex(inIdx + 3)) == currentSeg ? 1 : 0\\n          );\\n\\n          \" + updateSnippet + \"\\n        }\\n\\n        int inIdx = inOffset + \" + windowSizeNearestVec4 + \";\\n        if (\" + (windowSizeVec4Remainder === 1) + \") {\\n          vec4 values = vec4(\\n            getValue(batch, inIdx),\\n            initializationValue,\\n            initializationValue,\\n            initializationValue\\n          );\\n\\n          int inIdxSeg = int(getSegmentIdAtIndex(inIdx));\\n\\n          vec4 segFilter = vec4(\\n            int(getSegmentIdAtIndex(inIdx)) == currentSeg ? 1 : 0,\\n            0,\\n            0,\\n            0\\n          );\\n\\n          \" + updateSnippet + \"\\n        } else if (\" + (windowSizeVec4Remainder === 2) + \") {\\n          vec4 values = vec4(\\n            getValue(batch, inIdx),\\n            getValue(batch, inIdx + 1),\\n            initializationValue,\\n            initializationValue\\n          );\\n\\n          vec4 segFilter = vec4(\\n            int(getSegmentIdAtIndex(inIdx)) == currentSeg ? 1 : 0,\\n            int(getSegmentIdAtIndex(inIdx + 1)) == currentSeg ? 1 : 0,\\n              0,\\n              0\\n          );\\n\\n          \" + updateSnippet + \"\\n        } else if (\" + (windowSizeVec4Remainder === 3) + \") {\\n          vec4 values = vec4(\\n            getValue(batch, inIdx),\\n            getValue(batch, inIdx + 1),\\n            getValue(batch, inIdx + 2),\\n            initializationValue\\n          );\\n\\n          vec4 segFilter = vec4(\\n            int(getSegmentIdAtIndex(inIdx)) == currentSeg ? 1 : 0,\\n            int(getSegmentIdAtIndex(inIdx + 1)) == currentSeg ? 1 : 0,\\n            int(getSegmentIdAtIndex(inIdx + 2)) == currentSeg ? 1 : 0,\\n            0\\n          );\\n\\n          \" + updateSnippet + \"\\n        }\\n        setOutput(\" + returnValue + \");\\n      }\\n    \";\n    }\n    return SegmentOpProgram;\n}());\nexports.SegmentOpProgram = SegmentOpProgram;\n//# sourceMappingURL=segment_gpu.js.map","\n/**\n * @license\n * Copyright 2017 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar shader_compiler_1 = require(\"./shader_compiler\");\nvar SelectProgram = /** @class */ (function () {\n    function SelectProgram(cRank, shape, rank) {\n        this.variableNames = ['c', 'a', 'b'];\n        this.outputShape = shape;\n        var cCoords;\n        var abCoords;\n        if (rank > 4) {\n            throw Error(\"Where for rank \" + rank + \" is not yet supported\");\n        }\n        if (rank === 1) {\n            abCoords = \"resRC\";\n            cCoords = \"resRC\";\n        }\n        else {\n            var currentCoords = ['resRC.x', 'resRC.y', 'resRC.z', 'resRC.w'];\n            var cCoordVars = [];\n            var abCoordVars = [];\n            for (var i = 0; i < shape.length; i++) {\n                abCoordVars.push(\"\" + currentCoords[i]);\n                if (i < cRank) {\n                    cCoordVars.push(\"\" + currentCoords[i]);\n                }\n            }\n            cCoords = cCoordVars.join();\n            abCoords = abCoordVars.join();\n        }\n        var dtype = shader_compiler_1.getCoordsDataType(rank);\n        this.userCode = \"\\n      void main() {\\n        \" + dtype + \" resRC = getOutputCoords();\\n        float cVal = getC(\" + cCoords + \");\\n        if (cVal >= 1.0) {\\n          setOutput(getA(\" + abCoords + \"));\\n        } else {\\n          setOutput(getB(\" + abCoords + \"));\\n        }\\n      }\\n    \";\n    }\n    return SelectProgram;\n}());\nexports.SelectProgram = SelectProgram;\n//# sourceMappingURL=select_gpu.js.map","\n/**\n * @license\n * Copyright 2017 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar shader_compiler_1 = require(\"./shader_compiler\");\nvar SliceProgram = /** @class */ (function () {\n    function SliceProgram(destSize) {\n        this.variableNames = ['source'];\n        this.outputShape = destSize;\n        this.rank = destSize.length;\n        var dtype = shader_compiler_1.getCoordsDataType(this.rank);\n        var uniformPart = \"uniform int start[\" + this.rank + \"];\";\n        var sourceCoords = getCoords(this.rank);\n        var body;\n        var coordSum = destSize.map(function (_, i) {\n            return \"sourceLoc.\" + coords[i] + \" = start[\" + i + \"] + coords.\" + coords[i] + \";\";\n        });\n        body = \"\\n        \" + dtype + \" sourceLoc;\\n        \" + dtype + \" coords = getOutputCoords();\\n        \" + coordSum.join('\\n') + \"\\n      \";\n        this.userCode = \"\\n      \" + uniformPart + \"\\n      void main() {\\n        \" + body + \"\\n        setOutput(getSource(\" + sourceCoords + \"));\\n      }\\n    \";\n    }\n    SliceProgram.prototype.getCustomSetupFunc = function (start) {\n        var _this = this;\n        if (start.length !== this.rank) {\n            throw Error(\"The rank (\" + this.rank + \") of the program must match the \" +\n                (\"length of start (\" + start.length + \")\"));\n        }\n        return function (gpgpu, webGLProgram) {\n            if (_this.startLoc == null) {\n                _this.startLoc = gpgpu.getUniformLocationNoThrow(webGLProgram, 'start');\n                if (_this.startLoc == null) {\n                    // This means the compiler has optimized and realized it doesn't need\n                    // the uniform.\n                    return;\n                }\n            }\n            gpgpu.gl.uniform1iv(_this.startLoc, start);\n        };\n    };\n    return SliceProgram;\n}());\nexports.SliceProgram = SliceProgram;\nvar coords = ['x', 'y', 'z', 'w', 'u', 'v'];\nfunction getCoords(rank) {\n    if (rank === 1) {\n        return 'sourceLoc';\n    }\n    else if (rank <= 6) {\n        return coords.slice(0, rank).map(function (x) { return 'sourceLoc.' + x; }).join(',');\n    }\n    else {\n        throw Error(\"Slicing for rank \" + rank + \" is not yet supported\");\n    }\n}\n//# sourceMappingURL=slice_gpu.js.map","\n/**\n * @license\n * Copyright 2019 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar shader_compiler_1 = require(\"./shader_compiler\");\nvar packing_util_1 = require(\"../packing_util\");\nvar SlicePackedProgram = /** @class */ (function () {\n    function SlicePackedProgram(destSize) {\n        this.variableNames = ['source'];\n        this.usesPackedTextures = true;\n        this.outputShape = destSize;\n        this.rank = destSize.length;\n        var dtype = shader_compiler_1.getCoordsDataType(this.rank);\n        var coords = packing_util_1.getChannels('coords', this.rank);\n        var sourceLoc = packing_util_1.getChannels('sourceLoc', this.rank);\n        var innerDims = this.rank === 1 ? 'sourceLoc' : \"vec2(\" + sourceLoc.slice(-2).join() + \")\";\n        var getChannel = \"getChannel(getSource(\" + sourceLoc.join() + \"), \" + innerDims + \")\";\n        var upperRow = \"\\n      result.x = \" + getChannel + \";\\n      if (++\" + coords[this.rank - 1] + \" < \" + destSize[this.rank - 1] + \") {\\n        ++\" + sourceLoc[this.rank - 1] + \";\\n        result.y = \" + getChannel + \";\\n        --\" + sourceLoc[this.rank - 1] + \";\\n      }\\n    \";\n        var lowerRow = this.rank === 1 ? '' : \"\\n      --\" + coords[this.rank - 1] + \";\\n      if (++\" + coords[this.rank - 2] + \" < \" + destSize[this.rank - 2] + \") {\\n        ++\" + sourceLoc[this.rank - 2] + \";\\n        result.z = \" + getChannel + \";\\n        if (++\" + coords[this.rank - 1] + \" < \" + destSize[this.rank - 1] + \") {\\n          ++\" + sourceLoc[this.rank - 1] + \";\\n          result.w = \" + getChannel + \";\\n        }\\n      }\\n    \";\n        var sourceLocSetup = this.rank <= 4 ?\n            \"sourceLoc = coords +\\n            \" + dtype + \"(\" + destSize.map(function (_, i) { return \"start[\" + i + \"]\"; }).join() + \");\" :\n            destSize.map(function (_, i) { return sourceLoc[i] + \" = \" + coords[i] + \" + start[\" + i + \"];\"; })\n                .join('\\n');\n        this.userCode = \"\\n      uniform int start[\" + this.rank + \"];\\n      void main() {\\n        \" + dtype + \" coords = getOutputCoords();\\n        \" + dtype + \" sourceLoc;\\n        \" + sourceLocSetup + \" \\n        vec4 result = vec4(0.);\\n        \" + upperRow + \"\\n        \" + lowerRow + \"\\n        setOutput(result);\\n      }\\n    \";\n    }\n    SlicePackedProgram.prototype.getCustomSetupFunc = function (start) {\n        var _this = this;\n        if (start.length !== this.rank) {\n            throw Error(\"The rank (\" + this.rank + \") of the program must match the \" +\n                (\"length of start (\" + start.length + \")\"));\n        }\n        return function (gpgpu, webGLProgram) {\n            if (_this.startLoc == null) {\n                _this.startLoc = gpgpu.getUniformLocationNoThrow(webGLProgram, 'start');\n                if (_this.startLoc == null) {\n                    // This means the compiler has optimized and realized it doesn't need\n                    // the uniform.\n                    return;\n                }\n            }\n            gpgpu.gl.uniform1iv(_this.startLoc, start);\n        };\n    };\n    return SlicePackedProgram;\n}());\nexports.SlicePackedProgram = SlicePackedProgram;\n//# sourceMappingURL=slice_packed_gpu.js.map","\n/**\n * @license\n * Copyright 2017 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar shader_compiler_1 = require(\"./shader_compiler\");\nvar StridedSliceProgram = /** @class */ (function () {\n    function StridedSliceProgram(begin, strides, size, shrinkAxis) {\n        this.variableNames = ['x'];\n        var shape = size.filter(function (v, index) { return shrinkAxis.indexOf(index) === -1; });\n        this.outputShape = shape;\n        var rank = size.length;\n        var inputDtype = shader_compiler_1.getCoordsDataType(size.length);\n        var dtype = shader_compiler_1.getCoordsDataType(shape.length);\n        var newCoords = '';\n        if (rank === 1) {\n            newCoords = 'coords * strides + begin';\n        }\n        else {\n            var outputAxis_1 = 0;\n            newCoords =\n                size.map(function (_, i) {\n                    if (shrinkAxis.indexOf(i) === -1) {\n                        outputAxis_1++;\n                        return shape.length === 1 ?\n                            \"coords * strides[\" + i + \"] + begin[\" + i + \"]\" :\n                            \"coords[\" + (outputAxis_1 - 1) + \"] * strides[\" + i + \"] + begin[\" + i + \"]\";\n                    }\n                    else {\n                        return \"begin[\" + i + \"]\";\n                    }\n                })\n                    .join(',');\n        }\n        this.userCode = \"\\n      \" + inputDtype + \" begin = \" + inputDtype + \"(\" + begin + \");\\n      \" + inputDtype + \" strides = \" + inputDtype + \"(\" + strides + \");\\n\\n      void main() {\\n        \" + dtype + \" coords = getOutputCoords();\\n        setOutput(getX(\" + newCoords + \"));\\n      }\\n    \";\n    }\n    return StridedSliceProgram;\n}());\nexports.StridedSliceProgram = StridedSliceProgram;\n//# sourceMappingURL=strided_slice_gpu.js.map","\n/**\n * @license\n * Copyright 2017 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar environment_1 = require(\"../../environment\");\nvar tex_util_1 = require(\"./tex_util\");\nvar TextureManager = /** @class */ (function () {\n    function TextureManager(gpgpu) {\n        this.gpgpu = gpgpu;\n        this.numUsedTextures = 0;\n        this.numFreeTextures = 0;\n        this.freeTextures = {};\n        this.logEnabled = false;\n        this.usedTextures = {};\n    }\n    TextureManager.prototype.acquireTexture = function (shapeRC, usage, isPacked) {\n        var physicalTexType = getPhysicalFromLogicalTextureType(usage, isPacked);\n        var shapeKey = getKeyFromTextureShape(shapeRC, physicalTexType, isPacked);\n        if (!(shapeKey in this.freeTextures)) {\n            this.freeTextures[shapeKey] = [];\n        }\n        if (!(shapeKey in this.usedTextures)) {\n            this.usedTextures[shapeKey] = [];\n        }\n        if (this.freeTextures[shapeKey].length > 0) {\n            this.numFreeTextures--;\n            this.numUsedTextures++;\n            this.log();\n            var newTexture_1 = this.freeTextures[shapeKey].shift();\n            this.usedTextures[shapeKey].push(newTexture_1);\n            return newTexture_1;\n        }\n        this.numUsedTextures++;\n        this.log();\n        var newTexture;\n        if (physicalTexType === tex_util_1.PhysicalTextureType.PACKED_2X2_FLOAT32) {\n            newTexture = this.gpgpu.createPackedMatrixTexture(shapeRC[0], shapeRC[1]);\n        }\n        else if (physicalTexType === tex_util_1.PhysicalTextureType.PACKED_2X2_FLOAT16) {\n            newTexture =\n                this.gpgpu.createFloat16PackedMatrixTexture(shapeRC[0], shapeRC[1]);\n        }\n        else if (physicalTexType === tex_util_1.PhysicalTextureType.UNPACKED_FLOAT32) {\n            newTexture =\n                this.gpgpu.createFloat32MatrixTexture(shapeRC[0], shapeRC[1]);\n        }\n        else if (physicalTexType === tex_util_1.PhysicalTextureType.UNPACKED_FLOAT16) {\n            newTexture =\n                this.gpgpu.createFloat16MatrixTexture(shapeRC[0], shapeRC[1]);\n        }\n        else if (physicalTexType === tex_util_1.PhysicalTextureType.PACKED_4X1_UNSIGNED_BYTE) {\n            newTexture =\n                this.gpgpu.createUnsignedBytesMatrixTexture(shapeRC[0], shapeRC[1]);\n        }\n        this.usedTextures[shapeKey].push(newTexture);\n        return newTexture;\n    };\n    TextureManager.prototype.releaseTexture = function (texture, shape, logicalTexType, isPacked) {\n        if (this.freeTextures == null) {\n            // Already disposed.\n            return;\n        }\n        var physicalTexType = getPhysicalFromLogicalTextureType(logicalTexType, isPacked);\n        var shapeKey = getKeyFromTextureShape(shape, physicalTexType, isPacked);\n        if (!(shapeKey in this.freeTextures)) {\n            this.freeTextures[shapeKey] = [];\n        }\n        this.freeTextures[shapeKey].push(texture);\n        this.numFreeTextures++;\n        this.numUsedTextures--;\n        var texList = this.usedTextures[shapeKey];\n        var texIndex = texList.indexOf(texture);\n        if (texIndex < 0) {\n            throw new Error('Cannot release a texture that was never provided by this ' +\n                'texture manager');\n        }\n        texList.splice(texIndex, 1);\n        this.log();\n    };\n    TextureManager.prototype.log = function () {\n        if (!this.logEnabled) {\n            return;\n        }\n        var total = this.numFreeTextures + this.numUsedTextures;\n        console.log('Free/Used', this.numFreeTextures + \" / \" + this.numUsedTextures, \"(\" + total + \")\");\n    };\n    TextureManager.prototype.getNumUsedTextures = function () {\n        return this.numUsedTextures;\n    };\n    TextureManager.prototype.getNumFreeTextures = function () {\n        return this.numFreeTextures;\n    };\n    TextureManager.prototype.dispose = function () {\n        var _this = this;\n        if (this.freeTextures == null) {\n            // Already disposed.\n            return;\n        }\n        for (var texShape in this.freeTextures) {\n            this.freeTextures[texShape].forEach(function (tex) {\n                _this.gpgpu.deleteMatrixTexture(tex);\n            });\n        }\n        for (var texShape in this.usedTextures) {\n            this.usedTextures[texShape].forEach(function (tex) {\n                _this.gpgpu.deleteMatrixTexture(tex);\n            });\n        }\n        this.freeTextures = null;\n        this.usedTextures = null;\n        this.numUsedTextures = 0;\n        this.numFreeTextures = 0;\n    };\n    return TextureManager;\n}());\nexports.TextureManager = TextureManager;\nfunction getPhysicalFromLogicalTextureType(logicalTexType, isPacked) {\n    if (logicalTexType === tex_util_1.TextureUsage.UPLOAD) {\n        return isPacked ? tex_util_1.PhysicalTextureType.PACKED_2X2_FLOAT32 :\n            tex_util_1.PhysicalTextureType.UNPACKED_FLOAT32;\n    }\n    else if (logicalTexType === tex_util_1.TextureUsage.RENDER || logicalTexType == null) {\n        if (isPacked) {\n            return environment_1.ENV.getBool('WEBGL_RENDER_FLOAT32_ENABLED') ?\n                tex_util_1.PhysicalTextureType.PACKED_2X2_FLOAT32 :\n                tex_util_1.PhysicalTextureType.PACKED_2X2_FLOAT16;\n        }\n        return environment_1.ENV.getBool('WEBGL_RENDER_FLOAT32_ENABLED') ?\n            tex_util_1.PhysicalTextureType.UNPACKED_FLOAT32 :\n            tex_util_1.PhysicalTextureType.UNPACKED_FLOAT16;\n    }\n    else if (logicalTexType === tex_util_1.TextureUsage.DOWNLOAD ||\n        logicalTexType === tex_util_1.TextureUsage.PIXELS) {\n        return tex_util_1.PhysicalTextureType.PACKED_4X1_UNSIGNED_BYTE;\n    }\n    throw new Error(\"Unknown logical texture type \" + logicalTexType);\n}\nfunction getKeyFromTextureShape(shapeRowsCol, physicalTexType, isPacked) {\n    return shapeRowsCol[0] + \"_\" + shapeRowsCol[1] + \"_\" + physicalTexType + \"_\" + isPacked;\n}\n//# sourceMappingURL=texture_manager.js.map","\n/**\n * @license\n * Copyright 2017 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar shader_compiler_1 = require(\"./shader_compiler\");\nvar TileProgram = /** @class */ (function () {\n    function TileProgram(aShape, reps) {\n        this.variableNames = ['A'];\n        var outputShape = new Array(aShape.length);\n        for (var i = 0; i < outputShape.length; i++) {\n            outputShape[i] = aShape[i] * reps[i];\n        }\n        this.outputShape = outputShape;\n        this.rank = outputShape.length;\n        var dtype = shader_compiler_1.getCoordsDataType(this.rank);\n        var sourceCoords = getSourceCoords(aShape);\n        this.userCode = \"\\n      void main() {\\n        \" + dtype + \" resRC = getOutputCoords();\\n        setOutput(getA(\" + sourceCoords + \"));\\n      }\\n    \";\n    }\n    return TileProgram;\n}());\nexports.TileProgram = TileProgram;\nfunction getSourceCoords(aShape) {\n    var rank = aShape.length;\n    if (rank > 5) {\n        throw Error(\"Tile for rank \" + rank + \" is not yet supported\");\n    }\n    if (rank === 1) {\n        return \"imod(resRC, \" + aShape[0] + \")\";\n    }\n    var currentCoords = ['resRC.x', 'resRC.y', 'resRC.z', 'resRC.w', 'resRC.u'];\n    var sourceCoords = [];\n    for (var i = 0; i < aShape.length; i++) {\n        sourceCoords.push(\"imod(\" + currentCoords[i] + \", \" + aShape[i] + \")\");\n    }\n    return sourceCoords.join();\n}\n//# sourceMappingURL=tile_gpu.js.map","\n/**\n * @license\n * Copyright 2017 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar shader_compiler_1 = require(\"./shader_compiler\");\nvar TransposeProgram = /** @class */ (function () {\n    function TransposeProgram(aShape, newDim) {\n        this.variableNames = ['A'];\n        var outputShape = new Array(aShape.length);\n        for (var i = 0; i < outputShape.length; i++) {\n            outputShape[i] = aShape[newDim[i]];\n        }\n        this.outputShape = outputShape;\n        this.rank = outputShape.length;\n        var dtype = shader_compiler_1.getCoordsDataType(this.rank);\n        var switched = getSwitchedCoords(newDim);\n        this.userCode = \"\\n    void main() {\\n      \" + dtype + \" resRC = getOutputCoords();\\n      setOutput(getA(\" + switched + \"));\\n    }\\n    \";\n    }\n    return TransposeProgram;\n}());\nexports.TransposeProgram = TransposeProgram;\nfunction getSwitchedCoords(newDim) {\n    var rank = newDim.length;\n    if (rank > 6) {\n        throw Error(\"Transpose for rank \" + rank + \" is not yet supported\");\n    }\n    var originalOrder = ['resRC.x', 'resRC.y', 'resRC.z', 'resRC.w', 'resRC.u', 'resRC.v'];\n    var switchedCoords = new Array(rank);\n    for (var i = 0; i < newDim.length; i++) {\n        switchedCoords[newDim[i]] = originalOrder[i];\n    }\n    return switchedCoords.join();\n}\n//# sourceMappingURL=transpose_gpu.js.map","\n/**\n * @license\n * Copyright 2019 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar shader_compiler_1 = require(\"./shader_compiler\");\nvar packing_util_1 = require(\"../packing_util\");\nvar TransposePackedProgram = /** @class */ (function () {\n    function TransposePackedProgram(aShape, newDim) {\n        this.variableNames = ['A'];\n        this.usesPackedTextures = true;\n        var outputShape = new Array(aShape.length);\n        for (var i = 0; i < outputShape.length; i++) {\n            outputShape[i] = aShape[newDim[i]];\n        }\n        this.outputShape = outputShape;\n        this.rank = outputShape.length;\n        if (this.rank > 6) {\n            throw Error(\"Packed transpose for rank \" + this.rank + \" is not yet supported.\");\n        }\n        var dtype = shader_compiler_1.getCoordsDataType(this.rank);\n        var outputOrder = packing_util_1.getVecChannels('rc', this.rank);\n        var switchedOrder = new Array(this.rank);\n        for (var i = 0; i < newDim.length; i++) {\n            switchedOrder[newDim[i]] = outputOrder[i];\n        }\n        var innerDims = \"vec2(\" + switchedOrder.slice(-2).join() + \")\";\n        var nextColumn = \"++\" + outputOrder[this.rank - 1] + \" < \" + outputShape[this.rank - 1];\n        var getc = \"getChannel(getA(\" + switchedOrder.join() + \"), \" + innerDims + \")\";\n        this.userCode = \"\\n    void main() {\\n      \" + dtype + \" rc = getOutputCoords();\\n      vec4 result = vec4(0.);\\n      result[0] = \" + getc + \";\\n      if(\" + nextColumn + \") {\\n        result[1] = \" + getc + \";\\n      }\\n      --\" + outputOrder[this.rank - 1] + \";\\n      if(++\" + outputOrder[this.rank - 2] + \" < \" + outputShape[this.rank - 2] + \") {\\n        result[2] = \" + getc + \";\\n        if(\" + nextColumn + \") {\\n          result[3] = \" + getc + \";\\n        }\\n      }  \\n      setOutput(result);\\n    }\\n    \";\n    }\n    return TransposePackedProgram;\n}());\nexports.TransposePackedProgram = TransposePackedProgram;\n//# sourceMappingURL=transpose_packed_gpu.js.map","\n/**\n * @license\n * Copyright 2017 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar erf_util = require(\"../../ops/erf_util\");\nvar selu_util = require(\"../../ops/selu_util\");\nvar UnaryOpProgram = /** @class */ (function () {\n    function UnaryOpProgram(aShape, opSnippet) {\n        this.variableNames = ['A'];\n        this.outputShape = aShape;\n        this.userCode = \"\\n      float unaryOperation(float x) {\\n        \" + opSnippet + \"\\n      }\\n\\n      void main() {\\n        float x = getAAtOutCoords();\\n        float y = unaryOperation(x);\\n\\n        setOutput(y);\\n      }\\n    \";\n    }\n    return UnaryOpProgram;\n}());\nexports.UnaryOpProgram = UnaryOpProgram;\nvar CHECK_NAN_SNIPPET = \"if (isnan(x)) return x;\";\nexports.LINEAR = \"return x;\";\nexports.ABS = \"return abs(x);\";\nexports.RELU = CHECK_NAN_SNIPPET + \"\\n  return (x < 0.0) ? 0.0 : x;\\n\";\nexports.ELU = \"return (x >= 0.0) ? x : (exp(x) - 1.0);\";\nexports.SELU = \"\\n  // Stable and Attracting Fixed Point (0, 1) for Normalized Weights.\\n  // see: https://arxiv.org/abs/1706.02515\\n  float scaleAlpha = \" + selu_util.SELU_SCALEALPHA + \";\\n  float scale = \" + selu_util.SELU_SCALE + \";\\n  return (x >= 0.0) ? scale * x : scaleAlpha * (exp(x) - 1.0);\\n\";\nfunction STEP(alpha) {\n    if (alpha === void 0) { alpha = 0.0; }\n    return CHECK_NAN_SNIPPET + (\"\\n    return x > 0.0 ? 1.0 : float(\" + alpha + \");\\n  \");\n}\nexports.STEP = STEP;\nexports.NEG = \"return -x;\";\nexports.CEIL = \"return ceil(x);\";\nexports.FLOOR = \"return floor(x);\";\nexports.SIGN = \"\\n  if (isnan(x)) { return 0.0; }\\n  return sign(x);\\n\";\nexports.IS_NAN = \"return float(isnan(x));\";\nexports.IS_INF = \"return float(isinf(x));\";\nexports.IS_FINITE = \"return float(!isnan(x) && !isinf(x));\";\nexports.ROUND = \"\\n  // OpenGL ES does not support round function.\\n  // The algorithm is based on banker's rounding.\\n  float base = floor(x);\\n  if ((x - base) < 0.5) {\\n    return floor(x);\\n  } else if ((x - base) > 0.5) {\\n    return ceil(x);\\n  } else {\\n    if (mod(base, 2.0) == 0.0) {\\n      return base;\\n    } else {\\n      return base + 1.0;\\n    }\\n  }\\n\";\nexports.EXP = \"return exp(x);\";\nexports.EXPM1 = \"return exp(x) - 1.0;\";\nexports.LOG = \"if (x < 0.0) return NAN;\\n  return log(x);\";\nexports.LOG1P = \"return log(1.0 + x);\";\nexports.SQRT = \"return sqrt(x);\";\nexports.RSQRT = \"return inversesqrt(x);\";\nexports.SIGMOID = \"return 1.0 / (1.0 + exp(-1.0 * x));\";\n/**\n * mirrors the implementation of tf.nn.softplus: https://goo.gl/vkcvwX\n *\n * epsilon is the difference between 1.0 and the next representable\n * float. For a single precision 32 bit float this should be 2^-23, see:\n * https://math.byu.edu/~schow/work/IEEEFloatingPoint.htm\n *\n * too_large = (x > -threshold) is value above which exp(x) may overflow\n * but softplus(x) == x is within machine epsilon\n *\n * too_small = (x < threshold) is value below which exp(x) may underflow,\n * but softplus(x) == exp(x) is within machine epsilon.\n */\nexports.SOFTPLUS = \"\\n  float epsilon = 1.1920928955078125e-7;\\n  float threshold = log(epsilon) + 2.0;\\n\\n  bool too_large = x > -threshold;\\n  bool too_small = x < threshold;\\n\\n  float result;\\n  float exp_x = exp(x);\\n\\n  if (too_large){\\n    result = x;\\n  }\\n  else if (too_small){\\n    result = exp_x;\\n  }\\n  else{\\n    result = log(exp_x + 1.0);\\n  }\\n  return result;\\n\";\nexports.SIN = CHECK_NAN_SNIPPET + \"\\n  return sin(x);\\n\";\nexports.COS = CHECK_NAN_SNIPPET + \"\\n  return cos(x);\\n\";\nexports.TAN = \"return tan(x);\";\nexports.ASIN = \"return asin(x);\";\nexports.ACOS = \"return acos(x);\";\nexports.ATAN = CHECK_NAN_SNIPPET + \"\\n  return atan(x);\\n\";\nexports.SINH = \"\\n  float e2x = exp(x);\\n  return (e2x - 1.0 / e2x) / 2.0;\\n\";\nexports.COSH = \"\\n  float e2x = exp(-x);\\n  return (e2x + 1.0 / e2x) / 2.0;\\n\";\nexports.TANH = \"\\n  float e2x = exp(-2.0 * abs(x));\\n  return sign(x) * (1.0 - e2x) / (1.0 + e2x);\\n\";\nexports.ASINH = \"return log(x + sqrt(x * x + 1.0));\";\nexports.ACOSH = CHECK_NAN_SNIPPET + \"\\n  if (x < 1.0) return NAN;\\n  return log(x + sqrt(x * x - 1.0));\";\nexports.ATANH = CHECK_NAN_SNIPPET + \"\\n  if ((x < -1.0) || (x > 1.0)) return NAN;\\n  return (log(1.0 + x) - log(1.0 - x)) / 2.0;\";\nexports.ERF = \"\\n  // Error function is calculated approximately with elementary function.\\n  // See \\\"Handbook of Mathematical Functions with Formulas,\\n  // Graphs, and Mathematical Tables\\\", Abramowitz and Stegun.\\n  float p = \" + erf_util.ERF_P + \";\\n  float a1 = \" + erf_util.ERF_A1 + \";\\n  float a2 = \" + erf_util.ERF_A2 + \";\\n  float a3 = \" + erf_util.ERF_A3 + \";\\n  float a4 = \" + erf_util.ERF_A4 + \";\\n  float a5 = \" + erf_util.ERF_A5 + \";\\n\\n  float t = 1.0 / (1.0 + p * x);\\n  return 1.0 - (((((a5*t + a4)*t) + a3)*t + a2)*t + a1)*t*exp(-x*x);\\n\";\nexports.SQUARE = \"return x * x;\";\nexports.RECIPROCAL = \"return 1.0 / x;\";\nexports.LOGICAL_NOT = \"return float(!(x >= 1.0));\";\nexports.TO_INT = \"return float(int(x));\";\nexports.CLONE = 'return x;';\n//# sourceMappingURL=unaryop_gpu.js.map","\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.ERF_P = 0.3275911;\nexports.ERF_A1 = 0.254829592;\nexports.ERF_A2 = -0.284496736;\nexports.ERF_A3 = 1.421413741;\nexports.ERF_A4 = -1.453152027;\nexports.ERF_A5 = 1.061405429;\n//# sourceMappingURL=erf_util.js.map","\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.SELU_SCALEALPHA = 1.7580993408473768599402175208123;\nexports.SELU_SCALE = 1.0507009873554804934193349852946;\n//# sourceMappingURL=selu_util.js.map","\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.LINEAR = \"return x;\";\nexports.LOG = \"\\n  vec4 result = log(x);\\n  vec4 isNaN = vec4(lessThan(x, vec4(0.0)));\\n  result.r = isNaN.r == 1.0 ? NAN : result.r;\\n  result.g = isNaN.g == 1.0 ? NAN : result.g;\\n  result.b = isNaN.b == 1.0 ? NAN : result.b;\\n  result.a = isNaN.a == 1.0 ? NAN : result.a;\\n\\n  return result;\\n\";\nexports.RELU = \"\\n  vec4 result = x * vec4(greaterThanEqual(x, vec4(0.0)));\\n  bvec4 isNaN = isnan(x);\\n\\n  result.r = isNaN.r ? x.r : result.r;\\n  result.g = isNaN.g ? x.g : result.g;\\n  result.b = isNaN.b ? x.b : result.b;\\n  result.a = isNaN.a ? x.a : result.a;\\n\\n  return result;\\n\";\nvar UnaryOpPackedProgram = /** @class */ (function () {\n    function UnaryOpPackedProgram(aShape, opSnippet) {\n        this.variableNames = ['A'];\n        this.usesPackedTextures = true;\n        this.outputShape = aShape;\n        this.userCode = \"\\n      vec4 unaryOperation(vec4 x) {\\n        \" + opSnippet + \"\\n      }\\n\\n      void main() {\\n        vec4 x = getAAtOutCoords();\\n        vec4 y = unaryOperation(x);\\n\\n        setOutput(y);\\n      }\\n    \";\n    }\n    return UnaryOpPackedProgram;\n}());\nexports.UnaryOpPackedProgram = UnaryOpPackedProgram;\n//# sourceMappingURL=unaryop_packed_gpu.js.map","\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar packing_util_1 = require(\"../packing_util\");\nvar shader_compiler_1 = require(\"./shader_compiler\");\nvar UnpackProgram = /** @class */ (function () {\n    function UnpackProgram(outputShape) {\n        this.variableNames = ['A'];\n        this.usesPackedTextures = true;\n        this.outputShape = outputShape;\n        var rank = outputShape.length;\n        var channels = packing_util_1.getChannels('rc', rank);\n        var dtype = shader_compiler_1.getCoordsDataType(rank);\n        var sourceCoords = packing_util_1.getSourceCoords(rank, channels);\n        var innerDims = channels.slice(-2);\n        var coords = rank <= 1 ? 'rc' : \"vec2(\" + innerDims.join(',') + \")\";\n        this.userCode = \"\\n      void main() {\\n        \" + dtype + \" rc = getOutputCoords();\\n        vec4 packedInput = getA(\" + sourceCoords + \");\\n\\n        setOutput(getChannel(packedInput, \" + coords + \"));\\n      }\\n    \";\n    }\n    return UnpackProgram;\n}());\nexports.UnpackProgram = UnpackProgram;\n//# sourceMappingURL=unpack_gpu.js.map","\n/**\n * @license\n * Copyright 2017 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : new P(function (resolve) { resolve(result.value); }).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nvar __generator = (this && this.__generator) || function (thisArg, body) {\n    var _ = { label: 0, sent: function() { if (t[0] & 1) throw t[1]; return t[1]; }, trys: [], ops: [] }, f, y, t, g;\n    return g = { next: verb(0), \"throw\": verb(1), \"return\": verb(2) }, typeof Symbol === \"function\" && (g[Symbol.iterator] = function() { return this; }), g;\n    function verb(n) { return function (v) { return step([n, v]); }; }\n    function step(op) {\n        if (f) throw new TypeError(\"Generator is already executing.\");\n        while (_) try {\n            if (f = 1, y && (t = op[0] & 2 ? y[\"return\"] : op[0] ? y[\"throw\"] || ((t = y[\"return\"]) && t.call(y), 0) : y.next) && !(t = t.call(y, op[1])).done) return t;\n            if (y = 0, t) op = [op[0] & 2, t.value];\n            switch (op[0]) {\n                case 0: case 1: t = op; break;\n                case 4: _.label++; return { value: op[1], done: false };\n                case 5: _.label++; y = op[1]; op = [0]; continue;\n                case 7: op = _.ops.pop(); _.trys.pop(); continue;\n                default:\n                    if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) { _ = 0; continue; }\n                    if (op[0] === 3 && (!t || (op[1] > t[0] && op[1] < t[3]))) { _.label = op[1]; break; }\n                    if (op[0] === 6 && _.label < t[1]) { _.label = t[1]; t = op; break; }\n                    if (t && _.label < t[2]) { _.label = t[2]; _.ops.push(op); break; }\n                    if (t[2]) _.ops.pop();\n                    _.trys.pop(); continue;\n            }\n            op = body.call(thisArg, _);\n        } catch (e) { op = [6, e]; y = 0; } finally { f = t = 0; }\n        if (op[0] & 5) throw op[1]; return { value: op[0] ? op[1] : void 0, done: true };\n    }\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar seedrandom = require(\"seedrandom\");\nvar engine_1 = require(\"../../engine\");\nvar environment_1 = require(\"../../environment\");\nvar log_1 = require(\"../../log\");\nvar array_ops_util = require(\"../../ops/array_ops_util\");\nvar axis_util = require(\"../../ops/axis_util\");\nvar broadcast_util = require(\"../../ops/broadcast_util\");\nvar concat_util = require(\"../../ops/concat_util\");\nvar erf_util = require(\"../../ops/erf_util\");\nvar gather_nd_util = require(\"../../ops/gather_nd_util\");\nvar ops = require(\"../../ops/ops\");\nvar ops_1 = require(\"../../ops/ops\");\nvar scatter_nd_util = require(\"../../ops/scatter_nd_util\");\nvar selu_util = require(\"../../ops/selu_util\");\nvar slice_util_1 = require(\"../../ops/slice_util\");\nvar tensor_1 = require(\"../../tensor\");\nvar types_1 = require(\"../../types\");\nvar util = require(\"../../util\");\nvar util_1 = require(\"../../util\");\nvar backend_1 = require(\"../backend\");\nvar backend_util = require(\"../backend_util\");\nvar complex_util = require(\"../complex_util\");\nvar non_max_suppression_impl_1 = require(\"../non_max_suppression_impl\");\nvar split_shared_1 = require(\"../split_shared\");\nvar topk_impl_1 = require(\"../topk_impl\");\nvar where_impl_1 = require(\"../where_impl\");\nfunction mapActivation(backend, activation, x) {\n    if (activation === 'linear') {\n        return backend.linear(x);\n    }\n    else if (activation === 'relu') {\n        return backend.relu(x);\n    }\n    throw new Error(\"Activation \" + activation + \" has not been implemented for the CPU backend.\");\n}\nvar MathBackendCPU = /** @class */ (function () {\n    function MathBackendCPU() {\n        this.blockSize = 48;\n        this.firstUse = true;\n        if (environment_1.ENV.get('IS_BROWSER')) {\n            this.fromPixels2DContext =\n                document.createElement('canvas').getContext('2d');\n        }\n        this.data = new backend_1.DataStorage(this, engine_1.ENGINE);\n    }\n    MathBackendCPU.prototype.register = function (dataId, shape, dtype) {\n        if (this.firstUse) {\n            this.firstUse = false;\n            if (environment_1.ENV.get('IS_NODE')) {\n                log_1.warn('\\n============================\\n' +\n                    'Hi there . Looks like you are running TensorFlow.js in ' +\n                    'Node.js. To speed things up dramatically, install our node ' +\n                    'backend, which binds to TensorFlow C++, by running ' +\n                    'npm i @tensorflow/tfjs-node, ' +\n                    'or npm i @tensorflow/tfjs-node-gpu if you have CUDA. ' +\n                    'Then call require(\\'@tensorflow/tfjs-node\\'); (-gpu ' +\n                    'suffix for CUDA) at the start of your program. ' +\n                    'Visit https://github.com/tensorflow/tfjs-node for more details.' +\n                    '\\n============================\\n');\n            }\n        }\n        if (this.data.has(dataId)) {\n            throw new Error(\"Data buffer is already registered\");\n        }\n        this.data.set(dataId, { dtype: dtype });\n    };\n    MathBackendCPU.prototype.write = function (dataId, values) {\n        if (values == null) {\n            throw new Error('MathBackendCPU.write(): values can not be null');\n        }\n        this.data.get(dataId).values = values;\n    };\n    MathBackendCPU.prototype.fromPixels = function (pixels, numChannels) {\n        if (pixels == null) {\n            throw new Error('pixels passed to tf.browser.fromPixels() can not be null');\n        }\n        var vals;\n        // tslint:disable-next-line:no-any\n        if (environment_1.ENV.get('IS_NODE') && pixels.getContext == null) {\n            throw new Error('When running in node, pixels must be an HTMLCanvasElement ' +\n                'like the one returned by the `canvas` npm package');\n        }\n        // tslint:disable-next-line:no-any\n        if (pixels.getContext != null) {\n            // tslint:disable-next-line:no-any\n            vals = pixels\n                .getContext('2d')\n                .getImageData(0, 0, pixels.width, pixels.height)\n                .data;\n        }\n        else if (pixels instanceof ImageData ||\n            pixels.data instanceof Uint8Array) {\n            vals = pixels.data;\n        }\n        else if (pixels instanceof HTMLImageElement ||\n            pixels instanceof HTMLVideoElement) {\n            if (this.fromPixels2DContext == null) {\n                throw new Error('Can\\'t read pixels from HTMLImageElement outside ' +\n                    'the browser.');\n            }\n            this.fromPixels2DContext.canvas.width = pixels.width;\n            this.fromPixels2DContext.canvas.height = pixels.height;\n            this.fromPixels2DContext.drawImage(pixels, 0, 0, pixels.width, pixels.height);\n            vals = this.fromPixels2DContext\n                .getImageData(0, 0, pixels.width, pixels.height)\n                .data;\n        }\n        else {\n            throw new Error('pixels passed to tf.browser.fromPixels() must be either an ' +\n                \"HTMLVideoElement, HTMLImageElement, HTMLCanvasElement, ImageData \" +\n                \"or {data: Uint32Array, width: number, height: number}, \" +\n                (\"but was \" + pixels.constructor.name));\n        }\n        var values;\n        if (numChannels === 4) {\n            values = new Int32Array(vals);\n        }\n        else {\n            var numPixels = pixels.width * pixels.height;\n            values = new Int32Array(numPixels * numChannels);\n            for (var i = 0; i < numPixels; i++) {\n                for (var channel = 0; channel < numChannels; ++channel) {\n                    values[i * numChannels + channel] = vals[i * 4 + channel];\n                }\n            }\n        }\n        var outShape = [pixels.height, pixels.width, numChannels];\n        return ops_1.tensor3d(values, outShape, 'int32');\n    };\n    MathBackendCPU.prototype.read = function (dataId) {\n        return __awaiter(this, void 0, void 0, function () {\n            return __generator(this, function (_a) {\n                return [2 /*return*/, this.readSync(dataId)];\n            });\n        });\n    };\n    MathBackendCPU.prototype.readSync = function (dataId) {\n        var _a = this.data.get(dataId), dtype = _a.dtype, complexTensors = _a.complexTensors;\n        if (dtype === 'complex64') {\n            var realValues = this.readSync(complexTensors.real.dataId);\n            var imagValues = this.readSync(complexTensors.imag.dataId);\n            return complex_util.mergeRealAndImagArrays(realValues, imagValues);\n        }\n        return this.data.get(dataId).values;\n    };\n    MathBackendCPU.prototype.bufferSync = function (t) {\n        return ops_1.buffer(t.shape, t.dtype, this.readSync(t.dataId));\n    };\n    MathBackendCPU.prototype.disposeData = function (dataId) {\n        if (this.data.has(dataId)) {\n            var complexTensors = this.data.get(dataId).complexTensors;\n            if (complexTensors != null) {\n                complexTensors.real.dispose();\n                complexTensors.imag.dispose();\n            }\n            this.data.delete(dataId);\n        }\n    };\n    MathBackendCPU.prototype.time = function (f) {\n        return __awaiter(this, void 0, void 0, function () {\n            var start, kernelMs;\n            return __generator(this, function (_a) {\n                start = util_1.now();\n                f();\n                kernelMs = util_1.now() - start;\n                return [2 /*return*/, { kernelMs: kernelMs }];\n            });\n        });\n    };\n    MathBackendCPU.prototype.memory = function () {\n        return {\n            // Unreliable due to automatic gc. The numbers above are cumulative.\n            unreliable: true,\n            reasons: ['The reported memory is an upper bound. Due to automatic garbage ' +\n                    'collection, the true allocated memory may be less.']\n        };\n    };\n    MathBackendCPU.prototype.complex = function (real, imag) {\n        var result = tensor_1.Tensor.make(real.shape, {}, 'complex64');\n        var resultData = this.data.get(result.dataId);\n        // The backend owns the reference to the underlying real and imaginary\n        // clones. These will explicitly get disposed when the complex tensor is\n        // disposed.\n        resultData.complexTensors = {\n            real: engine_1.ENGINE.keep(real.clone()),\n            imag: engine_1.ENGINE.keep(imag.clone())\n        };\n        return result;\n    };\n    MathBackendCPU.prototype.real = function (input) {\n        var resultData = this.data.get(input.dataId);\n        return resultData.complexTensors.real.clone();\n    };\n    MathBackendCPU.prototype.imag = function (input) {\n        var resultData = this.data.get(input.dataId);\n        return resultData.complexTensors.imag.clone();\n    };\n    MathBackendCPU.prototype.assertNotComplex = function (tensor, opName) {\n        if (!Array.isArray(tensor)) {\n            tensor = [tensor];\n        }\n        tensor.forEach(function (t) {\n            if (t != null) {\n                util.assert(t.dtype !== 'complex64', function () { return opName + \" does not support complex64 tensors.\"; });\n            }\n        });\n    };\n    MathBackendCPU.prototype.slice = function (x, begin, size) {\n        this.assertNotComplex(x, 'slice');\n        var isContinous = slice_util_1.isSliceContinous(x.shape, begin, size);\n        if (isContinous) {\n            var flatOffset = slice_util_1.computeFlatOffset(begin, x.strides);\n            var length_1 = util.sizeFromShape(size);\n            var vals = this.readSync(x.dataId);\n            return ops_1.tensor(vals.subarray(flatOffset, flatOffset + length_1), size, x.dtype);\n        }\n        var buffer = ops.buffer(size, x.dtype);\n        var xBuf = this.bufferSync(x);\n        for (var i = 0; i < buffer.size; ++i) {\n            var loc = buffer.indexToLoc(i);\n            var xLoc = loc.map(function (idx, j) { return idx + begin[j]; });\n            buffer.values[i] = xBuf.get.apply(xBuf, xLoc);\n        }\n        return buffer.toTensor();\n    };\n    MathBackendCPU.prototype.stridedSlice = function (x, begin, end, strides, beginMask, endMask, ellipsisMask, newAxisMask, shrinkAxisMask) {\n        this.assertNotComplex(x, 'stridedSlice');\n        var _a = slice_util_1.getStridedSlicedInfo(x.shape, begin, end, strides, beginMask, endMask, ellipsisMask, newAxisMask, shrinkAxisMask), beginIndex = _a[0], size = _a[1], shrinkAxis = _a[2];\n        var shape = size.filter(function (v, index) { return shrinkAxis.indexOf(index) === -1; });\n        if (shape.some(function (axis) { return axis === 0; })) {\n            return ops.tensor([], shape);\n        }\n        var buffer = ops.buffer(size, x.dtype);\n        var xBuf = this.bufferSync(x);\n        for (var i = 0; i < buffer.size; i++) {\n            var loc = buffer.indexToLoc(i);\n            var newLoc = new Array(loc.length);\n            for (var j = 0; j < newLoc.length; j++) {\n                newLoc[j] = loc[j] * strides[j] + beginIndex[j];\n            }\n            buffer.set.apply(buffer, [xBuf.get.apply(xBuf, newLoc)].concat(loc));\n        }\n        return buffer.toTensor().reshape(shape);\n    };\n    MathBackendCPU.prototype.unstack = function (x, axis) {\n        var num = x.shape[axis];\n        var outShape = new Array(x.rank - 1);\n        var outIndex = 0;\n        for (var i = 0; i < x.rank; i++) {\n            if (i !== axis) {\n                outShape[outIndex++] = x.shape[i];\n            }\n        }\n        var begin = new Array(x.rank).fill(0);\n        var size = x.shape.slice();\n        size[axis] = 1;\n        var res = new Array(num);\n        for (var i = 0; i < res.length; i++) {\n            begin[axis] = i;\n            res[i] = this.slice(x, begin, size).reshape(outShape);\n        }\n        return res;\n    };\n    MathBackendCPU.prototype.reverse = function (x, axis) {\n        this.assertNotComplex(x, 'reverse');\n        var buffer = ops.buffer(x.shape, x.dtype);\n        var xBuf = this.bufferSync(x);\n        var _loop_1 = function (i) {\n            var outLoc = buffer.indexToLoc(i);\n            var inLoc = outLoc.slice();\n            axis.forEach(function (ax) { return inLoc[ax] = x.shape[ax] - 1 - inLoc[ax]; });\n            buffer.set.apply(buffer, [xBuf.get.apply(xBuf, inLoc)].concat(outLoc));\n        };\n        for (var i = 0; i < buffer.size; i++) {\n            _loop_1(i);\n        }\n        return buffer.toTensor();\n    };\n    MathBackendCPU.prototype.concat = function (tensors, axis) {\n        var _this = this;\n        this.assertNotComplex(tensors, 'concat');\n        var tensors2D = tensors.map(function (t) {\n            var innerSize = util.sizeFromShape(t.shape.slice(axis));\n            return t.as2D(-1, innerSize);\n        });\n        var outShape = concat_util.computeOutShape(tensors2D.map(function (t) { return t.shape; }), 1 /* axis */);\n        var values = ops.buffer(outShape, tensors[0].dtype)\n            .values;\n        if (tensors2D[0].shape[0] === 1) {\n            // Use built-in TypedArray.set() method for speed.\n            var offset_1 = 0;\n            tensors2D.forEach(function (t) {\n                values.set(_this.readSync(t.dataId), offset_1);\n                offset_1 += t.size;\n            });\n        }\n        else {\n            var colOffset_1 = 0;\n            tensors2D.forEach(function (t) {\n                var tVals = _this.readSync(t.dataId);\n                var tIdx = 0;\n                for (var row = 0; row < t.shape[0]; ++row) {\n                    var resIdx = row * outShape[1] + colOffset_1;\n                    for (var col = 0; col < t.shape[1]; ++col) {\n                        values[resIdx + col] = tVals[tIdx++];\n                    }\n                }\n                colOffset_1 += t.shape[1];\n            });\n        }\n        var finalOutShape = concat_util.computeOutShape(tensors.map(function (t) { return t.shape; }), axis);\n        return ops_1.tensor(values, finalOutShape, tensors[0].dtype);\n    };\n    MathBackendCPU.prototype.neg = function (x) {\n        this.assertNotComplex(x, 'neg');\n        return this.multiply(ops.scalar(-1), x);\n    };\n    MathBackendCPU.prototype.add = function (a, b) {\n        if (a.dtype === 'complex64' || b.dtype === 'complex64') {\n            return this.broadcastedBinaryComplexOp(a.cast('complex64'), b.cast('complex64'), function (aReal, aImag, bReal, bImag) {\n                return { real: aReal + bReal, imag: aImag + bImag };\n            });\n        }\n        return this.broadcastedBinaryOp(a, b, types_1.upcastType(a.dtype, b.dtype), function (aValue, bValue) { return aValue + bValue; });\n    };\n    MathBackendCPU.prototype.addN = function (tensors) {\n        var _this = this;\n        this.assertNotComplex(tensors, 'addN');\n        var vals = tensors.map(function (t) { return _this.readSync(t.dataId); });\n        var result = ops.buffer(tensors[0].shape, tensors[0].dtype);\n        var resultVals = result.values;\n        for (var i = 0; i < tensors.length; i++) {\n            var currVals = vals[i];\n            for (var j = 0; j < resultVals.length; j++) {\n                resultVals[j] += currVals[j];\n            }\n        }\n        return result.toTensor();\n    };\n    MathBackendCPU.prototype.subtract = function (a, b) {\n        if (a.dtype === 'complex64' || b.dtype === 'complex64') {\n            return this.broadcastedBinaryComplexOp(a.cast('complex64'), b.cast('complex64'), function (aReal, aImag, bReal, bImag) {\n                return { real: aReal - bReal, imag: aImag - bImag };\n            });\n        }\n        return this.broadcastedBinaryOp(a, b, types_1.upcastType(a.dtype, b.dtype), function (aValue, bValue) { return aValue - bValue; });\n    };\n    MathBackendCPU.prototype.pow = function (a, b) {\n        this.assertNotComplex([a, b], 'pow');\n        return this.broadcastedBinaryOp(a, b, a.dtype, function (aValue, bValue) { return Math.pow(aValue, bValue); });\n    };\n    MathBackendCPU.prototype.batchMatMul = function (a, b, transposeA, transposeB) {\n        this.assertNotComplex([a, b], 'matMul');\n        var sharedDim = transposeA ? a.shape[1] : a.shape[2];\n        var leftDim = transposeA ? a.shape[2] : a.shape[1];\n        var rightDim = transposeB ? b.shape[1] : b.shape[2];\n        var batchDim = a.shape[0];\n        var aValues = this.readSync(a.dataId);\n        var bValues = this.readSync(b.dataId);\n        var _a = transposeA ?\n            [a.strides[0], 1, a.strides[1]] :\n            [a.strides[0], a.strides[1], 1], aBatch = _a[0], aOuterStep = _a[1], aInnerStep = _a[2];\n        var _b = transposeB ?\n            [1, b.strides[1], b.strides[0]] :\n            [b.strides[1], 1, b.strides[0]], bInnerStep = _b[0], bOuterStep = _b[1], bBatch = _b[2];\n        var size = leftDim * rightDim;\n        var result = ops_1.buffer([batchDim, leftDim, rightDim], a.dtype);\n        var resVals = result.values;\n        var blockSize = this.blockSize;\n        for (var b_1 = 0; b_1 < batchDim; b_1++) {\n            for (var i0 = 0; i0 < leftDim; i0 += blockSize) {\n                for (var j0 = 0; j0 < rightDim; j0 += blockSize) {\n                    for (var k0 = 0; k0 < sharedDim; k0 += blockSize) {\n                        // for when blockSize doesn't evenly divide the input\n                        var iBlock = Math.min(i0 + blockSize, leftDim);\n                        var jBlock = Math.min(j0 + blockSize, rightDim);\n                        var kBlock = Math.min(k0 + blockSize, sharedDim);\n                        for (var i = i0; i < iBlock; i++) {\n                            for (var j = j0; j < jBlock; j++) {\n                                var sum = 0.0;\n                                for (var k = k0; k < kBlock; k++) {\n                                    sum += aValues[b_1 * aBatch + i * aOuterStep + k * aInnerStep] *\n                                        bValues[k * bInnerStep + j * bOuterStep + b_1 * bBatch];\n                                }\n                                resVals[b_1 * size + (i * rightDim + j)] += sum;\n                            }\n                        }\n                    }\n                }\n            }\n        }\n        return result.toTensor();\n    };\n    MathBackendCPU.prototype.fusedBatchMatMul = function (a, b, transposeA, transposeB, bias, activation) {\n        var result = this.batchMatMul(a, b, transposeA, transposeB);\n        if (bias) {\n            result = this.add(result, bias);\n        }\n        if (activation) {\n            result = mapActivation(this, activation, result);\n        }\n        return result;\n    };\n    MathBackendCPU.prototype.multiply = function (a, b) {\n        if (a.dtype === 'complex64' || b.dtype === 'complex64') {\n            return this.broadcastedBinaryComplexOp(a.cast('complex64'), b.cast('complex64'), function (aReal, aImag, bReal, bImag) {\n                return {\n                    real: aReal * bReal - aImag * bImag,\n                    imag: aReal * bImag + aImag * bReal\n                };\n            });\n        }\n        return this.broadcastedBinaryOp(a, b, types_1.upcastType(a.dtype, b.dtype), function (aValue, bValue) { return aValue * bValue; });\n    };\n    MathBackendCPU.prototype.realDivide = function (a, b) {\n        this.assertNotComplex([a, b], 'realDivide');\n        var op = function (a, b) { return a / b; };\n        var outputDtype = 'float32';\n        return this.broadcastedBinaryOp(a, b, outputDtype, op);\n    };\n    MathBackendCPU.prototype.floorDiv = function (a, b) {\n        this.assertNotComplex([a, b], 'floorDiv');\n        var op = function (a, b) { return Math.floor(a / b); };\n        var outputDtype = 'int32';\n        return this.broadcastedBinaryOp(a, b, outputDtype, op);\n    };\n    MathBackendCPU.prototype.sum = function (x, axes) {\n        this.assertNotComplex(x, 'sum');\n        axis_util.assertAxesAreInnerMostDims('sum', axes, x.rank);\n        var _a = axis_util.computeOutAndReduceShapes(x.shape, axes), outShape = _a[0], reduceShape = _a[1];\n        var resultDtype = types_1.upcastType(x.dtype, 'int32');\n        var result = ops.zeros(outShape, resultDtype);\n        var reduceSize = util.sizeFromShape(reduceShape);\n        var vals = this.readSync(result.dataId);\n        var aVals = this.readSync(x.dataId);\n        for (var i = 0; i < vals.length; ++i) {\n            var offset = i * reduceSize;\n            var sum = 0;\n            for (var j = 0; j < reduceSize; ++j) {\n                sum += aVals[offset + j];\n            }\n            vals[i] = sum;\n        }\n        return result;\n    };\n    MathBackendCPU.prototype.prod = function (x, axes) {\n        this.assertNotComplex(x, 'sum');\n        var _a = axis_util.computeOutAndReduceShapes(x.shape, axes), outShape = _a[0], reduceShape = _a[1];\n        var resultDtype = types_1.upcastType(x.dtype, 'int32');\n        var result = ops.zeros(outShape, resultDtype);\n        var reduceSize = util.sizeFromShape(reduceShape);\n        var vals = this.readSync(result.dataId);\n        var aVals = this.readSync(x.dataId);\n        for (var i = 0; i < vals.length; ++i) {\n            var offset = i * reduceSize;\n            var prod = 1;\n            for (var j = 0; j < reduceSize; ++j) {\n                prod *= aVals[offset + j];\n            }\n            vals[i] = prod;\n        }\n        return result;\n    };\n    MathBackendCPU.prototype.unsortedSegmentSum = function (x, segmentIds, numSegments) {\n        this.assertNotComplex(x, 'unsortedSegmentSum');\n        var res = [];\n        // Reshape the segment id's so that they can be broadcast with\n        // x. The new shape should be [segmentIds.shape, 1, ..., 1]\n        var numIters = x.rank - segmentIds.rank;\n        for (var i = 0; i < numIters; ++i) {\n            segmentIds = segmentIds.expandDims(i + 1);\n        }\n        for (var i = 0; i < numSegments; ++i) {\n            var segmentId = ops.scalar(i, 'int32');\n            var mask = ops.equal(segmentId, segmentIds).asType('float32');\n            var sum = mask.mul(x).sum(0);\n            res.push(sum);\n        }\n        return ops.stack(res);\n    };\n    MathBackendCPU.prototype.argMin = function (x, axis) {\n        this.assertNotComplex(x, 'argMin');\n        var axes = [axis];\n        axis_util.assertAxesAreInnerMostDims('argMin', axes, x.rank);\n        var _a = axis_util.computeOutAndReduceShapes(x.shape, axes), outShape = _a[0], reduceShape = _a[1];\n        var result = ops.zeros(outShape, 'int32');\n        var reduceSize = util.sizeFromShape(reduceShape);\n        var vals = this.readSync(result.dataId);\n        var aVals = this.readSync(x.dataId);\n        for (var i = 0; i < vals.length; ++i) {\n            var offset = i * reduceSize;\n            var min = aVals[offset];\n            var minIndex = 0;\n            for (var j = 0; j < reduceSize; ++j) {\n                var value = aVals[offset + j];\n                if (value < min) {\n                    min = value;\n                    minIndex = j;\n                }\n            }\n            vals[i] = minIndex;\n        }\n        return result;\n    };\n    MathBackendCPU.prototype.argMax = function (x, axis) {\n        this.assertNotComplex(x, 'argMax');\n        var axes = [axis];\n        axis_util.assertAxesAreInnerMostDims('argMax', axes, x.rank);\n        var _a = axis_util.computeOutAndReduceShapes(x.shape, axes), outShape = _a[0], reduceShape = _a[1];\n        var result = ops.zeros(outShape, 'int32');\n        var reduceSize = util.sizeFromShape(reduceShape);\n        var vals = this.readSync(result.dataId);\n        var aVals = this.readSync(x.dataId);\n        for (var i = 0; i < vals.length; ++i) {\n            var offset = i * reduceSize;\n            var max = aVals[offset];\n            var maxIndex = 0;\n            for (var j = 0; j < reduceSize; ++j) {\n                var value = aVals[offset + j];\n                if (value > max) {\n                    max = value;\n                    maxIndex = j;\n                }\n            }\n            vals[i] = maxIndex;\n        }\n        return result;\n    };\n    MathBackendCPU.prototype.cumsum = function (x, axis, exclusive, reverse) {\n        this.assertNotComplex(x, 'cumsum');\n        if (axis !== x.rank - 1) {\n            throw new Error(\"backend.cumsum in CPU expects an inner-most axis=\" + (x.rank - 1) + \" \" +\n                (\"but got axis=\" + axis));\n        }\n        var resultDtype = types_1.upcastType(x.dtype, 'int32');\n        var result = ops.zeros(x.shape, resultDtype);\n        var vals = this.readSync(result.dataId);\n        var aVals = this.readSync(x.dataId);\n        var finalDim = x.shape[x.rank - 1];\n        var indexAdjuster = reverse ?\n            function (i, j) { return i + finalDim - j - 1; } :\n            function (i, j) { return i + j; };\n        for (var i = 0; i < aVals.length; i += finalDim) {\n            for (var j = 0; j < finalDim; j++) {\n                var idx = indexAdjuster(i, j);\n                if (j === 0) {\n                    vals[idx] = exclusive ? 0 : aVals[idx];\n                }\n                else {\n                    var prevIdx = indexAdjuster(i, j - 1);\n                    vals[idx] = exclusive ? aVals[prevIdx] + vals[prevIdx] :\n                        aVals[idx] + vals[prevIdx];\n                }\n            }\n        }\n        return result;\n    };\n    MathBackendCPU.prototype.equal = function (a, b) {\n        this.assertNotComplex([a, b], 'equal');\n        return this.broadcastedBinaryOp(a, b, 'bool', function (aVal, bVal) {\n            return (aVal === bVal) ? 1 : 0;\n        });\n    };\n    MathBackendCPU.prototype.notEqual = function (a, b) {\n        this.assertNotComplex([a, b], 'notEqual');\n        return this.broadcastedBinaryOp(a, b, 'bool', function (aVal, bVal) {\n            return (aVal !== bVal) ? 1 : 0;\n        });\n    };\n    MathBackendCPU.prototype.less = function (a, b) {\n        this.assertNotComplex([a, b], 'less');\n        return this.broadcastedBinaryOp(a, b, 'bool', function (aVal, bVal) {\n            return (aVal < bVal) ? 1 : 0;\n        });\n    };\n    MathBackendCPU.prototype.lessEqual = function (a, b) {\n        this.assertNotComplex([a, b], 'lessEqual');\n        return this.broadcastedBinaryOp(a, b, 'bool', function (aVal, bVal) {\n            return (aVal <= bVal) ? 1 : 0;\n        });\n    };\n    MathBackendCPU.prototype.greater = function (a, b) {\n        this.assertNotComplex([a, b], 'greater');\n        return this.broadcastedBinaryOp(a, b, 'bool', function (aVal, bVal) {\n            return (aVal > bVal) ? 1 : 0;\n        });\n    };\n    MathBackendCPU.prototype.greaterEqual = function (a, b) {\n        this.assertNotComplex([a, b], 'greaterEqual');\n        return this.broadcastedBinaryOp(a, b, 'bool', function (aVal, bVal) {\n            return (aVal >= bVal) ? 1 : 0;\n        });\n    };\n    MathBackendCPU.prototype.logicalNot = function (x) {\n        this.assertNotComplex(x, 'logicalNot');\n        var values = this.readSync(x.dataId);\n        var newValues = new Uint8Array(values.length);\n        for (var i = 0; i < values.length; ++i) {\n            newValues[i] = values[i] ? 0 : 1;\n        }\n        return tensor_1.Tensor.make(x.shape, { values: newValues }, 'bool');\n    };\n    MathBackendCPU.prototype.logicalAnd = function (a, b) {\n        this.assertNotComplex([a, b], 'logicalAnd');\n        return this.broadcastedBinaryOp(a, b, 'bool', function (aVal, bVal) {\n            return aVal && bVal;\n        });\n    };\n    MathBackendCPU.prototype.logicalOr = function (a, b) {\n        this.assertNotComplex([a, b], 'logicalOr');\n        return this.broadcastedBinaryOp(a, b, 'bool', function (aVal, bVal) {\n            return aVal || bVal;\n        });\n    };\n    MathBackendCPU.prototype.select = function (condition, a, b) {\n        this.assertNotComplex([condition, a, b], 'select');\n        var values = this.readSync(condition.dataId);\n        var aValues = this.readSync(a.dataId);\n        var bValues = this.readSync(b.dataId);\n        var result = ops.zeros(a.shape, types_1.upcastType(a.dtype, b.dtype));\n        var newValues = this.readSync(result.dataId);\n        var index = 0;\n        var offset = condition.rank === 0 || condition.rank > 1 || a.rank === 1 ?\n            1 :\n            a.shape[1];\n        for (var i = 0; i < values.length; i++) {\n            for (var j = 0; j < offset; j++) {\n                if (values[i] === 1) {\n                    newValues[index++] = aValues[i];\n                }\n                else {\n                    newValues[index++] = bValues[i];\n                }\n            }\n        }\n        return result;\n    };\n    MathBackendCPU.prototype.where = function (condition) {\n        this.assertNotComplex([condition], 'where');\n        var condVals = this.readSync(condition.dataId);\n        return where_impl_1.whereImpl(condition.shape, condVals);\n    };\n    MathBackendCPU.prototype.topk = function (x, k, sorted) {\n        this.assertNotComplex(x, 'topk');\n        var xVals = this.readSync(x.dataId);\n        return topk_impl_1.topkImpl(xVals, x.shape, x.dtype, k, sorted);\n    };\n    MathBackendCPU.prototype.min = function (x, axes) {\n        this.assertNotComplex(x, 'min');\n        axis_util.assertAxesAreInnerMostDims('min', axes, x.rank);\n        var _a = axis_util.computeOutAndReduceShapes(x.shape, axes), outShape = _a[0], reduceShape = _a[1];\n        var result = ops.zeros(outShape, x.dtype);\n        var reduceSize = util.sizeFromShape(reduceShape);\n        var vals = this.readSync(result.dataId);\n        var aVals = this.readSync(x.dataId);\n        for (var i = 0; i < vals.length; ++i) {\n            var offset = i * reduceSize;\n            var min = aVals[offset];\n            for (var j = 0; j < reduceSize; ++j) {\n                var value = aVals[offset + j];\n                if (value < min) {\n                    min = value;\n                }\n            }\n            vals[i] = min;\n        }\n        return result;\n    };\n    MathBackendCPU.prototype.minimum = function (a, b) {\n        this.assertNotComplex([a, b], 'minimum');\n        return this.broadcastedBinaryOp(a, b, a.dtype, function (aVal, bVal) { return Math.min(aVal, bVal); });\n    };\n    MathBackendCPU.prototype.mod = function (a, b) {\n        this.assertNotComplex([a, b], 'mod');\n        return this.broadcastedBinaryOp(a, b, a.dtype, function (aVal, bVal) {\n            var rem = aVal % bVal;\n            if ((aVal < 0 && bVal < 0) || (aVal >= 0 && bVal >= 0)) {\n                return rem;\n            }\n            else {\n                return (rem + bVal) % bVal;\n            }\n        });\n    };\n    MathBackendCPU.prototype.max = function (x, axes) {\n        this.assertNotComplex(x, 'max');\n        axis_util.assertAxesAreInnerMostDims('max', axes, x.rank);\n        var _a = axis_util.computeOutAndReduceShapes(x.shape, axes), outShape = _a[0], reduceShape = _a[1];\n        var result = ops.zeros(outShape, x.dtype);\n        var reduceSize = util.sizeFromShape(reduceShape);\n        var vals = this.readSync(result.dataId);\n        var aVals = this.readSync(x.dataId);\n        for (var i = 0; i < vals.length; ++i) {\n            var offset = i * reduceSize;\n            var max = aVals[offset];\n            for (var j = 0; j < reduceSize; ++j) {\n                var value = aVals[offset + j];\n                if (value > max) {\n                    max = value;\n                }\n            }\n            vals[i] = max;\n        }\n        return result;\n    };\n    MathBackendCPU.prototype.maximum = function (a, b) {\n        this.assertNotComplex([a, b], 'maximum');\n        return this.broadcastedBinaryOp(a, b, a.dtype, function (aVal, bVal) { return Math.max(aVal, bVal); });\n    };\n    MathBackendCPU.prototype.all = function (x, axes) {\n        this.assertNotComplex(x, 'all');\n        axis_util.assertAxesAreInnerMostDims('all', axes, x.rank);\n        var _a = axis_util.computeOutAndReduceShapes(x.shape, axes), outShape = _a[0], reduceShape = _a[1];\n        var result = ops.zeros(outShape, x.dtype);\n        var reduceSize = util.sizeFromShape(reduceShape);\n        var vals = this.readSync(result.dataId);\n        var aVals = this.readSync(x.dataId);\n        for (var i = 0; i < vals.length; ++i) {\n            var offset = i * reduceSize;\n            var all = aVals[offset];\n            for (var j = 0; j < reduceSize; ++j) {\n                var value = aVals[offset + j];\n                all = all && value;\n            }\n            vals[i] = all;\n        }\n        return result;\n    };\n    MathBackendCPU.prototype.any = function (x, axes) {\n        this.assertNotComplex(x, 'any');\n        axis_util.assertAxesAreInnerMostDims('any', axes, x.rank);\n        var _a = axis_util.computeOutAndReduceShapes(x.shape, axes), outShape = _a[0], reduceShape = _a[1];\n        var result = ops.zeros(outShape, x.dtype);\n        var reduceSize = util.sizeFromShape(reduceShape);\n        var vals = this.readSync(result.dataId);\n        var aVals = this.readSync(x.dataId);\n        for (var i = 0; i < vals.length; ++i) {\n            var offset = i * reduceSize;\n            var anyVal = aVals[offset];\n            for (var j = 0; j < reduceSize; ++j) {\n                var value = aVals[offset + j];\n                anyVal = anyVal || value;\n            }\n            vals[i] = anyVal;\n        }\n        return result;\n    };\n    MathBackendCPU.prototype.squaredDifference = function (a, b) {\n        this.assertNotComplex([a, b], 'squaredDifference');\n        return this.broadcastedBinaryOp(a, b, a.dtype, function (aVal, bVal) {\n            var diff = aVal - bVal;\n            return diff * diff;\n        });\n    };\n    MathBackendCPU.prototype.ceil = function (x) {\n        this.assertNotComplex(x, 'ceil');\n        var values = this.readSync(x.dataId);\n        var newValues = new Float32Array(values.length);\n        for (var i = 0; i < values.length; ++i) {\n            newValues[i] = Math.ceil(values[i]);\n        }\n        return tensor_1.Tensor.make(x.shape, { values: newValues });\n    };\n    MathBackendCPU.prototype.floor = function (x) {\n        this.assertNotComplex(x, 'floor');\n        var values = this.readSync(x.dataId);\n        var newValues = new Float32Array(values.length);\n        for (var i = 0; i < values.length; ++i) {\n            newValues[i] = Math.floor(values[i]);\n        }\n        return tensor_1.Tensor.make(x.shape, { values: newValues });\n    };\n    MathBackendCPU.prototype.sign = function (x) {\n        this.assertNotComplex(x, 'x');\n        var values = this.readSync(x.dataId);\n        var newValues = new Float32Array(values.length);\n        for (var i = 0; i < values.length; ++i) {\n            if (values[i] < 0) {\n                newValues[i] = -1;\n            }\n            else if (values[i] > 0) {\n                newValues[i] = 1;\n            }\n            else {\n                newValues[i] = 0;\n            }\n        }\n        return tensor_1.Tensor.make(x.shape, { values: newValues });\n    };\n    MathBackendCPU.prototype.isNaN = function (x) {\n        this.assertNotComplex(x, 'x');\n        var values = this.readSync(x.dataId);\n        var newValues = new Uint8Array(values.length);\n        for (var i = 0; i < values.length; ++i) {\n            if (Number.isNaN(values[i])) {\n                newValues[i] = 1;\n            }\n        }\n        return tensor_1.Tensor.make(x.shape, { values: newValues }, 'bool');\n    };\n    MathBackendCPU.prototype.isInf = function (x) {\n        this.assertNotComplex(x, 'x');\n        var values = this.readSync(x.dataId);\n        var newValues = new Uint8Array(values.length);\n        for (var i = 0; i < values.length; ++i) {\n            if (Math.abs(values[i]) === Infinity) {\n                newValues[i] = 1;\n            }\n        }\n        return tensor_1.Tensor.make(x.shape, { values: newValues }, 'bool');\n    };\n    MathBackendCPU.prototype.isFinite = function (x) {\n        this.assertNotComplex(x, 'x');\n        var values = this.readSync(x.dataId);\n        var newValues = new Uint8Array(values.length);\n        for (var i = 0; i < values.length; ++i) {\n            if (Number.isFinite(values[i])) {\n                newValues[i] = 1;\n            }\n        }\n        return tensor_1.Tensor.make(x.shape, { values: newValues }, 'bool');\n    };\n    MathBackendCPU.prototype.round = function (x) {\n        this.assertNotComplex(x, 'round');\n        var values = this.readSync(x.dataId);\n        var newValues = new Float32Array(values.length);\n        for (var i = 0; i < values.length; ++i) {\n            // The algorithm is based on banker's rounding.\n            var base = Math.floor(values[i]);\n            if (values[i] - base < 0.5) {\n                newValues[i] = Math.floor(values[i]);\n            }\n            else if (values[i] - base > 0.5) {\n                newValues[i] = Math.ceil(values[i]);\n            }\n            else {\n                if (base % 2.0 === 0.0) {\n                    newValues[i] = base;\n                }\n                else {\n                    newValues[i] = base + 1.0;\n                }\n            }\n        }\n        return tensor_1.Tensor.make(x.shape, { values: newValues });\n    };\n    MathBackendCPU.prototype.exp = function (x) {\n        this.assertNotComplex(x, 'exp');\n        var values = this.readSync(x.dataId);\n        var newValues = new Float32Array(values.length);\n        for (var i = 0; i < values.length; ++i) {\n            newValues[i] = Math.exp(values[i]);\n        }\n        return tensor_1.Tensor.make(x.shape, { values: newValues });\n    };\n    MathBackendCPU.prototype.expm1 = function (x) {\n        this.assertNotComplex(x, 'expm1');\n        var values = this.readSync(x.dataId);\n        var newValues = new Float32Array(values.length);\n        for (var i = 0; i < values.length; ++i) {\n            newValues[i] = Math.expm1(values[i]);\n        }\n        return tensor_1.Tensor.make(x.shape, { values: newValues });\n    };\n    MathBackendCPU.prototype.log = function (x) {\n        this.assertNotComplex(x, 'log');\n        var values = this.readSync(x.dataId);\n        var newValues = new Float32Array(values.length);\n        for (var i = 0; i < values.length; ++i) {\n            var value = values[i];\n            newValues[i] = Math.log(value);\n        }\n        return tensor_1.Tensor.make(x.shape, { values: newValues });\n    };\n    MathBackendCPU.prototype.log1p = function (x) {\n        this.assertNotComplex(x, 'log1p');\n        var values = this.readSync(x.dataId);\n        var newValues = new Float32Array(values.length);\n        for (var i = 0; i < values.length; ++i) {\n            var value = values[i];\n            newValues[i] = Math.log1p(value);\n        }\n        return tensor_1.Tensor.make(x.shape, { values: newValues });\n    };\n    MathBackendCPU.prototype.sqrt = function (x) {\n        this.assertNotComplex(x, 'sqrt');\n        var values = this.readSync(x.dataId);\n        var newValues = new Float32Array(values.length);\n        for (var i = 0; i < values.length; ++i) {\n            var value = values[i];\n            newValues[i] = Math.sqrt(value);\n        }\n        return tensor_1.Tensor.make(x.shape, { values: newValues });\n    };\n    MathBackendCPU.prototype.rsqrt = function (x) {\n        this.assertNotComplex(x, 'rsqrt');\n        var values = this.readSync(x.dataId);\n        var newValues = new Float32Array(values.length);\n        for (var i = 0; i < values.length; ++i) {\n            var value = values[i];\n            newValues[i] = 1 / Math.sqrt(value);\n        }\n        return tensor_1.Tensor.make(x.shape, { values: newValues });\n    };\n    MathBackendCPU.prototype.square = function (x) {\n        this.assertNotComplex(x, 'square');\n        var values = this.readSync(x.dataId);\n        var newValues = new Float32Array(values.length);\n        for (var i = 0; i < values.length; ++i) {\n            var value = values[i];\n            newValues[i] = value * value;\n        }\n        return tensor_1.Tensor.make(x.shape, { values: newValues });\n    };\n    MathBackendCPU.prototype.reciprocal = function (x) {\n        this.assertNotComplex(x, 'reciprocal');\n        var values = this.readSync(x.dataId);\n        var newValues = new Float32Array(values.length);\n        for (var i = 0; i < values.length; ++i) {\n            newValues[i] = 1 / values[i];\n        }\n        return tensor_1.Tensor.make(x.shape, { values: newValues });\n    };\n    MathBackendCPU.prototype.linear = function (x) {\n        return x;\n    };\n    MathBackendCPU.prototype.relu = function (x) {\n        this.assertNotComplex(x, 'relu');\n        var res = ops.zeros(x.shape, x.dtype);\n        var resVals = this.readSync(res.dataId);\n        var inVals = this.readSync(x.dataId);\n        for (var i = 0; i < inVals.length; ++i) {\n            resVals[i] = Math.max(0, inVals[i]);\n        }\n        return res;\n    };\n    MathBackendCPU.prototype.prelu = function (x, a) {\n        this.assertNotComplex([x, a], 'prelu');\n        return this.broadcastedBinaryOp(x, a, x.dtype, function (xValue, aValue) { return xValue < 0 ? aValue * xValue : xValue; });\n    };\n    MathBackendCPU.prototype.elu = function (x) {\n        this.assertNotComplex(x, 'elu');\n        var resultValues = new Float32Array(x.size);\n        var values = this.readSync(x.dataId);\n        for (var i = 0; i < values.length; ++i) {\n            var v = values[i];\n            if (v >= 0) {\n                resultValues[i] = v;\n            }\n            else {\n                resultValues[i] = (Math.exp(v) - 1);\n            }\n        }\n        return tensor_1.Tensor.make(x.shape, { values: resultValues });\n    };\n    MathBackendCPU.prototype.eluDer = function (dy, y) {\n        this.assertNotComplex([dy, y], 'eluDer');\n        var resultValues = new Float32Array(y.size);\n        var values = this.readSync(y.dataId);\n        var dyValues = this.readSync(dy.dataId);\n        for (var i = 0; i < values.length; ++i) {\n            var v = values[i];\n            if (v >= 1) {\n                resultValues[i] = dyValues[i];\n            }\n            else {\n                resultValues[i] = dyValues[i] * (v + 1);\n            }\n        }\n        return tensor_1.Tensor.make(y.shape, { values: resultValues });\n    };\n    MathBackendCPU.prototype.selu = function (x) {\n        this.assertNotComplex(x, 'selu');\n        // Stable and Attracting Fixed Point (0, 1) for Normalized Weights.\n        // see: https://arxiv.org/abs/1706.02515\n        var scaleAlpha = selu_util.SELU_SCALEALPHA;\n        var scale = selu_util.SELU_SCALE;\n        var resultValues = new Float32Array(x.size);\n        var values = this.readSync(x.dataId);\n        for (var i = 0; i < values.length; ++i) {\n            var v = values[i];\n            if (v >= 0) {\n                resultValues[i] = scale * v;\n            }\n            else {\n                resultValues[i] = scaleAlpha * (Math.exp(v) - 1);\n            }\n        }\n        return tensor_1.Tensor.make(x.shape, { values: resultValues });\n    };\n    MathBackendCPU.prototype.clip = function (x, min, max) {\n        this.assertNotComplex(x, 'clip');\n        var resultValues = new Float32Array(x.size);\n        var values = this.readSync(x.dataId);\n        for (var i = 0; i < values.length; ++i) {\n            var v = values[i];\n            resultValues[i] = v > max ? max : (v < min ? min : v);\n        }\n        return tensor_1.Tensor.make(x.shape, { values: resultValues });\n    };\n    MathBackendCPU.prototype.abs = function (x) {\n        var resultValues = new Float32Array(x.size);\n        var values = this.readSync(x.dataId);\n        for (var i = 0; i < values.length; ++i) {\n            resultValues[i] = Math.abs(values[i]);\n        }\n        return tensor_1.Tensor.make(x.shape, { values: resultValues });\n    };\n    MathBackendCPU.prototype.complexAbs = function (x) {\n        var resultValues = new Float32Array(x.size);\n        var values = this.readSync(x.dataId);\n        for (var i = 0; i < x.size; ++i) {\n            var real = values[i * 2];\n            var imag = values[i * 2 + 1];\n            resultValues[i] = Math.hypot(real, imag);\n        }\n        return tensor_1.Tensor.make(x.shape, { values: resultValues });\n    };\n    MathBackendCPU.prototype.int = function (x) {\n        this.assertNotComplex(x, 'int');\n        var resultValues = new Int32Array(x.size);\n        var values = this.readSync(x.dataId);\n        for (var i = 0; i < values.length; ++i) {\n            resultValues[i] = values[i];\n        }\n        return tensor_1.Tensor.make(x.shape, { values: resultValues }, 'int32');\n    };\n    MathBackendCPU.prototype.sigmoid = function (x) {\n        this.assertNotComplex(x, 'sigmoid');\n        var resultValues = new Float32Array(x.size);\n        var values = this.readSync(x.dataId);\n        for (var i = 0; i < values.length; ++i) {\n            resultValues[i] = 1 / (1 + Math.exp(-values[i]));\n        }\n        return tensor_1.Tensor.make(x.shape, { values: resultValues });\n    };\n    MathBackendCPU.prototype.softplus = function (x) {\n        this.assertNotComplex(x, 'softplus');\n        // mirrors the implementation of tf.nn.softplus: https://goo.gl/vkcvwX\n        // epsilon is the difference between 1.0 and the next representable float.\n        // For a single precision 32 bit float this should be 2^-23, see:\n        // https://math.byu.edu/~schow/work/IEEEFloatingPoint.htm\n        var epsilon = 1.1920928955078125e-7;\n        var threshold = Math.log(epsilon) + 2.0;\n        var resultValues = new Float32Array(x.size);\n        var values = this.readSync(x.dataId);\n        for (var i = 0; i < values.length; ++i) {\n            // Value above which exp(x) may overflow, but softplus(x) == x\n            // is within machine epsilon.\n            var tooLarge = values[i] > -threshold;\n            // Value below which exp(x) may underflow, but softplus(x) == exp(x)\n            // is within machine epsilon.\n            var tooSmall = values[i] < threshold;\n            var expX = Math.exp(values[i]);\n            var result = void 0;\n            if (tooSmall) {\n                result = expX;\n            }\n            else if (tooLarge) {\n                result = values[i];\n            }\n            else {\n                result = Math.log(1.0 + expX);\n            }\n            resultValues[i] = result;\n        }\n        return tensor_1.Tensor.make(x.shape, { values: resultValues });\n    };\n    MathBackendCPU.prototype.sin = function (x) {\n        this.assertNotComplex(x, 'sin');\n        var resultValues = new Float32Array(x.size);\n        var values = this.readSync(x.dataId);\n        for (var i = 0; i < values.length; ++i) {\n            resultValues[i] = Math.sin(values[i]);\n        }\n        return tensor_1.Tensor.make(x.shape, { values: resultValues });\n    };\n    MathBackendCPU.prototype.cos = function (x) {\n        this.assertNotComplex(x, 'cos');\n        var resultValues = new Float32Array(x.size);\n        var values = this.readSync(x.dataId);\n        for (var i = 0; i < values.length; ++i) {\n            resultValues[i] = Math.cos(values[i]);\n        }\n        return tensor_1.Tensor.make(x.shape, { values: resultValues });\n    };\n    MathBackendCPU.prototype.tan = function (x) {\n        this.assertNotComplex(x, 'tan');\n        var resultValues = new Float32Array(x.size);\n        var values = this.readSync(x.dataId);\n        for (var i = 0; i < values.length; ++i) {\n            resultValues[i] = Math.tan(values[i]);\n        }\n        return tensor_1.Tensor.make(x.shape, { values: resultValues });\n    };\n    MathBackendCPU.prototype.asin = function (x) {\n        this.assertNotComplex(x, 'asin');\n        var resultValues = new Float32Array(x.size);\n        var values = this.readSync(x.dataId);\n        for (var i = 0; i < values.length; ++i) {\n            resultValues[i] = Math.asin(values[i]);\n        }\n        return tensor_1.Tensor.make(x.shape, { values: resultValues });\n    };\n    MathBackendCPU.prototype.acos = function (x) {\n        this.assertNotComplex(x, 'acos');\n        var resultValues = new Float32Array(x.size);\n        var values = this.readSync(x.dataId);\n        for (var i = 0; i < values.length; ++i) {\n            resultValues[i] = Math.acos(values[i]);\n        }\n        return tensor_1.Tensor.make(x.shape, { values: resultValues });\n    };\n    MathBackendCPU.prototype.atan = function (x) {\n        this.assertNotComplex(x, 'atan');\n        var resultValues = new Float32Array(x.size);\n        var values = this.readSync(x.dataId);\n        for (var i = 0; i < values.length; ++i) {\n            resultValues[i] = Math.atan(values[i]);\n        }\n        return tensor_1.Tensor.make(x.shape, { values: resultValues });\n    };\n    MathBackendCPU.prototype.atan2 = function (a, b) {\n        this.assertNotComplex([a, b], 'atan2');\n        return this.broadcastedBinaryOp(a, b, a.dtype, function (aValue, bValue) { return Math.atan2(aValue, bValue); });\n    };\n    MathBackendCPU.prototype.sinh = function (x) {\n        this.assertNotComplex(x, 'sinh');\n        var resultValues = new Float32Array(x.size);\n        var values = this.readSync(x.dataId);\n        for (var i = 0; i < values.length; ++i) {\n            resultValues[i] = Math.sinh(values[i]);\n        }\n        return tensor_1.Tensor.make(x.shape, { values: resultValues });\n    };\n    MathBackendCPU.prototype.cosh = function (x) {\n        this.assertNotComplex(x, 'cosh');\n        var resultValues = new Float32Array(x.size);\n        var values = this.readSync(x.dataId);\n        for (var i = 0; i < values.length; ++i) {\n            resultValues[i] = Math.cosh(values[i]);\n        }\n        return tensor_1.Tensor.make(x.shape, { values: resultValues });\n    };\n    MathBackendCPU.prototype.tanh = function (x) {\n        this.assertNotComplex(x, 'tanh');\n        var resultValues = new Float32Array(x.size);\n        var values = this.readSync(x.dataId);\n        for (var i = 0; i < values.length; ++i) {\n            resultValues[i] = util.tanh(values[i]);\n        }\n        return tensor_1.Tensor.make(x.shape, { values: resultValues });\n    };\n    MathBackendCPU.prototype.asinh = function (x) {\n        this.assertNotComplex(x, 'asinh');\n        var resultValues = new Float32Array(x.size);\n        var values = this.readSync(x.dataId);\n        for (var i = 0; i < values.length; ++i) {\n            resultValues[i] = Math.asinh(values[i]);\n        }\n        return tensor_1.Tensor.make(x.shape, { values: resultValues });\n    };\n    MathBackendCPU.prototype.acosh = function (x) {\n        this.assertNotComplex(x, 'acosh');\n        var resultValues = new Float32Array(x.size);\n        var values = this.readSync(x.dataId);\n        for (var i = 0; i < values.length; ++i) {\n            resultValues[i] = Math.acosh(values[i]);\n        }\n        return tensor_1.Tensor.make(x.shape, { values: resultValues });\n    };\n    MathBackendCPU.prototype.atanh = function (x) {\n        this.assertNotComplex(x, 'atanh');\n        var resultValues = new Float32Array(x.size);\n        var values = this.readSync(x.dataId);\n        for (var i = 0; i < values.length; ++i) {\n            resultValues[i] = Math.atanh(values[i]);\n        }\n        return tensor_1.Tensor.make(x.shape, { values: resultValues });\n    };\n    MathBackendCPU.prototype.erf = function (x) {\n        this.assertNotComplex(x, 'erf');\n        var resultValues = new Float32Array(x.size);\n        var values = this.readSync(x.dataId);\n        var p = erf_util.ERF_P;\n        var a1 = erf_util.ERF_A1;\n        var a2 = erf_util.ERF_A2;\n        var a3 = erf_util.ERF_A3;\n        var a4 = erf_util.ERF_A4;\n        var a5 = erf_util.ERF_A5;\n        for (var i = 0; i < values.length; ++i) {\n            var v = values[i];\n            var t = 1.0 / (1.0 + p * v);\n            resultValues[i] = 1.0 -\n                (((((a5 * t + a4) * t) + a3) * t + a2) * t + a1) * t *\n                    Math.exp(-v * v);\n        }\n        return tensor_1.Tensor.make(x.shape, { values: resultValues });\n    };\n    MathBackendCPU.prototype.step = function (x, alpha) {\n        if (alpha === void 0) { alpha = 0; }\n        this.assertNotComplex(x, 'step');\n        var resultValues = new Float32Array(x.size);\n        var values = this.readSync(x.dataId);\n        for (var i = 0; i < values.length; ++i) {\n            var value = values[i];\n            if (isNaN(value)) {\n                resultValues[i] = NaN;\n            }\n            else {\n                resultValues[i] = value > 0 ? 1 : alpha;\n            }\n        }\n        return tensor_1.Tensor.make(x.shape, { values: resultValues });\n    };\n    MathBackendCPU.prototype.conv2d = function (x, filter, convInfo) {\n        this.assertNotComplex([x, filter], 'conv2d');\n        var filterHeight = convInfo.filterHeight;\n        var filterWidth = convInfo.filterWidth;\n        var dilationHeight = convInfo.dilationHeight;\n        var dilationWidth = convInfo.dilationWidth;\n        var padLeft = convInfo.padInfo.left;\n        var padTop = convInfo.padInfo.top;\n        var y = ops.buffer(convInfo.outShape, x.dtype);\n        var xVals = this.readSync(x.dataId);\n        var wVals = this.readSync(filter.dataId);\n        var yVals = y.values;\n        for (var b = 0; b < convInfo.batchSize; ++b) {\n            var xOffset1 = b * x.strides[0];\n            var yOffset1 = b * y.strides[0];\n            for (var yR = 0; yR < convInfo.outHeight; ++yR) {\n                var yOffset2 = yOffset1 + yR * y.strides[1];\n                var xRCorner = yR * convInfo.strideHeight - padTop;\n                for (var wR = 0; wR < filterHeight; wR++) {\n                    var xR = xRCorner + wR * dilationHeight;\n                    if (xR < 0 || xR >= convInfo.inHeight) {\n                        continue;\n                    }\n                    var wOffset1 = wR * filter.strides[0];\n                    var xOffset2 = xOffset1 + xR * x.strides[1];\n                    for (var yC = 0; yC < convInfo.outWidth; ++yC) {\n                        var yOffset3 = yOffset2 + yC * convInfo.outChannels;\n                        var xCCorner = yC * convInfo.strideWidth - padLeft;\n                        for (var wC = 0; wC < filterWidth; wC++) {\n                            var xC = xCCorner + wC * dilationWidth;\n                            if (xC < 0 || xC >= convInfo.inWidth) {\n                                continue;\n                            }\n                            var wOffset2 = wOffset1 + wC * filter.strides[1];\n                            var xOffset3 = xOffset2 + xC * convInfo.inChannels;\n                            var wOffset3 = wOffset2;\n                            for (var d1 = 0; d1 < convInfo.inChannels; ++d1) {\n                                var xVal = xVals[xOffset3 + d1];\n                                for (var d2 = 0; d2 < convInfo.outChannels; ++d2) {\n                                    yVals[yOffset3 + d2] += xVal * wVals[wOffset3 + d2];\n                                }\n                                wOffset3 += convInfo.outChannels;\n                            }\n                        }\n                    }\n                }\n            }\n        }\n        return y.toTensor();\n    };\n    MathBackendCPU.prototype.conv3d = function (x, filter, convInfo) {\n        var filterDepth = convInfo.filterDepth;\n        var filterHeight = convInfo.filterHeight;\n        var filterWidth = convInfo.filterWidth;\n        var dilationDepth = convInfo.dilationDepth;\n        var dilationHeight = convInfo.dilationHeight;\n        var dilationWidth = convInfo.dilationWidth;\n        var padFront = convInfo.padInfo.front;\n        var padLeft = convInfo.padInfo.left;\n        var padTop = convInfo.padInfo.top;\n        var y = ops.buffer(convInfo.outShape, x.dtype);\n        var xVals = this.readSync(x.dataId);\n        var wVals = this.readSync(filter.dataId);\n        var yVals = y.values;\n        for (var b = 0; b < convInfo.batchSize; ++b) {\n            var xOffset1 = b * x.strides[0];\n            var yOffset1 = b * y.strides[0];\n            for (var yF = 0; yF < convInfo.outDepth; ++yF) {\n                var yOffset2 = yOffset1 + yF * y.strides[1];\n                var xFCorner = yF * convInfo.strideDepth - padFront;\n                for (var wF = 0; wF < filterDepth; wF++) {\n                    var xF = xFCorner + wF * dilationDepth;\n                    if (xF < 0 || xF >= convInfo.inDepth) {\n                        continue;\n                    }\n                    var wOffset1 = wF * filter.strides[0];\n                    var xOffset2 = xOffset1 + xF * x.strides[1];\n                    for (var yR = 0; yR < convInfo.outHeight; ++yR) {\n                        var yOffset3 = yOffset2 + yR * y.strides[2];\n                        var xRCorner = yR * convInfo.strideHeight - padTop;\n                        for (var wR = 0; wR < filterHeight; wR++) {\n                            var xR = xRCorner + wR * dilationHeight;\n                            if (xR < 0 || xR >= convInfo.inHeight) {\n                                continue;\n                            }\n                            var wOffset2 = wOffset1 + wR * filter.strides[1];\n                            var xOffset3 = xOffset2 + xR * x.strides[2];\n                            for (var yC = 0; yC < convInfo.outWidth; ++yC) {\n                                var yOffset4 = yOffset3 + yC * convInfo.outChannels;\n                                var xCCorner = yC * convInfo.strideWidth - padLeft;\n                                for (var wC = 0; wC < filterWidth; wC++) {\n                                    var xC = xCCorner + wC * dilationWidth;\n                                    if (xC < 0 || xC >= convInfo.inWidth) {\n                                        continue;\n                                    }\n                                    var wOffset3 = wOffset2 + wC * filter.strides[2];\n                                    var xOffset4 = xOffset3 + xC * convInfo.inChannels;\n                                    var wOffset4 = wOffset3;\n                                    for (var d1 = 0; d1 < convInfo.inChannels; ++d1) {\n                                        var xVal = xVals[xOffset4 + d1];\n                                        for (var d2 = 0; d2 < convInfo.outChannels; ++d2) {\n                                            yVals[yOffset4 + d2] += xVal * wVals[wOffset4 + d2];\n                                        }\n                                        wOffset4 += convInfo.outChannels;\n                                    }\n                                }\n                            }\n                        }\n                    }\n                }\n            }\n        }\n        return y.toTensor();\n    };\n    MathBackendCPU.prototype.conv2dDerInput = function (dy, filter, convInfo) {\n        this.assertNotComplex([dy, filter], 'conv2dDerInput');\n        var dx = ops.buffer(convInfo.inShape, 'float32');\n        var dxValues = dx.values;\n        var _a = dx.strides, dxS0 = _a[0], dxS1 = _a[1], dxS2 = _a[2];\n        var dyValues = this.readSync(dy.dataId);\n        var _b = dy.strides, dyS0 = _b[0], dyS1 = _b[1], dyS2 = _b[2];\n        var fltValues = this.readSync(filter.dataId);\n        var _c = filter.strides, fltS0 = _c[0], fltS1 = _c[1], fltS2 = _c[2];\n        var batchSize = convInfo.batchSize, filterHeight = convInfo.filterHeight, filterWidth = convInfo.filterWidth, inChannels = convInfo.inChannels, inHeight = convInfo.inHeight, inWidth = convInfo.inWidth, outChannels = convInfo.outChannels, outHeight = convInfo.outHeight, outWidth = convInfo.outWidth, strideHeight = convInfo.strideHeight, strideWidth = convInfo.strideWidth;\n        var topPad = filterHeight - 1 - convInfo.padInfo.top;\n        var leftPad = filterWidth - 1 - convInfo.padInfo.left;\n        for (var b = 0; b < batchSize; ++b) {\n            for (var d1 = 0; d1 < inChannels; ++d1) {\n                for (var xR = 0; xR < inHeight; ++xR) {\n                    var xRCorner = xR - topPad;\n                    var xRMin = Math.max(0, Math.ceil(xRCorner / strideHeight));\n                    var yRMax = Math.min(outHeight, (filterHeight + xRCorner) / strideHeight);\n                    for (var xC = 0; xC < inWidth; ++xC) {\n                        var xCCorner = xC - leftPad;\n                        var xCMin = Math.max(0, Math.ceil(xCCorner / strideWidth));\n                        var yCMax = Math.min(outWidth, (filterWidth + xCCorner) / strideWidth);\n                        var dotProd = 0;\n                        for (var yR = xRMin; yR < yRMax; ++yR) {\n                            var wR = yR * strideHeight - xRCorner;\n                            for (var yC = xCMin; yC < yCMax; ++yC) {\n                                var wC = yC * strideWidth - xCCorner;\n                                var dyOffset = dyS0 * b + dyS1 * yR + dyS2 * yC;\n                                var fltOffset = fltS0 * (filterHeight - 1 - wR) +\n                                    fltS1 * (filterWidth - 1 - wC) + fltS2 * d1;\n                                for (var d2 = 0; d2 < outChannels; ++d2) {\n                                    var pixel = dyValues[dyOffset + d2];\n                                    var weight = fltValues[fltOffset + d2];\n                                    dotProd += pixel * weight;\n                                }\n                            }\n                        }\n                        dxValues[dxS0 * b + dxS1 * xR + dxS2 * xC + d1] = dotProd;\n                    }\n                }\n            }\n        }\n        return dx.toTensor();\n    };\n    MathBackendCPU.prototype.conv3dDerInput = function (dy, filter, convInfo) {\n        var dx = ops.buffer(convInfo.inShape, 'float32');\n        var dxValues = dx.values;\n        var _a = dx.strides, dxS0 = _a[0], dxS1 = _a[1], dxS2 = _a[2], dxS3 = _a[3];\n        var dyValues = this.readSync(dy.dataId);\n        var _b = dy.strides, dyS0 = _b[0], dyS1 = _b[1], dyS2 = _b[2], dyS3 = _b[3];\n        var fltValues = this.readSync(filter.dataId);\n        var _c = filter.strides, fltS0 = _c[0], fltS1 = _c[1], fltS2 = _c[2], fltS3 = _c[3];\n        var batchSize = convInfo.batchSize, filterDepth = convInfo.filterDepth, filterHeight = convInfo.filterHeight, filterWidth = convInfo.filterWidth, inChannels = convInfo.inChannels, inDepth = convInfo.inDepth, inHeight = convInfo.inHeight, inWidth = convInfo.inWidth, outChannels = convInfo.outChannels, outDepth = convInfo.outDepth, outHeight = convInfo.outHeight, outWidth = convInfo.outWidth, strideDepth = convInfo.strideDepth, strideHeight = convInfo.strideHeight, strideWidth = convInfo.strideWidth;\n        var frontPad = filterDepth - 1 - convInfo.padInfo.front;\n        var topPad = filterHeight - 1 - convInfo.padInfo.top;\n        var leftPad = filterWidth - 1 - convInfo.padInfo.left;\n        for (var b = 0; b < batchSize; ++b) {\n            for (var d1 = 0; d1 < inChannels; ++d1) {\n                // Frames of depth\n                for (var xF = 0; xF < inDepth; ++xF) {\n                    var xFCorner = xF - frontPad;\n                    var xFMin = Math.max(0, Math.ceil(xFCorner / strideDepth));\n                    var yFMax = Math.min(outDepth, (filterDepth + xFCorner) / strideDepth);\n                    // Rows as per standard 2d matrix notation\n                    for (var xR = 0; xR < inHeight; ++xR) {\n                        var xRCorner = xR - topPad;\n                        var xRMin = Math.max(0, Math.ceil(xRCorner / strideHeight));\n                        var yRMax = Math.min(outHeight, (filterHeight + xRCorner) / strideHeight);\n                        // Columns as per standard 2d matrix notation\n                        for (var xC = 0; xC < inWidth; ++xC) {\n                            var xCCorner = xC - leftPad;\n                            var xCMin = Math.max(0, Math.ceil(xCCorner / strideWidth));\n                            var yCMax = Math.min(outWidth, (filterWidth + xCCorner) / strideWidth);\n                            var dotProd = 0;\n                            for (var yF = xFMin; yF < yFMax; ++yF) {\n                                var wF = yF * strideDepth - xFCorner;\n                                for (var yR = xRMin; yR < yRMax; ++yR) {\n                                    var wR = yR * strideHeight - xRCorner;\n                                    for (var yC = xCMin; yC < yCMax; ++yC) {\n                                        var wC = yC * strideWidth - xCCorner;\n                                        var dyOffset = dyS0 * b + dyS1 * yF + dyS2 * yR + dyS3 * yC;\n                                        var fltOffset = fltS0 * (filterDepth - 1 - wF) +\n                                            fltS1 * (filterHeight - 1 - wR) +\n                                            fltS2 * (filterWidth - 1 - wC) + fltS3 * d1;\n                                        for (var d2 = 0; d2 < outChannels; ++d2) {\n                                            var pixel = dyValues[dyOffset + d2];\n                                            var weight = fltValues[fltOffset + d2];\n                                            dotProd += pixel * weight;\n                                        }\n                                    }\n                                }\n                            }\n                            dxValues[dxS0 * b + dxS1 * xF + dxS2 * xR + dxS3 * xC + d1] =\n                                dotProd;\n                        }\n                    }\n                }\n            }\n        }\n        return dx.toTensor();\n    };\n    MathBackendCPU.prototype.conv2dDerFilter = function (x, dy, convInfo) {\n        this.assertNotComplex([x, dy], 'conv2dDerFilter');\n        var strideHeight = convInfo.strideHeight;\n        var strideWidth = convInfo.strideWidth;\n        var filterHeight = convInfo.filterHeight;\n        var filterWidth = convInfo.filterWidth;\n        var dW = ops.buffer(convInfo.filterShape, 'float32');\n        var leftPad = convInfo.padInfo.left;\n        var topPad = convInfo.padInfo.top;\n        var xBuf = this.bufferSync(x);\n        var dyBuf = this.bufferSync(dy);\n        for (var wR = 0; wR < filterHeight; ++wR) {\n            var yRMin = Math.max(0, Math.ceil((topPad - wR) / strideHeight));\n            var yRMax = Math.min(convInfo.outHeight, (convInfo.inHeight + topPad - wR) / strideHeight);\n            for (var wC = 0; wC < filterWidth; ++wC) {\n                var yCMin = Math.max(0, Math.ceil((leftPad - wC) / strideWidth));\n                var yCMax = Math.min(convInfo.outWidth, (convInfo.inWidth + leftPad - wC) / strideWidth);\n                for (var d1 = 0; d1 < convInfo.inChannels; ++d1) {\n                    for (var d2 = 0; d2 < convInfo.outChannels; ++d2) {\n                        // Need to convolve.\n                        var dotProd = 0;\n                        for (var b = 0; b < convInfo.batchSize; ++b) {\n                            for (var yR = yRMin; yR < yRMax; ++yR) {\n                                var xR = wR + yR * strideHeight - topPad;\n                                for (var yC = yCMin; yC < yCMax; ++yC) {\n                                    var xC = wC + yC * strideWidth - leftPad;\n                                    dotProd += xBuf.get(b, xR, xC, d1) * dyBuf.get(b, yR, yC, d2);\n                                }\n                            }\n                        }\n                        dW.set(dotProd, wR, wC, d1, d2);\n                    }\n                }\n            }\n        }\n        return dW.toTensor();\n    };\n    MathBackendCPU.prototype.conv3dDerFilter = function (x, dy, convInfo) {\n        var strideDepth = convInfo.strideDepth;\n        var strideHeight = convInfo.strideHeight;\n        var strideWidth = convInfo.strideWidth;\n        var filterDepth = convInfo.filterDepth;\n        var filterHeight = convInfo.filterHeight;\n        var filterWidth = convInfo.filterWidth;\n        var dw = ops.buffer(convInfo.filterShape, 'float32');\n        var dwValues = dw.values;\n        var _a = dw.strides, dwS0 = _a[0], dwS1 = _a[1], dwS2 = _a[2], dwS3 = _a[3];\n        var dyValues = this.readSync(dy.dataId);\n        var _b = dy.strides, dyS0 = _b[0], dyS1 = _b[1], dyS2 = _b[2], dyS3 = _b[3];\n        var xValues = this.readSync(x.dataId);\n        var _c = x.strides, xS0 = _c[0], xS1 = _c[1], xS2 = _c[2], xS3 = _c[3];\n        var frontPad = convInfo.padInfo.front;\n        var leftPad = convInfo.padInfo.left;\n        var topPad = convInfo.padInfo.top;\n        for (var wF = 0; wF < filterDepth; ++wF) {\n            var yFMin = Math.max(0, Math.ceil((frontPad - wF) / strideDepth));\n            var yFMax = Math.min(convInfo.outDepth, (convInfo.inDepth + frontPad - wF) / strideDepth);\n            var wOffset1 = wF * dwS0;\n            for (var wR = 0; wR < filterHeight; ++wR) {\n                var yRMin = Math.max(0, Math.ceil((topPad - wR) / strideHeight));\n                var yRMax = Math.min(convInfo.outHeight, (convInfo.inHeight + topPad - wR) / strideHeight);\n                var wOffset2 = wR * dwS1 + wOffset1;\n                for (var wC = 0; wC < filterWidth; ++wC) {\n                    var yCMin = Math.max(0, Math.ceil((leftPad - wC) / strideWidth));\n                    var yCMax = Math.min(convInfo.outWidth, (convInfo.inWidth + leftPad - wC) / strideWidth);\n                    var wOffset3 = wC * dwS2 + wOffset2;\n                    for (var d1 = 0; d1 < convInfo.inChannels; ++d1) {\n                        var wOffset4 = d1 * dwS3 + wOffset3;\n                        for (var d2 = 0; d2 < convInfo.outChannels; ++d2) {\n                            var dotProd = 0;\n                            for (var b = 0; b < convInfo.batchSize; ++b) {\n                                var xOffset1 = b * xS0;\n                                var yOffset1 = b * dyS0;\n                                for (var yF = yFMin; yF < yFMax; ++yF) {\n                                    var xF = wF + yF * strideDepth - frontPad;\n                                    var xOffset2 = xF * xS1 + xOffset1;\n                                    var yOffset2 = yF * dyS1 + yOffset1;\n                                    for (var yR = yRMin; yR < yRMax; ++yR) {\n                                        var xR = wR + yR * strideHeight - topPad;\n                                        var xOffset3 = xR * xS2 + xOffset2;\n                                        var yOffset3 = yR * dyS2 + yOffset2;\n                                        for (var yC = yCMin; yC < yCMax; ++yC) {\n                                            var xC = wC + yC * strideWidth - leftPad;\n                                            var xOffset4 = xC * xS3 + xOffset3;\n                                            var yOffset4 = yC * dyS3 + yOffset3;\n                                            dotProd +=\n                                                xValues[xOffset4 + d1] * dyValues[yOffset4 + d2];\n                                        }\n                                    }\n                                }\n                            }\n                            dwValues[wOffset4 + d2] = dotProd;\n                        }\n                    }\n                }\n            }\n        }\n        return dw.toTensor();\n    };\n    MathBackendCPU.prototype.depthwiseConv2D = function (x, filter, convInfo) {\n        this.assertNotComplex([x, filter], 'depthwiseConv2D');\n        var filterHeight = convInfo.filterHeight;\n        var filterWidth = convInfo.filterWidth;\n        var dilationHeight = convInfo.dilationHeight;\n        var dilationWidth = convInfo.dilationWidth;\n        var padLeft = convInfo.padInfo.left;\n        var padTop = convInfo.padInfo.top;\n        var chMul = convInfo.outChannels / convInfo.inChannels;\n        var y = ops.buffer(convInfo.outShape, x.dtype);\n        var xVals = this.readSync(x.dataId);\n        var wVals = this.readSync(filter.dataId);\n        var yVals = y.values;\n        for (var b = 0; b < convInfo.batchSize; ++b) {\n            var xOffset1 = b * x.strides[0];\n            var yOffset1 = b * y.strides[0];\n            for (var yR = 0; yR < convInfo.outHeight; ++yR) {\n                var yOffset2 = yOffset1 + yR * y.strides[1];\n                var xRCorner = yR * convInfo.strideHeight - padLeft;\n                for (var wR = 0; wR < filterHeight; ++wR) {\n                    var xR = xRCorner + wR * dilationHeight;\n                    if (xR < 0 || xR >= convInfo.inHeight) {\n                        continue;\n                    }\n                    var wOffset1 = wR * filter.strides[0];\n                    var xOffset2 = xOffset1 + xR * x.strides[1];\n                    for (var yC = 0; yC < convInfo.outWidth; ++yC) {\n                        var yOffset3 = yOffset2 + yC * y.strides[2];\n                        var xCCorner = yC * convInfo.strideWidth - padTop;\n                        for (var wC = 0; wC < filterWidth; ++wC) {\n                            var xC = xCCorner + wC * dilationWidth;\n                            if (xC < 0 || xC >= convInfo.inWidth) {\n                                continue;\n                            }\n                            var wOffset2 = wOffset1 + wC * filter.strides[1];\n                            var xOffset3 = xOffset2 + xC * convInfo.inChannels;\n                            var yOffset4 = yOffset3;\n                            var wOffset3 = wOffset2;\n                            for (var d1 = 0; d1 < convInfo.inChannels; ++d1) {\n                                var xVal = xVals[xOffset3 + d1];\n                                for (var q = 0; q < chMul; ++q) {\n                                    yVals[yOffset4 + q] += xVal * wVals[wOffset3 + q];\n                                }\n                                yOffset4 += chMul;\n                                wOffset3 += chMul;\n                            }\n                        }\n                    }\n                }\n            }\n        }\n        return y.toTensor();\n    };\n    MathBackendCPU.prototype.depthwiseConv2DDerInput = function (dy, filter, convInfo) {\n        this.assertNotComplex([dy, filter], 'depthwiseConv2DDerInput');\n        var dx = ops.buffer(convInfo.inShape, 'float32');\n        var dxValues = dx.values;\n        var _a = dx.strides, dxS0 = _a[0], dxS1 = _a[1], dxS2 = _a[2];\n        var dyValues = this.readSync(dy.dataId);\n        var _b = dy.strides, dyS0 = _b[0], dyS1 = _b[1], dyS2 = _b[2];\n        var fltValues = this.readSync(filter.dataId);\n        var _c = filter.strides, fltS0 = _c[0], fltS1 = _c[1], fltS2 = _c[2];\n        var batchSize = convInfo.batchSize, filterHeight = convInfo.filterHeight, filterWidth = convInfo.filterWidth, inChannels = convInfo.inChannels, inHeight = convInfo.inHeight, inWidth = convInfo.inWidth, outChannels = convInfo.outChannels, outHeight = convInfo.outHeight, outWidth = convInfo.outWidth, strideHeight = convInfo.strideHeight, strideWidth = convInfo.strideWidth;\n        var topPad = filterHeight - 1 - convInfo.padInfo.top;\n        var leftPad = filterWidth - 1 - convInfo.padInfo.left;\n        var chMul = outChannels / inChannels;\n        for (var b = 0; b < batchSize; ++b) {\n            for (var d1 = 0; d1 < inChannels; ++d1) {\n                for (var xR = 0; xR < inHeight; ++xR) {\n                    var xRCorner = xR - topPad;\n                    var xRMin = Math.max(0, Math.ceil(xRCorner / strideHeight));\n                    var yRMax = Math.min(outHeight, (filterHeight + xRCorner) / strideHeight);\n                    for (var xC = 0; xC < inWidth; ++xC) {\n                        var xCCorner = xC - leftPad;\n                        var xCMin = Math.max(0, Math.ceil(xCCorner / strideWidth));\n                        var yCMax = Math.min(outWidth, (filterWidth + xCCorner) / strideWidth);\n                        var dotProd = 0;\n                        for (var yR = xRMin; yR < yRMax; ++yR) {\n                            var wR = yR * strideHeight - xRCorner;\n                            for (var yC = xCMin; yC < yCMax; ++yC) {\n                                var wC = yC * strideWidth - xCCorner;\n                                var dyOffset = dyS0 * b + dyS1 * yR + dyS2 * yC;\n                                var fltOffset = fltS0 * (filterHeight - 1 - wR) +\n                                    fltS1 * (filterWidth - 1 - wC) + fltS2 * d1;\n                                for (var dm = 0; dm < chMul; ++dm) {\n                                    var d2 = d1 * chMul + dm;\n                                    var pixel = dyValues[dyOffset + d2];\n                                    var weight = fltValues[fltOffset + dm];\n                                    dotProd += pixel * weight;\n                                }\n                            }\n                        }\n                        dxValues[dxS0 * b + dxS1 * xR + dxS2 * xC + d1] = dotProd;\n                    }\n                }\n            }\n        }\n        return dx.toTensor();\n    };\n    MathBackendCPU.prototype.depthwiseConv2DDerFilter = function (x, dy, convInfo) {\n        this.assertNotComplex([x, dy], 'depthwiseConv2DDerFilter');\n        var strideHeight = convInfo.strideHeight;\n        var strideWidth = convInfo.strideWidth;\n        var filterHeight = convInfo.filterHeight;\n        var filterWidth = convInfo.filterWidth;\n        var dW = ops.buffer(convInfo.filterShape, 'float32');\n        var leftPad = convInfo.padInfo.left;\n        var topPad = convInfo.padInfo.top;\n        var chMul = convInfo.outChannels / convInfo.inChannels;\n        var xBuf = this.bufferSync(x);\n        var dyBuf = this.bufferSync(dy);\n        for (var wR = 0; wR < filterHeight; ++wR) {\n            var yRMin = Math.max(0, Math.ceil((topPad - wR) / strideHeight));\n            var yRMax = Math.min(convInfo.outHeight, (convInfo.inHeight + topPad - wR) / strideHeight);\n            for (var wC = 0; wC < filterWidth; ++wC) {\n                var yCMin = Math.max(0, Math.ceil((leftPad - wC) / strideWidth));\n                var yCMax = Math.min(convInfo.outWidth, (convInfo.inWidth + leftPad - wC) / strideWidth);\n                for (var d2 = 0; d2 < convInfo.outChannels; ++d2) {\n                    var d1 = Math.trunc(d2 / chMul);\n                    var dm = d2 % chMul;\n                    var dotProd = 0;\n                    for (var b = 0; b < convInfo.batchSize; ++b) {\n                        for (var yR = yRMin; yR < yRMax; ++yR) {\n                            var xR = wR + yR * strideHeight - topPad;\n                            for (var yC = yCMin; yC < yCMax; ++yC) {\n                                var xC = wC + yC * strideWidth - leftPad;\n                                dotProd += xBuf.get(b, xR, xC, d1) * dyBuf.get(b, yR, yC, d2);\n                            }\n                        }\n                    }\n                    dW.set(dotProd, wR, wC, d1, dm);\n                }\n            }\n        }\n        return dW.toTensor();\n    };\n    MathBackendCPU.prototype.tile = function (x, reps) {\n        this.assertNotComplex(x, 'tile');\n        var newShape = new Array(x.rank);\n        for (var i = 0; i < newShape.length; i++) {\n            newShape[i] = x.shape[i] * reps[i];\n        }\n        var result = ops.buffer(newShape, x.dtype);\n        var xBuf = this.bufferSync(x);\n        for (var i = 0; i < result.values.length; ++i) {\n            var newLoc = result.indexToLoc(i);\n            var originalLoc = new Array(x.rank);\n            for (var i_1 = 0; i_1 < originalLoc.length; i_1++) {\n                originalLoc[i_1] = newLoc[i_1] % x.shape[i_1];\n            }\n            var originalIndex = xBuf.locToIndex(originalLoc);\n            result.values[i] = xBuf.values[originalIndex];\n        }\n        return result.toTensor();\n    };\n    MathBackendCPU.prototype.pad = function (x, paddings, constantValue) {\n        this.assertNotComplex(x, 'pad');\n        var outShape = paddings.map(function (p, i) { return p[0] /* beforePad */ + x.shape[i] + p[1]; } /* afterPad */);\n        var start = paddings.map(function (p) { return p[0]; });\n        var xBuffer = this.bufferSync(x);\n        var buffer = ops.buffer(outShape, x.dtype);\n        if (constantValue !== 0) {\n            buffer.values.fill(constantValue);\n        }\n        for (var i = 0; i < x.size; i++) {\n            var coords = xBuffer.indexToLoc(i);\n            var outCoords = coords.map(function (c, i) { return c + start[i]; });\n            buffer.set.apply(buffer, [xBuffer.get.apply(xBuffer, coords)].concat(outCoords));\n        }\n        return buffer.toTensor();\n    };\n    MathBackendCPU.prototype.transpose = function (x, perm) {\n        this.assertNotComplex(x, 'transpose');\n        var newShape = new Array(x.rank);\n        for (var i = 0; i < newShape.length; i++) {\n            newShape[i] = x.shape[perm[i]];\n        }\n        var values = this.readSync(x.dataId);\n        var result = ops_1.buffer(newShape, x.dtype);\n        var xBuf = this.bufferSync(x);\n        for (var i = 0; i < x.size; ++i) {\n            var loc = xBuf.indexToLoc(i);\n            // Permute location.\n            var newLoc = new Array(loc.length);\n            for (var i_2 = 0; i_2 < newLoc.length; i_2++) {\n                newLoc[i_2] = loc[perm[i_2]];\n            }\n            var newIndex = result.locToIndex(newLoc);\n            result.values[newIndex] = values[i];\n        }\n        return result.toTensor();\n    };\n    MathBackendCPU.prototype.gather = function (x, indices, axis) {\n        this.assertNotComplex([x, indices], 'gather');\n        var newShape = x.shape.slice();\n        var indicesValues = this.readSync(indices.dataId);\n        newShape[axis] = indicesValues.length;\n        var result = ops_1.buffer(newShape, x.dtype);\n        var xBuf = this.bufferSync(x);\n        for (var i = 0; i < result.size; ++i) {\n            var newLoc = result.indexToLoc(i);\n            var originalLoc = newLoc.slice();\n            originalLoc[axis] = indicesValues[newLoc[axis]];\n            var originalIndex = xBuf.locToIndex(originalLoc);\n            result.values[i] = xBuf.values[originalIndex];\n        }\n        return result.toTensor();\n    };\n    MathBackendCPU.prototype.batchToSpaceND = function (x, blockShape, crops) {\n        this.assertNotComplex([x], 'batchToSpaceND');\n        var prod = blockShape.reduce(function (a, b) { return a * b; });\n        var reshaped = array_ops_util.getReshaped(x.shape, blockShape, prod);\n        var permuted = array_ops_util.getPermuted(reshaped.length, blockShape.length);\n        var reshapedPermuted = array_ops_util.getReshapedPermuted(x.shape, blockShape, prod);\n        var sliceBeginCoords = array_ops_util.getSliceBeginCoords(crops, blockShape.length);\n        var sliceSize = array_ops_util.getSliceSize(reshapedPermuted, crops, blockShape.length);\n        return x.reshape(reshaped)\n            .transpose(permuted)\n            .reshape(reshapedPermuted)\n            .slice(sliceBeginCoords, sliceSize);\n    };\n    MathBackendCPU.prototype.spaceToBatchND = function (x, blockShape, paddings) {\n        this.assertNotComplex([x], 'spaceToBatchND');\n        var prod = blockShape.reduce(function (a, b) { return a * b; });\n        var completePaddings = [[0, 0]];\n        completePaddings.push.apply(completePaddings, paddings);\n        for (var i = 1 + blockShape.length; i < x.shape.length; ++i) {\n            completePaddings.push([0, 0]);\n        }\n        var paddedX = x.pad(completePaddings);\n        var reshapedPaddedShape = array_ops_util.getReshaped(paddedX.shape, blockShape, prod, false);\n        var permutedReshapedPaddedPermutation = array_ops_util.getPermuted(reshapedPaddedShape.length, blockShape.length, false);\n        var flattenShape = array_ops_util.getReshapedPermuted(paddedX.shape, blockShape, prod, false);\n        return paddedX.reshape(reshapedPaddedShape)\n            .transpose(permutedReshapedPaddedPermutation)\n            .reshape(flattenShape);\n    };\n    MathBackendCPU.prototype.pool = function (x, convInfo, poolType) {\n        this.assertNotComplex(x, 'pool');\n        var strideHeight = convInfo.strideHeight;\n        var strideWidth = convInfo.strideWidth;\n        var dilationHeight = convInfo.dilationHeight;\n        var dilationWidth = convInfo.dilationWidth;\n        var effectiveFilterHeight = convInfo.effectiveFilterHeight;\n        var effectiveFilterWidth = convInfo.effectiveFilterWidth;\n        var padTop = convInfo.padInfo.top;\n        var padLeft = convInfo.padInfo.left;\n        var initialValue = (poolType === 'max' ? Number.NEGATIVE_INFINITY :\n            Number.POSITIVE_INFINITY);\n        var xValues = this.readSync(x.dataId);\n        var output = ops.buffer(convInfo.outShape, x.dtype);\n        var outputVals = output.values;\n        var outputBatchStrides = convInfo.outShape[1] * convInfo.outShape[2] * convInfo.outShape[3];\n        var outputRowStrides = convInfo.outShape[2] * convInfo.outShape[3];\n        var outputColStrides = convInfo.outShape[3];\n        for (var b = 0; b < convInfo.batchSize; ++b) {\n            var outputBatchOffset = b * outputBatchStrides;\n            var inputBatchOffset = b * x.strides[0];\n            for (var d = 0; d < convInfo.inChannels; ++d) {\n                for (var yR = 0; yR < convInfo.outHeight; ++yR) {\n                    var xRCorner = yR * strideHeight - padTop;\n                    var xRMin = Math.max(0, xRCorner);\n                    var xRMax = Math.min(convInfo.inHeight, effectiveFilterHeight + xRCorner);\n                    var outputRowOffset = outputBatchOffset + yR * outputRowStrides;\n                    for (var yC = 0; yC < convInfo.outWidth; ++yC) {\n                        var xCCorner = yC * strideWidth - padLeft;\n                        var xCMin = Math.max(0, xCCorner);\n                        var xCMax = Math.min(convInfo.inWidth, effectiveFilterWidth + xCCorner);\n                        var minMaxValue = initialValue;\n                        var avgValue = 0;\n                        var count = 0;\n                        for (var xR = xRMin; xR < xRMax; xR += dilationHeight) {\n                            var xROffset = inputBatchOffset + xR * x.strides[1];\n                            for (var xC = xCMin; xC < xCMax; xC += dilationWidth) {\n                                var xCOffset = xROffset + xC * x.strides[2];\n                                var pixel = xValues[xCOffset + d];\n                                if ((poolType === 'max' && pixel > minMaxValue)) {\n                                    minMaxValue = pixel;\n                                }\n                                else if (poolType === 'avg') {\n                                    avgValue += pixel;\n                                    count++;\n                                }\n                            }\n                            if (isNaN(minMaxValue)) {\n                                break;\n                            }\n                        }\n                        var outputOffset = outputRowOffset + yC * outputColStrides + d;\n                        outputVals[outputOffset] =\n                            poolType === 'avg' ? avgValue / count : minMaxValue;\n                    }\n                }\n            }\n        }\n        return output.toTensor();\n    };\n    MathBackendCPU.prototype.maxPool = function (x, convInfo) {\n        return this.pool(x, convInfo, 'max');\n    };\n    MathBackendCPU.prototype.maxPoolPositions = function (x, convInfo) {\n        var maxPositions = ops.buffer(convInfo.outShape, 'int32');\n        var strideHeight = convInfo.strideHeight;\n        var strideWidth = convInfo.strideWidth;\n        var dilationHeight = convInfo.dilationHeight;\n        var dilationWidth = convInfo.dilationWidth;\n        var effectiveFilterHeight = convInfo.effectiveFilterHeight;\n        var effectiveFilterWidth = convInfo.effectiveFilterWidth;\n        var padTop = convInfo.padInfo.top;\n        var padLeft = convInfo.padInfo.left;\n        var xBuf = this.bufferSync(x);\n        for (var b = 0; b < convInfo.batchSize; ++b) {\n            for (var d = 0; d < convInfo.inChannels; ++d) {\n                for (var yR = 0; yR < convInfo.outHeight; ++yR) {\n                    var xRCorner = yR * strideHeight - padTop;\n                    var xRMin = xRCorner;\n                    while (xRMin < 0) {\n                        xRMin += dilationHeight;\n                    }\n                    // const xRMin = Math.max(0, xRCorner);\n                    var xRMax = Math.min(convInfo.inHeight, effectiveFilterHeight + xRCorner);\n                    for (var yC = 0; yC < convInfo.outWidth; ++yC) {\n                        var xCCorner = yC * strideWidth - padLeft;\n                        var xCMin = xCCorner;\n                        while (xCMin < 0) {\n                            xCMin += dilationWidth;\n                        }\n                        var xCMax = Math.min(convInfo.inWidth, effectiveFilterWidth + xCCorner);\n                        var maxValue = Number.NEGATIVE_INFINITY;\n                        var maxPosition = -1;\n                        for (var xR = xRMin; xR < xRMax; xR += dilationHeight) {\n                            var wR = xR - xRCorner;\n                            for (var xC = xCMin; xC < xCMax; xC += dilationWidth) {\n                                var wC = xC - xCCorner;\n                                var pixel = xBuf.get(b, xR, xC, d);\n                                if (pixel > maxValue) {\n                                    maxValue = pixel;\n                                    maxPosition = wR * effectiveFilterWidth + wC;\n                                }\n                            }\n                        }\n                        maxPositions.set(maxPosition, b, yR, yC, d);\n                    }\n                }\n            }\n        }\n        return maxPositions.toTensor();\n    };\n    MathBackendCPU.prototype.maxPoolBackprop = function (dy, x, y, convInfo) {\n        this.assertNotComplex([x, y], 'maxPoolBackprop');\n        var maxPositions = this.maxPoolPositions(x, convInfo);\n        var strideHeight = convInfo.strideHeight;\n        var strideWidth = convInfo.strideWidth;\n        var dilationHeight = convInfo.dilationHeight;\n        var dilationWidth = convInfo.dilationWidth;\n        var effectiveFilterHeight = convInfo.effectiveFilterHeight;\n        var effectiveFilterWidth = convInfo.effectiveFilterWidth;\n        var padLeft = effectiveFilterWidth - 1 - convInfo.padInfo.left;\n        var padTop = effectiveFilterHeight - 1 - convInfo.padInfo.top;\n        var dx = ops.buffer(x.shape, 'float32');\n        var maxPosBuf = this.bufferSync(maxPositions);\n        var dyBuf = this.bufferSync(dy);\n        for (var b = 0; b < convInfo.batchSize; ++b) {\n            for (var d = 0; d < convInfo.inChannels; ++d) {\n                for (var dxR = 0; dxR < convInfo.inHeight; ++dxR) {\n                    for (var dxC = 0; dxC < convInfo.inWidth; ++dxC) {\n                        // Shader code begins.\n                        var dyRCorner = dxR - padTop;\n                        var dyCCorner = dxC - padLeft;\n                        var dotProd = 0;\n                        for (var wR = 0; wR < effectiveFilterHeight; wR += dilationHeight) {\n                            var dyR = (dyRCorner + wR) / strideHeight;\n                            if (dyR < 0 || dyR >= convInfo.outHeight ||\n                                Math.floor(dyR) !== dyR) {\n                                continue;\n                            }\n                            for (var wC = 0; wC < effectiveFilterWidth; wC += dilationWidth) {\n                                var dyC = (dyCCorner + wC) / strideWidth;\n                                if (dyC < 0 || dyC >= convInfo.outWidth ||\n                                    Math.floor(dyC) !== dyC) {\n                                    continue;\n                                }\n                                var maxPos = effectiveFilterHeight * effectiveFilterWidth -\n                                    1 - maxPosBuf.get(b, dyR, dyC, d);\n                                var curPos = wR * effectiveFilterWidth + wC;\n                                var mask = maxPos === curPos ? 1 : 0;\n                                if (mask === 0) {\n                                    continue;\n                                }\n                                var pixel = dyBuf.get(b, dyR, dyC, d);\n                                dotProd += pixel * mask;\n                            }\n                        }\n                        dx.set(dotProd, b, dxR, dxC, d);\n                    }\n                }\n            }\n        }\n        return dx.toTensor();\n    };\n    MathBackendCPU.prototype.avgPoolBackprop = function (dy, x, convInfo) {\n        this.assertNotComplex([dy, x], 'avgPoolBackprop');\n        var strideHeight = convInfo.strideHeight;\n        var strideWidth = convInfo.strideWidth;\n        var filterHeight = convInfo.filterHeight;\n        var filterWidth = convInfo.filterWidth;\n        var dilationHeight = convInfo.dilationHeight;\n        var dilationWidth = convInfo.dilationWidth;\n        var effectiveFilterHeight = convInfo.effectiveFilterHeight;\n        var effectiveFilterWidth = convInfo.effectiveFilterWidth;\n        var padLeft = effectiveFilterWidth - 1 - convInfo.padInfo.left;\n        var padTop = effectiveFilterHeight - 1 - convInfo.padInfo.top;\n        var dx = ops.buffer(x.shape, 'float32');\n        var avgMultiplier = 1 / (filterHeight * filterWidth);\n        var dyBuf = this.bufferSync(dy);\n        for (var b = 0; b < convInfo.batchSize; ++b) {\n            for (var d = 0; d < convInfo.inChannels; ++d) {\n                for (var dxR = 0; dxR < convInfo.inHeight; ++dxR) {\n                    for (var dxC = 0; dxC < convInfo.inWidth; ++dxC) {\n                        // Shader code begins.\n                        var dyRCorner = dxR - padTop;\n                        var dyCCorner = dxC - padLeft;\n                        var dotProd = 0;\n                        for (var wR = 0; wR < effectiveFilterHeight; wR += dilationHeight) {\n                            var dyR = (dyRCorner + wR) / strideHeight;\n                            if (dyR < 0 || dyR >= convInfo.outHeight ||\n                                Math.floor(dyR) !== dyR) {\n                                continue;\n                            }\n                            for (var wC = 0; wC < effectiveFilterWidth; wC += dilationWidth) {\n                                var dyC = (dyCCorner + wC) / strideWidth;\n                                if (dyC < 0 || dyC >= convInfo.outWidth ||\n                                    Math.floor(dyC) !== dyC) {\n                                    continue;\n                                }\n                                var pixel = dyBuf.get(b, dyR, dyC, d);\n                                dotProd += pixel;\n                            }\n                        }\n                        dx.set(dotProd * avgMultiplier, b, dxR, dxC, d);\n                    }\n                }\n            }\n        }\n        return dx.toTensor();\n    };\n    MathBackendCPU.prototype.cast = function (x, dtype) {\n        return backend_util.castTensor(x, dtype, this);\n    };\n    MathBackendCPU.prototype.reshape = function (x, shape) {\n        return backend_util.reshapeTensor(x, shape);\n    };\n    MathBackendCPU.prototype.avgPool = function (x, convInfo) {\n        this.assertNotComplex(x, 'avgPool');\n        return this.pool(x, convInfo, 'avg').toFloat();\n    };\n    MathBackendCPU.prototype.resizeBilinear = function (x, newHeight, newWidth, alignCorners) {\n        this.assertNotComplex(x, 'resizeBilinear');\n        var _a = x.shape, batch = _a[0], oldHeight = _a[1], oldWidth = _a[2], numChannels = _a[3];\n        var xValues = this.readSync(x.dataId);\n        var result = new Float32Array(util.sizeFromShape([batch, newHeight, newWidth, numChannels]));\n        var effectiveInputSize = [\n            (alignCorners && newHeight > 1) ? oldHeight - 1 : oldHeight,\n            (alignCorners && newWidth > 1) ? oldWidth - 1 : oldWidth\n        ];\n        var effectiveOutputSize = [\n            (alignCorners && newHeight > 1) ? newHeight - 1 : newHeight,\n            (alignCorners && newWidth > 1) ? newWidth - 1 : newWidth\n        ];\n        var outputIdx = 0;\n        var effectiveRowSizeRatio = effectiveInputSize[0] / effectiveOutputSize[0];\n        var effectiveColSizeRatio = effectiveInputSize[1] / effectiveOutputSize[1];\n        for (var b = 0; b < batch; b++) {\n            for (var r = 0; r < newHeight; r++) {\n                var sourceFracRow = effectiveRowSizeRatio * r;\n                var sourceRowFloor = Math.floor(sourceFracRow);\n                var rowFrac = sourceFracRow - sourceRowFloor;\n                var sourceRowCeil = Math.min(oldHeight - 1, Math.ceil(sourceFracRow));\n                var topRowOffset = b * x.strides[0] + sourceRowFloor * x.strides[1];\n                var botRowOffset = b * x.strides[0] + sourceRowCeil * x.strides[1];\n                for (var c = 0; c < newWidth; c++) {\n                    var sourceFracCol = effectiveColSizeRatio * c;\n                    var sourceColFloor = Math.floor(sourceFracCol);\n                    var colFrac = sourceFracCol - sourceColFloor;\n                    var sourceColCeil = Math.min(oldWidth - 1, Math.ceil(sourceFracCol));\n                    var topLeftOffest = topRowOffset + sourceColFloor * x.strides[2];\n                    var botLeftOffset = botRowOffset + sourceColFloor * x.strides[2];\n                    var topRightOffset = topRowOffset + +sourceColCeil * x.strides[2];\n                    var botRightOffest = botRowOffset + sourceColCeil * x.strides[2];\n                    for (var d = 0; d < numChannels; d++) {\n                        // Begin shader.\n                        // Compute the fractional index of the source.\n                        var topLeft = xValues[topLeftOffest + d];\n                        var bottomLeft = xValues[botLeftOffset + d];\n                        var topRight = xValues[topRightOffset + d];\n                        var bottomRight = xValues[botRightOffest + d];\n                        var top_1 = topLeft + (topRight - topLeft) * colFrac;\n                        var bottom = bottomLeft + (bottomRight - bottomLeft) * colFrac;\n                        var newValue = top_1 + (bottom - top_1) * rowFrac;\n                        result[outputIdx++] = newValue;\n                    }\n                }\n            }\n        }\n        return ops.tensor(result, [batch, newHeight, newWidth, numChannels]);\n    };\n    MathBackendCPU.prototype.resizeBilinearBackprop = function (dy, x, alignCorners) {\n        this.assertNotComplex([dy, x], 'resizeBilinearBackprop');\n        var _a = x.shape, batch = _a[0], xHeight = _a[1], xWidth = _a[2], depth = _a[3];\n        var _b = dy.shape, yHeight = _b[1], yWidth = _b[2];\n        var output = new Float32Array(batch * xHeight * xWidth * depth);\n        // In the backwards pass, we want to find the pixels that were generated\n        // for each pixel in the input image the forward pass and add the\n        // corresponding coefficient from dy to the gradient (with some\n        // interpolation).\n        var effectiveXSize = [\n            (alignCorners && yHeight > 1) ? xHeight - 1 : xHeight,\n            (alignCorners && yWidth > 1) ? xWidth - 1 : xWidth\n        ];\n        var effectiveYSize = [\n            (alignCorners && yHeight > 1) ? yHeight - 1 : yHeight,\n            (alignCorners && yWidth > 1) ? yWidth - 1 : yWidth\n        ];\n        var heightScale = effectiveXSize[0] / effectiveYSize[0];\n        var widthScale = effectiveXSize[1] / effectiveYSize[1];\n        // Reference implementation\n        // tslint:disable-next-line:max-line-length\n        // https://github.com/tensorflow/tensorflow/blob/3039375c86a5bbc9610c7725dcaa95d635f87ba2/tensorflow/core/kernels/resize_bilinear_op.cc#L275\n        var dyValues = this.readSync(dy.dataId);\n        var offset = 0;\n        for (var b = 0; b < batch; b++) {\n            var bOffset = b * x.strides[0];\n            for (var r = 0; r < yHeight; r++) {\n                var dxR = r * heightScale;\n                var topDxRIndex = Math.floor(dxR);\n                var bottomDxRIndex = Math.min(Math.ceil(dxR), xHeight - 1);\n                var topDxROffset = bOffset + topDxRIndex * x.strides[1];\n                var bottomDxROffset = bOffset + bottomDxRIndex * x.strides[1];\n                var dxRLerp = dxR - topDxRIndex;\n                var inverseDxRLerp = 1.0 - dxRLerp;\n                for (var c = 0; c < yWidth; c++) {\n                    var dxC = c * widthScale;\n                    var leftDxCIndex = Math.floor(dxC);\n                    var rightDxCIndex = Math.min(Math.ceil(dxC), xWidth - 1);\n                    var dxCLerp = dxC - leftDxCIndex;\n                    var inverseDxCLerp = 1.0 - dxCLerp;\n                    var topLeftRCOffset = topDxROffset + leftDxCIndex * x.strides[2];\n                    var topRightRCOffset = topDxROffset + rightDxCIndex * x.strides[2];\n                    var bottomLeftRCOffset = bottomDxROffset + leftDxCIndex * x.strides[2];\n                    var bottomRightRCOffset = bottomDxROffset + rightDxCIndex * x.strides[2];\n                    var inverseDxRLerpTimesInverseDxCLerp = inverseDxRLerp * inverseDxCLerp;\n                    var inverseDxRLerpTimesDxCLerp = inverseDxRLerp * dxCLerp;\n                    var dxRLerpTimesInverseDxCLerp = dxRLerp * inverseDxCLerp;\n                    var dxRLerpTimesDxCLerp = dxRLerp * dxCLerp;\n                    for (var d = 0; d < depth; d++) {\n                        var dyVal = dyValues[offset++];\n                        output[topLeftRCOffset + d] +=\n                            dyVal * inverseDxRLerpTimesInverseDxCLerp;\n                        output[topRightRCOffset + d] += dyVal * inverseDxRLerpTimesDxCLerp;\n                        output[bottomLeftRCOffset + d] +=\n                            dyVal * dxRLerpTimesInverseDxCLerp;\n                        output[bottomRightRCOffset + d] += dyVal * dxRLerpTimesDxCLerp;\n                    }\n                }\n            }\n        }\n        return ops.tensor4d(output, [batch, xWidth, xHeight, depth], x.dtype);\n    };\n    MathBackendCPU.prototype.resizeNearestNeighbor = function (x, newHeight, newWidth, alignCorners) {\n        this.assertNotComplex(x, 'resizeNearestNeighbor');\n        var _a = x.shape, batch = _a[0], oldHeight = _a[1], oldWidth = _a[2], numChannels = _a[3];\n        var xValues = this.readSync(x.dataId);\n        var output = new Float32Array(batch * newHeight * newWidth * numChannels);\n        var effectiveInputSize = [\n            (alignCorners && newHeight > 1) ? oldHeight - 1 : oldHeight,\n            (alignCorners && newWidth > 1) ? oldWidth - 1 : oldWidth\n        ];\n        var effectiveOutputSize = [\n            (alignCorners && newHeight > 1) ? newHeight - 1 : newHeight,\n            (alignCorners && newWidth > 1) ? newWidth - 1 : newWidth\n        ];\n        var effectiveRowSizeRatio = effectiveInputSize[0] / effectiveOutputSize[0];\n        var effectiveColSizeRatio = effectiveInputSize[1] / effectiveOutputSize[1];\n        var outputOffset = 0;\n        for (var b = 0; b < batch; b++) {\n            var batchOffset = b * x.strides[0];\n            for (var r = 0; r < newHeight; r++) {\n                var sourceFracRow = effectiveRowSizeRatio * r;\n                var sourceNearestRow = Math.min(oldHeight - 1, alignCorners ? Math.round(sourceFracRow) :\n                    Math.floor(sourceFracRow));\n                var rowOffset = batchOffset + sourceNearestRow * x.strides[1];\n                for (var c = 0; c < newWidth; c++) {\n                    var sourceFracCol = effectiveColSizeRatio * c;\n                    var sourceNearestCol = Math.min(oldWidth - 1, alignCorners ? Math.round(sourceFracCol) :\n                        Math.floor(sourceFracCol));\n                    var colOffset = rowOffset + sourceNearestCol * x.strides[2];\n                    for (var d = 0; d < numChannels; d++) {\n                        // Begin shader.\n                        // Compute the fractional index of the source.\n                        var newVal = xValues[colOffset + d];\n                        output[outputOffset++] = newVal;\n                    }\n                }\n            }\n        }\n        return ops.tensor(output, [batch, newHeight, newWidth, numChannels], x.dtype);\n    };\n    MathBackendCPU.prototype.resizeNearestNeighborBackprop = function (dy, x, alignCorners) {\n        this.assertNotComplex([dy, x], 'resizeNearestNeighborBackprop');\n        var _a = x.shape, batch = _a[0], xHeight = _a[1], xWidth = _a[2], depth = _a[3];\n        var _b = dy.shape, yHeight = _b[1], yWidth = _b[2];\n        var output = new Float32Array(batch * xHeight * xWidth * depth);\n        var dyValues = this.readSync(dy.dataId);\n        // In the backwards pass, we want to find the pixels that were generated\n        // for each pixel in the input image the forward pass\n        var effectiveXSize = [\n            (alignCorners && yHeight > 1) ? xHeight - 1 : xHeight,\n            (alignCorners && yWidth > 1) ? xWidth - 1 : xWidth\n        ];\n        var effectiveYSize = [\n            (alignCorners && yHeight > 1) ? yHeight - 1 : yHeight,\n            (alignCorners && yWidth > 1) ? yWidth - 1 : yWidth\n        ];\n        var heightScale = effectiveXSize[0] / effectiveYSize[0];\n        var widthScale = effectiveXSize[1] / effectiveYSize[1];\n        var invHeightScale = 1 / heightScale;\n        var invWidthScale = 1 / widthScale;\n        // This defines the size of the window of values around a particular\n        // index in dy that we want to search for contributions to dx.\n        var winHeight = (Math.ceil(invHeightScale) * 2) + 2;\n        var winWidth = (Math.ceil(invWidthScale) * 2) + 2;\n        // Loop over the output space.\n        for (var b = 0; b < batch; b++) {\n            var batchOffset = b * x.strides[0];\n            for (var r = 0; r < xHeight; r++) {\n                var rowOffset = batchOffset + r * x.strides[1];\n                // Compute bounds for where in dy we will look\n                var startRLerp = Math.floor(r * invHeightScale);\n                var startDyR = Math.floor(startRLerp - (winHeight / 2));\n                for (var c = 0; c < xWidth; c++) {\n                    var colOffset = rowOffset + c * x.strides[2];\n                    // Compute bounds for where in dy we will look\n                    var startCLerp = Math.floor(c * invWidthScale);\n                    var startDyC = Math.floor(startCLerp - (winWidth / 2));\n                    for (var d = 0; d < depth; d++) {\n                        var accum = 0;\n                        // loop over dy\n                        for (var dyRIndex = 0; dyRIndex < winHeight; dyRIndex++) {\n                            var dyR = dyRIndex + startDyR;\n                            // Guard against the window exceeding the bounds of dy\n                            if (dyR < 0 || dyR >= yHeight) {\n                                continue;\n                            }\n                            var dyROffset = batchOffset + dyR * dy.strides[1];\n                            var sourceFracRow = dyR * heightScale;\n                            var sourceNearestRow = Math.min(xHeight - 1, alignCorners ? Math.round(sourceFracRow) :\n                                Math.floor(sourceFracRow));\n                            if (r !== sourceNearestRow) {\n                                continue;\n                            }\n                            for (var dyCIndex = 0; dyCIndex < winWidth; dyCIndex++) {\n                                var dyC = dyCIndex + startDyC;\n                                // Guard against the window exceeding the bounds of dy\n                                if (dyC < 0 || dyC >= yWidth) {\n                                    continue;\n                                }\n                                var dyCOffset = dyROffset + dyC * dy.strides[2];\n                                var sourceFracCol = dyC * widthScale;\n                                var sourceNearestCol = Math.min(xWidth - 1, alignCorners ? Math.round(sourceFracCol) :\n                                    Math.floor(sourceFracCol));\n                                if (c === sourceNearestCol) {\n                                    accum += dyValues[dyCOffset + d];\n                                }\n                            }\n                        }\n                        output[colOffset + d] = accum;\n                    }\n                }\n            }\n        }\n        return ops.tensor4d(output, x.shape, x.dtype);\n    };\n    MathBackendCPU.prototype.batchNormalization = function (x, mean, variance, varianceEpsilon, scale, offset) {\n        this.assertNotComplex([x, mean, variance, scale, offset], 'batchNorm');\n        var xVals = this.readSync(x.dataId);\n        var mVals = this.readSync(mean.dataId);\n        var varVals = this.readSync(variance.dataId);\n        var sVals = scale ? this.readSync(scale.dataId) :\n            new Float32Array([1]);\n        var offVals = offset ? this.readSync(offset.dataId) :\n            new Float32Array([0]);\n        var outVals = new Float32Array(xVals.length);\n        var offValsLength = offVals.length;\n        var sValsLength = sVals.length;\n        var varValsLength = varVals.length;\n        var mValsLength = mVals.length;\n        var offi = 0;\n        var mi = 0;\n        var si = 0;\n        var vi = 0;\n        for (var i = 0; i < xVals.length; ++i) {\n            outVals[i] = offVals[offi++] +\n                (xVals[i] - mVals[mi++]) * sVals[si++] /\n                    Math.sqrt(varVals[vi++] + varianceEpsilon);\n            if (offi >= offValsLength) {\n                offi = 0;\n            }\n            if (mi >= mValsLength) {\n                mi = 0;\n            }\n            if (si >= sValsLength) {\n                si = 0;\n            }\n            if (vi >= varValsLength) {\n                vi = 0;\n            }\n        }\n        return ops_1.tensor4d(outVals, x.shape);\n    };\n    MathBackendCPU.prototype.localResponseNormalization4D = function (x, depthRadius, bias, alpha, beta) {\n        this.assertNotComplex(x, 'localResponseNormalization4D');\n        var channels = x.shape[3];\n        var maxD = channels - 1;\n        var xValues = this.readSync(x.dataId);\n        var size = x.size;\n        var result = new Float32Array(size);\n        function sumAcrossChannels(offset) {\n            var currentChannel = offset % channels;\n            var beginSumOffset = offset - currentChannel + Math.max(0, currentChannel - depthRadius);\n            var endSumOffset = offset - currentChannel +\n                Math.min(currentChannel + depthRadius, maxD);\n            var sum = 0.0;\n            for (; beginSumOffset <= endSumOffset; beginSumOffset++) {\n                var z = xValues[beginSumOffset];\n                sum += z * z;\n            }\n            return sum;\n        }\n        for (var offset = 0; offset < size; offset++) {\n            var sum = sumAcrossChannels(offset);\n            var val = xValues[offset] * Math.pow(bias + alpha * sum, -beta);\n            result[offset] = val;\n        }\n        return ops.tensor4d(result, x.shape);\n    };\n    MathBackendCPU.prototype.LRNGrad = function (dy, inputImage, outputImage, depthRadius, bias, alpha, beta) {\n        this.assertNotComplex(dy, 'LRNGrad');\n        var channels = dy.shape[3];\n        var dyValues = this.readSync(dy.dataId);\n        var inputImageValues = this.readSync(inputImage.dataId);\n        var outputImageValues = this.readSync(outputImage.dataId);\n        var result = new Float32Array(dy.size);\n        var size = dy.size;\n        for (var offset = 0; offset < size; offset++) {\n            var currentChannel = offset % channels;\n            var depthBegin = (offset - currentChannel) + Math.max(0, currentChannel - depthRadius);\n            var depthEnd = (offset - currentChannel) +\n                Math.min(channels, currentChannel + depthRadius + 1);\n            var norm = 0;\n            for (var k = depthBegin; k < depthEnd; k++) {\n                norm += Math.pow(inputImageValues[k], 2);\n            }\n            norm = alpha * norm + bias;\n            for (var k = depthBegin; k < depthEnd; k++) {\n                var dyi = -2 * alpha * beta * inputImageValues[k] *\n                    outputImageValues[offset] / norm;\n                if (offset === k) {\n                    dyi += Math.pow(norm, -beta);\n                }\n                dyi *= dyValues[offset];\n                result[k] += dyi;\n            }\n        }\n        return ops.tensor4d(result, dy.shape);\n    };\n    MathBackendCPU.prototype.multinomial = function (logits, normalized, numSamples, seed) {\n        this.assertNotComplex(logits, 'multinomial');\n        var probabilities = normalized ? logits : ops.softmax(logits);\n        var batchSize = probabilities.shape[0];\n        var numEvents = probabilities.shape[1];\n        var res = ops.zeros([batchSize, numSamples], 'int32');\n        var resVals = this.readSync(res.dataId);\n        var probVals = this.readSync(probabilities.dataId);\n        for (var b = 0; b < batchSize; ++b) {\n            var offset = b * numEvents;\n            // The cdf won't include the last event. It will be implicit if no other\n            // event happened.\n            var cdf = new Float32Array(numEvents - 1);\n            cdf[0] = probVals[offset];\n            for (var event_1 = 1; event_1 < cdf.length; ++event_1) {\n                cdf[event_1] = cdf[event_1 - 1] + probVals[offset + event_1];\n            }\n            var random = seedrandom.alea(seed.toString());\n            var outOffset = b * numSamples;\n            for (var sampleId = 0; sampleId < numSamples; ++sampleId) {\n                var r = random();\n                // Assume last event happened by default.\n                resVals[outOffset + sampleId] = cdf.length;\n                for (var event_2 = 0; event_2 < cdf.length; event_2++) {\n                    if (r < cdf[event_2]) {\n                        resVals[outOffset + sampleId] = event_2;\n                        break;\n                    }\n                }\n            }\n        }\n        return res;\n    };\n    MathBackendCPU.prototype.oneHot = function (indices, depth, onValue, offValue) {\n        this.assertNotComplex(indices, 'oneHot');\n        var res = new Float32Array(indices.size * depth);\n        res.fill(offValue);\n        var indicesVal = this.readSync(indices.dataId);\n        for (var event_3 = 0; event_3 < indices.size; ++event_3) {\n            if (indicesVal[event_3] >= 0 && indicesVal[event_3] < depth) {\n                res[event_3 * depth + indicesVal[event_3]] = onValue;\n            }\n        }\n        return ops.tensor2d(res, [indices.size, depth], 'int32');\n    };\n    MathBackendCPU.prototype.nonMaxSuppression = function (boxes, scores, maxOutputSize, iouThreshold, scoreThreshold) {\n        this.assertNotComplex(boxes, 'nonMaxSuppression');\n        var boxesVals = this.readSync(boxes.dataId);\n        var scoresVals = this.readSync(scores.dataId);\n        return non_max_suppression_impl_1.nonMaxSuppressionImpl(boxesVals, scoresVals, maxOutputSize, iouThreshold, scoreThreshold);\n    };\n    MathBackendCPU.prototype.fft = function (x) {\n        return this.fftBatch(x, false);\n    };\n    MathBackendCPU.prototype.ifft = function (x) {\n        return this.fftBatch(x, true);\n    };\n    /**\n     * Calculate FFT of inner most elements of batch tensor.\n     */\n    MathBackendCPU.prototype.fftBatch = function (x, inverse) {\n        var batch = x.shape[0];\n        var innerDim = x.shape[1];\n        // Collects real and imaginary values separately.\n        var realResult = ops.buffer(x.shape, 'float32');\n        var imagResult = ops.buffer(x.shape, 'float32');\n        var real = ops.real(x).as2D(batch, innerDim);\n        var imag = ops.imag(x).as2D(batch, innerDim);\n        for (var b = 0; b < batch; b++) {\n            // TODO: Support slice ops for complex type.\n            var r = real.slice([b, 0], [1, innerDim]);\n            var i = imag.slice([b, 0], [1, innerDim]);\n            var input = ops.complex(r, i);\n            // Run FFT by batch element.\n            var res = this.readSync(this.fftImpl(input, inverse).dataId);\n            for (var d = 0; d < innerDim; d++) {\n                var c = complex_util.getComplexWithIndex(res, d);\n                realResult.values[b * innerDim + d] = c.real;\n                imagResult.values[b * innerDim + d] = c.imag;\n            }\n        }\n        var t = ops.complex(realResult.toTensor(), imagResult.toTensor());\n        return t.as2D(batch, innerDim);\n    };\n    MathBackendCPU.prototype.fftImpl = function (x, inverse) {\n        var x1D = x.as1D();\n        var n = x1D.size;\n        if (this.isExponentOf2(n)) {\n            var result = this.fftRadix2(x1D, n, inverse).as2D(x.shape[0], x.shape[1]);\n            if (inverse) {\n                result = ops.complex(ops.real(result).div(ops_1.scalar(n)), ops.imag(result).div(ops_1.scalar(n)));\n            }\n            return result;\n        }\n        else {\n            var data = this.readSync(x.dataId);\n            var rawOutput = this.fourierTransformByMatmul(data, n, inverse);\n            var output = complex_util.splitRealAndImagArrays(rawOutput);\n            return ops.complex(output.real, output.imag).as2D(x.shape[0], x.shape[1]);\n        }\n    };\n    MathBackendCPU.prototype.isExponentOf2 = function (size) {\n        return (size & size - 1) === 0;\n    };\n    // FFT using Cooley-Tukey algorithm on radix 2 dimensional input.\n    MathBackendCPU.prototype.fftRadix2 = function (input, size, inverse) {\n        if (size === 1) {\n            return input;\n        }\n        var data = this.readSync(input.dataId);\n        var half = size / 2;\n        var evenComplex = complex_util.complexWithEvenIndex(data);\n        var evenTensor = ops.complex(evenComplex.real, evenComplex.imag).as1D();\n        var oddComplex = complex_util.complexWithOddIndex(data);\n        var oddTensor = ops.complex(oddComplex.real, oddComplex.imag).as1D();\n        // Recursive call for half part of original input.\n        evenTensor = this.fftRadix2(evenTensor, half, inverse);\n        oddTensor = this.fftRadix2(oddTensor, half, inverse);\n        var e = complex_util.exponents(size, inverse);\n        var exponent = ops.complex(e.real, e.imag).mul(oddTensor);\n        var addPart = evenTensor.add(exponent);\n        var subPart = evenTensor.sub(exponent);\n        var realTensor = ops.real(addPart).concat(ops.real(subPart));\n        var imagTensor = ops.imag(addPart).concat(ops.imag(subPart));\n        return ops.complex(realTensor, imagTensor).as1D();\n    };\n    // Calculate fourier transform by multplying sinusoid matrix.\n    MathBackendCPU.prototype.fourierTransformByMatmul = function (data, size, inverse) {\n        var ret = new Float32Array(size * 2);\n        // TODO: Use matmul instead once it supports complex64 type.\n        for (var r = 0; r < size; r++) {\n            var real = 0.0;\n            var imag = 0.0;\n            for (var c = 0; c < size; c++) {\n                var e = complex_util.exponent(r * c, size, inverse);\n                var term = complex_util.getComplexWithIndex(data, c);\n                real += term.real * e.real - term.imag * e.imag;\n                imag += term.real * e.imag + term.imag * e.real;\n            }\n            if (inverse) {\n                real /= size;\n                imag /= size;\n            }\n            complex_util.assignToTypedArray(ret, real, imag, r);\n        }\n        return ret;\n    };\n    MathBackendCPU.prototype.depthToSpace = function (x, blockSize, dataFormat) {\n        util.assert(dataFormat === 'NHWC', function () { return \"Only NHWC dataFormat supported on CPU for depthToSpace. Got \" + dataFormat; });\n        util.assert(blockSize > 1, function () {\n            return \"blockSize should be > 1 for depthToSpace, but was: \" + blockSize;\n        });\n        var batchSize = x.shape[0];\n        var inputHeight = x.shape[1];\n        var inputWidth = x.shape[2];\n        var inputDepth = x.shape[3];\n        var outputHeight = inputHeight * blockSize;\n        var outputWidth = inputWidth * blockSize;\n        var outputDepth = inputDepth / (blockSize * blockSize);\n        var xValues = this.readSync(x.dataId);\n        var result = new Float32Array(batchSize * outputHeight * outputWidth * outputDepth);\n        var outputIdx = 0;\n        for (var b = 0; b < batchSize; ++b) {\n            for (var h = 0; h < outputHeight; ++h) {\n                var inH = Math.floor(h / blockSize);\n                var offsetH = (h % blockSize);\n                for (var w = 0; w < outputWidth; ++w) {\n                    var inW = Math.floor(w / blockSize);\n                    var offsetW = (w % blockSize);\n                    var offsetD = (offsetH * blockSize + offsetW) * outputDepth;\n                    for (var d = 0; d < outputDepth; ++d) {\n                        var inD = d + offsetD;\n                        var inputIdx = inD + inputDepth * (inW + inputWidth * (inH + inputHeight * b));\n                        result[outputIdx++] = xValues[inputIdx];\n                    }\n                }\n            }\n        }\n        return ops.tensor4d(result, [batchSize, outputHeight, outputWidth, outputDepth]);\n    };\n    MathBackendCPU.prototype.broadcastedBinaryOp = function (a, b, dtype, op) {\n        var newShape = broadcast_util.assertAndGetBroadcastShape(a.shape, b.shape);\n        var result = ops.buffer(newShape, dtype);\n        var aVals = this.readSync(a.dataId);\n        var bVals = this.readSync(b.dataId);\n        var aBroadcastDims = broadcast_util.getBroadcastDims(a.shape, newShape);\n        var bBroadcastDims = broadcast_util.getBroadcastDims(b.shape, newShape);\n        var resVals = result.values;\n        if (aBroadcastDims.length + bBroadcastDims.length === 0) {\n            for (var i = 0; i < resVals.length; ++i) {\n                resVals[i] = op(aVals[i % aVals.length], bVals[i % bVals.length]);\n            }\n        }\n        else {\n            var aBuf = this.bufferSync(a);\n            var bBuf = this.bufferSync(b);\n            var _loop_2 = function (i) {\n                var loc = result.indexToLoc(i);\n                var aLoc = loc.slice(-a.rank);\n                aBroadcastDims.forEach(function (d) { return aLoc[d] = 0; });\n                var aIndex = aBuf.locToIndex(aLoc);\n                var bLoc = loc.slice(-b.rank);\n                bBroadcastDims.forEach(function (d) { return bLoc[d] = 0; });\n                var bIndex = bBuf.locToIndex(bLoc);\n                resVals[i] = op(aVals[aIndex], bVals[bIndex]);\n            };\n            for (var i = 0; i < resVals.length; ++i) {\n                _loop_2(i);\n            }\n        }\n        return result.toTensor();\n    };\n    MathBackendCPU.prototype.broadcastedBinaryComplexOp = function (a, b, op) {\n        var newShape = broadcast_util.assertAndGetBroadcastShape(a.shape, b.shape);\n        var realResult = ops.buffer(newShape, 'float32');\n        var imagResult = ops.buffer(newShape, 'float32');\n        var aVals = this.readSync(a.dataId);\n        var bVals = this.readSync(b.dataId);\n        var aBroadcastDims = broadcast_util.getBroadcastDims(a.shape, newShape);\n        var bBroadcastDims = broadcast_util.getBroadcastDims(b.shape, newShape);\n        var realVals = realResult.values;\n        var imagVals = imagResult.values;\n        if (aBroadcastDims.length + bBroadcastDims.length === 0) {\n            for (var i = 0; i < realVals.length; i++) {\n                var aIdx = i % aVals.length;\n                var bIdx = i % bVals.length;\n                var result = op(aVals[aIdx * 2], aVals[aIdx * 2 + 1], bVals[bIdx * 2], bVals[bIdx * 2 + 1]);\n                realVals[i] = result.real;\n                imagVals[i] = result.imag;\n            }\n        }\n        else {\n            var aRealBuf = this.bufferSync(this.data.get(a.dataId).complexTensors.real);\n            var bRealBuf = this.bufferSync(this.data.get(b.dataId).complexTensors.real);\n            var _loop_3 = function (i) {\n                var loc = realResult.indexToLoc(i);\n                var aLoc = loc.slice(-a.rank);\n                aBroadcastDims.forEach(function (d) { return aLoc[d] = 0; });\n                var aIndex = aRealBuf.locToIndex(aLoc);\n                var bLoc = loc.slice(-b.rank);\n                bBroadcastDims.forEach(function (d) { return bLoc[d] = 0; });\n                var bIndex = bRealBuf.locToIndex(bLoc);\n                var opResult = op(aVals[aIndex * 2], aVals[aIndex * 2 + 1], bVals[bIndex * 2], bVals[bIndex * 2 + 1]);\n                realVals[i] = opResult.real;\n                imagVals[i] = opResult.imag;\n            };\n            for (var i = 0; i < realVals.length; i++) {\n                _loop_3(i);\n            }\n        }\n        return this.complex(realResult.toTensor(), imagResult.toTensor());\n    };\n    MathBackendCPU.prototype.split = function (x, sizeSplits, axis) {\n        return split_shared_1.split(x, sizeSplits, axis);\n    };\n    MathBackendCPU.prototype.dispose = function () { };\n    MathBackendCPU.prototype.floatPrecision = function () {\n        return 32;\n    };\n    /** Returns the smallest representable number.  */\n    MathBackendCPU.prototype.epsilon = function () {\n        return backend_1.EPSILON_FLOAT32;\n    };\n    MathBackendCPU.prototype.cropAndResize = function (images, boxes, boxIndex, cropSize, method, extrapolationValue) {\n        var _a = images.shape, batch = _a[0], imageHeight = _a[1], imageWidth = _a[2], numChannels = _a[3];\n        var numBoxes = boxes.shape[0];\n        var cropHeight = cropSize[0], cropWidth = cropSize[1];\n        var output = ops.buffer([numBoxes, cropHeight, cropWidth, numChannels], images.dtype);\n        var boxVals = this.readSync(boxes.dataId);\n        var boxIndVals = this.readSync(boxIndex.dataId);\n        var imageVals = this.readSync(images.dataId);\n        var inStride = images.strides; // to calculate flat indexes into image\n        var outStride = output.strides; // to calculate flat indexes into output\n        // Reference implementation\n        // tslint:disable-next-line:max-line-length\n        // https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/crop_and_resize_op.cc\n        for (var b = 0; b < numBoxes; b++) {\n            var startInd = b * 4;\n            var y1 = boxVals[startInd];\n            var x1 = boxVals[startInd + 1];\n            var y2 = boxVals[startInd + 2];\n            var x2 = boxVals[startInd + 3];\n            var bInd = boxIndVals[b];\n            if (bInd >= batch) {\n                continue;\n            }\n            var heightScale = (cropHeight > 1) ?\n                (y2 - y1) * (imageHeight - 1) / (cropHeight - 1) :\n                0;\n            var widthScale = (cropWidth > 1) ? (x2 - x1) * (imageWidth - 1) / (cropWidth - 1) : 0;\n            for (var y = 0; y < cropHeight; y++) {\n                var yInd = (cropHeight > 1) ?\n                    y1 * (imageHeight - 1) + y * (heightScale) :\n                    0.5 * (y1 + y2) * (imageHeight - 1);\n                if (yInd < 0 || yInd > imageHeight - 1) {\n                    for (var x = 0; x < cropWidth; x++) {\n                        for (var c = 0; c < numChannels; c++) {\n                            var ind = c + x * outStride[2] + y * outStride[1] + b * outStride[0];\n                            output.values[ind] = extrapolationValue;\n                        }\n                    }\n                    continue;\n                }\n                if (method === 'bilinear') {\n                    var topInd = Math.floor(yInd);\n                    var bottomInd = Math.ceil(yInd);\n                    var yLerp = yInd - topInd;\n                    for (var x = 0; x < cropWidth; x++) {\n                        var xInd = (cropWidth > 1) ?\n                            x1 * (imageWidth - 1) + x * widthScale :\n                            0.5 * (x1 + x2) * (imageWidth - 1);\n                        if (xInd < 0 || xInd > imageWidth - 1) {\n                            for (var c = 0; c < numChannels; c++) {\n                                var ind = c + x * outStride[2] + y * outStride[1] + b * outStride[0];\n                                output.values[ind] = extrapolationValue;\n                            }\n                            continue;\n                        }\n                        var leftInd = Math.floor(xInd);\n                        var rightInd = Math.ceil(xInd);\n                        var xLerp = xInd - leftInd;\n                        for (var c = 0; c < numChannels; c++) {\n                            var ind = c + leftInd * inStride[2] + topInd * inStride[1] +\n                                bInd * inStride[0];\n                            var topLeft = imageVals[ind];\n                            ind = c + rightInd * inStride[2] + topInd * inStride[1] +\n                                bInd * inStride[0];\n                            var topRight = imageVals[ind];\n                            ind = c + leftInd * inStride[2] + bottomInd * inStride[1] +\n                                bInd * inStride[0];\n                            var bottomLeft = imageVals[ind];\n                            ind = c + rightInd * inStride[2] + bottomInd * inStride[1] +\n                                bInd * inStride[0];\n                            var bottomRight = imageVals[ind];\n                            var top_2 = topLeft + (topRight - topLeft) * xLerp;\n                            var bottom = bottomLeft + (bottomRight - bottomLeft) * xLerp;\n                            ind = c + x * outStride[2] + y * outStride[1] + b * outStride[0];\n                            output.values[ind] = top_2 + ((bottom - top_2) * yLerp);\n                        }\n                    }\n                }\n                else { // method == \"nearest\"\n                    for (var x = 0; x < cropWidth; ++x) {\n                        var xInd = (cropWidth > 1) ?\n                            x1 * (imageWidth - 1) + x * widthScale :\n                            0.5 * (x1 + x2) * (imageWidth - 1);\n                        if (xInd < 0 || xInd > imageWidth - 1) {\n                            for (var c = 0; c < numChannels; c++) {\n                                var ind = c + x * outStride[2] + y * outStride[1] + b * outStride[0];\n                                output.values[ind] = extrapolationValue;\n                            }\n                            continue;\n                        }\n                        var closestX = Math.round(xInd);\n                        var closestY = Math.round(yInd);\n                        for (var c = 0; c < numChannels; c++) {\n                            var inInd = c + closestX * inStride[2] +\n                                closestY * inStride[1] + bInd * inStride[0];\n                            var outInd = c + x * outStride[2] + y * outStride[1] + b * outStride[0];\n                            output.values[outInd] = imageVals[inInd];\n                        }\n                    }\n                }\n            }\n        }\n        return output.toTensor();\n    };\n    MathBackendCPU.prototype.sparseToDense = function (sparseIndices, sparseValues, outputShape, defaultValue) {\n        var _a = scatter_nd_util.calculateShapes(sparseValues, sparseIndices, outputShape), sliceRank = _a.sliceRank, numUpdates = _a.numUpdates, sliceSize = _a.sliceSize, strides = _a.strides, outputSize = _a.outputSize;\n        var sumDupeIndices = false;\n        return this.scatter(sparseIndices, sparseValues, outputShape, outputSize, sliceSize, numUpdates, sliceRank, strides, defaultValue, sumDupeIndices);\n    };\n    MathBackendCPU.prototype.gatherND = function (x, indices) {\n        var indicesShape = indices.shape;\n        var sliceRank = indicesShape[indicesShape.length - 1];\n        var _a = gather_nd_util.prepareAndValidate(x, indices), resultShape = _a[0], numSlices = _a[1], sliceSize = _a[2], strides = _a[3];\n        if (numSlices === 0) {\n            return ops_1.tensor([], resultShape, x.dtype);\n        }\n        var buffer = new tensor_1.TensorBuffer([numSlices, sliceSize], x.dtype);\n        var indicesData = this.readSync(indices.dataId);\n        var xData = this.readSync(x.dataId);\n        for (var i = 0; i < numSlices; i++) {\n            var index = [];\n            var flattenIndex = 0;\n            for (var j = 0; j < sliceRank; j++) {\n                var dim = indicesData[i * sliceRank + j];\n                flattenIndex += dim * strides[j];\n                index.push(dim);\n            }\n            if (flattenIndex < 0 || flattenIndex >= x.size / sliceSize) {\n                throw new Error(\"Invalid indices: \" + index + \" does not index into \" + x.shape);\n            }\n            for (var k = 0; k < sliceSize; k++) {\n                buffer.values[i * sliceSize + k] = xData[flattenIndex * sliceSize + k];\n            }\n        }\n        return buffer.toTensor().reshape(resultShape);\n    };\n    MathBackendCPU.prototype.scatterND = function (indices, updates, shape) {\n        var _a = scatter_nd_util.calculateShapes(updates, indices, shape), sliceRank = _a.sliceRank, numUpdates = _a.numUpdates, sliceSize = _a.sliceSize, strides = _a.strides, outputSize = _a.outputSize;\n        var defaultValue = ops_1.scalar(0);\n        var sumDupeIndices = true;\n        return this.scatter(indices, updates, shape, outputSize, sliceSize, numUpdates, sliceRank, strides, defaultValue, sumDupeIndices);\n    };\n    MathBackendCPU.prototype.fill = function (shape, value, dtype) {\n        dtype = dtype || util_1.inferDtype(value);\n        var values = util_1.getArrayFromDType(dtype, util_1.sizeFromShape(shape));\n        values.fill(value);\n        return tensor_1.Tensor.make(shape, { values: values }, dtype);\n    };\n    MathBackendCPU.prototype.onesLike = function (x) {\n        if (x.dtype === 'string') {\n            throw new Error('onesLike is not supported for string tensors');\n        }\n        else {\n            return this.fill(x.shape, 1, x.dtype);\n        }\n    };\n    MathBackendCPU.prototype.zerosLike = function (x) {\n        var values = util_1.getArrayFromDType(x.dtype, util_1.sizeFromShape(x.shape));\n        return tensor_1.Tensor.make(x.shape, { values: values }, x.dtype);\n    };\n    MathBackendCPU.prototype.linspace = function (start, stop, num) {\n        return backend_util.linspaceImpl(start, stop, num);\n    };\n    MathBackendCPU.prototype.scatter = function (indices, updates, shape, outputSize, sliceSize, numUpdates, sliceRank, strides, defaultValue, sumDupeIndices) {\n        var flattenShape = [outputSize / sliceSize, sliceSize];\n        var indicesData = this.readSync(indices.dataId);\n        var updatesData = this.readSync(updates.dataId);\n        if (outputSize === 0) {\n            return ops_1.tensor([], shape, updates.dtype);\n        }\n        var buffer = new tensor_1.TensorBuffer(flattenShape, updates.dtype);\n        buffer.values.fill(this.readSync(defaultValue.dataId)[0]);\n        for (var i = 0; i < numUpdates; i++) {\n            var index = [];\n            var flattenIndex = 0;\n            for (var j = 0; j < sliceRank; j++) {\n                var dim = indicesData[i * sliceRank + j];\n                index.push(dim);\n                flattenIndex += dim * strides[j];\n            }\n            if (flattenIndex < 0 || flattenIndex >= outputSize / sliceSize) {\n                throw new Error(\"Invalid indices: \" + index + \" does not index into \" + shape);\n            }\n            for (var k = 0; k < sliceSize; k++) {\n                if (sumDupeIndices) {\n                    buffer.values[flattenIndex * sliceSize + k] +=\n                        updatesData[i * sliceSize + k];\n                }\n                else {\n                    buffer.values[flattenIndex * sliceSize + k] = updates.rank === 0 ?\n                        updatesData[0] :\n                        updatesData[i * sliceSize + k];\n                }\n            }\n        }\n        return buffer.toTensor().reshape(shape);\n    };\n    return MathBackendCPU;\n}());\nexports.MathBackendCPU = MathBackendCPU;\nengine_1.ENGINE.registerBackend('cpu', function () { return new MathBackendCPU(); }, 1 /* priority */);\n//# sourceMappingURL=backend_cpu.js.map","\n/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nfunction __export(m) {\n    for (var p in m) if (!exports.hasOwnProperty(p)) exports[p] = m[p];\n}\nObject.defineProperty(exports, \"__esModule\", { value: true });\n__export(require(\"./batchnorm\"));\n__export(require(\"./complex_ops\"));\n__export(require(\"./concat_split\"));\n__export(require(\"./conv\"));\n__export(require(\"./matmul\"));\n__export(require(\"./reverse\"));\n__export(require(\"./pool\"));\n__export(require(\"./slice\"));\n__export(require(\"./unary_ops\"));\n__export(require(\"./reduction_ops\"));\n__export(require(\"./compare\"));\n__export(require(\"./binary_ops\"));\n__export(require(\"./relu_ops\"));\n__export(require(\"./logical_ops\"));\n__export(require(\"./array_ops\"));\n__export(require(\"./tensor_ops\"));\n__export(require(\"./transpose\"));\n__export(require(\"./softmax\"));\n__export(require(\"./lrn\"));\n__export(require(\"./norm\"));\n__export(require(\"./segment_ops\"));\n__export(require(\"./lstm\"));\n__export(require(\"./moving_average\"));\n__export(require(\"./strided_slice\"));\n__export(require(\"./topk\"));\n__export(require(\"./scatter_nd\"));\n__export(require(\"./spectral_ops\"));\n__export(require(\"./sparse_to_dense\"));\n__export(require(\"./gather_nd\"));\n__export(require(\"./dropout\"));\n__export(require(\"./signal_ops\"));\nvar operation_1 = require(\"./operation\");\nexports.op = operation_1.op;\n// Second level exports.\nvar losses = require(\"./loss_ops\");\nexports.losses = losses;\nvar linalg = require(\"./linalg_ops\");\nexports.linalg = linalg;\nvar image = require(\"./image_ops\");\nexports.image = image;\nvar spectral = require(\"./spectral_ops\");\nexports.spectral = spectral;\nvar fused = require(\"./fused_ops\");\nexports.fused = fused;\nvar signal = require(\"./signal_ops\");\nexports.signal = signal;\n//# sourceMappingURL=ops.js.map","\n/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar engine_1 = require(\"../engine\");\nvar globals_1 = require(\"../globals\");\nvar tensor_util_env_1 = require(\"../tensor_util_env\");\nvar util = require(\"../util\");\nvar array_ops_1 = require(\"./array_ops\");\nvar broadcast_util_1 = require(\"./broadcast_util\");\nvar operation_1 = require(\"./operation\");\nvar tensor_ops_1 = require(\"./tensor_ops\");\nvar unary_ops_1 = require(\"./unary_ops\");\n/**\n * Batch normalization, strictly for 2D. For the more relaxed version, see\n * `tf.batchNorm`.\n *\n * @param x The input Tensor.\n * @param mean A mean Tensor.\n * @param variance A variance Tensor.\n * @param offset An offset Tensor.\n * @param scale A scale Tensor.\n * @param varianceEpsilon A small float number to avoid dividing by 0.\n */\nfunction batchNorm2d_(x, mean, variance, offset, scale, varianceEpsilon) {\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'batchNorm');\n    var $mean = tensor_util_env_1.convertToTensor(mean, 'mean', 'batchNorm');\n    var $variance = tensor_util_env_1.convertToTensor(variance, 'variance', 'batchNorm');\n    var $scale;\n    if (scale != null) {\n        $scale = tensor_util_env_1.convertToTensor(scale, 'scale', 'batchNorm');\n    }\n    var $offset;\n    if (offset != null) {\n        $offset = tensor_util_env_1.convertToTensor(offset, 'offset', 'batchNorm');\n    }\n    util.assert($x.rank === 2, function () { return \"Error in batchNorm3D: x must be rank 3 but got rank \" +\n        ($x.rank + \".\"); });\n    util.assert($mean.rank === 2 || $mean.rank === 1, function () { return \"Error in batchNorm2D: mean must be rank 2 or rank 1 but \" +\n        (\"got rank \" + $mean.rank + \".\"); });\n    util.assert($variance.rank === 2 || $variance.rank === 1, function () { return \"Error in batchNorm2D: variance must be rank 2 or rank 1 \" +\n        (\"but got rank \" + $variance.rank + \".\"); });\n    if ($scale != null) {\n        util.assert($scale.rank === 2 || $scale.rank === 1, function () { return \"Error in batchNorm2D: scale must be rank 2 or rank 1 \" +\n            (\"but got rank \" + $scale.rank + \".\"); });\n    }\n    if ($offset != null) {\n        util.assert($offset.rank === 2 || $offset.rank === 1, function () { return \"Error in batchNorm2D: offset must be rank 2 or rank 1 \" +\n            (\"but got rank \" + $offset.rank + \".\"); });\n    }\n    return batchNorm_($x, $mean, $variance, $offset, $scale, varianceEpsilon);\n}\n/**\n * Batch normalization, strictly for 3D. For the more relaxed version, see\n * `tf.batchNorm`.\n *\n * @param x The input Tensor.\n * @param mean A mean Tensor.\n * @param variance A variance Tensor.\n * @param offset An offset Tensor.\n * @param scale A scale Tensor.\n * @param varianceEpsilon A small float number to avoid dividing by 0.\n */\nfunction batchNorm3d_(x, mean, variance, offset, scale, varianceEpsilon) {\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'batchNorm');\n    var $mean = tensor_util_env_1.convertToTensor(mean, 'mean', 'batchNorm');\n    var $variance = tensor_util_env_1.convertToTensor(variance, 'variance', 'batchNorm');\n    var $scale;\n    if (scale != null) {\n        $scale = tensor_util_env_1.convertToTensor(scale, 'scale', 'batchNorm');\n    }\n    var $offset;\n    if (offset != null) {\n        $offset = tensor_util_env_1.convertToTensor(offset, 'offset', 'batchNorm');\n    }\n    util.assert($x.rank === 3, function () { return \"Error in batchNorm3D: x must be rank 3 but got rank \" +\n        ($x.rank + \".\"); });\n    util.assert($mean.rank === 3 || $mean.rank === 1, function () { return \"Error in batchNorm3D: mean must be rank 3 or rank 1 but \" +\n        (\"got rank \" + $mean.rank + \".\"); });\n    util.assert($variance.rank === 3 || $variance.rank === 1, function () { return \"Error in batchNorm3D: variance must be rank 3 or rank 1 \" +\n        (\"but got rank \" + $variance.rank + \".\"); });\n    if ($scale != null) {\n        util.assert($scale.rank === 3 || $scale.rank === 1, function () { return \"Error in batchNorm3D: scale must be rank 3 or rank 1 \" +\n            (\"but got rank \" + $scale.rank + \".\"); });\n    }\n    if ($offset != null) {\n        util.assert($offset.rank === 3 || $offset.rank === 1, function () { return \"Error in batchNorm3D: offset must be rank 3 or rank 1 \" +\n            (\"but got rank \" + $offset.rank + \".\"); });\n    }\n    return batchNorm_($x, $mean, $variance, $offset, $scale, varianceEpsilon);\n}\n/**\n * Batch normalization, strictly for 4D. For the more relaxed version, see\n * `tf.batchNorm`.\n *\n * @param x The input Tensor.\n * @param mean A mean Tensor.\n * @param variance A variance Tensor.\n * @param offset An offset Tensor.\n * @param scale A scale Tensor.\n * @param varianceEpsilon A small float number to avoid dividing by 0.\n */\nfunction batchNorm4d_(x, mean, variance, offset, scale, varianceEpsilon) {\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'batchNorm');\n    var $mean = tensor_util_env_1.convertToTensor(mean, 'mean', 'batchNorm');\n    var $variance = tensor_util_env_1.convertToTensor(variance, 'variance', 'batchNorm');\n    var $scale;\n    if (scale != null) {\n        $scale = tensor_util_env_1.convertToTensor(scale, 'scale', 'batchNorm');\n    }\n    var $offset;\n    if (offset != null) {\n        $offset = tensor_util_env_1.convertToTensor(offset, 'offset', 'batchNorm');\n    }\n    util.assert($x.rank === 4, function () { return \"Error in batchNorm4D: x must be rank 4 but got rank \" +\n        ($x.rank + \".\"); });\n    util.assert($mean.rank === 4 || $mean.rank === 1, function () { return \"Error in batchNorm4D: mean must be rank 4 or rank 1 but \" +\n        (\"got rank \" + $mean.rank + \".\"); });\n    util.assert($variance.rank === 4 || $variance.rank === 1, function () { return \"Error in batchNorm4D: variance must be rank 4 or rank 1 \" +\n        (\"but got rank \" + $variance.rank + \".\"); });\n    if ($scale != null) {\n        util.assert($scale.rank === 4 || $scale.rank === 1, function () { return \"Error in batchNorm4D: scale must be rank 4 or rank 1 \" +\n            (\"but got rank \" + $scale.rank + \".\"); });\n    }\n    if ($offset != null) {\n        util.assert($offset.rank === 4 || $offset.rank === 1, function () { return \"Error in batchNorm4D: offset must be rank 4 or rank 1 \" +\n            (\"but got rank \" + $offset.rank + \".\"); });\n    }\n    return batchNorm_($x, $mean, $variance, $offset, $scale, varianceEpsilon);\n}\n/**\n * @deprecated Please use `tf.batchNorm` instead and note the positional\n *     argument change of scale, offset, and varianceEpsilon.\n */\nfunction batchNormalization_(x, mean, variance, varianceEpsilon, scale, offset) {\n    if (varianceEpsilon === void 0) { varianceEpsilon = .001; }\n    warnDeprecation();\n    return batchNorm_(x, mean, variance, offset, scale, varianceEpsilon);\n}\n/**\n * Batch normalization.\n *\n * As described in\n * [http://arxiv.org/abs/1502.03167](http://arxiv.org/abs/1502.03167).\n *\n * Mean, variance, scale, and offset can be of two shapes:\n *   - The same shape as the input.\n *   - In the common case, the depth dimension is the last dimension of x, so\n *     the values would be an `tf.Tensor1D` of shape [depth].\n *\n * Also available are stricter rank-specific methods with the same signature\n * as this method that assert that parameters passed are of given rank\n *   - `tf.batchNorm2d`\n *   - `tf.batchNorm3d`\n *   - `tf.batchNorm4d`\n *\n * @param x The input Tensor.\n * @param mean A mean Tensor.\n * @param variance A variance Tensor.\n * @param offset An offset Tensor.\n * @param scale A scale Tensor.\n * @param varianceEpsilon A small float number to avoid dividing by 0.\n */\n/** @doc {heading: 'Operations', subheading: 'Normalization'} */\nfunction batchNorm_(x, mean, variance, offset, scale, varianceEpsilon) {\n    if (varianceEpsilon == null) {\n        varianceEpsilon = 0.001;\n    }\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'batchNorm');\n    var $mean = tensor_util_env_1.convertToTensor(mean, 'mean', 'batchNorm');\n    var $variance = tensor_util_env_1.convertToTensor(variance, 'variance', 'batchNorm');\n    var $scale;\n    if (scale != null) {\n        $scale = tensor_util_env_1.convertToTensor(scale, 'scale', 'batchNorm');\n    }\n    var $offset;\n    if (offset != null) {\n        $offset = tensor_util_env_1.convertToTensor(offset, 'offset', 'batchNorm');\n    }\n    util.assert($mean.rank === $variance.rank, function () { return 'Batch normalization gradient requires mean and variance to have ' +\n        'equal ranks.'; });\n    util.assert($offset == null || $mean.rank === $offset.rank, function () { return 'Batch normalization gradient requires mean and offset to have ' +\n        'equal ranks.'; });\n    util.assert($scale == null || $mean.rank === $scale.rank, function () { return 'Batch normalization gradient requires mean and scale to have ' +\n        'equal ranks.'; });\n    var x4D;\n    if ($x.rank === 0 || $x.rank === 1) {\n        x4D = $x.as4D(1, 1, 1, $x.size);\n    }\n    else if ($x.rank === 2) {\n        x4D = $x.as4D(1, 1, $x.shape[0], $x.shape[1]);\n    }\n    else if ($x.rank === 3) {\n        x4D = $x.as4D(1, $x.shape[0], $x.shape[1], $x.shape[2]);\n    }\n    else {\n        x4D = $x;\n    }\n    var der = function (dy, saved) {\n        var $x = saved[0], $mean = saved[1], $variance = saved[2], $scale = saved[3];\n        var scaleValue = $scale == null ? tensor_ops_1.scalar(1) : $scale;\n        var reductionAxes = broadcast_util_1.getReductionAxes($mean.shape, x4D.shape);\n        var tileShape = [];\n        if ($mean.rank === 1) {\n            for (var i = 0; i < x4D.shape.length - 1; ++i) {\n                tileShape.push(x4D.shape[i]);\n            }\n            tileShape.push(1);\n        }\n        var xMinusMean = $x.sub($mean);\n        var dyTimesScaleValue = dy.mul(scaleValue);\n        var oneOverSqrtVariance = unary_ops_1.rsqrt($variance.add(tensor_ops_1.scalar(varianceEpsilon)));\n        var minusHalfRCube = oneOverSqrtVariance.mul(oneOverSqrtVariance)\n            .mul(oneOverSqrtVariance)\n            .mul(tensor_ops_1.scalar(-0.5));\n        var derX = function () {\n            if ($mean.rank === 1) {\n                return dy.mul(array_ops_1.tile(oneOverSqrtVariance.as4D(1, 1, 1, $mean.shape[0]), tileShape))\n                    .mul(scaleValue)\n                    .reshape($x.shape);\n            }\n            else {\n                return dy.mul(oneOverSqrtVariance).mul(scaleValue).reshape($x.shape);\n            }\n        };\n        var derMean = function () {\n            var meanDer = oneOverSqrtVariance.mul(tensor_ops_1.scalar(-1)).mul(dyTimesScaleValue);\n            if ($mean.rank === 1) {\n                meanDer = meanDer.sum(reductionAxes);\n            }\n            return meanDer.reshape($mean.shape);\n        };\n        var derVariance = function () {\n            var varianceDer = minusHalfRCube.mul(xMinusMean).mul(dyTimesScaleValue);\n            if ($mean.rank === 1) {\n                varianceDer = varianceDer.sum(reductionAxes);\n            }\n            return varianceDer.reshape($mean.shape);\n        };\n        var derScale = function () {\n            var xMinusMean2TimesRsqrt = xMinusMean.mul(oneOverSqrtVariance);\n            var scaleDer = dy.mul(xMinusMean2TimesRsqrt);\n            if ($mean.rank === 1) {\n                scaleDer = scaleDer.sum(reductionAxes);\n            }\n            return scaleDer.reshape($mean.shape);\n        };\n        var derOffset = function () {\n            var offsetDer = dy;\n            if ($mean.rank === 1) {\n                offsetDer = offsetDer.sum(reductionAxes);\n            }\n            return offsetDer.reshape($mean.shape);\n        };\n        return {\n            $x: derX,\n            $mean: derMean,\n            $variance: derVariance,\n            $scale: derScale,\n            $offset: derOffset\n        };\n    };\n    var res = engine_1.ENGINE.runKernel(function (backend, save) {\n        var res = backend.batchNormalization(x4D, batchnormReshape4D($mean), batchnormReshape4D($variance), varianceEpsilon, batchnormReshape4D($scale), batchnormReshape4D($offset));\n        save([$x, $mean, $variance, $scale]);\n        return res;\n    }, { $x: $x, $mean: $mean, $variance: $variance, $scale: $scale, $offset: $offset }, der);\n    return res.reshape($x.shape);\n}\nfunction batchnormReshape4D(x) {\n    if (x == null) {\n        return null;\n    }\n    if (x.rank === 0) {\n        return x.as1D();\n    }\n    else if (x.rank === 1) {\n        return x;\n    }\n    else if (x.rank === 2) {\n        return x.as4D(1, 1, x.shape[0], x.shape[1]);\n    }\n    else if (x.rank === 3) {\n        return x.as4D(1, x.shape[0], x.shape[1], x.shape[2]);\n    }\n    return x;\n}\n/**\n * @deprecated Please use `tf.batchNorm2d` instead and note the positional\n *     argument change of scale, offset, and varianceEpsilon.\n */\nfunction batchNormalization2d_(x, mean, variance, varianceEpsilon, scale, offset) {\n    if (varianceEpsilon === void 0) { varianceEpsilon = .001; }\n    warnDeprecation();\n    return batchNorm2d_(x, mean, variance, offset, scale, varianceEpsilon);\n}\n/**\n * @deprecated Please use `tf.batchNorm3d` instead and note the positional\n *     argument change of scale, offset, and varianceEpsilon.\n */\nfunction batchNormalization3d_(x, mean, variance, varianceEpsilon, scale, offset) {\n    if (varianceEpsilon === void 0) { varianceEpsilon = .001; }\n    warnDeprecation();\n    return batchNorm3d_(x, mean, variance, offset, scale, varianceEpsilon);\n}\n/**\n * @deprecated Please use `tf.batchNorm4d` instead and note the positional\n *     argument change of scale, offset, and varianceEpsilon.\n */\nfunction batchNormalization4d_(x, mean, variance, varianceEpsilon, scale, offset) {\n    if (varianceEpsilon === void 0) { varianceEpsilon = .001; }\n    warnDeprecation();\n    return batchNorm4d_(x, mean, variance, offset, scale, varianceEpsilon);\n}\nfunction warnDeprecation() {\n    globals_1.deprecationWarn('tf.batchNormalization() is going away. ' +\n        'Use tf.batchNorm() instead, and note the positional argument change ' +\n        'of scale, offset, and varianceEpsilon');\n}\nexports.batchNormalization2d = operation_1.op({ batchNormalization2d_: batchNormalization2d_ });\nexports.batchNormalization3d = operation_1.op({ batchNormalization3d_: batchNormalization3d_ });\nexports.batchNormalization4d = operation_1.op({ batchNormalization4d_: batchNormalization4d_ });\nexports.batchNormalization = operation_1.op({ batchNormalization_: batchNormalization_ });\nexports.batchNorm = operation_1.op({ batchNorm_: batchNorm_ });\nexports.batchNorm2d = operation_1.op({ batchNorm2d_: batchNorm2d_ });\nexports.batchNorm3d = operation_1.op({ batchNorm3d_: batchNorm3d_ });\nexports.batchNorm4d = operation_1.op({ batchNorm4d_: batchNorm4d_ });\n//# sourceMappingURL=batchnorm.js.map","\n/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar engine_1 = require(\"../engine\");\nvar tensor_util_env_1 = require(\"../tensor_util_env\");\nvar util = require(\"../util\");\nvar operation_1 = require(\"./operation\");\nvar tensor_ops_1 = require(\"./tensor_ops\");\n/**\n * Computes `-1 * x` element-wise.\n *\n * ```js\n * const x = tf.tensor2d([1, 2, -2, 0], [2, 2]);\n *\n * x.neg().print();  // or tf.neg(x)\n * ```\n *\n * @param x The input tensor.\n */\n/** @doc {heading: 'Operations', subheading: 'Basic math'} */\nfunction neg_(x) {\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'neg');\n    var grad = function (dy) {\n        return { $x: function () { return dy.neg(); } };\n    };\n    return engine_1.ENGINE.runKernel(function (backend) { return backend.neg($x); }, { $x: $x }, grad);\n}\n/**\n * Computes ceiling of input `tf.Tensor` element-wise: `ceil(x)`\n *\n * ```js\n * const x = tf.tensor1d([.6, 1.1, -3.3]);\n *\n * x.ceil().print();  // or tf.ceil(x)\n * ```\n * @param x The input Tensor.\n */\n/** @doc {heading: 'Operations', subheading: 'Basic math'} */\nfunction ceil_(x) {\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'ceil');\n    // TODO(manrajgrover): Return null for gradients when backprop supports it.\n    var grad = function (dy) {\n        return { $x: function () { return tensor_ops_1.zerosLike(dy); } };\n    };\n    return engine_1.ENGINE.runKernel(function (backend) { return backend.ceil($x); }, { $x: $x }, grad);\n}\n/**\n * Computes floor of input `tf.Tensor` element-wise: `floor(x)`.\n *\n * ```js\n * const x = tf.tensor1d([.6, 1.1, -3.3]);\n *\n * x.floor().print();  // or tf.floor(x)\n * ```\n * @param x The input tensor.\n */\n/** @doc {heading: 'Operations', subheading: 'Basic math'} */\nfunction floor_(x) {\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'floor');\n    // TODO(nsthorat): Let gradients be null for cases where we want to stop\n    // backpropgation.\n    var grad = function (dy) {\n        return { $x: function () { return tensor_ops_1.zerosLike(dy); } };\n    };\n    return engine_1.ENGINE.runKernel(function (backend) { return backend.floor($x); }, { $x: $x }, grad);\n}\n/**\n * Returns an element-wise indication of the sign of a number.\n *\n * ```js\n * const x = tf.tensor1d([.6, 1.1, -3.3, NaN, 0]);\n *\n * x.sign().print();  // or tf.sign(x)\n * ```\n * @param x The input Tensor.\n */\n/** @doc {heading: 'Operations', subheading: 'Basic math'} */\nfunction sign_(x) {\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'sign');\n    var grad = function (dy) {\n        return { $x: function () { return tensor_ops_1.zerosLike(dy); } };\n    };\n    return engine_1.ENGINE.runKernel(function (backend) { return backend.sign($x); }, { $x: $x }, grad);\n}\n/**\n * RReturns which elements of x are NaN.\n *\n * ```js\n * const x = tf.tensor1d([NaN, Infinity, -Infinity, 0, 1]);\n *\n * x.isNaN().print();  // or tf.isNaN(x)\n * ```\n * @param x The input Tensor.\n */\n/** @doc {heading: 'Operations', subheading: 'Basic math'} */\nfunction isNaN_(x) {\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'isNaN');\n    // TODO(nsthorat): Let gradients be null for cases where we want to stop\n    // backpropgation.\n    var grad = function (dy) {\n        return { $x: function () { return tensor_ops_1.zerosLike(dy); } };\n    };\n    return engine_1.ENGINE.runKernel(function (backend) { return backend.isNaN($x); }, { $x: $x }, grad);\n}\n/**\n * Returns which elements of x are Infinity or -Infinity.\n *\n * ```js\n * const x = tf.tensor1d([NaN, Infinity, -Infinity, 0, 1]);\n *\n * x.isInf().print();  // or tf.isNaN(x)\n * ```\n * @param x The input Tensor.\n */\n/** @doc {heading: 'Operations', subheading: 'Basic math'} */\nfunction isInf_(x) {\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'isInf');\n    // TODO(nsthorat): Let gradients be null for cases where we want to stop\n    // backpropgation.\n    var grad = function (dy) {\n        return { $x: function () { return tensor_ops_1.zerosLike(dy); } };\n    };\n    return engine_1.ENGINE.runKernel(function (backend) { return backend.isInf($x); }, { $x: $x }, grad);\n}\n/**\n * Returns which elements of x are finite.\n *\n * ```js\n * const x = tf.tensor1d([NaN, Infinity, -Infinity, 0, 1]);\n *\n * x.isFinite().print();  // or tf.isNaN(x)\n * ```\n * @param x The input Tensor.\n */\n/** @doc {heading: 'Operations', subheading: 'Basic math'} */\nfunction isFinite_(x) {\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'isFinite');\n    // TODO(nsthorat): Let gradients be null for cases where we want to stop\n    // backpropgation.\n    var grad = function (dy) {\n        return { $x: function () { return tensor_ops_1.zerosLike(dy); } };\n    };\n    return engine_1.ENGINE.runKernel(function (backend) { return backend.isFinite($x); }, { $x: $x }, grad);\n}\n/**\n * Computes round of input `tf.Tensor` element-wise: `round(x)`.\n * It implements banker's rounding.\n *\n * ```js\n * const x = tf.tensor1d([.6, 1.1, -3.3]);\n *\n * x.round().print();  // or tf.round(x)\n * ```\n * @param x The input tensor.\n */\n/** @doc {heading: 'Operations', subheading: 'Basic math'} */\nfunction round_(x) {\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'round');\n    // TODO(nsthorat): Let gradients be null for cases where we want to stop\n    // backpropgation.\n    var grad = function (dy) {\n        return { $x: function () { return tensor_ops_1.zerosLike(dy); } };\n    };\n    return engine_1.ENGINE.runKernel(function (backend) { return backend.round($x); }, { $x: $x }, grad);\n}\n/**\n * Computes exponential of the input `tf.Tensor` element-wise. `e ^ x`\n *\n * ```js\n * const x = tf.tensor1d([1, 2, -3]);\n *\n * x.exp().print();  // or tf.exp(x)\n * ```\n * @param x The input tensor.\n */\n/** @doc {heading: 'Operations', subheading: 'Basic math'} */\nfunction exp_(x) {\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'exp');\n    var bck = function (dy, saved) {\n        return { $x: function () { return dy.mulStrict(saved[0]); } };\n    };\n    return engine_1.ENGINE.runKernel(function (backend, save) {\n        var y = backend.exp($x);\n        save([y]);\n        return y;\n    }, { $x: $x }, bck);\n}\n/**\n * Computes exponential of the input `tf.Tensor` minus one element-wise.\n * `e ^ x - 1`\n *\n * ```js\n * const x = tf.tensor1d([1, 2, -3]);\n *\n * x.expm1().print();  // or tf.expm1(x)\n * ```\n * @param x The input tensor.\n */\n/** @doc {heading: 'Operations', subheading: 'Basic math'} */\nfunction expm1_(x) {\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'expm1');\n    var grad = function (dy, saved) {\n        var $x = saved[0];\n        return { $x: function () { return dy.mul($x.exp()); } };\n    };\n    return engine_1.ENGINE.runKernel(function (backend, save) {\n        var res = backend.expm1($x);\n        save([$x]);\n        return res;\n    }, { $x: $x }, grad);\n}\n/**\n * Computes natural logarithm of the input `tf.Tensor` element-wise: `ln(x)`\n *\n * ```js\n * const x = tf.tensor1d([1, 2, Math.E]);\n *\n * x.log().print();  // or tf.log(x)\n * ```\n * @param x The input tensor.\n */\n/** @doc {heading: 'Operations', subheading: 'Basic math'} */\nfunction log_(x) {\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'log');\n    var grad = function (dy, saved) {\n        var $x = saved[0];\n        return { $x: function () { return dy.div($x.toFloat()); } };\n    };\n    return engine_1.ENGINE.runKernel(function (backend, save) {\n        var res = backend.log($x);\n        save([$x]);\n        return res;\n    }, { $x: $x }, grad);\n}\n/**\n * Computes natural logarithm of the input `tf.Tensor` plus one\n * element-wise: `ln(1 + x)`\n *\n * ```js\n * const x = tf.tensor1d([1, 2, Math.E - 1]);\n *\n * x.log1p().print();  // or tf.log1p(x)\n * ```\n * @param x The input tensor.\n */\n/** @doc {heading: 'Operations', subheading: 'Basic math'} */\nfunction log1p_(x) {\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'log1p');\n    var grad = function (dy, saved) {\n        var $x = saved[0];\n        return { $x: function () { return dy.div($x.add(1)); } };\n    };\n    return engine_1.ENGINE.runKernel(function (backend, save) {\n        var res = backend.log1p($x);\n        save([$x]);\n        return res;\n    }, { $x: $x }, grad);\n}\n/**\n * Computes square root of the input `tf.Tensor` element-wise: `y = sqrt(x)`\n *\n * ```js\n * const x = tf.tensor1d([1, 2, 4, -1]);\n *\n * x.sqrt().print();  // or tf.sqrt(x)\n * ```\n * @param x The input tensor.\n */\n/** @doc {heading: 'Operations', subheading: 'Basic math'} */\nfunction sqrt_(x) {\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'sqrt');\n    var grad = function (dy, saved) {\n        var $x = saved[0];\n        return { $x: function () { return dy.div($x.toFloat().sqrt().mul(2)); } };\n    };\n    return engine_1.ENGINE.runKernel(function (backend, save) {\n        var res = backend.sqrt($x);\n        save([$x]);\n        return res;\n    }, { $x: $x }, grad);\n}\n/**\n * Computes reciprocal of square root of the input `tf.Tensor` element-wise:\n * `y = 1 / sqrt(x)`\n *\n * ```js\n * const x = tf.tensor1d([1, 2, 4, -1]);\n *\n * x.rsqrt().print();  // or tf.rsqrt(x)\n * ```\n * @param x The input tensor.\n */\n/** @doc {heading: 'Operations', subheading: 'Basic math'} */\nfunction rsqrt_(x) {\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'rsqrt');\n    var grad = function (dy, saved) {\n        var $x = saved[0];\n        return { $x: function () { return dy.div($x.pow(1.5).mul(2)).neg(); } };\n    };\n    return engine_1.ENGINE.runKernel(function (backend, save) {\n        var res = backend.rsqrt($x);\n        save([$x]);\n        return res;\n    }, { $x: $x }, grad);\n}\n/**\n * Computes square of `x` element-wise: `x ^ 2`\n *\n * ```js\n * const x = tf.tensor1d([1, 2, Math.sqrt(2), -1]);\n *\n * x.square().print();  // or tf.square(x)\n * ```\n * @param x The input Tensor.\n */\n/** @doc {heading: 'Operations', subheading: 'Basic math'} */\nfunction square_(x) {\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'square');\n    var grad = function (dy, saved) {\n        var $x = saved[0];\n        return { $x: function () { return dy.mul($x.toFloat().mul(2)); } };\n    };\n    return engine_1.ENGINE.runKernel(function (backend, save) {\n        save([$x]);\n        return backend.square($x);\n    }, { $x: $x }, grad);\n}\n/**\n * Computes reciprocal of x element-wise: `1 / x`\n *\n * ```js\n * const x = tf.tensor1d([0, 1, 2]);\n *\n * x.reciprocal().print();  // or tf.reciprocal(x)\n * ```\n * @param x The input tensor.\n */\n/** @doc {heading: 'Operations', subheading: 'Basic math'} */\nfunction reciprocal_(x) {\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'reciprocal');\n    var grad = function (dy, saved) {\n        var $x = saved[0];\n        return { $x: function () { return dy.div($x.square().neg()); } };\n    };\n    return engine_1.ENGINE.runKernel(function (backend, save) {\n        var res = backend.reciprocal($x);\n        save([$x]);\n        return res;\n    }, { $x: $x }, grad);\n}\n/**\n * Computes absolute value element-wise: `abs(x)`\n *\n * ```js\n * const x = tf.tensor1d([-1, 2, -3, 4]);\n *\n * x.abs().print();  // or tf.abs(x)\n * ```\n * @param x The input `tf.Tensor`.\n */\n/** @doc {heading: 'Operations', subheading: 'Basic math'} */\nfunction abs_(x) {\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'abs');\n    if ($x.dtype === 'complex64') {\n        return engine_1.ENGINE.runKernel(function (backend) { return backend.complexAbs($x); }, { $x: $x });\n    }\n    var grad = function (dy, saved) {\n        var $x = saved[0];\n        return { $x: function () { return dy.mul($x.toFloat().step(-1)); } };\n    };\n    return engine_1.ENGINE.runKernel(function (backend, save) {\n        var res = backend.abs($x);\n        save([$x]);\n        return res;\n    }, { $x: $x }, grad);\n}\n/**\n * Clips values element-wise. `max(min(x, clipValueMax), clipValueMin)`\n *\n * ```js\n * const x = tf.tensor1d([-1, 2, -3, 4]);\n *\n * x.clipByValue(-2, 3).print();  // or tf.clipByValue(x, -2, 3)\n * ```\n * @param x The input tensor.\n * @param clipValueMin Lower-bound of range to be clipped to.\n * @param clipValueMax Upper-bound of range to be clipped to.\n */\n/** @doc {heading: 'Operations', subheading: 'Basic math'} */\nfunction clipByValue_(x, clipValueMin, clipValueMax) {\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'clipByValue');\n    util.assert((clipValueMin <= clipValueMax), function () { return \"Error in clip: min (\" + clipValueMin + \") must be \" +\n        (\"less than or equal to max (\" + clipValueMax + \").\"); });\n    var grad = function (dy, saved) {\n        var $x = saved[0];\n        return {\n            $x: function () { return dy.where($x.greaterEqual(clipValueMin)\n                .logicalAnd($x.lessEqual(clipValueMax)), tensor_ops_1.zerosLike(dy)); },\n        };\n    };\n    return engine_1.ENGINE.runKernel(function (backend, save) {\n        var res = backend.clip($x, clipValueMin, clipValueMax);\n        save([$x]);\n        return res;\n    }, { $x: $x }, grad);\n}\n/**\n * Computes sigmoid element-wise, `1 / (1 + exp(-x))`\n *\n * ```js\n * const x = tf.tensor1d([0, -1, 2, -3]);\n *\n * x.sigmoid().print();  // or tf.sigmoid(x)\n * ```\n * @param x The input tensor.\n */\n/** @doc {heading: 'Operations', subheading: 'Basic math'} */\nfunction sigmoid_(x) {\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'sigmoid');\n    var grad = function (dy, saved) {\n        var y = saved[0];\n        return { $x: function () { return dy.mul(y.mul(tensor_ops_1.scalar(1).sub(y))); } };\n    };\n    return engine_1.ENGINE.runKernel(function (backend, save) {\n        var y = backend.sigmoid($x);\n        save([y]);\n        return y;\n    }, { $x: $x }, grad);\n}\n/**\n * Computes log sigmoid of the input `tf.Tensor` element-wise:\n * `logSigmoid(x)`. For numerical stability, we use `-tf.softplus(-x)`.\n *\n * ```js\n * const x = tf.tensor1d([0, 1, -1, .7]);\n *\n * x.logSigmoid().print();  // or tf.logSigmoid(x)\n * ```\n * @param x The input tensor.\n */\n/** @doc {heading: 'Operations', subheading: 'Basic math'} */\nfunction logSigmoid_(x) {\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'logSigmoid');\n    var grad = function (dy, saved) {\n        var $x = saved[0];\n        return { $x: function () { return dy.mul($x.neg().sigmoid()); } };\n    };\n    return engine_1.ENGINE.runKernel(function (backend, save) {\n        var res = backend.softplus($x.neg()).neg();\n        save([$x]);\n        return res;\n    }, { $x: $x }, grad);\n}\n/**\n * Computes softplus of the input `tf.Tensor` element-wise: `log(exp(x) + 1)`\n *\n * ```js\n * const x = tf.tensor1d([0, 1, -1, .7]);\n *\n * x.softplus().print();  // or tf.softplus(x)\n * ```\n * @param x The input tensor.\n */\n/** @doc {heading: 'Operations', subheading: 'Basic math'} */\nfunction softplus_(x) {\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'softplus');\n    var grad = function (dy, saved) {\n        var $x = saved[0];\n        return { $x: function () { return dy.mul($x.sigmoid()); } };\n    };\n    return engine_1.ENGINE.runKernel(function (backend, save) {\n        var res = backend.softplus($x);\n        save([$x]);\n        return res;\n    }, { $x: $x }, grad);\n}\n/**\n * Computes sin of the input Tensor element-wise: `sin(x)`\n *\n * ```js\n * const x = tf.tensor1d([0, Math.PI / 2, Math.PI * 3 / 4]);\n *\n * x.sin().print();  // or tf.sin(x)\n * ```\n * @param x The input tensor.\n */\n/** @doc {heading: 'Operations', subheading: 'Basic math'} */\nfunction sin_(x) {\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'sin');\n    var grad = function (dy, saved) {\n        var $x = saved[0];\n        return { $x: function () { return $x.toFloat().cos().mul(dy); } };\n    };\n    return engine_1.ENGINE.runKernel(function (backend, save) {\n        var res = backend.sin($x);\n        save([$x]);\n        return res;\n    }, { $x: $x }, grad);\n}\n/**\n * Computes cos of the input `tf.Tensor` element-wise: `cos(x)`\n *\n * ```js\n * const x = tf.tensor1d([0, Math.PI / 2, Math.PI * 3 / 4]);\n *\n * x.cos().print();  // or tf.cos(x)\n * ```\n * @param x The input tensor.\n */\n/** @doc {heading: 'Operations', subheading: 'Basic math'} */\nfunction cos_(x) {\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'cos');\n    var grad = function (dy, saved) {\n        var $x = saved[0];\n        return { $x: function () { return $x.toFloat().sin().neg().mul(dy); } };\n    };\n    return engine_1.ENGINE.runKernel(function (backend, save) {\n        var res = backend.cos($x);\n        save([$x]);\n        return res;\n    }, { $x: $x }, grad);\n}\n/**\n * Computes tan of the input `tf.Tensor` element-wise, `tan(x)`\n *\n * ```js\n * const x = tf.tensor1d([0, Math.PI / 2, Math.PI * 3 / 4]);\n *\n * x.tan().print();  // or tf.tan(x)\n * ```\n * @param x The input tensor.\n */\n/** @doc {heading: 'Operations', subheading: 'Basic math'} */\nfunction tan_(x) {\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'tan');\n    var grad = function (dy, saved) {\n        var $x = saved[0];\n        return { $x: function () { return dy.div($x.cos().square()); } };\n    };\n    return engine_1.ENGINE.runKernel(function (backend, save) {\n        var res = backend.tan($x);\n        save([$x]);\n        return res;\n    }, { $x: $x }, grad);\n}\n/**\n * Computes asin of the input `tf.Tensor` element-wise: `asin(x)`\n *\n * ```js\n * const x = tf.tensor1d([0, 1, -1, .7]);\n *\n * x.asin().print();  // or tf.asin(x)\n * ```\n * @param x The input tensor.\n */\n/** @doc {heading: 'Operations', subheading: 'Basic math'} */\nfunction asin_(x) {\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'asin');\n    var grad = function (dy, saved) {\n        var $x = saved[0];\n        return {\n            $x: function () { return dy.divStrict(tensor_ops_1.scalar(1).sub($x.toFloat().square()).sqrt()); }\n        };\n    };\n    return engine_1.ENGINE.runKernel(function (backend, save) {\n        var res = backend.asin($x);\n        save([$x]);\n        return res;\n    }, { $x: $x }, grad);\n}\n/**\n * Computes acos of the input `tf.Tensor` element-wise: `acos(x)`\n *\n * ```js\n * const x = tf.tensor1d([0, 1, -1, .7]);\n *\n * x.acos().print();  // or tf.acos(x)\n * ```\n * @param x The input tensor.\n */\n/** @doc {heading: 'Operations', subheading: 'Basic math'} */\nfunction acos_(x) {\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'acos');\n    var grad = function (dy, saved) {\n        var $x = saved[0];\n        return {\n            $x: function () {\n                return dy.divStrict(tensor_ops_1.scalar(1).sub($x.toFloat().square()).sqrt()).neg();\n            }\n        };\n    };\n    return engine_1.ENGINE.runKernel(function (backend, save) {\n        var res = backend.acos($x);\n        save([$x]);\n        return res;\n    }, { $x: $x }, grad);\n}\n/**\n * Computes atan of the input `tf.Tensor` element-wise: `atan(x)`\n *\n * ```js\n * const x = tf.tensor1d([0, 1, -1, .7]);\n *\n * x.atan().print();  // or tf.atan(x)\n * ```\n * @param x The input tensor.\n */\n/** @doc {heading: 'Operations', subheading: 'Basic math'} */\nfunction atan_(x) {\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'atan');\n    var grad = function (dy, saved) {\n        var $x = saved[0];\n        return { $x: function () { return dy.div($x.toFloat().square().add(1)); } };\n    };\n    return engine_1.ENGINE.runKernel(function (backend, save) {\n        var res = backend.atan($x);\n        save([$x]);\n        return res;\n    }, { $x: $x }, grad);\n}\n/**\n * Computes hyperbolic sin of the input `tf.Tensor` element-wise: `sinh(x)`\n *\n * ```js\n * const x = tf.tensor1d([0, 1, -1, .7]);\n *\n * x.sinh().print();  // or tf.sinh(x)\n * ```\n * @param x The input tensor.\n */\n/** @doc {heading: 'Operations', subheading: 'Basic math'} */\nfunction sinh_(x) {\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'sinh');\n    var grad = function (dy, saved) {\n        var $x = saved[0];\n        return { $x: function () { return $x.toFloat().cosh().mulStrict(dy); } };\n    };\n    return engine_1.ENGINE.runKernel(function (backend, save) {\n        var res = backend.sinh($x);\n        save([$x]);\n        return res;\n    }, { $x: $x }, grad);\n}\n/**\n * Computes hyperbolic cos of the input `tf.Tensor` element-wise: `cosh(x)`\n *\n * ```js\n * const x = tf.tensor1d([0, 1, -1, .7]);\n *\n * x.cosh().print();  // or tf.cosh(x)\n * ```\n * @param x The input tensor.\n */\n/** @doc {heading: 'Operations', subheading: 'Basic math'} */\nfunction cosh_(x) {\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'cosh');\n    var grad = function (dy, saved) {\n        var $x = saved[0];\n        return { $x: function () { return $x.toFloat().sinh().mulStrict(dy); } };\n    };\n    return engine_1.ENGINE.runKernel(function (backend, save) {\n        var res = backend.cosh($x);\n        save([$x]);\n        return res;\n    }, { $x: $x }, grad);\n}\n/**\n * Computes hyperbolic tangent of the input `tf.Tensor` element-wise: `tanh(x)`\n *\n * ```js\n * const x = tf.tensor1d([0, 1, -1, 70]);\n *\n * x.tanh().print();  // or tf.tanh(x)\n * ```\n * @param x The input tensor.\n */\n/** @doc {heading: 'Operations', subheading: 'Basic math'} */\nfunction tanh_(x) {\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'tanh');\n    var grad = function (dy, saved) {\n        var y = saved[0];\n        return { $x: function () { return tensor_ops_1.scalar(1).sub(y.square()).mulStrict(dy); } };\n    };\n    return engine_1.ENGINE.runKernel(function (backend, save) {\n        var y = backend.tanh($x);\n        save([y]);\n        return y;\n    }, { $x: $x }, grad);\n}\n/**\n * Computes inverse hyperbolic sin of the input `tf.Tensor` element-wise:\n * `asinh(x)`\n *\n * ```js\n * const x = tf.tensor1d([0, 1, -1, .7]);\n *\n * x.asinh().print();  // or tf.asinh(x)\n * ```\n * @param x The input tensor.\n */\n/** @doc {heading: 'Operations', subheading: 'Basic math'} */\nfunction asinh_(x) {\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'asinh');\n    var grad = function (dy, saved) {\n        var $x = saved[0];\n        return {\n            $x: function () { return dy.divStrict(tensor_ops_1.scalar(1).add($x.toFloat().square()).sqrt()); }\n        };\n    };\n    return engine_1.ENGINE.runKernel(function (backend, save) {\n        var res = backend.asinh($x);\n        save([$x]);\n        return res;\n    }, { $x: $x }, grad);\n}\n/**\n * Computes the inverse hyperbolic cos of the input `tf.Tensor` element-wise:\n * `acosh(x)`\n *\n * ```js\n * const x = tf.tensor1d([10, 1, 3, 5.7]);\n *\n * x.acosh().print();  // or tf.acosh(x)\n * ```\n * @param x The input tensor.\n */\n/** @doc {heading: 'Operations', subheading: 'Basic math'} */\nfunction acosh_(x) {\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'acosh');\n    var grad = function (dy, saved) {\n        var $x = saved[0];\n        return { $x: function () { return dy.divStrict($x.toFloat().square().sub(1).sqrt()); } };\n    };\n    return engine_1.ENGINE.runKernel(function (backend, save) {\n        var res = backend.acosh($x);\n        save([$x]);\n        return res;\n    }, { $x: $x }, grad);\n}\n/**\n * Computes inverse hyperbolic tan of the input `tf.Tensor` element-wise:\n * `atanh(x)`\n *\n * ```js\n * const x = tf.tensor1d([0, .1, -.1, .7]);\n *\n * x.atanh().print();  // or tf.atanh(x)\n * ```\n * @param x The input tensor.\n */\n/** @doc {heading: 'Operations', subheading: 'Basic math'} */\nfunction atanh_(x) {\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'atanh');\n    var grad = function (dy, saved) {\n        var $x = saved[0];\n        return { $x: function () { return dy.div(tensor_ops_1.scalar(1).sub($x.toFloat().square())); } };\n    };\n    return engine_1.ENGINE.runKernel(function (backend, save) {\n        var res = backend.atanh($x);\n        save([$x]);\n        return res;\n    }, { $x: $x }, grad);\n}\n/**\n * Computes gause error function of the input `tf.Tensor` element-wise:\n * `erf(x)`\n *\n * ```js\n * const x = tf.tensor1d([0, .1, -.1, .7]);\n *\n * x.erf().print(); // or tf.erf(x);\n * ```\n * @param x The input tensor.\n */\n/** @doc {heading: 'Operations', subheading: 'Basic math'} */\nfunction erf_(x) {\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'erf');\n    util.assert($x.dtype === 'int32' || $x.dtype === 'float32', function () { return 'Input dtype must be `int32` or `float32`.'; });\n    if ($x.dtype === 'int32') {\n        $x = $x.toFloat();\n    }\n    var grad = function (dy, saved) {\n        var $x = saved[0];\n        return {\n            $x: function () { return dy.mul($x.square().neg().exp().mul(2 / Math.sqrt(Math.PI))); }\n        };\n    };\n    return engine_1.ENGINE.runKernel(function (backend, save) {\n        var res = backend.erf($x);\n        save([$x]);\n        return res;\n    }, { $x: $x }, grad);\n}\n/**\n * Computes step of the input `tf.Tensor` element-wise: `x > 0 ? 1 : alpha * x`\n *\n * ```js\n * const x = tf.tensor1d([0, 2, -1, -3]);\n *\n * x.step(.5).print();  // or tf.step(x, .5)\n * ```\n * @param x The input tensor.\n * @param alpha The gradient when input is negative.\n */\n/** @doc {heading: 'Operations', subheading: 'Basic math'} */\nfunction step_(x, alpha) {\n    if (alpha === void 0) { alpha = 0.0; }\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'step');\n    // TODO(manrajgrover): Return null for gradients when backprop supports\n    // it.\n    var grad = function (dy) {\n        return { $x: function () { return tensor_ops_1.zerosLike(dy); } };\n    };\n    return engine_1.ENGINE.runKernel(function (backend) { return backend.step($x, alpha); }, { $x: $x }, grad);\n}\nexports.abs = operation_1.op({ abs_: abs_ });\nexports.acos = operation_1.op({ acos_: acos_ });\nexports.acosh = operation_1.op({ acosh_: acosh_ });\nexports.asin = operation_1.op({ asin_: asin_ });\nexports.asinh = operation_1.op({ asinh_: asinh_ });\nexports.atan = operation_1.op({ atan_: atan_ });\nexports.atanh = operation_1.op({ atanh_: atanh_ });\nexports.ceil = operation_1.op({ ceil_: ceil_ });\nexports.clipByValue = operation_1.op({ clipByValue_: clipByValue_ });\nexports.cos = operation_1.op({ cos_: cos_ });\nexports.cosh = operation_1.op({ cosh_: cosh_ });\nexports.erf = operation_1.op({ erf_: erf_ });\nexports.exp = operation_1.op({ exp_: exp_ });\nexports.expm1 = operation_1.op({ expm1_: expm1_ });\nexports.floor = operation_1.op({ floor_: floor_ });\nexports.log = operation_1.op({ log_: log_ });\nexports.log1p = operation_1.op({ log1p_: log1p_ });\nexports.logSigmoid = operation_1.op({ logSigmoid_: logSigmoid_ });\nexports.neg = operation_1.op({ neg_: neg_ });\nexports.reciprocal = operation_1.op({ reciprocal_: reciprocal_ });\nexports.round = operation_1.op({ round_: round_ });\nexports.rsqrt = operation_1.op({ rsqrt_: rsqrt_ });\nexports.sigmoid = operation_1.op({ sigmoid_: sigmoid_ });\nexports.sign = operation_1.op({ sign_: sign_ });\nexports.isNaN = operation_1.op({ isNaN_: isNaN_ });\nexports.isInf = operation_1.op({ isInf_: isInf_ });\nexports.isFinite = operation_1.op({ isFinite_: isFinite_ });\nexports.sin = operation_1.op({ sin_: sin_ });\nexports.sinh = operation_1.op({ sinh_: sinh_ });\nexports.softplus = operation_1.op({ softplus_: softplus_ });\nexports.sqrt = operation_1.op({ sqrt_: sqrt_ });\nexports.square = operation_1.op({ square_: square_ });\nexports.step = operation_1.op({ step_: step_ });\nexports.tan = operation_1.op({ tan_: tan_ });\nexports.tanh = operation_1.op({ tanh_: tanh_ });\n//# sourceMappingURL=unary_ops.js.map","\n/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar engine_1 = require(\"../engine\");\nvar tensor_util_env_1 = require(\"../tensor_util_env\");\nvar util = require(\"../util\");\nvar conv_util = require(\"./conv_util\");\nvar operation_1 = require(\"./operation\");\n/**\n * Computes a 1D convolution over the input x.\n *\n * @param x The input tensor, of rank 3 or rank 2, of shape\n *     `[batch, width, inChannels]`. If rank 2, batch of 1 is assumed.\n * @param filter The filter, rank 3, of shape\n *     `[filterWidth, inDepth, outDepth]`.\n * @param stride The number of entries by which the filter is moved right at\n *     each step.\n * @param pad The type of padding algorithm.\n *    - `same` and stride 1: output will be of same size as input,\n *       regardless of filter size.\n *    - `valid`: output will be smaller than input if filter is larger\n *       than 1x1.\n *   - For more info, see this guide:\n *     [https://www.tensorflow.org/api_guides/python/nn#Convolution](\n *          https://www.tensorflow.org/api_guides/python/nn#Convolution)\n * @param dataFormat An optional string from \"NWC\", \"NCW\". Defaults to \"NWC\",\n *     the data is stored in the order of [batch, in_width, in_channels]. Only\n *     \"NWC\" is currently supported.\n * @param dilation The dilation rate in which we sample input values in\n *     atrous convolution. Defaults to `1`. If it is greater than 1, then\n *     stride must be `1`.\n * @param dimRoundingMode The rounding mode used when computing output\n *     dimensions if pad is a number. If none is provided, it will not round\n *     and error if the output is of fractional size.\n */\n/** @doc {heading: 'Operations', subheading: 'Convolution'} */\nfunction conv1d_(x, filter, stride, pad, dataFormat, dilation, dimRoundingMode) {\n    if (dataFormat === void 0) { dataFormat = 'NWC'; }\n    if (dilation === void 0) { dilation = 1; }\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'conv1d');\n    var $filter = tensor_util_env_1.convertToTensor(filter, 'filter', 'conv1d');\n    var x3D = $x;\n    var reshapedTo3D = false;\n    if ($x.rank === 2) {\n        reshapedTo3D = true;\n        x3D = $x.as3D(1, $x.shape[0], $x.shape[1]);\n    }\n    util.assert(x3D.rank === 3, function () { return \"Error in conv1d: input must be rank 3, but got rank \" + x3D.rank + \".\"; });\n    util.assert($filter.rank === 3, function () { return \"Error in conv1d: filter must be rank 3, but got rank \" +\n        ($filter.rank + \".\"); });\n    if (dimRoundingMode != null) {\n        util.assert(util.isInt(pad), function () { return \"Error in conv1d: pad must be an integer when using, \" +\n            (\"dimRoundingMode \" + dimRoundingMode + \" but got pad \" + pad + \".\"); });\n    }\n    util.assert(x3D.shape[2] === $filter.shape[1], function () { return \"Error in conv1d: depth of input (\" + x3D.shape[2] + \") must match \" +\n        (\"input depth for filter \" + $filter.shape[1] + \".\"); });\n    util.assert(conv_util.eitherStridesOrDilationsAreOne(stride, dilation), function () { return 'Error in conv1D: Either stride or dilation must be 1. ' +\n        (\"Got stride \" + stride + \" and dilation '\" + dilation + \"'\"); });\n    util.assert(dataFormat === 'NWC', function () { return \"Error in conv1d: got dataFormat of \" + dataFormat + \" but only NWC is currently supported.\"; });\n    var filter4D = $filter.as4D(1, $filter.shape[0], $filter.shape[1], $filter.shape[2]);\n    var input4D = x3D.as4D(x3D.shape[0], 1, x3D.shape[1], x3D.shape[2]);\n    var strides = [1, stride];\n    var dilations = [1, dilation];\n    var conv2dDataFormat = 'NHWC';\n    var res = exports.conv2d(input4D, filter4D, strides, pad, conv2dDataFormat, dilations, dimRoundingMode);\n    if (reshapedTo3D) {\n        return res.as2D(res.shape[2], res.shape[3]);\n    }\n    return res.as3D(res.shape[0], res.shape[2], res.shape[3]);\n}\n/**\n * Computes a 2D convolution over the input x.\n *\n * @param x The input tensor, of rank 4 or rank 3, of shape\n *     `[batch, height, width, inChannels]`. If rank 3, batch of 1 is\n * assumed.\n * @param filter The filter, rank 4, of shape\n *     `[filterHeight, filterWidth, inDepth, outDepth]`.\n * @param strides The strides of the convolution: `[strideHeight,\n * strideWidth]`.\n * @param pad The type of padding algorithm.\n *    - `same` and stride 1: output will be of same size as input,\n *       regardless of filter size.\n *    - `valid`: output will be smaller than input if filter is larger\n *       than 1x1.\n *   - For more info, see this guide:\n *     [https://www.tensorflow.org/api_guides/python/nn#Convolution](\n *          https://www.tensorflow.org/api_guides/python/nn#Convolution)\n * @param dataFormat: An optional string from: \"NHWC\", \"NCHW\". Defaults to\n *     \"NHWC\". Specify the data format of the input and output data. With the\n *     default format \"NHWC\", the data is stored in the order of: [batch,\n *     height, width, channels]. Only \"NHWC\" is currently supported.\n * @param dilations The dilation rates: `[dilationHeight, dilationWidth]`\n *     in which we sample input values across the height and width dimensions\n *     in atrous convolution. Defaults to `[1, 1]`. If `dilations` is a single\n *     number, then `dilationHeight == dilationWidth`. If it is greater than\n *     1, then all values of `strides` must be 1.\n * @param dimRoundingMode The rounding mode used when computing output\n *     dimensions if pad is a number. If none is provided, it will not round\n *     and error if the output is of fractional size.\n */\n/** @doc {heading: 'Operations', subheading: 'Convolution'} */\nfunction conv2d_(x, filter, strides, pad, dataFormat, dilations, dimRoundingMode) {\n    if (dataFormat === void 0) { dataFormat = 'NHWC'; }\n    if (dilations === void 0) { dilations = [1, 1]; }\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'conv2d');\n    var $filter = tensor_util_env_1.convertToTensor(filter, 'filter', 'conv2d');\n    var x4D = $x;\n    var reshapedTo4D = false;\n    if ($x.rank === 3) {\n        reshapedTo4D = true;\n        x4D = $x.as4D(1, $x.shape[0], $x.shape[1], $x.shape[2]);\n    }\n    util.assert(x4D.rank === 4, function () { return \"Error in conv2d: input must be rank 4, but got rank \" + x4D.rank + \".\"; });\n    util.assert($filter.rank === 4, function () { return \"Error in conv2d: filter must be rank 4, but got rank \" +\n        ($filter.rank + \".\"); });\n    if (dimRoundingMode != null) {\n        util.assert(util.isInt(pad), function () { return \"Error in conv2d: pad must be an integer when using, \" +\n            (\"dimRoundingMode \" + dimRoundingMode + \" but got pad \" + pad + \".\"); });\n    }\n    util.assert(x4D.shape[3] === $filter.shape[2], function () { return \"Error in conv2d: depth of input (\" + x4D.shape[3] + \") must match \" +\n        (\"input depth for filter \" + $filter.shape[2] + \".\"); });\n    util.assert(conv_util.eitherStridesOrDilationsAreOne(strides, dilations), function () { return 'Error in conv2D: Either strides or dilations must be 1. ' +\n        (\"Got strides \" + strides + \" and dilations '\" + dilations + \"'\"); });\n    util.assert(dataFormat === 'NHWC', function () { return \"Error in conv2d: got dataFormat of \" + dataFormat + \" but only NHWC is currently supported.\"; });\n    var convInfo = conv_util.computeConv2DInfo(x4D.shape, $filter.shape, strides, dilations, pad, dimRoundingMode);\n    var grad = function (dy, saved) {\n        var _a = saved, $filter = _a[0], x4D = _a[1];\n        util.assert(conv_util.tupleValuesAreOne(dilations), function () { return 'Error in gradient of conv2D: dilation rates greater than 1 ' +\n            (\"are not yet supported in gradients. Got dilations '\" + dilations + \"'\"); });\n        return {\n            x: function () { return conv2dDerInput_(x4D.shape, dy, $filter, strides, pad); },\n            $filter: function () { return conv2dDerFilter_(x4D, dy, $filter.shape, strides, pad); }\n        };\n    };\n    var res = engine_1.ENGINE.runKernel(function (backend, save) {\n        var res = backend.conv2d(x4D, $filter, convInfo);\n        save([$filter, x4D]);\n        return res;\n    }, { x: x4D, $filter: $filter }, grad);\n    if (reshapedTo4D) {\n        return res.as3D(res.shape[1], res.shape[2], res.shape[3]);\n    }\n    return res;\n}\n/**\n * Computes the derivative of the input of a 2D convolution.\n *\n * @param xShape The shape of the input: [batch, height, width, inDepth].\n * If length of 3, batch of 1 is assumed.\n * @param dy The derivative of the output, of rank 4 or rank 3 of shape\n *   `[batch, outHeight, outWidth, outDepth]`. If rank 3, batch of 1 is\n * assumed.\n * @param filter The filter, rank 4, of shape\n *     `[filterHeight, filterWidth, inDepth, outDepth]`.\n * @param strides The strides of the convolution: `[strideHeight,\n * strideWidth]`.\n * @param pad The type of padding algorithm used:\n *    - `same` and stride 1: output will be of same size as input,\n *       regardless of filter size.\n *    - `valid`: output will be smaller than input if filter is larger\n *       than 1x1.\n * @param dimRoundingMode The rounding mode used when computing output\n *     dimensions if pad is a number. If none is provided, it will not round\n *     and error if the output is of fractional size.\n */\nfunction conv2dDerInput_(xShape, dy, filter, strides, pad, dimRoundingMode) {\n    util.assert(xShape.length === dy.rank, function () { return \"Length of inShape \" +\n        (\"(\" + xShape.length + \") and rank of dy (\" + dy.rank + \") must match\"); });\n    var xShape4D = xShape;\n    var dy4D = dy;\n    var reshapedTo4D = false;\n    if (dy.rank === 3) {\n        reshapedTo4D = true;\n        dy4D = dy.as4D(1, dy.shape[0], dy.shape[1], dy.shape[2]);\n        xShape4D = [1, xShape[0], xShape[1], xShape[2]];\n    }\n    var inDepth = xShape4D[3];\n    var outDepth = dy4D.shape[3];\n    util.assert(xShape4D.length === 4, function () {\n        return \"Error in conv2dDerInput: inShape must be length 4, but got length \" +\n            (xShape4D.length + \".\");\n    });\n    util.assert(dy4D.rank === 4, function () { return \"Error in conv2dDerInput: dy must be rank 4, but got \" +\n        (\"rank \" + dy4D.rank); });\n    util.assert(filter.rank === 4, function () { return \"Error in conv2dDerInput: filter must be rank 4, but got \" +\n        (\"rank \" + filter.rank); });\n    util.assert(inDepth === filter.shape[2], function () { return \"Error in conv2dDerInput: depth of input (\" + inDepth + \") must \" +\n        (\"match input depth for filter \" + filter.shape[2] + \".\"); });\n    util.assert(outDepth === filter.shape[3], function () { return \"Error in conv2dDerInput: depth of output (\" + outDepth + \") must \" +\n        (\"match output depth for filter \" + filter.shape[3] + \".\"); });\n    if (dimRoundingMode != null) {\n        util.assert(util.isInt(pad), function () { return \"Error in conv2dDerInput: pad must be an integer when using, \" +\n            (\"dimRoundingMode \" + dimRoundingMode + \" but got pad \" + pad + \".\"); });\n    }\n    var dilations = 1;\n    var grad = function (ddx, saved) {\n        var dataFormat = 'NHWC';\n        var filter = saved[0], dy4D = saved[1];\n        return {\n            dy4D: function () { return exports.conv2d(ddx, filter, strides, pad, dataFormat, dilations, dimRoundingMode); },\n            filter: function () { return exports.conv2dDerFilter(ddx, dy4D, filter.shape, strides, pad, dimRoundingMode); }\n        };\n    };\n    var convInfo = conv_util.computeConv2DInfo(xShape4D, filter.shape, strides, dilations, pad, dimRoundingMode);\n    var res = engine_1.ENGINE.runKernel(function (backend, save) {\n        var res = backend.conv2dDerInput(dy4D, filter, convInfo);\n        save([filter, dy4D]);\n        return res;\n    }, { dy4D: dy4D, filter: filter }, grad);\n    if (reshapedTo4D) {\n        return res.as3D(res.shape[1], res.shape[2], res.shape[3]);\n    }\n    return res;\n}\n/**\n * Computes the derivative of the filter of a 2D convolution.\n *\n * @param x The input tensor, of rank 4 or rank 3 of shape\n *     [batch, height, width, inChannels]. If rank 3, batch of 1 is assumed.\n * @param dy The dy image, of rank 4 or rank 3, of shape\n *     [batch, height, width, outDepth]. If rank 3, batch of 1 is assumed.\n * @param filterShape The shape of the filter, length 4,\n *     [filterHeight, filterWidth, inDepth, outDepth].\n * @param strides The strides of the convolution: [strideHeight,\n * strideWidth].\n * @param pad A string from: 'same', 'valid'. The type of padding algorithm\n *     used in the forward prop of the op.\n * @param dimRoundingMode A string from: 'ceil', 'round', 'floor'. The\n *     rounding mode used when computing output dimensions if pad is a\n *     number. If none is provided, it will not round and error if the output\n *     is of fractional size.\n */\nfunction conv2dDerFilter_(x, dy, filterShape, strides, pad, dimRoundingMode) {\n    var x4D = x;\n    if (x.rank === 3) {\n        x4D = x.as4D(1, x.shape[0], x.shape[1], x.shape[2]);\n    }\n    var dy4D = dy;\n    if (dy4D.rank === 3) {\n        dy4D = dy.as4D(1, dy.shape[0], dy.shape[1], dy.shape[2]);\n    }\n    util.assert(x4D.rank === 4, function () { return \"Error in conv2dDerFilter: input must be rank 4, but got shape \" +\n        (x4D.shape + \".\"); });\n    util.assert(dy4D.rank === 4, function () { return \"Error in conv2dDerFilter: dy must be rank 4, but got shape \" +\n        (dy4D.shape + \".\"); });\n    util.assert(filterShape.length === 4, function () { return \"Error in conv2dDerFilter: filterShape must be length 4, but got \" +\n        (filterShape + \".\"); });\n    util.assert(x4D.shape[3] === filterShape[2], function () { return \"Error in conv2dDerFilter: depth of input \" + x4D.shape[3] + \") must \" +\n        (\"match input depth in filter (\" + filterShape[2] + \".\"); });\n    util.assert(dy4D.shape[3] === filterShape[3], function () { return \"Error in conv2dDerFilter: depth of dy (\" + dy4D.shape[3] + \") must \" +\n        (\"match output depth for filter (\" + filterShape[3] + \").\"); });\n    if (dimRoundingMode != null) {\n        util.assert(util.isInt(pad), function () { return \"Error in conv2dDerFilter: pad must be an integer when using, \" +\n            (\"dimRoundingMode \" + dimRoundingMode + \" but got pad \" + pad + \".\"); });\n    }\n    var dilations = 1;\n    var convInfo = conv_util.computeConv2DInfo(x4D.shape, filterShape, strides, dilations, pad, dimRoundingMode);\n    return engine_1.ENGINE.runKernel(function (backend) { return backend.conv2dDerFilter(x4D, dy4D, convInfo); }, { x4D: x4D, dy4D: dy4D });\n}\n/**\n * Computes the transposed 2D convolution of an image, also known as a\n * deconvolution.\n *\n * @param x The input image, of rank 4 or rank 3, of shape\n *   `[batch, height, width, inDepth]`. If rank 3, batch of 1 is assumed.\n * @param filter The filter, rank 4, of shape\n *     `[filterHeight, filterWidth, outDepth, inDepth]`.\n *     `inDepth` must match `inDepth` in `x`.\n * @param outputShape Output shape, of rank 4 or rank 3:\n *     `[batch, height, width, outDepth]`. If rank 3, batch of 1 is assumed.\n * @param strides The strides of the original convolution:\n *     `[strideHeight, strideWidth]`.\n * @param pad  The type of padding algorithm used in the non-transpose version\n *    of the op.\n * @param dimRoundingMode The rounding mode used when computing output\n *    dimensions if pad is a number. If none is provided, it will not round\n *    and error if the output is of fractional size.\n */\n/** @doc {heading: 'Operations', subheading: 'Convolution'} */\nfunction conv2dTranspose_(x, filter, outputShape, strides, pad, dimRoundingMode) {\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'conv2dTranspose');\n    var $filter = tensor_util_env_1.convertToTensor(filter, 'filter', 'conv2dTranspose');\n    return conv2dDerInput_(outputShape, $x, $filter, strides, pad, dimRoundingMode);\n}\n/**\n * Depthwise 2D convolution.\n *\n * Given a 4D `input` array and a `filter` array of shape\n * `[filterHeight, filterWidth, inChannels, channelMultiplier]` containing\n * `inChannels` convolutional filters of depth 1, this op applies a\n * different filter to each input channel (expanding from 1 channel to\n * `channelMultiplier` channels for each), then concatenates the results\n * together. The output has `inChannels * channelMultiplier` channels.\n *\n * See\n * [https://www.tensorflow.org/api_docs/python/tf/nn/depthwise_conv2d](\n *     https://www.tensorflow.org/api_docs/python/tf/nn/depthwise_conv2d)\n * for more details.\n *\n * @param x The input tensor, of rank 4 or rank 3, of shape\n *     `[batch, height, width, inChannels]`. If rank 3, batch of 1 is\n * assumed.\n * @param filter The filter tensor, rank 4, of shape\n *     `[filterHeight, filterWidth, inChannels, channelMultiplier]`.\n * @param strides The strides of the convolution: `[strideHeight,\n * strideWidth]`. If strides is a single number, then `strideHeight ==\n * strideWidth`.\n * @param pad The type of padding algorithm.\n *   - `same` and stride 1: output will be of same size as input,\n *       regardless of filter size.\n *   - `valid`: output will be smaller than input if filter is larger\n *       than 1x1.\n *   - For more info, see this guide:\n *     [https://www.tensorflow.org/api_guides/python/nn#Convolution](\n *          https://www.tensorflow.org/api_guides/python/nn#Convolution)\n * @param dilations The dilation rates: `[dilationHeight, dilationWidth]`\n *     in which we sample input values across the height and width dimensions\n *     in atrous convolution. Defaults to `[1, 1]`. If `rate` is a single\n *     number, then `dilationHeight == dilationWidth`. If it is greater than\n *     1, then all values of `strides` must be 1.\n * @param dataFormat: An optional string from: \"NHWC\", \"NCHW\". Defaults to\n *     \"NHWC\". Specify the data format of the input and output data. With the\n *     default format \"NHWC\", the data is stored in the order of: [batch,\n *     height, width, channels]. Only \"NHWC\" is currently supported.\n * @param dimRoundingMode The rounding mode used when computing output\n *     dimensions if pad is a number. If none is provided, it will not round\n *     and error if the output is of fractional size.\n */\n/** @doc {heading: 'Operations', subheading: 'Convolution'} */\nfunction depthwiseConv2d_(x, filter, strides, pad, dataFormat, dilations, dimRoundingMode) {\n    if (dataFormat === void 0) { dataFormat = 'NHWC'; }\n    if (dilations === void 0) { dilations = [1, 1]; }\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'depthwiseConv2d');\n    var $filter = tensor_util_env_1.convertToTensor(filter, 'filter', 'depthwiseConv2d');\n    var x4D = $x;\n    var reshapedTo4D = false;\n    if ($x.rank === 3) {\n        reshapedTo4D = true;\n        x4D = $x.as4D(1, $x.shape[0], $x.shape[1], $x.shape[2]);\n    }\n    util.assert(x4D.rank === 4, function () { return \"Error in depthwiseConv2d: input must be rank 4, but got \" +\n        (\"rank \" + x4D.rank + \".\"); });\n    util.assert($filter.rank === 4, function () { return \"Error in depthwiseConv2d: filter must be rank 4, but got rank \" +\n        ($filter.rank + \".\"); });\n    util.assert(x4D.shape[3] === $filter.shape[2], function () { return \"Error in depthwiseConv2d: number of input channels \" +\n        (\"(\" + x4D.shape[3] + \") must match the inChannels dimension in \") +\n        (\"filter \" + $filter.shape[2] + \".\"); });\n    if (dilations == null) {\n        dilations = [1, 1];\n    }\n    util.assert(conv_util.eitherStridesOrDilationsAreOne(strides, dilations), function () {\n        return 'Error in depthwiseConv2d: Either strides or dilations must be 1. ' +\n            (\"Got strides \" + strides + \" and dilations '\" + dilations + \"'\");\n    });\n    if (dimRoundingMode != null) {\n        util.assert(util.isInt(pad), function () { return \"Error in depthwiseConv2d: pad must be an integer when using, \" +\n            (\"dimRoundingMode \" + dimRoundingMode + \" but got pad \" + pad + \".\"); });\n    }\n    var convInfo = conv_util.computeConv2DInfo(x4D.shape, $filter.shape, strides, dilations, pad, dimRoundingMode, true /* depthwise */);\n    var grad = function (dy, saved) {\n        util.assert(conv_util.tupleValuesAreOne(dilations), function () { return 'Error in gradient of depthwiseConv2d: dilation rates ' +\n            \"greater than 1 are not yet supported. Got dilations \" +\n            (\"'\" + dilations + \"'\"); });\n        var x4D = saved[0], $filter = saved[1];\n        return {\n            x: function () { return depthwiseConv2dDerInput(x4D.shape, dy, $filter, convInfo); },\n            $filter: function () { return depthwiseConv2dDerFilter(x4D, dy, $filter.shape, convInfo); },\n        };\n    };\n    var res = engine_1.ENGINE.runKernel(function (backend, save) {\n        var res = backend.depthwiseConv2D(x4D, $filter, convInfo);\n        save([x4D, $filter]);\n        return res;\n    }, { x: x4D, $filter: $filter }, grad);\n    if (reshapedTo4D) {\n        return res.as3D(res.shape[1], res.shape[2], res.shape[3]);\n    }\n    return res;\n}\n/**\n * 2-D convolution with separable filters.\n *\n * Performs a depthwise convolution that acts separately on channels followed\n * by a pointwise convolution that mixes channels. Note that this is\n * separability between dimensions [1, 2] and 3, not spatial separability\n * between dimensions 1 and 2.\n *\n * See\n * [https://www.tensorflow.org/api_docs/python/tf/nn/separable_conv2d](\n *     https://www.tensorflow.org/api_docs/python/tf/nn/separable_conv2d)\n * for more details.\n *\n * @param x The input tensor, of rank 4 or rank 3, of shape\n *     `[batch, height, width, inChannels]`. If rank 3, batch of 1 is\n * assumed.\n * @param depthwiseFilter The depthwise filter tensor, rank 4, of shape\n *     `[filterHeight, filterWidth, inChannels, channelMultiplier]`. This is\n *     the filter used in the first step.\n * @param pointwiseFilter The pointwise filter tensor, rank 4, of shape\n *     `[1, 1, inChannels * channelMultiplier, outChannels]`. This is\n *     the filter used in the second step.\n * @param strides The strides of the convolution: `[strideHeight,\n * strideWidth]`. If strides is a single number, then `strideHeight ==\n * strideWidth`.\n * @param pad The type of padding algorithm.\n *   - `same` and stride 1: output will be of same size as input,\n *       regardless of filter size.\n *   - `valid`: output will be smaller than input if filter is larger\n *       than 1x1.\n *   - For more info, see this guide:\n *     [https://www.tensorflow.org/api_guides/python/nn#Convolution](\n *          https://www.tensorflow.org/api_guides/python/nn#Convolution)\n * @param dilations The dilation rates: `[dilationHeight, dilationWidth]`\n *     in which we sample input values across the height and width dimensions\n *     in atrous convolution. Defaults to `[1, 1]`. If `rate` is a single\n *     number, then `dilationHeight == dilationWidth`. If it is greater than\n *     1, then all values of `strides` must be 1.\n * @param dataFormat: An optional string from: \"NHWC\", \"NCHW\". Defaults to\n *     \"NHWC\". Specify the data format of the input and output data. With the\n *     default format \"NHWC\", the data is stored in the order of: [batch,\n *     height, width, channels]. Only \"NHWC\" is currently supported.\n */\n/** @doc {heading: 'Operations', subheading: 'Convolution'} */\nfunction separableConv2d_(x, depthwiseFilter, pointwiseFilter, strides, pad, dilation, dataFormat) {\n    if (dilation === void 0) { dilation = [1, 1]; }\n    if (dataFormat === void 0) { dataFormat = 'NHWC'; }\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'separableConv2d');\n    var $depthwiseFilter = tensor_util_env_1.convertToTensor(depthwiseFilter, 'depthwiseFilter', 'separableConv2d');\n    var $pointwiseFilter = tensor_util_env_1.convertToTensor(pointwiseFilter, 'pointwiseFilter', 'separableConv2d');\n    var x4D = $x;\n    var reshapedTo4D = false;\n    if ($x.rank === 3) {\n        reshapedTo4D = true;\n        x4D = $x.as4D(1, $x.shape[0], $x.shape[1], $x.shape[2]);\n    }\n    if (dataFormat === 'NCHW') {\n        throw new Error('separableConv2d currently does not support dataFormat NCHW; only ' +\n            'NHWC is supported');\n    }\n    util.assert(x4D.rank === 4, function () { return \"Error in separableConv2d: input must be rank 4, but got \" +\n        (\"rank \" + x4D.rank + \".\"); });\n    util.assert($depthwiseFilter.rank === 4, function () { return \"Error in separableConv2d: depthwise filter must be rank 4, but \" +\n        (\"got rank \" + $depthwiseFilter.rank + \".\"); });\n    util.assert($pointwiseFilter.rank === 4, function () { return \"Error in separableConv2d: pointwise filter must be rank 4, but \" +\n        (\"got rank \" + $depthwiseFilter.rank + \".\"); });\n    util.assert($pointwiseFilter.shape[0] === 1, function () {\n        return \"Error in separableConv2d: the first dimension of pointwise filter \" +\n            (\" must be 1, but got \" + $pointwiseFilter.shape[0] + \".\");\n    });\n    util.assert($pointwiseFilter.shape[1] === 1, function () { return \"Error in separableConv2d: the second dimension of pointwise \" +\n        (\"filter must be 1, but got \" + $pointwiseFilter.shape[1] + \".\"); });\n    var inChannels = $depthwiseFilter.shape[2];\n    var channelMultiplier = $depthwiseFilter.shape[3];\n    util.assert($pointwiseFilter.shape[2] === inChannels * channelMultiplier, function () {\n        return \"Error in separableConv2d: the third dimension of pointwise filter \" +\n            (\"must be \" + inChannels * channelMultiplier + \", \") +\n            (\"but got \" + $pointwiseFilter.shape[2] + \".\");\n    });\n    var depthwise = exports.depthwiseConv2d(x4D, $depthwiseFilter, strides, pad, dataFormat, dilation);\n    var pointwiseStride = 1;\n    var res = exports.conv2d(depthwise, $pointwiseFilter, pointwiseStride, 'valid', dataFormat);\n    if (reshapedTo4D) {\n        return res.as3D(res.shape[1], res.shape[2], res.shape[3]);\n    }\n    return res;\n}\nfunction parseTupleParam(param) {\n    if (typeof param === 'number') {\n        return [param, param, param];\n    }\n    if (param.length === 2) {\n        return [param[0], param[1], 1];\n    }\n    return param;\n}\nfunction tupleValuesAreOne(param) {\n    var _a = parseTupleParam(param), dimA = _a[0], dimB = _a[1], dimC = _a[2];\n    return dimA === 1 && dimB === 1 && dimC === 1;\n}\nfunction eitherStridesOrDilationsAreOne(strides, dilations) {\n    return tupleValuesAreOne(strides) || tupleValuesAreOne(dilations);\n}\nfunction depthwiseConv2dDerInput(xShape, dy, filter, convInfo) {\n    var dy4D = dy;\n    var reshapedTo4D = false;\n    if (dy.rank === 3) {\n        reshapedTo4D = true;\n        dy4D = dy.as4D(1, dy.shape[0], dy.shape[1], dy.shape[2]);\n    }\n    var res = engine_1.ENGINE.runKernel(function (backend) { return backend.depthwiseConv2DDerInput(dy4D, filter, convInfo); }, { dy4D: dy4D });\n    if (reshapedTo4D) {\n        return res.as3D(res.shape[1], res.shape[2], res.shape[3]);\n    }\n    return res;\n}\nfunction depthwiseConv2dDerFilter(x, dy, filterShape, convInfo) {\n    var x4D = x;\n    if (x.rank === 3) {\n        x4D = x.as4D(1, x.shape[0], x.shape[1], x.shape[2]);\n    }\n    var dy4D = dy;\n    if (dy4D.rank === 3) {\n        dy4D = dy.as4D(1, dy.shape[0], dy.shape[1], dy.shape[2]);\n    }\n    return engine_1.ENGINE.runKernel(function (backend) { return backend.depthwiseConv2DDerFilter(x4D, dy4D, convInfo); }, { x4D: x4D, dy4D: dy4D });\n}\n/**\n * Computes a 3D convolution over the input x.\n *\n * @param x The input tensor, of rank 5 or rank 4, of shape\n *     `[batch, depth, height, width, channels]`. If rank 4,\n * batch of 1 is assumed.\n * @param filter The filter, rank 5, of shape\n *     `[filterDepth, filterHeight, filterWidth, inChannels, outChannels]`.\n *      inChannels must match between input and filter.\n * @param strides The strides of the convolution: `[strideDepth, strideHeight,\n * strideWidth]`.\n * @param pad The type of padding algorithm.\n *    - `same` and stride 1: output will be of same size as input,\n *       regardless of filter size.\n *    - `valid`: output will be smaller than input if filter is larger\n *       than 1x1.\n *   - For more info, see this guide:\n *     [https://www.tensorflow.org/api_guides/python/nn#Convolution](\n *          https://www.tensorflow.org/api_guides/python/nn#Convolution)\n * @param dataFormat: An optional string from: \"NDHWC\", \"NCDHW\". Defaults to\n *     \"NDHWC\". Specify the data format of the input and output data. With the\n *     default format \"NDHWC\", the data is stored in the order of: [batch,\n *     depth, height, width, channels]. Only \"NDHWC\" is currently supported.\n * @param dilations The dilation rates: `[dilationDepth, dilationHeight,\n *     dilationWidth]` in which we sample input values across the height\n *     and width dimensions in atrous convolution. Defaults to `[1, 1, 1]`.\n *     If `dilations` is a single number, then\n *     `dilationDepth == dilationHeight == dilationWidth`. If it is greater\n *     than 1, then all values of `strides` must be 1.\n */\n/** @doc {heading: 'Operations', subheading: 'Convolution'} */\nfunction conv3d_(x, filter, strides, pad, dataFormat, dilations) {\n    if (dataFormat === void 0) { dataFormat = 'NDHWC'; }\n    if (dilations === void 0) { dilations = [1, 1, 1]; }\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'conv3d');\n    var $filter = tensor_util_env_1.convertToTensor(filter, 'filter', 'conv3d');\n    var x5D = $x;\n    var reshapedTo5D = false;\n    if ($x.rank === 4) {\n        reshapedTo5D = true;\n        x5D = $x.as5D(1, $x.shape[0], $x.shape[1], $x.shape[2], $x.shape[3]);\n    }\n    util.assert(x5D.rank === 5, function () { return \"Error in conv3d: input must be rank 5, but got rank \" + x5D.rank + \".\"; });\n    util.assert($filter.rank === 5, function () { return \"Error in conv3d: filter must be rank 5, but got rank \" +\n        ($filter.rank + \".\"); });\n    util.assert(x5D.shape[4] === $filter.shape[3], function () { return \"Error in conv3d: depth of input (\" + x5D.shape[4] + \") must match \" +\n        (\"input depth for filter \" + $filter.shape[3] + \".\"); });\n    util.assert(eitherStridesOrDilationsAreOne(strides, dilations), function () { return 'Error in conv3D: Either strides or dilations must be 1. ' +\n        (\"Got strides \" + strides + \" and dilations '\" + dilations + \"'\"); });\n    util.assert(dataFormat === 'NDHWC', function () { return \"Error in conv3d: got dataFormat of \" + dataFormat + \" but only NDHWC is currently supported.\"; });\n    var convInfo = conv_util.computeConv3DInfo(x5D.shape, $filter.shape, strides, dilations, pad);\n    var grad = function (dy, saved) {\n        util.assert(tupleValuesAreOne(dilations), function () {\n            return 'Error in gradient of conv3D: dilation rates greater than 1 are ' +\n                (\"not yet supported in gradients. Got dilations '\" + dilations + \"'\");\n        });\n        var x5D = saved[0], $filter = saved[1];\n        return {\n            x: function () { return conv3dDerInput_(x5D.shape, dy, $filter, strides, pad); },\n            $filter: function () { return conv3dDerFilter_(x5D, dy, $filter.shape, strides, pad); }\n        };\n    };\n    var res = engine_1.ENGINE.runKernel(function (backend, save) {\n        var res = backend.conv3d(x5D, $filter, convInfo);\n        save([x5D, $filter]);\n        return res;\n    }, { x: x5D, $filter: $filter }, grad);\n    if (reshapedTo5D) {\n        return res.as4D(res.shape[1], res.shape[2], res.shape[3], res.shape[4]);\n    }\n    return res;\n}\n/**\n * Computes the derivative of the input of a 3D convolution.\n *\n * @param xShape The shape of the input: [batch, depth, height, width,\n * in_channels]. If length of 4, batch of 1 is assumed.\n * @param dy The derivative of the output, of rank 5 or rank 4 of shape\n *   `[batch, outDepth, outHeight, outWidth, in_channels]`.\n * If rank 4, batch of 1 is assumed.\n * @param filter The filter, rank 5, of shape\n *     `[filterDepth, filterHeight, filterWidth, inDepth, outDepth]`.\n * @param strides The strides of the convolution: `[strideDepth, strideHeight,\n * strideWidth]`.\n * @param pad The type of padding algorithm used:\n *    - `same` and stride 1: output will be of same size as input,\n *       regardless of filter size.\n *    - `valid`: output will be smaller than input if filter is larger\n *       than 1x1.\n */\nfunction conv3dDerInput_(xShape, dy, filter, strides, pad) {\n    util.assert(xShape.length === dy.rank, function () { return \"Length of inShape \" +\n        (\"(\" + xShape.length + \") and rank of dy (\" + dy.rank + \") must match\"); });\n    var xShape5D = xShape;\n    var dy5D = dy;\n    var reshapedTo5D = false;\n    if (dy.rank === 4) {\n        reshapedTo5D = true;\n        dy5D = dy.as5D(1, dy.shape[0], dy.shape[1], dy.shape[2], dy.shape[3]);\n        xShape5D = [1, xShape[0], xShape[1], xShape[2], xShape[3]];\n    }\n    var inDepth = xShape5D[4];\n    var outDepth = dy5D.shape[4];\n    util.assert(xShape5D.length === 5, function () {\n        return \"Error in conv3dDerInput: inShape must be length 5, but got length \" +\n            (xShape5D.length + \".\");\n    });\n    util.assert(dy5D.rank === 5, function () { return \"Error in conv3dDerInput: dy must be rank 5, but got \" +\n        (\"rank \" + dy5D.rank); });\n    util.assert(filter.rank === 5, function () { return \"Error in conv3dDerInput: filter must be rank 5, but got \" +\n        (\"rank \" + filter.rank); });\n    util.assert(inDepth === filter.shape[3], function () { return \"Error in conv3dDerInput: depth of input (\" + inDepth + \") must \" +\n        (\"match input depth for filter \" + filter.shape[3] + \".\"); });\n    util.assert(outDepth === filter.shape[4], function () { return \"Error in conv3dDerInput: depth of output (\" + outDepth + \") must \" +\n        (\"match output depth for filter \" + filter.shape[4] + \".\"); });\n    var dilations = 1;\n    var convInfo = conv_util.computeConv3DInfo(xShape5D, filter.shape, strides, dilations, pad);\n    var res = engine_1.ENGINE.runKernel(function (backend) { return backend.conv3dDerInput(dy5D, filter, convInfo); }, { dy5D: dy5D });\n    if (reshapedTo5D) {\n        return res.as4D(res.shape[1], res.shape[2], res.shape[3], res.shape[4]);\n    }\n    return res;\n}\n/**\n * Computes the derivative of the filter of a 3D convolution.\n *\n * @param x The input tensor, of rank 5 or rank 4 of shape\n *     [batch, depth, height, width, inChannels]. If rank 4, batch of 1 is\n *     assumed.\n * @param dy The dy image, of rank 5 or rank 4, of shape\n *     [batch, depth, height, width, outDepth]. If rank 4, batch of 1 is\n *     assumed.\n * @param filterShape The shape of the filter, length 5,\n *     [filterDepth, filterHeight, filterWidth, inDepth, outDepth].\n * @param strides The strides of the convolution: [strideDepth, strideHeight,\n * strideWidth].\n * @param pad A string from: 'same', 'valid'. The type of padding algorithm\n *     used in the forward prop of the op.\n */\nfunction conv3dDerFilter_(x, dy, filterShape, strides, pad) {\n    var x5D = x;\n    if (x.rank === 4) {\n        x5D = x.as5D(1, x.shape[0], x.shape[1], x.shape[2], x.shape[3]);\n    }\n    var dy5D = dy;\n    if (dy5D.rank === 4) {\n        dy5D = dy.as5D(1, dy.shape[0], dy.shape[1], dy.shape[2], dy.shape[3]);\n    }\n    util.assert(x5D.rank === 5, function () { return \"Error in conv3dDerFilter: input must be rank 5, but got shape \" +\n        (x5D.shape + \".\"); });\n    util.assert(dy5D.rank === 5, function () { return \"Error in conv3dDerFilter: dy must be rank 5, but got shape \" +\n        (dy5D.shape + \".\"); });\n    util.assert(filterShape.length === 5, function () { return \"Error in conv3dDerFilter: filterShape must be length 5, but got \" +\n        (filterShape + \".\"); });\n    util.assert(x5D.shape[4] === filterShape[3], function () { return \"Error in conv3dDerFilter: depth of input \" + x5D.shape[4] + \") must \" +\n        (\"match input depth in filter (\" + filterShape[3] + \".\"); });\n    util.assert(dy5D.shape[4] === filterShape[4], function () { return \"Error in conv3dDerFilter: depth of dy (\" + dy5D.shape[4] + \") must \" +\n        (\"match output depth for filter (\" + filterShape[4] + \").\"); });\n    var dilations = 1;\n    var convInfo = conv_util.computeConv3DInfo(x5D.shape, filterShape, strides, dilations, pad);\n    return engine_1.ENGINE.runKernel(function (backend) { return backend.conv3dDerFilter(x5D, dy5D, convInfo); }, { x5D: x5D, dy5D: dy5D });\n}\nexports.conv1d = operation_1.op({ conv1d_: conv1d_ });\nexports.conv2d = operation_1.op({ conv2d_: conv2d_ });\nexports.conv3d = operation_1.op({ conv3d_: conv3d_ });\nexports.conv2dDerFilter = operation_1.op({ conv2dDerFilter_: conv2dDerFilter_ });\nexports.depthwiseConv2d = operation_1.op({ depthwiseConv2d_: depthwiseConv2d_ });\nexports.separableConv2d = operation_1.op({ separableConv2d_: separableConv2d_ });\nexports.conv2dTranspose = operation_1.op({ conv2dTranspose_: conv2dTranspose_ });\n//# sourceMappingURL=conv.js.map","\n/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar engine_1 = require(\"../engine\");\nvar tensor_util_1 = require(\"../tensor_util\");\nvar tensor_util_env_1 = require(\"../tensor_util_env\");\nvar util = require(\"../util\");\nvar operation_1 = require(\"./operation\");\n/**\n * Computes the dot product of two matrices, A * B. These must be matrices.\n *\n * ```js\n * const a = tf.tensor2d([1, 2], [1, 2]);\n * const b = tf.tensor2d([1, 2, 3, 4], [2, 2]);\n *\n * a.matMul(b).print();  // or tf.matMul(a, b)\n * ```\n * @param a First matrix in dot product operation.\n * @param b Second matrix in dot product operation.\n * @param transposeA If true, `a` is transposed before multiplication.\n * @param transposeB If true, `b` is transposed before multiplication.\n */\n/** @doc {heading: 'Operations', subheading: 'Matrices'} */\nfunction matMul_(a, b, transposeA, transposeB) {\n    if (transposeA === void 0) { transposeA = false; }\n    if (transposeB === void 0) { transposeB = false; }\n    var _a;\n    var $a = tensor_util_env_1.convertToTensor(a, 'a', 'matMul');\n    var $b = tensor_util_env_1.convertToTensor(b, 'b', 'matMul');\n    _a = tensor_util_1.makeTypesMatch($a, $b), $a = _a[0], $b = _a[1];\n    var innerShapeA = transposeA ? $a.shape[$a.rank - 2] : $a.shape[$a.rank - 1];\n    var innerShapeB = transposeB ? $b.shape[$b.rank - 1] : $b.shape[$b.rank - 2];\n    var outerShapeA = transposeA ? $a.shape[$a.rank - 1] : $a.shape[$a.rank - 2];\n    var outerShapeB = transposeB ? $b.shape[$b.rank - 2] : $b.shape[$b.rank - 1];\n    var outerDimsA = $a.shape.slice(0, -2);\n    var outerDimsB = $b.shape.slice(0, -2);\n    var batchDimA = util.sizeFromShape(outerDimsA);\n    var batchDimB = util.sizeFromShape(outerDimsB);\n    util.assert($a.rank >= 2 && $b.rank >= 2 && $a.rank === $b.rank, function () { return \"Error in matMul: inputs must have the same rank of at least 2, \" +\n        (\"got ranks \" + $a.rank + \" and \" + $b.rank + \".\"); });\n    util.assert(util.arraysEqual(outerDimsA, outerDimsB), function () { return \"Error in matMul: outer dimensions (\" + outerDimsA + \") and (\" +\n        (outerDimsB + \") of Tensors with shapes \" + $a.shape + \" and \") +\n        ($b.shape + \" must match.\"); });\n    util.assert(innerShapeA === innerShapeB, function () { return \"Error in matMul: inner shapes (\" + innerShapeA + \") and (\" +\n        (innerShapeB + \") of Tensors with shapes \" + $a.shape + \" and \") +\n        ($b.shape + \" and transposeA=\" + transposeA) +\n        (\" and transposeB=\" + transposeB + \" must match.\"); });\n    var outShape = $a.shape.slice(0, -2).concat([outerShapeA, outerShapeB]);\n    var a3D = transposeA ? $a.as3D(batchDimA, innerShapeA, outerShapeA) :\n        $a.as3D(batchDimA, outerShapeA, innerShapeA);\n    var b3D = transposeB ? $b.as3D(batchDimB, outerShapeB, innerShapeB) :\n        $b.as3D(batchDimB, innerShapeB, outerShapeB);\n    var grad = function (dy, saved) {\n        var _a = saved, a3D = _a[0], b3D = _a[1];\n        if (!transposeA && !transposeB) {\n            return {\n                $a: function () { return dy.matMul(b3D, false, true); },\n                $b: function () { return a3D.matMul(dy, true, false); }\n            };\n        }\n        else if (!transposeA && transposeB) {\n            return {\n                $a: function () { return dy.matMul(b3D, false, false); },\n                $b: function () { return dy.matMul(a3D, true, false); }\n            };\n        }\n        else if (transposeA && !transposeB) {\n            return {\n                $a: function () { return b3D.matMul(dy, false, true); },\n                $b: function () { return a3D.matMul(dy, false, false); }\n            };\n        }\n        else {\n            return {\n                $a: function () { return b3D.matMul(dy, true, true); },\n                $b: function () { return dy.matMul(a3D, true, true); }\n            };\n        }\n    };\n    var res = engine_1.ENGINE.runKernel(function (backend, save) {\n        var res = backend.batchMatMul(a3D, b3D, transposeA, transposeB);\n        save([a3D, b3D]);\n        return res;\n    }, { $a: a3D, $b: b3D }, grad);\n    return res.reshape(outShape);\n}\n/**\n * Computes the outer product of two vectors, `v1` and `v2`.\n *\n * ```js\n * const a = tf.tensor1d([1, 2, 3]);\n * const b = tf.tensor1d([3, 4, 5]);\n *\n * tf.outerProduct(a, b).print();\n * ```\n * @param v1 The first vector in the outer product operation.\n * @param v2 The second vector in the outer product operation.\n */\n/** @doc {heading: 'Operations', subheading: 'Matrices'} */\nfunction outerProduct_(v1, v2) {\n    var $v1 = tensor_util_env_1.convertToTensor(v1, 'v1', 'outerProduct');\n    var $v2 = tensor_util_env_1.convertToTensor(v2, 'v2', 'outerProduct');\n    util.assert($v1.rank === 1 && $v2.rank === 1, function () { return \"Error in outerProduct: inputs must be rank 1, but got ranks \" +\n        ($v1.rank + \" and \" + $v2.rank + \".\"); });\n    return $v1.as2D(-1, 1).matMul($v2.as2D(1, -1));\n}\n/**\n * Computes the dot product of two matrices and/or vectors, `t1` and `t2`.\n *\n * ```js\n * const a = tf.tensor1d([1, 2]);\n * const b = tf.tensor2d([[1, 2], [3, 4]]);\n * const c = tf.tensor2d([[1, 2, 3], [4, 5, 6]]);\n *\n * a.dot(b).print();  // or tf.dot(a, b)\n * b.dot(a).print();\n * b.dot(c).print();\n * ```\n * @param t1 The first tensor in the dot operation.\n * @param t2 The second tensor in the dot operation.\n */\n/** @doc {heading: 'Operations', subheading: 'Matrices'} */\nfunction dot_(t1, t2) {\n    var $t1 = tensor_util_env_1.convertToTensor(t1, 't1', 'dot');\n    var $t2 = tensor_util_env_1.convertToTensor(t2, 't2', 'dot');\n    util.assert(($t1.rank === 1 || $t1.rank === 2) && ($t2.rank === 1 || $t2.rank === 2), function () { return \"Error in dot: inputs must all be rank 1 or 2, but got ranks \" +\n        ($t1.rank + \" and \" + $t2.rank + \".\"); });\n    var t1Inner = ($t1.rank === 1 ? $t1.size : $t1.shape[1]);\n    var t2Inner = ($t2.rank === 1 ? $t2.size : $t2.shape[0]);\n    util.assert(t1Inner === t2Inner, function () { return \"Error in dot: inner dimensions of inputs must match, but got \" +\n        (t1Inner + \" and \" + t2Inner + \".\"); });\n    if ($t1.rank === 1 && $t2.rank === 1) {\n        return $t1.as2D(1, -1).matMul($t2.as2D(-1, 1)).asScalar();\n    }\n    else if ($t1.rank === 1 && $t2.rank === 2) {\n        return $t1.as2D(1, -1).matMul($t2.as2D($t2.shape[0], $t2.shape[1])).as1D();\n    }\n    else if ($t1.rank === 2 && $t2.rank === 1) {\n        return $t1.matMul($t2.as2D(-1, 1)).as1D();\n    }\n    else {\n        return $t1.matMul($t2.as2D($t2.shape[0], $t2.shape[1]));\n    }\n}\nexports.matMul = operation_1.op({ matMul_: matMul_ });\nexports.dot = operation_1.op({ dot_: dot_ });\nexports.outerProduct = operation_1.op({ outerProduct_: outerProduct_ });\n//# sourceMappingURL=matmul.js.map","\n/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar engine_1 = require(\"../engine\");\nvar tensor_util_env_1 = require(\"../tensor_util_env\");\nvar util = require(\"../util\");\nvar operation_1 = require(\"./operation\");\n/**\n * Reverses a `tf.Tensor1D`.\n *\n * @param x The input tensor.\n */\nfunction reverse1d_(x) {\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'reverse');\n    util.assert($x.rank === 1, function () { return \"Error in reverse1D: x must be rank 1 but got rank \" + $x.rank + \".\"; });\n    return exports.reverse($x, 0);\n}\n/**\n * Reverses a `tf.Tensor2D` along a specified axis.\n *\n * @param x The input tensor.\n * @param axis The set of dimensions to reverse. Must be in the\n *     range [-rank(x), rank(x)). Defaults to all axes.\n */\nfunction reverse2d_(x, axis) {\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'reverse');\n    util.assert($x.rank === 2, function () { return \"Error in reverse2D: x must be rank 2 but got rank \" + $x.rank + \".\"; });\n    return exports.reverse($x, axis);\n}\n/**\n * Reverses a `tf.Tensor3D` along a specified axis.\n *\n * @param x The input tensor.\n * @param axis The set of dimensions to reverse. Must be in the\n *     range [-rank(x), rank(x)). Defaults to all axes.\n */\nfunction reverse3d_(x, axis) {\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'reverse');\n    util.assert($x.rank === 3, function () { return \"Error in reverse3D: x must be rank 3 but got rank \" + $x.rank + \".\"; });\n    return exports.reverse($x, axis);\n}\n/**\n * Reverses a `tf.Tensor4D` along a specified axis.\n *\n * @param x The input tensor.\n * @param axis The set of dimensions to reverse. Must be in the\n *     range [-rank(x), rank(x)). Defaults to all axes.\n */\nfunction reverse4d_(x, axis) {\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'reverse');\n    util.assert($x.rank === 4, function () { return \"Error in reverse4D: x must be rank 4 but got rank \" + $x.rank + \".\"; });\n    return exports.reverse($x, axis);\n}\n/**\n * Reverses a `tf.Tensor` along a specified axis.\n *\n * Also available are stricter rank-specific methods that assert that `x` is\n * of the given rank:\n *   - `tf.reverse1d`\n *   - `tf.reverse2d`\n *   - `tf.reverse3d`\n *   - `tf.reverse4d`\n *\n * Except `tf.reverse1d` (which does not have axis param), all methods have\n * same signature as this method.\n *\n * ```js\n * const x = tf.tensor1d([1, 2, 3, 4]);\n *\n * x.reverse().print();\n * ```\n *\n * ```js\n * const x = tf.tensor2d([1, 2, 3, 4], [2, 2]);\n *\n * const axis = 1;\n * x.reverse(axis).print();\n * ```\n * @param x The input tensor to be reversed.\n * @param axis The set of dimensions to reverse. Must be in the\n *     range [-rank(x), rank(x)). Defaults to all axes.\n */\n/** @doc {heading: 'Tensors', subheading: 'Slicing and Joining'} */\nfunction reverse_(x, axis) {\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'reverse');\n    if ($x.rank === 0) {\n        return $x.clone();\n    }\n    var axes = util.parseAxisParam(axis, $x.shape);\n    var grad = function (dy) {\n        return { $x: function () { return dy.reverse(axes); } };\n    };\n    var res = engine_1.ENGINE.runKernel(function (backend) { return backend.reverse($x, axes); }, { $x: $x }, grad);\n    return res.reshapeAs($x);\n}\nexports.reverse = operation_1.op({ reverse_: reverse_ });\nexports.reverse1d = operation_1.op({ reverse1d_: reverse1d_ });\nexports.reverse2d = operation_1.op({ reverse2d_: reverse2d_ });\nexports.reverse3d = operation_1.op({ reverse3d_: reverse3d_ });\nexports.reverse4d = operation_1.op({ reverse4d_: reverse4d_ });\n//# sourceMappingURL=reverse.js.map","\n/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar engine_1 = require(\"../engine\");\nvar tensor_util_env_1 = require(\"../tensor_util_env\");\nvar util = require(\"../util\");\nvar array_ops_1 = require(\"./array_ops\");\nvar conv_util = require(\"./conv_util\");\nvar operation_1 = require(\"./operation\");\n/**\n * Computes the 2D max pooling of an image.\n *\n * @param x The input tensor, of rank 4 or rank 3 of shape\n *     `[batch, height, width, inChannels]`. If rank 3, batch of 1 is assumed.\n * @param filterSize The filter size: `[filterHeight, filterWidth]`. If\n *     `filterSize` is a single number, then `filterHeight == filterWidth`.\n * @param strides The strides of the pooling: `[strideHeight, strideWidth]`. If\n *     `strides` is a single number, then `strideHeight == strideWidth`.\n * @param dilations The dilation rates: `[dilationHeight, dilationWidth]`\n *     in which we sample input values across the height and width dimensions\n *     in dilated pooling. Defaults to `[1, 1]`. If `dilations` is a single\n *     number, then `dilationHeight == dilationWidth`. If it is greater than\n *     1, then all values of `strides` must be 1.\n * @param pad The type of padding algorithm.\n *    - `same` and stride 1: output will be of same size as input,\n *       regardless of filter size.\n *    - `valid`: output will be smaller than input if filter is larger\n *       than 1x1.\n *    - For more info, see this guide:\n *     [https://www.tensorflow.org/api_guides/python/nn#Convolution](\n *          https://www.tensorflow.org/api_guides/python/nn#Convolution)\n * @param dimRoundingMode The rounding mode used when computing output\n *     dimensions if pad is a number. If none is provided, it will not round\n *     and error if the output is of fractional size.\n */\nfunction maxPoolImpl_(x, filterSize, strides, dilations, pad, dimRoundingMode) {\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'maxPool');\n    var x4D = $x;\n    var reshapedTo4D = false;\n    if ($x.rank === 3) {\n        reshapedTo4D = true;\n        x4D = $x.as4D(1, $x.shape[0], $x.shape[1], $x.shape[2]);\n    }\n    if (dilations == null) {\n        dilations = [1, 1];\n    }\n    util.assert(x4D.rank === 4, function () { return \"Error in maxPool: input must be rank 4 but got rank \" + x4D.rank + \".\"; });\n    util.assert(conv_util.eitherStridesOrDilationsAreOne(strides, dilations), function () { return 'Error in maxPool: Either strides or dilations must be 1. ' +\n        (\"Got strides \" + strides + \" and dilations '\" + dilations + \"'\"); });\n    if (dimRoundingMode != null) {\n        util.assert(util.isInt(pad), function () { return \"Error in maxPool: pad must be an integer when using, \" +\n            (\"dimRoundingMode \" + dimRoundingMode + \" but got pad \" + pad + \".\"); });\n    }\n    var convInfo = conv_util.computePool2DInfo(x4D.shape, filterSize, strides, dilations, pad, dimRoundingMode);\n    var grad = function (dy, saved) {\n        var x4D = saved[0], y = saved[1];\n        return {\n            x: function () { return maxPoolBackprop(dy, x4D, y, filterSize, strides, dilations, pad); }\n        };\n    };\n    var res = engine_1.ENGINE.runKernel(function (backend, save) {\n        var y = backend.maxPool(x4D, convInfo);\n        save([x4D, y]);\n        return y;\n    }, { x: x4D }, grad);\n    if (reshapedTo4D) {\n        return res.as3D(res.shape[1], res.shape[2], res.shape[3]);\n    }\n    return res;\n}\n/**\n * Computes the 2D max pooling of an image.\n *\n * @param x The input tensor, of rank 4 or rank 3 of shape\n *     `[batch, height, width, inChannels]`. If rank 3, batch of 1 is assumed.\n * @param filterSize The filter size: `[filterHeight, filterWidth]`. If\n *     `filterSize` is a single number, then `filterHeight == filterWidth`.\n * @param strides The strides of the pooling: `[strideHeight, strideWidth]`. If\n *     `strides` is a single number, then `strideHeight == strideWidth`.\n * @param pad The type of padding algorithm.\n *    - `same` and stride 1: output will be of same size as input,\n *       regardless of filter size.\n *    - `valid`: output will be smaller than input if filter is larger\n *       than 1x1.\n *    - For more info, see this guide:\n *     [https://www.tensorflow.org/api_guides/python/nn#Convolution](\n *          https://www.tensorflow.org/api_guides/python/nn#Convolution)\n * @param dimRoundingMode The rounding mode used when computing output\n *     dimensions if pad is a number. If none is provided, it will not round\n *     and error if the output is of fractional size.\n */\n/** @doc {heading: 'Operations', subheading: 'Convolution'} */\nfunction maxPool_(x, filterSize, strides, pad, dimRoundingMode) {\n    return maxPoolImpl_(x, filterSize, strides, 1, pad, dimRoundingMode);\n}\n/**\n * Computes the 2D average pooling of an image.\n *\n * @param x The input tensor, of rank 4 or rank 3 of shape\n *     `[batch, height, width, inChannels]`. If rank 3, batch of 1 is assumed.\n * @param filterSize The filter size: `[filterHeight, filterWidth]`. If\n *     `filterSize` is a single number, then `filterHeight == filterWidth`.\n * @param strides The strides of the pooling: `[strideHeight, strideWidth]`. If\n *     `strides` is a single number, then `strideHeight == strideWidth`.\n * @param dilations The dilation rates: `[dilationHeight, dilationWidth]`\n *     in which we sample input values across the height and width dimensions\n *     in dilated pooling. Defaults to `[1, 1]`. If `dilations` is a single\n *     number, then `dilationHeight == dilationWidth`. If it is greater than\n *     1, then all values of `strides` must be 1.\n * @param pad The type of padding algorithm:\n *    - `same` and stride 1: output will be of same size as input,\n *       regardless of filter size.\n *    - `valid`: output will be smaller than input if filter is larger\n *       than 1x1.\n *    - For more info, see this guide:\n *     [https://www.tensorflow.org/api_guides/python/nn#Convolution](\n *         https://www.tensorflow.org/api_guides/python/nn#Convolution)\n * @param dimRoundingMode The rounding mode used when computing output\n *     dimensions if pad is a number. If none is provided, it will not round\n *     and error if the output is of fractional size.\n */\nfunction avgPoolImpl_(x, filterSize, strides, dilations, pad, dimRoundingMode) {\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'avgPool', 'float32');\n    if (dilations == null) {\n        dilations = [1, 1];\n    }\n    util.assert(conv_util.eitherStridesOrDilationsAreOne(strides, dilations), function () { return 'Error in avgPool: Either strides or dilations must be 1. ' +\n        (\"Got strides \" + strides + \" and dilations '\" + dilations + \"'\"); });\n    var x4D = $x;\n    var reshapedTo4D = false;\n    if ($x.rank === 3) {\n        reshapedTo4D = true;\n        x4D = $x.as4D(1, $x.shape[0], $x.shape[1], $x.shape[2]);\n    }\n    util.assert(x4D.rank === 4, function () { return \"Error in avgPool: x must be rank 4 but got rank \" + x4D.rank + \".\"; });\n    if (dimRoundingMode != null) {\n        util.assert(util.isInt(pad), function () { return \"Error in avgPool: pad must be an integer when using, \" +\n            (\"dimRoundingMode \" + dimRoundingMode + \" but got pad \" + pad + \".\"); });\n    }\n    var convInfo = conv_util.computePool2DInfo(x4D.shape, filterSize, strides, dilations, pad, dimRoundingMode);\n    var grad = function (dy) {\n        return {\n            x: function () { return avgPoolBackprop(dy, x4D, filterSize, strides, dilations, pad); }\n        };\n    };\n    var res = engine_1.ENGINE.runKernel(function (backend) { return backend.avgPool(x4D, convInfo); }, { x: x4D }, grad);\n    res = res.cast($x.dtype);\n    if (reshapedTo4D) {\n        return res.as3D(res.shape[1], res.shape[2], res.shape[3]);\n    }\n    return res;\n}\n/**\n * Computes the 2D average pooling of an image.\n *\n * @param x The input tensor, of rank 4 or rank 3 of shape\n *     `[batch, height, width, inChannels]`. If rank 3, batch of 1 is assumed.\n * @param filterSize The filter size: `[filterHeight, filterWidth]`. If\n *     `filterSize` is a single number, then `filterHeight == filterWidth`.\n * @param strides The strides of the pooling: `[strideHeight, strideWidth]`. If\n *     `strides` is a single number, then `strideHeight == strideWidth`.\n * @param pad The type of padding algorithm:\n *    - `same` and stride 1: output will be of same size as input,\n *       regardless of filter size.\n *    - `valid`: output will be smaller than input if filter is larger\n *       than 1x1.\n *    - For more info, see this guide:\n *     [https://www.tensorflow.org/api_guides/python/nn#Convolution](\n *         https://www.tensorflow.org/api_guides/python/nn#Convolution)\n * @param dimRoundingMode The rounding mode used when computing output\n *     dimensions if pad is a number. If none is provided, it will not round\n *     and error if the output is of fractional size.\n */\n/** @doc {heading: 'Operations', subheading: 'Convolution'} */\nfunction avgPool_(x, filterSize, strides, pad, dimRoundingMode) {\n    return avgPoolImpl_(x, filterSize, strides, 1, pad, dimRoundingMode);\n}\n/**\n * Performs an N-D pooling operation\n *\n * @param input The input tensor, of rank 4 or rank 3 of shape\n *     `[batch, height, width, inChannels]`. If rank 3, batch of 1 is assumed.\n * @param windowShape The filter size: `[filterHeight, filterWidth]`. If\n *     `filterSize` is a single number, then `filterHeight == filterWidth`.\n * @param poolingType The type of pooling, either 'max' or 'avg'.\n * @param pad The type of padding algorithm:\n *    - `same` and stride 1: output will be of same size as input,\n *       regardless of filter size.\n *    - `valid`: output will be smaller than input if filter is larger\n *       than 1x1.\n *    - For more info, see this guide:\n *     [https://www.tensorflow.org/api_guides/python/nn#Convolution](\n *         https://www.tensorflow.org/api_guides/python/nn#Convolution)\n * @param dilations The dilation rates: `[dilationHeight, dilationWidth]`\n *     in which we sample input values across the height and width dimensions\n *     in dilated pooling. Defaults to `[1, 1]`. If `dilationRate` is a single\n *     number, then `dilationHeight == dilationWidth`. If it is greater than\n *     1, then all values of `strides` must be 1.\n * @param strides The strides of the pooling: `[strideHeight, strideWidth]`. If\n *     `strides` is a single number, then `strideHeight == strideWidth`.\n */\n/** @doc {heading: 'Operations', subheading: 'Convolution'} */\nfunction pool_(input, windowShape, poolingType, pad, dilations, strides) {\n    if (dilations == null) {\n        dilations = [1, 1];\n    }\n    if (strides == null) {\n        strides = 1;\n    }\n    if (pad === 0) {\n        pad = 'valid';\n    }\n    var $x = tensor_util_env_1.convertToTensor(input, 'x', 'maxPool');\n    var x4D = $x;\n    var reshapedTo4D = false;\n    if ($x.rank === 3) {\n        reshapedTo4D = true;\n        x4D = $x.as4D(1, $x.shape[0], $x.shape[1], $x.shape[2]);\n    }\n    util.assert(conv_util.eitherStridesOrDilationsAreOne(strides, dilations), function () { return 'Error in pool: Either strides or dilations must be 1. ' +\n        (\"Got strides \" + strides + \" and dilations '\" + dilations + \"'\"); });\n    var convInfo = conv_util.computePool2DInfo(x4D.shape, windowShape, strides, dilations, pad);\n    var dilation = [convInfo.dilationHeight, convInfo.dilationWidth];\n    // The following implementation does batchToSpace(pool(spaceToBatch(x)))\n    // whenever dilation > 1 since the TF kernels do not support dilation > 1.\n    // tslint:disable-next-line:max-line-length\n    // https://github.com/tensorflow/tensorflow/blob/50f6bb67dc98c9b74630b6047aae7a4f8a40fd02/tensorflow/python/ops/nn_ops.py#L1037\n    var basePadding;\n    if (pad === 'same') {\n        basePadding = withSpaceToBatchBasePaddings([convInfo.filterHeight, convInfo.filterWidth], dilation);\n    }\n    else {\n        basePadding = [[0, 0], [0, 0]];\n    }\n    var isDilationOne = dilation[0] === 1 && dilation[1] === 1;\n    var _a = requiredSpaceToBatchPaddings([convInfo.inHeight, convInfo.inWidth], dilation, basePadding), adjustedPadding = _a[0], adjustedCrops = _a[1];\n    var convertedPad = isDilationOne ? pad : 'valid';\n    var convertedX = isDilationOne ? x4D : array_ops_1.spaceToBatchND(x4D, dilation, adjustedPadding);\n    var forwardOp = poolingType === 'avg' ?\n        function () { return avgPoolImpl_(convertedX, windowShape, strides, 1 /* dilation */, convertedPad); } :\n        function () { return maxPoolImpl_(convertedX, windowShape, strides, 1 /* dilation */, convertedPad); };\n    var y = forwardOp();\n    var res = isDilationOne ? y : array_ops_1.batchToSpaceND(y, dilation, adjustedCrops);\n    if (reshapedTo4D) {\n        return res.as3D(res.shape[1], res.shape[2], res.shape[3]);\n    }\n    return res;\n}\n/**\n * Computes the backprop of a max pool.\n *\n * @param dy The dy error, of rank 4 or rank 3 of shape\n *     [batchSize, height, width, channels]. If rank 3, batch of 1 is\n * assumed.\n * @param input The original input image, of rank 4, of shape\n *     [batchSize, height, width, channels].\n * @param output The original output image, of rank 4, of shape\n *     [batchSize, outHeight, outWidth, channels].\n * @param filterSize The filter size: `[filterHeight, filterWidth]`. If\n *     `filterSize` is a single number, then `filterHeight == filterWidth`.\n * @param strides The strides of the pooling: `[strideHeight, strideWidth]`. If\n *     `strides` is a single number, then `strideHeight == strideWidth`.\n * @param pad A string from: 'same', 'valid'. The type of padding algorithm\n *     used in the forward prop of the op.\n * @param dimRoundingMode A string from: 'ceil', 'round', 'floor'. The\n *     rounding mode used when computing output dimensions if pad is a\n *     number. If none is provided, it will not round and error if the output\n *     is of fractional size.\n */\nfunction maxPoolBackprop(dy, input, output, filterSize, strides, dilations, pad, dimRoundingMode) {\n    var $dy = tensor_util_env_1.convertToTensor(dy, 'dy', 'maxPoolBackprop');\n    var $input = tensor_util_env_1.convertToTensor(input, 'input', 'maxPoolBackprop');\n    var $output = tensor_util_env_1.convertToTensor(output, 'output', 'maxPoolBackprop');\n    util.assert($input.rank === $dy.rank, function () { return \"Rank of input (\" + $input.rank + \") does not match rank of dy \" +\n        (\"(\" + $dy.rank + \")\"); });\n    if (dilations == null) {\n        dilations = [1, 1];\n    }\n    util.assert(conv_util.eitherStridesOrDilationsAreOne(strides, dilations), function () {\n        return 'Error in maxPoolBackProp: Either strides or dilations must be 1. ' +\n            (\"Got strides \" + strides + \" and dilations '\" + dilations + \"'\");\n    });\n    util.assert($dy.rank === 4, function () { return \"Error in maxPoolBackprop: dy must be rank 4 but got rank \" +\n        ($dy.rank + \".\"); });\n    util.assert($input.rank === 4, function () { return \"Error in maxPoolBackprop: input must be rank 4 but got rank \" +\n        ($input.rank + \".\"); });\n    if (dimRoundingMode != null) {\n        util.assert(util.isInt(pad), function () { return \"Error in maxPoolBackprop: pad must be an integer when using, \" +\n            (\"dimRoundingMode \" + dimRoundingMode + \" but got pad \" + pad + \".\"); });\n    }\n    var convInfo = conv_util.computePool2DInfo($input.shape, filterSize, strides, dilations, pad, dimRoundingMode);\n    var res = engine_1.ENGINE.runKernel(function (backend) { return backend.maxPoolBackprop($dy, $input, $output, convInfo); }, { $dy: $dy, $input: $input });\n    return res;\n}\n/**\n * Computes the backprop of an avg pool.\n *\n * @param dy The dy error, of rank 4 or rank 3 of shape\n *     [batchSize, height, width, channels]. If rank 3, batch of 1 is\n * assumed.\n * @param input The input image, of rank 4 or rank 3 of shape\n *     [batchSize, height, width, channels]. If rank 3, batch of 1 is\n * assumed.\n * @param filterSize The filter size: `[filterHeight, filterWidth]`. If\n *     `filterSize` is a single number, then `filterHeight == filterWidth`.\n * @param strides The strides of the pooling: `[strideHeight, strideWidth]`. If\n *     `strides` is a single number, then `strideHeight == strideWidth`.\n * @param pad A string from: 'same', 'valid'. The type of padding algorithm\n *     used in the forward prop of the op.\n */\nfunction avgPoolBackprop(dy, input, filterSize, strides, dilations, pad) {\n    var $dy = tensor_util_env_1.convertToTensor(dy, 'dy', 'avgPoolBackprop');\n    var $input = tensor_util_env_1.convertToTensor(input, 'input', 'avgPoolBackprop');\n    util.assert($input.rank === $dy.rank, function () { return \"Rank of input (\" + $input.rank + \") does not match rank of dy (\" + $dy.rank + \")\"; });\n    if (dilations == null) {\n        dilations = [1, 1];\n    }\n    util.assert(conv_util.eitherStridesOrDilationsAreOne(strides, dilations), function () {\n        return 'Error in avgPoolBackprop: Either strides or dilations must be 1. ' +\n            (\"Got strides \" + strides + \" and dilations '\" + dilations + \"'\");\n    });\n    var input4D = $input;\n    var dy4D = $dy;\n    var reshapedTo4D = false;\n    if ($input.rank === 3) {\n        reshapedTo4D = true;\n        input4D = $input.as4D(1, $input.shape[0], $input.shape[1], $input.shape[2]);\n        dy4D = $dy.as4D(1, $dy.shape[0], $dy.shape[1], $dy.shape[2]);\n    }\n    util.assert(dy4D.rank === 4, function () { return \"Error in avgPoolBackprop: dy must be rank 4 but got rank \" +\n        (dy4D.rank + \".\"); });\n    util.assert(input4D.rank === 4, function () { return \"Error in avgPoolBackprop: input must be rank 4 but got rank \" +\n        (input4D.rank + \".\"); });\n    var convInfo = conv_util.computePool2DInfo(input4D.shape, filterSize, strides, dilations, pad);\n    var res = engine_1.ENGINE.runKernel(function (backend) { return backend.avgPoolBackprop(dy4D, input4D, convInfo); }, { dy4D: dy4D, input4D: input4D });\n    if (reshapedTo4D) {\n        return res.as3D(res.shape[1], res.shape[2], res.shape[3]);\n    }\n    return res;\n}\n// Helper function to compute crops and paddings for pool with dilation > 1.\n// tslint:disable-next-line:max-line-length\n// https://github.com/tensorflow/tensorflow/blob/50f6bb67dc98c9b74630b6047aae7a4f8a40fd02/tensorflow/python/ops/array_ops.py#L2184\nfunction requiredSpaceToBatchPaddings(inputShape, blockShape, basePadding) {\n    var padStart = basePadding.map(function (b) { return b[0]; });\n    var origPadEnd = basePadding.map(function (b) { return b[1]; });\n    var fullInputShape = inputShape.concat(padStart, origPadEnd);\n    var padEndExtra = blockShape.map(function (b, i) { return (b - fullInputShape[i] % b) % b; });\n    var padEnd = origPadEnd.map(function (s, i) { return s + padEndExtra[i]; });\n    var paddings = blockShape.map(function (_, i) { return [padStart[i], padEnd[i]]; });\n    var crops = blockShape.map(function (_, i) { return [0, padEndExtra[i]]; });\n    return [paddings, crops];\n}\n// Helper function to compute base paddings for pool with dilation > 1.\n// tslint:disable-next-line:max-line-length\n// https://github.com/tensorflow/tensorflow/blob/50f6bb67dc98c9b74630b6047aae7a4f8a40fd02/tensorflow/python/ops/nn_ops.py#L524\nfunction withSpaceToBatchBasePaddings(filterShape, dilation) {\n    // Spatial dimensions of the filters and the upsampled filters in which we\n    // introduce (rate - 1) zeros between consecutive filter values.\n    var dilatedFilterShape = filterShape.map(function (s, i) {\n        return s + (s - 1) * (dilation[i] - 1);\n    });\n    var padExtraShape = dilatedFilterShape.map(function (s) { return s - 1; });\n    // When padding is odd, we pad more at end, following the same\n    // convention as conv2d.\n    var padExtraStart = padExtraShape.map(function (s) { return Math.floor(s / 2); });\n    var padExtraEnd = padExtraShape.map(function (s, i) { return s - padExtraStart[i]; });\n    return padExtraShape.map(function (_, i) {\n        return [padExtraStart[i], padExtraEnd[i]];\n    });\n}\nexports.maxPool = operation_1.op({ maxPool_: maxPool_ });\nexports.avgPool = operation_1.op({ avgPool_: avgPool_ });\nexports.pool = operation_1.op({ pool_: pool_ });\n//# sourceMappingURL=pool.js.map","\n/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar engine_1 = require(\"../engine\");\nvar tensor_util_env_1 = require(\"../tensor_util_env\");\nvar util = require(\"../util\");\nvar operation_1 = require(\"./operation\");\nvar slice_util = require(\"./slice_util\");\n/**\n * Extracts a 1D slice from 1D array starting at coordinates `begin` and is\n * of length `size`. See `slice` for details.\n */\nfunction slice1d_(x, begin, size) {\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'slice1d');\n    util.assert($x.rank === 1, function () {\n        return \"slice1d expects a rank-1 tensor, but got a rank-\" + $x.rank + \" tensor\";\n    });\n    return exports.slice($x, [begin], [size]);\n}\n/**\n * Extracts a 2D slice from a 2D array starting at coordinates `begin` and\n * is of size `size`. See `slice` for details.\n */\nfunction slice2d_(x, begin, size) {\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'slice2d');\n    util.assert($x.rank === 2, function () {\n        return \"slice2d expects a rank-2 tensor, but got a rank-\" + $x.rank + \" tensor\";\n    });\n    return exports.slice($x, begin, size);\n}\n/**\n * Extracts a 3D slice from a 3D array starting at coordinates `begin` and\n * is of size `size`. See `slice` for details.\n */\nfunction slice3d_(x, begin, size) {\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'slice3d');\n    util.assert($x.rank === 3, function () {\n        return \"slice3d expects a rank-3 tensor, but got a rank-\" + $x.rank + \" tensor\";\n    });\n    return exports.slice($x, begin, size);\n}\n/**\n * Extracts a 4D slice from a 4D array starting at coordinates `begin` and\n * is of size `size`. See `slice` for details.\n */\nfunction slice4d_(x, begin, size) {\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'slice4d');\n    util.assert($x.rank === 4, function () {\n        return \"slice4d expects a rank-4 tensor, but got a rank-\" + $x.rank + \" tensor\";\n    });\n    return exports.slice($x, begin, size);\n}\n/**\n * Extracts a slice from a `tf.Tensor` starting at coordinates `begin`\n * and is of size `size`.\n *\n * Also available are stricter rank-specific methods with the same signature\n * as this method that assert that `x` is of the given rank:\n *   - `tf.slice1d`\n *   - `tf.slice2d`\n *   - `tf.slice3d`\n *   - `tf.slice4d`\n *\n * ```js\n * const x = tf.tensor1d([1, 2, 3, 4]);\n *\n * x.slice([1], [2]).print();\n * ```\n *\n * ```js\n * const x = tf.tensor2d([1, 2, 3, 4], [2, 2]);\n *\n * x.slice([1, 0], [1, 2]).print();\n * ```\n * @param x The input `tf.Tensor` to slice from.\n * @param begin The coordinates to start the slice from. The length can be\n *     less than the rank of x - the rest of the axes will have implicit 0 as\n *     start. Can also be a single number, in which case it specifies the\n *     first axis.\n * @param size The size of the slice. The length can be less than the rank of\n *     x - the rest of the axes will have implicit -1. A value of -1 requests\n *     the rest of the dimensions in the axis. Can also be a single number,\n *     in which case it specifies the size of the first axis.\n */\n/** @doc {heading: 'Tensors', subheading: 'Slicing and Joining'} */\nfunction slice_(x, begin, size) {\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'slice');\n    if ($x.rank === 0) {\n        throw new Error('Slicing scalar is not possible');\n    }\n    // The following logic allows for more ergonomic calls.\n    var begin_;\n    if (typeof begin === 'number') {\n        begin_ = [begin].concat(new Array($x.rank - 1).fill(0));\n    }\n    else if (begin.length < $x.rank) {\n        begin_ = begin.concat(new Array($x.rank - begin.length).fill(0));\n    }\n    else {\n        begin_ = begin.slice();\n    }\n    var size_;\n    if (size == null) {\n        size_ = new Array($x.rank).fill(-1);\n    }\n    else if (typeof size === 'number') {\n        size_ = [size].concat(new Array($x.rank - 1).fill(-1));\n    }\n    else if (size.length < $x.rank) {\n        size_ = size.concat(new Array($x.rank - size.length).fill(-1));\n    }\n    else {\n        size_ = size;\n    }\n    size_ = size_.map(function (d, i) {\n        if (d >= 0) {\n            return d;\n        }\n        else {\n            util.assert(d === -1, function () { return 'Bad value in size'; });\n            return $x.shape[i] - begin_[i];\n        }\n    });\n    slice_util.assertParamsValid($x, begin_, size_);\n    var inputShape = $x.shape;\n    var grad = function (dy) {\n        // Create an Nx2 padding where the first column represents how many\n        // zeros are prepended (at start) for each dimension, and the second\n        // column indicates how many zeros are appended (at end).\n        // The number of zeros to append is the shape of the input\n        // elementwise-subtracted by both the begin vector and sizes vector.\n        var paddings = [];\n        for (var i = 0; i < dy.rank; i++) {\n            paddings.push([begin_[i], inputShape[i] - begin_[i] - size_[i]]);\n        }\n        return { $x: function () { return dy.pad(paddings); } };\n    };\n    return engine_1.ENGINE.runKernel(function (backend) { return backend.slice($x, begin_, size_); }, { $x: $x }, grad);\n}\nexports.slice = operation_1.op({ slice_: slice_ });\nexports.slice1d = operation_1.op({ slice1d_: slice1d_ });\nexports.slice2d = operation_1.op({ slice2d_: slice2d_ });\nexports.slice3d = operation_1.op({ slice3d_: slice3d_ });\nexports.slice4d = operation_1.op({ slice4d_: slice4d_ });\n//# sourceMappingURL=slice.js.map","\n/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar engine_1 = require(\"../engine\");\nvar gradients_1 = require(\"../gradients\");\nvar tensor_util_env_1 = require(\"../tensor_util_env\");\nvar util = require(\"../util\");\nvar axis_util = require(\"./axis_util\");\nvar operation_1 = require(\"./operation\");\nvar tensor_ops_1 = require(\"./tensor_ops\");\n/**\n * Computes the log(sum(exp(elements across the reduction dimensions)).\n *\n * Reduces the input along the dimensions given in `axis`. Unless `keepDims`\n * is true, the rank of the array is reduced by 1 for each entry in `axis`.\n * If `keepDims` is true, the reduced dimensions are retained with length 1.\n * If `axis` has no entries, all dimensions are reduced, and an array with a\n * single element is returned.\n *\n * ```js\n * const x = tf.tensor1d([1, 2, 3]);\n *\n * x.logSumExp().print();  // or tf.logSumExp(x)\n * ```\n *\n * ```js\n * const x = tf.tensor2d([1, 2, 3, 4], [2, 2]);\n *\n * const axis = 1;\n * x.logSumExp(axis).print();  // or tf.logSumExp(a, axis)\n * ```\n * @param x The input tensor.\n * @param axis The dimension(s) to reduce. If null (the default),\n *     reduces all dimensions.\n * @param keepDims If true, retains reduced dimensions with length\n *     of 1. Defaults to false.\n */\n/** @doc {heading: 'Operations', subheading: 'Reduction'} */\nfunction logSumExp_(x, axis, keepDims) {\n    if (axis === void 0) { axis = null; }\n    if (keepDims === void 0) { keepDims = false; }\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'logSumExp');\n    var axes = util.parseAxisParam(axis, $x.shape);\n    var xMax = $x.max(axes, true /* keepDims */);\n    var a = $x.sub(xMax);\n    var b = a.exp();\n    var c = b.sum(axes);\n    var d = c.log();\n    var res = xMax.reshape(d.shape).add(d);\n    if (keepDims) {\n        var newShape = axis_util.expandShapeToKeepDim(res.shape, axes);\n        return res.reshape(newShape);\n    }\n    return res;\n}\n/**\n * Computes the sum of elements across dimensions of a `tf.Tensor`.\n *\n * Reduces the input along the dimensions given in `axes`. Unless `keepDims`\n * is true, the rank of the `tf.Tensor` is reduced by 1 for each entry in\n * `axes`. If `keepDims` is true, the reduced dimensions are retained with\n * length 1. If axes has no entries, all dimensions are reduced, and a\n * `tf.Tensor` with a single element is returned.\n *\n * ```js\n * const x = tf.tensor1d([1, 2, 3]);\n *\n * x.sum().print();  // or tf.sum(x)\n * ```\n *\n * ```js\n * const x = tf.tensor2d([1, 2, 3, 4], [2, 2]);\n *\n * const axis = 1;\n * x.sum(axis).print();  // or tf.sum(x, axis)\n * ```\n *\n * @param x The input tensor to compute the sum over. If the dtype is `bool`\n *   it will be converted to `int32` and the output dtype will be `int32`.\n * @param axis The dimension(s) to reduce. By default it reduces\n *     all dimensions.\n * @param keepDims If true, retains reduced dimensions with size 1.\n */\n/** @doc {heading: 'Operations', subheading: 'Reduction'} */\nfunction sum_(x, axis, keepDims) {\n    if (axis === void 0) { axis = null; }\n    if (keepDims === void 0) { keepDims = false; }\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'sum');\n    if ($x.dtype === 'bool') {\n        $x = $x.toInt();\n    }\n    var axes = util.parseAxisParam(axis, $x.shape);\n    // Use a custom gradient to bypass 2 gradient backprops since sum is used\n    // extremely often.\n    var customOp = gradients_1.customGrad(function (x) {\n        var permutation = axis_util.getAxesPermutation(axes, x.rank);\n        var reductionAxes = axes;\n        var permutedX = x;\n        if (permutation != null) {\n            permutedX = x.transpose(permutation);\n            reductionAxes = axis_util.getInnerMostAxes(reductionAxes.length, x.rank);\n        }\n        var value = engine_1.ENGINE.runKernel(function (backend) { return backend.sum(permutedX, reductionAxes); }, { permutedX: permutedX });\n        if (keepDims) {\n            var newShape = axis_util.expandShapeToKeepDim(value.shape, axes);\n            value = value.reshape(newShape);\n        }\n        var gradFunc = function (dy) {\n            var expandedDyShape = x.shape.slice();\n            axes.forEach(function (axis) {\n                expandedDyShape[axis] = 1;\n            });\n            var expandedDy = dy.reshape(expandedDyShape);\n            var derX = expandedDy.mul(tensor_ops_1.ones(x.shape, 'float32'));\n            return derX;\n        };\n        return { value: value, gradFunc: gradFunc };\n    });\n    return customOp($x);\n}\n/**\n * Computes the product of elements across dimensions of a `tf.Tensor`.\n *\n * Reduces the input along the dimensions given in `axes`. Unless `keepDims`\n * is true, the rank of the `tf.Tensor` is reduced by 1 for each entry in\n * `axes`. If `keepDims` is true, the reduced dimensions are retained with\n * length 1. If `axes` has no entries, all dimensions are reduced, and a\n * `tf.Tensor` with a single element is returned.\n *\n * ```js\n * const x = tf.tensor1d([1, 2, 3]);\n *\n * x.prod().print();  // or tf.prod(x)\n * ```\n *\n * ```js\n * const x = tf.tensor2d([1, 2, 3, 4], [2, 2]);\n *\n * const axis = 1;\n * x.prod(axis).print();  // or tf.prod(x, axis)\n * ```\n *\n * @param x The input tensor to compute the product over. If the dtype is `bool`\n *   it will be converted to `int32` and the output dtype will be `int32`.\n * @param axis The dimension(s) to reduce. By default it reduces\n *     all dimensions.\n * @param keepDims If true, retains reduced dimensions with size 1.\n */\n/** @doc {heading: 'Operations', subheading: 'Reduction'} */\nfunction prod_(x, axis, keepDims) {\n    if (axis === void 0) { axis = null; }\n    if (keepDims === void 0) { keepDims = false; }\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'prod');\n    if ($x.dtype === 'bool') {\n        $x = $x.toInt();\n    }\n    var axes = util.parseAxisParam(axis, $x.shape);\n    var permutation = axis_util.getAxesPermutation(axes, $x.rank);\n    var reductionAxes = axes;\n    var permutedX = $x;\n    if (permutation != null) {\n        permutedX = $x.transpose(permutation);\n        reductionAxes = axis_util.getInnerMostAxes(reductionAxes.length, $x.rank);\n    }\n    var value = engine_1.ENGINE.runKernel(function (backend) { return backend.prod(permutedX, reductionAxes); }, { permutedX: permutedX });\n    if (keepDims) {\n        var newShape = axis_util.expandShapeToKeepDim(value.shape, axes);\n        value = value.reshape(newShape);\n    }\n    return value;\n}\n/**\n * Computes the mean of elements across dimensions of a `tf.Tensor`.\n *\n * Reduces `x` along the dimensions given in `axis`. Unless `keepDims` is\n * true, the rank of the `tf.Tensor` is reduced by 1 for each entry in `axis`.\n * If `keepDims` is true, the reduced dimensions are retained with length 1.\n * If `axis` has no entries, all dimensions are reduced, and a `tf.Tensor` with\n * a single element is returned.\n *\n * ```js\n * const x = tf.tensor1d([1, 2, 3]);\n *\n * x.mean().print();  // or tf.mean(a)\n * ```\n *\n * ```js\n * const x = tf.tensor2d([1, 2, 3, 4], [2, 2]);\n *\n * const axis = 1;\n * x.mean(axis).print();  // or tf.mean(x, axis)\n * ```\n *\n * @param x The input tensor.\n * @param axis The dimension(s) to reduce. By default it reduces\n *     all dimensions.\n * @param keepDims If true, retains reduced dimensions with size 1.\n */\n/** @doc {heading: 'Operations', subheading: 'Reduction'} */\nfunction mean_(x, axis, keepDims) {\n    if (axis === void 0) { axis = null; }\n    if (keepDims === void 0) { keepDims = false; }\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'mean');\n    var axes = util.parseAxisParam(axis, $x.shape);\n    var shapes = axis_util.computeOutAndReduceShapes($x.shape, axes);\n    var reduceShape = shapes[1];\n    var reduceSize = util.sizeFromShape(reduceShape);\n    // Use a custom gradient to bypass 2 gradient backprops since mean is used\n    // extremely often.\n    var customOp = gradients_1.customGrad(function (x) {\n        var reduceSizeScalar = tensor_ops_1.scalar(reduceSize);\n        // Cast if needed.\n        var xReduce = reduceSizeScalar.dtype === x.dtype ? x : x.cast(reduceSizeScalar.dtype);\n        var res = xReduce.div(reduceSizeScalar);\n        var value = res.sum(axis, keepDims);\n        var gradFunc = function (dy) {\n            var expandedDyShape = x.shape.slice();\n            axes.forEach(function (axis) {\n                expandedDyShape[axis] = 1;\n            });\n            var expandedDy = dy.reshape(expandedDyShape);\n            var derX = expandedDy.mul(tensor_ops_1.ones(x.shape, 'float32')).div(reduceSize);\n            return derX;\n        };\n        return { value: value, gradFunc: gradFunc };\n    });\n    return customOp($x);\n}\n/**\n * Gradient helper function for the min and max operations.\n */\nfunction gradForMinAndMax(dy, y, xOrig, origAxes, permutedAxes) {\n    if (y.rank < xOrig.rank) {\n        y = y.reshape(axis_util.expandShapeToKeepDim(y.shape, origAxes));\n    }\n    if (dy.rank < xOrig.rank) {\n        dy = dy.reshape(axis_util.expandShapeToKeepDim(dy.shape, origAxes));\n    }\n    return {\n        $x: function () {\n            var dx = dy.mul(xOrig.equal(y).cast(dy.dtype));\n            return permutedAxes == null ? dx : dx.transpose(permutedAxes);\n        }\n    };\n}\n/**\n * Computes the minimum value from the input.\n *\n * Reduces the input along the dimensions given in `axes`. Unless `keepDims`\n * is true, the rank of the array is reduced by 1 for each entry in `axes`.\n * If `keepDims` is true, the reduced dimensions are retained with length 1.\n * If `axes` has no entries, all dimensions are reduced, and an array with a\n * single element is returned.\n *\n * ```js\n * const x = tf.tensor1d([1, 2, 3]);\n *\n * x.min().print();  // or tf.min(x)\n * ```\n *\n * ```js\n * const x = tf.tensor2d([1, 2, 3, 4], [2, 2]);\n *\n * const axis = 1;\n * x.min(axis).print();  // or tf.min(x, axis)\n * ```\n *\n * @param x The input Tensor.\n * @param axis The dimension(s) to reduce. By default it reduces\n *     all dimensions.\n * @param keepDims If true, retains reduced dimensions with size 1.\n */\n/** @doc {heading: 'Operations', subheading: 'Reduction'} */\nfunction min_(x, axis, keepDims) {\n    if (axis === void 0) { axis = null; }\n    if (keepDims === void 0) { keepDims = false; }\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'min');\n    var xOrig = $x;\n    var origAxes = util.parseAxisParam(axis, $x.shape);\n    var axes = origAxes;\n    var permutedAxes = axis_util.getAxesPermutation(axes, $x.rank);\n    if (permutedAxes != null) {\n        $x = $x.transpose(permutedAxes);\n        axes = axis_util.getInnerMostAxes(axes.length, $x.rank);\n    }\n    var grad = function (dy, saved) {\n        return gradForMinAndMax(dy, saved[1], saved[0], origAxes, permutedAxes);\n    };\n    var res = engine_1.ENGINE.runKernel(function (backend, save) {\n        var y = backend.min($x, axes);\n        save([xOrig, y]);\n        return y;\n    }, { $x: $x }, grad);\n    if (keepDims) {\n        var newShape = axis_util.expandShapeToKeepDim(res.shape, origAxes);\n        res = res.reshape(newShape);\n    }\n    return res;\n}\n/**\n * Computes the maximum of elements across dimensions of a `tf.Tensor`.\n *\n * Reduces the input along the dimensions given in `axes`. Unless `keepDims`\n * is true, the rank of the `tf.Tensor` is reduced by 1 for each entry in\n * `axes`. If `keepDims` is true, the reduced dimensions are retained with\n * length 1. If `axes` has no entries, all dimensions are reduced, and an\n * `tf.Tensor` with a single element is returned.\n *\n * ```js\n * const x = tf.tensor1d([1, 2, 3]);\n *\n * x.max().print();  // or tf.max(x)\n * ```\n *\n * ```js\n * const x = tf.tensor2d([1, 2, 3, 4], [2, 2]);\n *\n * const axis = 1;\n * x.max(axis).print();  // or tf.max(x, axis)\n * ```\n *\n * @param x The input tensor.\n * @param axis The dimension(s) to reduce. By default it reduces\n *     all dimensions.\n * @param keepDims If true, retains reduced dimensions with size 1.\n */\n/** @doc {heading: 'Operations', subheading: 'Reduction'} */\nfunction max_(x, axis, keepDims) {\n    if (axis === void 0) { axis = null; }\n    if (keepDims === void 0) { keepDims = false; }\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'max');\n    var xOrig = $x;\n    var origAxes = util.parseAxisParam(axis, $x.shape);\n    var axes = origAxes;\n    var permutedAxes = axis_util.getAxesPermutation(axes, $x.rank);\n    if (permutedAxes != null) {\n        $x = $x.transpose(permutedAxes);\n        axes = axis_util.getInnerMostAxes(axes.length, $x.rank);\n    }\n    var grad = function (dy, saved) {\n        return gradForMinAndMax(dy, saved[1], saved[0], origAxes, permutedAxes);\n    };\n    var res = engine_1.ENGINE.runKernel(function (backend, save) {\n        var y = backend.max($x, axes);\n        save([xOrig, y]);\n        return y;\n    }, { $x: $x }, grad);\n    if (keepDims) {\n        var newShape = axis_util.expandShapeToKeepDim(res.shape, origAxes);\n        res = res.reshape(newShape);\n    }\n    return res;\n}\n/**\n * Returns the indices of the minimum values along an `axis`.\n *\n * The result has the same shape as `input` with the dimension along `axis`\n * removed.\n *\n * ```js\n * const x = tf.tensor1d([1, 2, 3]);\n *\n * x.argMin().print();  // or tf.argMin(x)\n * ```\n *\n * ```js\n * const x = tf.tensor2d([1, 2, 4, 3], [2, 2]);\n *\n * const axis = 1;\n * x.argMin(axis).print();  // or tf.argMin(x, axis)\n * ```\n *\n * @param x The input tensor.\n * @param axis The dimension to reduce. Defaults to 0 (outer-most dimension).\n *\n */\n/** @doc {heading: 'Operations', subheading: 'Reduction'} */\nfunction argMin_(x, axis) {\n    if (axis === void 0) { axis = 0; }\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'argMin');\n    if (axis == null) {\n        axis = 0;\n    }\n    var axes = util.parseAxisParam(axis, $x.shape);\n    var permutedAxes = axis_util.getAxesPermutation(axes, $x.rank);\n    if (permutedAxes != null) {\n        $x = $x.transpose(permutedAxes);\n        axes = axis_util.getInnerMostAxes(axes.length, $x.rank);\n    }\n    var grad = function (dy, saved) {\n        var $x = saved[0];\n        return { $x: function () { return tensor_ops_1.zerosLike($x); } };\n    };\n    return engine_1.ENGINE.runKernel(function (backend, save) {\n        var res = backend.argMin($x, axes[0]);\n        save([$x]);\n        return res;\n    }, { $x: $x }, grad);\n}\n/**\n * Returns the indices of the maximum values along an `axis`.\n *\n * The result has the same shape as `input` with the dimension along `axis`\n * removed.\n *\n * ```js\n * const x = tf.tensor1d([1, 2, 3]);\n *\n * x.argMax().print();  // or tf.argMax(x)\n * ```\n *\n * ```js\n * const x = tf.tensor2d([1, 2, 4, 3], [2, 2]);\n *\n * const axis = 1;\n * x.argMax(axis).print();  // or tf.argMax(x, axis)\n * ```\n *\n * @param x The input tensor.\n * @param axis The dimension to reduce. Defaults to 0 (outer-most dimension).\n */\n/** @doc {heading: 'Operations', subheading: 'Reduction'} */\nfunction argMax_(x, axis) {\n    if (axis === void 0) { axis = 0; }\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'argMax');\n    if (axis == null) {\n        axis = 0;\n    }\n    var axes = util.parseAxisParam(axis, $x.shape);\n    var permutedAxes = axis_util.getAxesPermutation(axes, $x.rank);\n    if (permutedAxes != null) {\n        $x = $x.transpose(permutedAxes);\n        axes = axis_util.getInnerMostAxes(axes.length, $x.rank);\n    }\n    var grad = function (dy, saved) {\n        var $x = saved[0];\n        return { $x: function () { return tensor_ops_1.zerosLike($x); } };\n    };\n    return engine_1.ENGINE.runKernel(function (backend, save) {\n        var res = backend.argMax($x, axes[0]);\n        save([$x]);\n        return res;\n    }, { $x: $x }, grad);\n}\n/**\n * Computes the logical and of elements across dimensions of a `tf.Tensor`.\n *\n * Reduces the input along the dimensions given in `axes`. Unless `keepDims`\n * is true, the rank of the `tf.Tensor` is reduced by 1 for each entry in\n * `axes`. If `keepDims` is true, the reduced dimensions are retained with\n * length 1. If `axes` has no entries, all dimensions are reduced, and an\n * `tf.Tensor` with a single element is returned.\n *\n * ```js\n * const x = tf.tensor1d([1, 1, 1], 'bool');\n *\n * x.all().print();  // or tf.all(x)\n * ```\n *\n * ```js\n * const x = tf.tensor2d([1, 1, 0, 0], [2, 2], 'bool');\n *\n * const axis = 1;\n * x.all(axis).print();  // or tf.all(x, axis)\n * ```\n *\n * @param x The input tensor. Must be of dtype bool.\n * @param axis The dimension(s) to reduce. By default it reduces\n *     all dimensions.\n * @param keepDims If true, retains reduced dimensions with size 1.\n */\n/** @doc {heading: 'Operations', subheading: 'Reduction'} */\nfunction all_(x, axis, keepDims) {\n    if (axis === void 0) { axis = null; }\n    if (keepDims === void 0) { keepDims = false; }\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'all', 'bool');\n    var origAxes = util.parseAxisParam(axis, $x.shape);\n    var axes = origAxes;\n    var permutedAxes = axis_util.getAxesPermutation(axes, $x.rank);\n    if (permutedAxes != null) {\n        $x = $x.transpose(permutedAxes);\n        axes = axis_util.getInnerMostAxes(axes.length, $x.rank);\n    }\n    var res = engine_1.ENGINE.runKernel(function (backend) { return backend.all($x, axes); }, { $x: $x });\n    if (keepDims) {\n        var newShape = axis_util.expandShapeToKeepDim(res.shape, origAxes);\n        return res.reshape(newShape);\n    }\n    return res;\n}\n/**\n * Computes the logical or of elements across dimensions of a `tf.Tensor`.\n *\n * Reduces the input along the dimensions given in `axes`. Unless `keepDims`\n * is true, the rank of the `tf.Tensor` is reduced by 1 for each entry in\n * `axes`. If `keepDims` is true, the reduced dimensions are retained with\n * length 1. If `axes` has no entries, all dimensions are reduced, and an\n * `tf.Tensor` with a single element is returned.\n *\n * ```js\n * const x = tf.tensor1d([1, 1, 1], 'bool');\n *\n * x.any().print();  // or tf.any(x)\n * ```\n *\n * ```js\n * const x = tf.tensor2d([1, 1, 0, 0], [2, 2], 'bool');\n *\n * const axis = 1;\n * x.any(axis).print();  // or tf.any(x, axis)\n * ```\n *\n * @param x The input tensor. Must be of dtype bool.\n * @param axis The dimension(s) to reduce. By default it reduces\n *     all dimensions.\n * @param keepDims If true, retains reduced dimensions with size 1.\n */\n/** @doc {heading: 'Operations', subheading: 'Reduction'} */\nfunction any_(x, axis, keepDims) {\n    if (axis === void 0) { axis = null; }\n    if (keepDims === void 0) { keepDims = false; }\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'any', 'bool');\n    var origAxes = util.parseAxisParam(axis, $x.shape);\n    var axes = origAxes;\n    var permutedAxes = axis_util.getAxesPermutation(axes, $x.rank);\n    if (permutedAxes != null) {\n        $x = $x.transpose(permutedAxes);\n        axes = axis_util.getInnerMostAxes(axes.length, $x.rank);\n    }\n    var res = engine_1.ENGINE.runKernel(function (backend) { return backend.any($x, axes); }, { $x: $x });\n    if (keepDims) {\n        var newShape = axis_util.expandShapeToKeepDim(res.shape, origAxes);\n        return res.reshape(newShape);\n    }\n    return res;\n}\n/**\n * Calculates the mean and variance of `x`. The mean and variance are\n * calculated by aggregating the contents of `x` across `axes`. If `x` is\n * 1-D and `axes = [0]` this is just the mean and variance of a vector.\n *\n * @param x The input tensor.\n * @param axis The dimension(s) along with to compute mean and\n *     variance. By default it reduces all dimensions.\n * @param keepDims If true, the moments have the same dimensionality as the\n *     input.\n * @return An object with two keys: `mean` and `variance`.\n */\n/** @doc {heading: 'Operations', subheading: 'Normalization'} */\nfunction moments_(x, axis, keepDims) {\n    if (axis === void 0) { axis = null; }\n    if (keepDims === void 0) { keepDims = false; }\n    x = tensor_util_env_1.convertToTensor(x, 'x', 'moments');\n    var axes = util.parseAxisParam(axis, x.shape);\n    var mean = x.mean(axes, keepDims);\n    var keepDimsShape = mean.shape;\n    if (!keepDims) {\n        keepDimsShape = axis_util.expandShapeToKeepDim(mean.shape, axes);\n    }\n    var devSquared = x.toFloat().sub(mean.reshape(keepDimsShape)).square();\n    var variance = devSquared.mean(axes, keepDims);\n    return { mean: mean, variance: variance };\n}\nexports.all = operation_1.op({ all_: all_ });\n// tslint:disable-next-line:variable-name\nexports.any = operation_1.op({ any_: any_ });\nexports.argMax = operation_1.op({ argMax_: argMax_ });\nexports.argMin = operation_1.op({ argMin_: argMin_ });\nexports.logSumExp = operation_1.op({ logSumExp_: logSumExp_ });\nexports.max = operation_1.op({ max_: max_ });\nexports.mean = operation_1.op({ mean_: mean_ });\nexports.min = operation_1.op({ min_: min_ });\nexports.moments = operation_1.op({ moments_: moments_ });\nexports.sum = operation_1.op({ sum_: sum_ });\nexports.prod = operation_1.op({ prod_: prod_ });\n//# sourceMappingURL=reduction_ops.js.map","\n/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar engine_1 = require(\"../engine\");\nvar tensor_util_1 = require(\"../tensor_util\");\nvar tensor_util_env_1 = require(\"../tensor_util_env\");\nvar util_1 = require(\"../util\");\nvar broadcast_util_1 = require(\"./broadcast_util\");\nvar operation_1 = require(\"./operation\");\nvar tensor_ops_1 = require(\"./tensor_ops\");\n/**\n * Returns the truth value of (a != b) element-wise. Supports broadcasting.\n *\n * We also expose `tf.notEqualStrict` which has the same signature as this op\n * and asserts that `a` and `b` are the same shape (does not broadcast).\n *\n * ```js\n * const a = tf.tensor1d([1, 2, 3]);\n * const b = tf.tensor1d([0, 2, 3]);\n *\n * a.notEqual(b).print();\n * ```\n * @param a The first input tensor.\n * @param b The second input tensor. Must have the same dtype as `a`.\n */\n/** @doc {heading: 'Operations', subheading: 'Logical'} */\nfunction notEqual_(a, b) {\n    var _a;\n    var $a = tensor_util_env_1.convertToTensor(a, 'a', 'notEqual');\n    var $b = tensor_util_env_1.convertToTensor(b, 'b', 'notEqual');\n    _a = tensor_util_1.makeTypesMatch($a, $b), $a = _a[0], $b = _a[1];\n    broadcast_util_1.assertAndGetBroadcastShape($a.shape, $b.shape);\n    return engine_1.ENGINE.runKernel(function (backend) { return backend.notEqual($a, $b); }, { $a: $a, $b: $b });\n}\n/**\n * Strict version of `tf.notEqual` that forces `a` and `b` to be of the same\n * shape.\n *\n * @param a The first input tensor.\n * @param b The second input tensor. Must have the same shape and dtype as\n *     `a`.\n */\nfunction notEqualStrict_(a, b) {\n    var $a = tensor_util_env_1.convertToTensor(a, 'a', 'notEqualStrict');\n    var $b = tensor_util_env_1.convertToTensor(b, 'b', 'notEqualStrict');\n    util_1.assertShapesMatch($a.shape, $b.shape, 'Error in notEqualStrict: ');\n    return $a.notEqual($b);\n}\n/**\n * Returns the truth value of (a < b) element-wise. Supports broadcasting.\n *\n * We also expose `tf.lessStrict` which has the same signature as this op and\n * asserts that `a` and `b` are the same shape (does not broadcast).\n *\n * ```js\n * const a = tf.tensor1d([1, 2, 3]);\n * const b = tf.tensor1d([2, 2, 2]);\n *\n * a.less(b).print();\n * ```\n * @param a The first input tensor.\n * @param b The second input tensor. Must have the same dtype as `a`.\n */\n/** @doc {heading: 'Operations', subheading: 'Logical'} */\nfunction less_(a, b) {\n    var _a;\n    var $a = tensor_util_env_1.convertToTensor(a, 'a', 'less');\n    var $b = tensor_util_env_1.convertToTensor(b, 'b', 'less');\n    _a = tensor_util_1.makeTypesMatch($a, $b), $a = _a[0], $b = _a[1];\n    broadcast_util_1.assertAndGetBroadcastShape($a.shape, $b.shape);\n    return engine_1.ENGINE.runKernel(function (backend) { return backend.less($a, $b); }, { $a: $a, $b: $b });\n}\n/**\n * Strict version of `tf.less` that forces `a` and `b` to be of the same\n * shape.\n *\n * @param a The first input tensor.\n * @param b The second input tensor. Must have the same shape and dtype as\n *     `a`.\n */\nfunction lessStrict_(a, b) {\n    var $a = tensor_util_env_1.convertToTensor(a, 'a', 'lessStrict');\n    var $b = tensor_util_env_1.convertToTensor(b, 'b', 'lessStrict');\n    util_1.assertShapesMatch($a.shape, $b.shape, 'Error in lessStrict: ');\n    return $a.less($b);\n}\n/**\n * Returns the truth value of (a == b) element-wise. Supports broadcasting.\n *\n * We also expose `tf.equalStrict` which has the same signature as this op\n * and asserts that `a` and `b` are the same shape (does not broadcast).\n *\n * ```js\n * const a = tf.tensor1d([1, 2, 3]);\n * const b = tf.tensor1d([2, 2, 2]);\n *\n * a.equal(b).print();\n * ```\n *\n * @param a The first input tensor.\n * @param b The second input tensor. Must have the same dtype as `a`.\n */\n/** @doc {heading: 'Operations', subheading: 'Logical'} */\nfunction equal_(a, b) {\n    var _a;\n    var $a = tensor_util_env_1.convertToTensor(a, 'a', 'equal');\n    var $b = tensor_util_env_1.convertToTensor(b, 'b', 'equal');\n    _a = tensor_util_1.makeTypesMatch($a, $b), $a = _a[0], $b = _a[1];\n    broadcast_util_1.assertAndGetBroadcastShape($a.shape, $b.shape);\n    return engine_1.ENGINE.runKernel(function (backend) { return backend.equal($a, $b); }, { $a: $a, $b: $b });\n}\nfunction equalStrict_(a, b) {\n    var $a = tensor_util_env_1.convertToTensor(a, 'a', 'equalStrict');\n    var $b = tensor_util_env_1.convertToTensor(b, 'b', 'equalStrict');\n    util_1.assertShapesMatch($a.shape, $b.shape, 'Error in equalStrict: ');\n    return $a.equal($b);\n}\n/**\n * Returns the truth value of (a <= b) element-wise. Supports broadcasting.\n *\n * We also expose `tf.lessEqualStrict` which has the same signature as this op\n * and asserts that `a` and `b` are the same shape (does not broadcast).\n *\n * ```js\n * const a = tf.tensor1d([1, 2, 3]);\n * const b = tf.tensor1d([2, 2, 2]);\n *\n * a.lessEqual(b).print();\n * ```\n *\n * @param a The first input tensor.\n * @param b The second input tensor. Must have the same dtype as `a`.\n */\n/** @doc {heading: 'Operations', subheading: 'Logical'} */\nfunction lessEqual_(a, b) {\n    var _a;\n    var $a = tensor_util_env_1.convertToTensor(a, 'a', 'lessEqual');\n    var $b = tensor_util_env_1.convertToTensor(b, 'b', 'lessEqual');\n    _a = tensor_util_1.makeTypesMatch($a, $b), $a = _a[0], $b = _a[1];\n    broadcast_util_1.assertAndGetBroadcastShape($a.shape, $b.shape);\n    return engine_1.ENGINE.runKernel(function (backend) { return backend.lessEqual($a, $b); }, { $a: $a, $b: $b });\n}\nfunction lessEqualStrict_(a, b) {\n    var $a = tensor_util_env_1.convertToTensor(a, 'a', 'lessEqualStrict');\n    var $b = tensor_util_env_1.convertToTensor(b, 'b', 'lessEqualStrict');\n    util_1.assertShapesMatch($a.shape, $b.shape, 'Error in lessEqualStrict: ');\n    return $a.lessEqual($b);\n}\n/**\n * Returns the truth value of (a > b) element-wise. Supports broadcasting.\n *\n * We also expose `tf.greaterStrict` which has the same signature as this\n * op and asserts that `a` and `b` are the same shape (does not broadcast).\n *\n * ```js\n * const a = tf.tensor1d([1, 2, 3]);\n * const b = tf.tensor1d([2, 2, 2]);\n *\n * a.greater(b).print();\n * ```\n *\n * @param a The first input tensor.\n * @param b The second input tensor. Must have the same dtype as `a`.\n */\n/** @doc {heading: 'Operations', subheading: 'Logical'} */\nfunction greater_(a, b) {\n    var _a;\n    var $a = tensor_util_env_1.convertToTensor(a, 'a', 'greater');\n    var $b = tensor_util_env_1.convertToTensor(b, 'b', 'greater');\n    _a = tensor_util_1.makeTypesMatch($a, $b), $a = _a[0], $b = _a[1];\n    broadcast_util_1.assertAndGetBroadcastShape($a.shape, $b.shape);\n    return engine_1.ENGINE.runKernel(function (backend) { return backend.greater($a, $b); }, { $a: $a, $b: $b });\n}\nfunction greaterStrict_(a, b) {\n    var $a = tensor_util_env_1.convertToTensor(a, 'a', 'greaterStrict');\n    var $b = tensor_util_env_1.convertToTensor(b, 'b', 'greaterStrict');\n    util_1.assertShapesMatch($a.shape, $b.shape, 'Error in greaterStrict: ');\n    return $a.greater($b);\n}\n/**\n * Returns the truth value of (a >= b) element-wise. Supports broadcasting.\n *\n * We also expose `tf.greaterEqualStrict` which has the same signature as this\n * op and asserts that `a` and `b` are the same shape (does not broadcast).\n *\n * ```js\n * const a = tf.tensor1d([1, 2, 3]);\n * const b = tf.tensor1d([2, 2, 2]);\n *\n * a.greaterEqual(b).print();\n * ```\n *\n * @param a The first input tensor.\n * @param b The second input tensor. Must have the same dtype as `a`.\n */\n/** @doc {heading: 'Operations', subheading: 'Logical'} */\nfunction greaterEqual_(a, b) {\n    var _a;\n    var $a = tensor_util_env_1.convertToTensor(a, 'a', 'greaterEqual');\n    var $b = tensor_util_env_1.convertToTensor(b, 'b', 'greaterEqual');\n    _a = tensor_util_1.makeTypesMatch($a, $b), $a = _a[0], $b = _a[1];\n    broadcast_util_1.assertAndGetBroadcastShape($a.shape, $b.shape);\n    var grad = function (dy, saved) {\n        var $a = saved[0], $b = saved[1];\n        return { $a: function () { return tensor_ops_1.zerosLike($a); }, $b: function () { return tensor_ops_1.zerosLike($b); } };\n    };\n    return engine_1.ENGINE.runKernel(function (backend, save) {\n        var res = backend.greaterEqual($a, $b);\n        save([$a, $b]);\n        return res;\n    }, { $a: $a, $b: $b }, grad);\n}\nfunction greaterEqualStrict_(a, b) {\n    var $a = tensor_util_env_1.convertToTensor(a, 'a', 'greaterEqualStrict');\n    var $b = tensor_util_env_1.convertToTensor(b, 'b', 'greaterEqualStrict');\n    util_1.assertShapesMatch($a.shape, $b.shape, 'Error in greaterEqualStrict: ');\n    return $a.greaterEqual($b);\n}\nexports.equal = operation_1.op({ equal_: equal_ });\nexports.equalStrict = operation_1.op({ equalStrict_: equalStrict_ });\nexports.greater = operation_1.op({ greater_: greater_ });\nexports.greaterEqual = operation_1.op({ greaterEqual_: greaterEqual_ });\nexports.greaterEqualStrict = operation_1.op({ greaterEqualStrict_: greaterEqualStrict_ });\nexports.greaterStrict = operation_1.op({ greaterStrict_: greaterStrict_ });\nexports.less = operation_1.op({ less_: less_ });\nexports.lessEqual = operation_1.op({ lessEqual_: lessEqual_ });\nexports.lessEqualStrict = operation_1.op({ lessEqualStrict_: lessEqualStrict_ });\nexports.lessStrict = operation_1.op({ lessStrict_: lessStrict_ });\nexports.notEqual = operation_1.op({ notEqual_: notEqual_ });\nexports.notEqualStrict = operation_1.op({ notEqualStrict_: notEqualStrict_ });\n//# sourceMappingURL=compare.js.map","\n/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar engine_1 = require(\"../engine\");\nvar tensor_util_1 = require(\"../tensor_util\");\nvar tensor_util_env_1 = require(\"../tensor_util_env\");\nvar types_1 = require(\"../types\");\nvar util = require(\"../util\");\nvar broadcast_util = require(\"./broadcast_util\");\nvar operation_1 = require(\"./operation\");\nvar tensor_ops_1 = require(\"./tensor_ops\");\nvar unary_ops_1 = require(\"./unary_ops\");\n/**\n * Adds two `tf.Tensor`s element-wise, A + B. Supports broadcasting.\n *\n * We also expose `tf.addStrict` which has the same signature as this op and\n * asserts that `a` and `b` are the same shape (does not broadcast).\n *\n * ```js\n * const a = tf.tensor1d([1, 2, 3, 4]);\n * const b = tf.tensor1d([10, 20, 30, 40]);\n *\n * a.add(b).print();  // or tf.add(a, b)\n * ```\n *\n * ```js\n * // Broadcast add a with b.\n * const a = tf.scalar(5);\n * const b = tf.tensor1d([10, 20, 30, 40]);\n *\n * a.add(b).print();  // or tf.add(a, b)\n * ```\n * @param a The first `tf.Tensor` to add.\n * @param b The second `tf.Tensor` to add. Must have the same type as `a`.\n */\n/** @doc {heading: 'Operations', subheading: 'Arithmetic'} */\nfunction add_(a, b) {\n    var _a;\n    var $a = tensor_util_env_1.convertToTensor(a, 'a', 'add');\n    var $b = tensor_util_env_1.convertToTensor(b, 'b', 'add');\n    _a = tensor_util_1.makeTypesMatch($a, $b), $a = _a[0], $b = _a[1];\n    var outShape = broadcast_util.assertAndGetBroadcastShape($a.shape, $b.shape);\n    var der = function (dy) {\n        var derA = function () {\n            var res = dy;\n            var reduceAxes = broadcast_util.getReductionAxes($a.shape, outShape);\n            if (reduceAxes.length > 0) {\n                res = res.sum(reduceAxes);\n            }\n            return res.reshape($a.shape);\n        };\n        var derB = function () {\n            var res = dy;\n            var reduceAxes = broadcast_util.getReductionAxes($b.shape, outShape);\n            if (reduceAxes.length > 0) {\n                res = res.sum(reduceAxes);\n            }\n            return res.reshape($b.shape);\n        };\n        return { $a: derA, $b: derB };\n    };\n    return engine_1.ENGINE.runKernel(function (backend) { return backend.add($a, $b); }, { $a: $a, $b: $b }, der);\n}\n/**\n * Adds a list of `tf.Tensor`s element-wise, each with the same shape and dtype.\n *\n * ```js\n * const a = tf.tensor1d([1, 2]);\n * const b = tf.tensor1d([3, 4]);\n * const c = tf.tensor1d([5, 6]);\n *\n * tf.addN([a, b, c]).print();\n * ```\n * @param tensors A list of tensors with the same shape and dtype.\n */\n/** @doc {heading: 'Operations', subheading: 'Arithmetic'} */\nfunction addN_(tensors) {\n    util.assert(Array.isArray(tensors), function () { return 'The argument passed to tf.addN() must be a list of tensors'; });\n    util.assert(tensors.length >= 1, function () { return \"Must pass at least one tensor to tf.addN(), but got \" +\n        (\"\" + tensors.length); });\n    var $tensors = tensors.map(function (t, i) { return tensor_util_env_1.convertToTensor(t, \"tensors\" + i, 'addN'); });\n    var firstTensor = $tensors[0];\n    $tensors.forEach(function (t) {\n        if (t.dtype !== firstTensor.dtype) {\n            throw new Error('All tensors passed to tf.addN() must have the same dtype');\n        }\n    });\n    $tensors.forEach(function (t) {\n        if (!util.arraysEqual(t.shape, firstTensor.shape)) {\n            throw new Error('All tensors passed to tf.addN() must have the same shape');\n        }\n    });\n    var der = function (dy) {\n        var ders = {};\n        $tensors.forEach(function (t, i) {\n            ders[i] = function () { return dy.clone(); };\n        });\n        return ders;\n    };\n    var inputs = $tensors;\n    return engine_1.ENGINE.runKernel(function (backend) { return backend.addN($tensors); }, inputs, der);\n}\n/**\n * Adds two `tf.Tensor`s element-wise, A + B.\n *\n * Inputs must be the same shape. For broadcasting support, use add() instead.\n *\n * @param a The first Tensor to add element-wise.\n * @param b The second Tensor to add element-wise.\n */\nfunction addStrict_(a, b) {\n    var $a = tensor_util_env_1.convertToTensor(a, 'a', 'addStrict');\n    var $b = tensor_util_env_1.convertToTensor(b, 'b', 'addStrict');\n    util.assertShapesMatch($a.shape, $b.shape, 'Error in addStrict: ');\n    return $a.add($b);\n}\n/**\n * Subtracts two `tf.Tensor`s element-wise, A - B. Supports broadcasting.\n *\n * We also expose `tf.subStrict` which has the same signature as this op and\n * asserts that `a` and `b` are the same shape (does not broadcast).\n *\n * ```js\n * const a = tf.tensor1d([10, 20, 30, 40]);\n * const b = tf.tensor1d([1, 2, 3, 4]);\n *\n * a.sub(b).print();  // or tf.sub(a, b)\n * ```\n *\n * ```js\n * // Broadcast subtract a with b.\n * const a = tf.tensor1d([10, 20, 30, 40]);\n * const b = tf.scalar(5);\n *\n * a.sub(b).print();  // or tf.sub(a, b)\n * ```\n * @param a The first `tf.Tensor` to subtract from.\n * @param b The second `tf.Tensor` to be subtracted. Must have the same dtype as\n * `a`.\n */\n/** @doc {heading: 'Operations', subheading: 'Arithmetic'} */\nfunction sub_(a, b) {\n    var _a;\n    var $a = tensor_util_env_1.convertToTensor(a, 'a', 'sub');\n    var $b = tensor_util_env_1.convertToTensor(b, 'b', 'sub');\n    _a = tensor_util_1.makeTypesMatch($a, $b), $a = _a[0], $b = _a[1];\n    var outShape = broadcast_util.assertAndGetBroadcastShape($a.shape, $b.shape);\n    var der = function (dy) {\n        var derA = function () {\n            var res = dy;\n            var reduceAxes = broadcast_util.getReductionAxes($a.shape, outShape);\n            if (reduceAxes.length > 0) {\n                res = res.sum(reduceAxes);\n            }\n            return res.reshape($a.shape);\n        };\n        var derB = function () {\n            var res = dy;\n            var reduceAxes = broadcast_util.getReductionAxes($b.shape, outShape);\n            if (reduceAxes.length > 0) {\n                res = res.sum(reduceAxes);\n            }\n            return res.neg().reshape($b.shape);\n        };\n        return { $a: derA, $b: derB };\n    };\n    return engine_1.ENGINE.runKernel(function (backend) { return backend.subtract($a, $b); }, { $a: $a, $b: $b }, der);\n}\n/**\n * Subtracts two `tf.Tensor`s element-wise, A - B. Inputs must\n * be the same shape.\n *\n * For broadcasting support, use `tf.sub` instead.\n *\n * @param a The first Tensor to subtract element-wise.\n * @param b The second Tensor to subtract element-wise.\n */\nfunction subStrict_(a, b) {\n    var $a = tensor_util_env_1.convertToTensor(a, 'a', 'subStrict');\n    var $b = tensor_util_env_1.convertToTensor(b, 'b', 'subStrict');\n    util.assertShapesMatch($a.shape, $b.shape, 'Error in subStrict: ');\n    return $a.sub($b);\n}\n/**\n * Computes the power of one `tf.Tensor` to another. Supports broadcasting.\n *\n * Given a `tf.Tensor` x and a `tf.Tensor` y, this operation computes x^y for\n * corresponding elements in x and y. The result's dtype will be the upcasted\n * type of the `base` and `exp` dtypes.\n *\n * ```js\n * const a = tf.tensor([[2, 3], [4, 5]])\n * const b = tf.tensor([[1, 2], [3, 0]]).toInt();\n *\n * a.pow(b).print();  // or tf.pow(a, b)\n * ```\n *\n * ```js\n * const a = tf.tensor([[1, 2], [3, 4]])\n * const b = tf.tensor(2).toInt();\n *\n * a.pow(b).print();  // or tf.pow(a, b)\n * ```\n * We also expose `powStrict` which has the same signature as this op and\n * asserts that `base` and `exp` are the same shape (does not broadcast).\n *\n * @param base The base `tf.Tensor` to pow element-wise.\n * @param exp The exponent `tf.Tensor` to pow element-wise.\n */\n/** @doc {heading: 'Operations', subheading: 'Arithmetic'} */\nfunction pow_(base, exp) {\n    var $base = tensor_util_env_1.convertToTensor(base, 'base', 'pow');\n    var $exp = tensor_util_env_1.convertToTensor(exp, 'exp', 'pow');\n    var outShape = broadcast_util.assertAndGetBroadcastShape($base.shape, $exp.shape);\n    base = $base.cast(types_1.upcastType($base.dtype, $exp.dtype));\n    exp = $exp.cast(types_1.upcastType($base.dtype, $exp.dtype));\n    var grad = function (dy, saved) {\n        var $base = saved[0], $exp = saved[1], y = saved[2];\n        var derBase = function () {\n            var expFloat = $exp.toFloat();\n            var res = dy.mul(expFloat.mul($base.pow(expFloat.sub(tensor_ops_1.scalar(1)))));\n            var reduceAxes = broadcast_util.getReductionAxes($base.shape, outShape);\n            if (reduceAxes.length > 0) {\n                res = res.sum(reduceAxes);\n            }\n            return res.reshape($base.shape);\n        };\n        var derExp = function () {\n            var condition = $base.greater(0);\n            var logBase = $base.log().where(condition, tensor_ops_1.zerosLike($base));\n            var res = dy.mul(y.mul(logBase));\n            var reduceAxes = broadcast_util.getReductionAxes($exp.shape, outShape);\n            if (reduceAxes.length > 0) {\n                res = res.sum(reduceAxes);\n            }\n            return res.reshape($exp.shape);\n        };\n        return { $base: derBase, $exp: derExp };\n    };\n    return engine_1.ENGINE.runKernel(function (backend, save) {\n        var y = backend.pow($base, $exp);\n        save([$base, $exp, y]);\n        return y;\n    }, { $base: $base, $exp: $exp }, grad);\n}\n/**\n * Computes the power of one `tf.Tensor` to another. Inputs must\n * be the same shape.\n *\n * For broadcasting support, use `tf.pow` instead.\n *\n * @param base The base tensor to pow element-wise.\n * @param exp The exponent tensor to pow element-wise.\n */\nfunction powStrict_(base, exp) {\n    util.assertShapesMatch(base.shape, exp.shape, 'Error in powStrict: ');\n    return base.pow(exp);\n}\n/**\n * Multiplies two `tf.Tensor`s element-wise, A * B. Supports broadcasting.\n *\n * We also expose `tf.mulStrict` which has the same signature as this op and\n * asserts that `a` and `b` are the same shape (does not broadcast).\n *\n * ```js\n * const a = tf.tensor1d([1, 2, 3, 4]);\n * const b = tf.tensor1d([2, 3, 4, 5]);\n *\n * a.mul(b).print();  // or tf.mul(a, b)\n * ```\n *\n * ```js\n * // Broadcast mul a with b.\n * const a = tf.tensor1d([1, 2, 3, 4]);\n * const b = tf.scalar(5);\n *\n * a.mul(b).print();  // or tf.mul(a, b)\n * ```\n * @param a The first tensor to multiply.\n * @param b The second tensor to multiply. Must have the same dtype as `a`.\n */\n/** @doc {heading: 'Operations', subheading: 'Arithmetic'} */\nfunction mul_(a, b) {\n    var _a;\n    var $a = tensor_util_env_1.convertToTensor(a, 'a', 'mul');\n    var $b = tensor_util_env_1.convertToTensor(b, 'b', 'mul');\n    _a = tensor_util_1.makeTypesMatch($a, $b), $a = _a[0], $b = _a[1];\n    var outShape = broadcast_util.assertAndGetBroadcastShape($a.shape, $b.shape);\n    var der = function (dy, saved) {\n        var $a = saved[0], $b = saved[1];\n        var derA = function () {\n            var res = dy.mul($b.toFloat());\n            var reduceAxes = broadcast_util.getReductionAxes($a.shape, outShape);\n            if (reduceAxes.length > 0) {\n                return res.sum(reduceAxes).reshape($a.shape);\n            }\n            return res;\n        };\n        var derB = function () {\n            var res = dy.mul($a.toFloat());\n            var reduceAxes = broadcast_util.getReductionAxes($b.shape, outShape);\n            if (reduceAxes.length > 0) {\n                return res.sum(reduceAxes).reshape($b.shape);\n            }\n            return res;\n        };\n        return { $a: derA, $b: derB };\n    };\n    return engine_1.ENGINE.runKernel(function (backend, save) {\n        var res = backend.multiply($a, $b);\n        save([$a, $b]);\n        return res;\n    }, { $a: $a, $b: $b }, der);\n}\n/**\n * Multiplies two `tf.Tensor`s element-wise, A * B.\n *\n * Inputs must be the same shape. For broadcasting support, use `tf.mul`.\n *\n * @param a The first tensor to multiply.\n * @param b The first tensor to multiply. Must have the same\n *    dtype as `a`.\n */\nfunction mulStrict_(a, b) {\n    var $a = tensor_util_env_1.convertToTensor(a, 'a', 'mul');\n    var $b = tensor_util_env_1.convertToTensor(b, 'b', 'mul');\n    util.assertShapesMatch($a.shape, $b.shape, 'Error in multiplyStrict: ');\n    return $a.mul($b);\n}\n/**\n * Divides two `tf.Tensor`s element-wise, A / B. Supports broadcasting.\n *\n * We also expose `tf.divStrict` which has the same signature as this op and\n * asserts that `a` and `b` are the same shape (does not broadcast).\n *\n * ```js\n * const a = tf.tensor1d([1, 4, 9, 16]);\n * const b = tf.tensor1d([1, 2, 3, 4]);\n *\n * a.div(b).print();  // or tf.div(a, b)\n * ```\n *\n * ```js\n * // Broadcast div a with b.\n * const a = tf.tensor1d([2, 4, 6, 8]);\n * const b = tf.scalar(2);\n *\n * a.div(b).print();  // or tf.div(a, b)\n * ```\n *\n * @param a The first tensor as the numerator.\n * @param b The second tensor as the denominator. Must have the same dtype as\n * `a`.\n */\n/** @doc {heading: 'Operations', subheading: 'Arithmetic'} */\nfunction div_(a, b) {\n    var _a;\n    var $a = tensor_util_env_1.convertToTensor(a, 'a', 'div');\n    var $b = tensor_util_env_1.convertToTensor(b, 'b', 'div');\n    _a = tensor_util_1.makeTypesMatch($a, $b), $a = _a[0], $b = _a[1];\n    if ($a.dtype === 'int32' && $b.dtype === 'int32') {\n        return exports.floorDiv($a, $b);\n    }\n    var outShape = broadcast_util.assertAndGetBroadcastShape($a.shape, $b.shape);\n    var der = function (dy, saved) {\n        var $a = saved[0], $b = saved[1];\n        var derA = function () {\n            var res = dy.div($b.toFloat());\n            var reduceAxes = broadcast_util.getReductionAxes($a.shape, outShape);\n            if (reduceAxes.length > 0) {\n                return res.sum(reduceAxes).reshape($a.shape);\n            }\n            return res;\n        };\n        var derB = function () {\n            var res = dy.mul($a.toFloat());\n            var reduceAxes = broadcast_util.getReductionAxes($b.shape, outShape);\n            if (reduceAxes.length > 0) {\n                res = res.sum(reduceAxes).reshape($b.shape);\n            }\n            var tmp = $b.square();\n            return res.div(tmp.toFloat()).neg();\n        };\n        return { $a: derA, $b: derB };\n    };\n    return engine_1.ENGINE.runKernel(function (backend, save) {\n        var res = backend.realDivide($a, $b);\n        save([$a, $b]);\n        return res;\n    }, { $a: $a, $b: $b }, der);\n}\n/**\n * Divides two `tf.Tensor`s element-wise, A / B. Supports broadcasting.\n * The result is rounded with floor function.\n *\n *\n * ```js\n * const a = tf.tensor1d([1, 4, 9, 16]);\n * const b = tf.tensor1d([1, 2, 3, 4]);\n *\n * a.floorDiv(b).print();  // or tf.div(a, b)\n * ```\n *\n * ```js\n * // Broadcast div a with b.\n * const a = tf.tensor1d([2, 4, 6, 8]);\n * const b = tf.scalar(2);\n *\n * a.floorDiv(b).print();  // or tf.floorDiv(a, b)\n * ```\n *\n * @param a The first tensor as the numerator.\n * @param b The second tensor as the denominator. Must have the same dtype as\n * `a`.\n */\n/** @doc {heading: 'Operations', subheading: 'Arithmetic'} */\nfunction floorDiv_(a, b) {\n    var _a;\n    var $a = tensor_util_env_1.convertToTensor(a, 'a', 'floorDiv');\n    var $b = tensor_util_env_1.convertToTensor(b, 'b', 'floorDiv');\n    _a = tensor_util_1.makeTypesMatch($a, $b), $a = _a[0], $b = _a[1];\n    var outShape = broadcast_util.assertAndGetBroadcastShape($a.shape, $b.shape);\n    var der = function (dy, saved) {\n        var $a = saved[0], $b = saved[1];\n        var derA = function () {\n            var res = dy.div($b.toFloat());\n            var reduceAxes = broadcast_util.getReductionAxes($a.shape, outShape);\n            if (reduceAxes.length > 0) {\n                return res.sum(reduceAxes).reshape($a.shape);\n            }\n            return res;\n        };\n        var derB = function () {\n            var res = dy.mul($a.toFloat());\n            var reduceAxes = broadcast_util.getReductionAxes($b.shape, outShape);\n            if (reduceAxes.length > 0) {\n                res = res.sum(reduceAxes).reshape($b.shape);\n            }\n            var tmp = $b.square();\n            return res.div(tmp.toFloat()).neg();\n        };\n        return { $a: derA, $b: derB };\n    };\n    return engine_1.ENGINE.runKernel(function (backend, save) {\n        var res = backend.floorDiv($a, $b);\n        save([$a, $b]);\n        return res;\n    }, { $a: $a, $b: $b }, der);\n}\n/**\n * Divides two `tf.Tensor`s element-wise, A / B. Inputs must\n * be the same shape.\n *\n * @param a The first tensor as the numerator for element-wise division.\n * @param b The second tensor as the denominator for element-wise division.\n */\nfunction divStrict_(a, b) {\n    var $a = tensor_util_env_1.convertToTensor(a, 'a', 'div');\n    var $b = tensor_util_env_1.convertToTensor(b, 'b', 'div');\n    util.assertShapesMatch($a.shape, $b.shape, 'Error in divideStrict: ');\n    return $a.div($b);\n}\n/**\n * Returns the mod of a and b element-wise.\n * `floor(x / y) * y + mod(x, y) = x`\n * Supports broadcasting.\n *\n * We also expose `tf.modStrict` which has the same signature as this op and\n * asserts that `a` and `b` are the same shape (does not broadcast).\n *\n * ```js\n * const a = tf.tensor1d([1, 4, 3, 16]);\n * const b = tf.tensor1d([1, 2, 9, 4]);\n *\n * a.mod(b).print();  // or tf.mod(a, b)\n * ```\n *\n * ```js\n * // Broadcast a mod b.\n * const a = tf.tensor1d([2, 4, 6, 8]);\n * const b = tf.scalar(5);\n *\n * a.mod(b).print();  // or tf.mod(a, b)\n * ```\n *\n * @param a The first tensor.\n * @param b The second tensor. Must have the same type as `a`.\n */\n/** @doc {heading: 'Operations', subheading: 'Arithmetic'} */\nfunction mod_(a, b) {\n    var _a;\n    var $a = tensor_util_env_1.convertToTensor(a, 'a', 'mod');\n    var $b = tensor_util_env_1.convertToTensor(b, 'b', 'mod');\n    _a = tensor_util_1.makeTypesMatch($a, $b), $a = _a[0], $b = _a[1];\n    var outShape = broadcast_util.assertAndGetBroadcastShape($a.shape, $b.shape);\n    var der = function (dy, saved) {\n        var $a = saved[0], $b = saved[1];\n        var derA = function () {\n            var reduceAxes = broadcast_util.getReductionAxes($a.shape, outShape);\n            if (reduceAxes.length > 0) {\n                return dy.sum(reduceAxes).reshape($a.shape);\n            }\n            return dy;\n        };\n        var derB = function () {\n            var res = dy.mul($a.div($b).floor().neg());\n            var reduceAxes = broadcast_util.getReductionAxes($b.shape, outShape);\n            if (reduceAxes.length > 0) {\n                return res.sum(reduceAxes).reshape($b.shape);\n            }\n            return res;\n        };\n        return { $a: derA, $b: derB };\n    };\n    return engine_1.ENGINE.runKernel(function (backend, save) {\n        var res = backend.mod($a, $b);\n        save([$a, $b]);\n        return res;\n    }, { $a: $a, $b: $b }, der);\n}\n/**\n * Returns the mod of a and b (`a < b ? a : b`) element-wise. Inputs must\n * be the same shape. For broadcasting support, use mod().\n *\n * @param a The first tensor.\n * @param b The second tensor. Must have the same dtype as `a`.\n */\nfunction modStrict_(a, b) {\n    var $a = tensor_util_env_1.convertToTensor(a, 'a', 'modStrict');\n    var $b = tensor_util_env_1.convertToTensor(b, 'b', 'modStrict');\n    util.assertShapesMatch($a.shape, $b.shape, 'Error in modStrict: ');\n    return $a.mod($b);\n}\n/**\n * Returns the min of a and b (`a < b ? a : b`) element-wise.\n * Supports broadcasting.\n *\n * We also expose `minimumStrict` which has the same signature as this op and\n * asserts that `a` and `b` are the same shape (does not broadcast).\n *\n * ```js\n * const a = tf.tensor1d([1, 4, 3, 16]);\n * const b = tf.tensor1d([1, 2, 9, 4]);\n *\n * a.minimum(b).print();  // or tf.minimum(a, b)\n * ```\n *\n * ```js\n * // Broadcast minimum a with b.\n * const a = tf.tensor1d([2, 4, 6, 8]);\n * const b = tf.scalar(5);\n *\n * a.minimum(b).print();  // or tf.minimum(a, b)\n * ```\n *\n * @param a The first tensor.\n * @param b The second tensor. Must have the same type as `a`.\n */\n/** @doc {heading: 'Operations', subheading: 'Arithmetic'} */\nfunction minimum_(a, b) {\n    var _a;\n    var $a = tensor_util_env_1.convertToTensor(a, 'a', 'minimum');\n    var $b = tensor_util_env_1.convertToTensor(b, 'b', 'minimum');\n    _a = tensor_util_1.makeTypesMatch($a, $b), $a = _a[0], $b = _a[1];\n    if ($a.dtype === 'bool') {\n        $a = $a.toInt();\n        $b = $b.toInt();\n    }\n    broadcast_util.assertAndGetBroadcastShape($a.shape, $b.shape);\n    var der = function (dy, saved) {\n        var $a = saved[0], $b = saved[1];\n        var derA = function () { return dy.mul($a.lessEqual($b).toFloat()); };\n        var derB = function () { return dy.mul($a.greater($b).toFloat()); };\n        return { $a: derA, $b: derB };\n    };\n    return engine_1.ENGINE.runKernel(function (backend, save) {\n        var res = backend.minimum($a, $b);\n        save([$a, $b]);\n        return res;\n    }, { $a: $a, $b: $b }, der);\n}\n/**\n * Returns the min of a and b (`a < b ? a : b`) element-wise. Inputs must\n * be the same shape. For broadcasting support, use minimum().\n *\n * @param a The first tensor.\n * @param b The second tensor. Must have the same dtype as `a`.\n */\nfunction minimumStrict_(a, b) {\n    var $a = tensor_util_env_1.convertToTensor(a, 'a', 'minimumStrict');\n    var $b = tensor_util_env_1.convertToTensor(b, 'b', 'minimumStrict');\n    util.assertShapesMatch($a.shape, $b.shape, 'Error in minimumStrict: ');\n    return $a.minimum($b);\n}\n/**\n * Returns the max of a and b (`a > b ? a : b`) element-wise.\n * Supports broadcasting.\n *\n * We also expose `tf.maximumStrict` which has the same signature as this op and\n * asserts that `a` and `b` are the same shape (does not broadcast).\n *\n * ```js\n * const a = tf.tensor1d([1, 4, 3, 16]);\n * const b = tf.tensor1d([1, 2, 9, 4]);\n *\n * a.maximum(b).print();  // or tf.maximum(a, b)\n * ```\n *\n * ```js\n * // Broadcast maximum a with b.\n * const a = tf.tensor1d([2, 4, 6, 8]);\n * const b = tf.scalar(5);\n *\n * a.maximum(b).print();  // or tf.maximum(a, b)\n * ```\n *\n * @param a The first tensor.\n * @param b The second tensor. Must have the same type as `a`.\n */\n/** @doc {heading: 'Operations', subheading: 'Arithmetic'} */\nfunction maximum_(a, b) {\n    var _a;\n    var $a = tensor_util_env_1.convertToTensor(a, 'a', 'maximum');\n    var $b = tensor_util_env_1.convertToTensor(b, 'b', 'maximum');\n    _a = tensor_util_1.makeTypesMatch($a, $b), $a = _a[0], $b = _a[1];\n    if ($a.dtype === 'bool') {\n        $a = $a.toInt();\n        $b = $b.toInt();\n    }\n    broadcast_util.assertAndGetBroadcastShape($a.shape, $b.shape);\n    var der = function (dy, saved) {\n        var $a = saved[0], $b = saved[1];\n        var derA = function () { return dy.mul($a.greaterEqual($b).toFloat()); };\n        var derB = function () { return dy.mul($a.less($b).toFloat()); };\n        return { $a: derA, $b: derB };\n    };\n    return engine_1.ENGINE.runKernel(function (backend, save) {\n        var res = backend.maximum($a, $b);\n        save([$a, $b]);\n        return res;\n    }, { $a: $a, $b: $b }, der);\n}\n/**\n * Returns the max of a and b (`a > b ? a : b`) element-wise. Inputs must\n * be the same shape. For broadcasting support, use maximum().\n *\n * @param a The first tensor.\n * @param b The second tensor. Must have the same dtype as `a`.\n */\nfunction maximumStrict_(a, b) {\n    var $a = tensor_util_env_1.convertToTensor(a, 'a', 'maximumStrict');\n    var $b = tensor_util_env_1.convertToTensor(b, 'b', 'maximumStrict');\n    util.assertShapesMatch($a.shape, $b.shape, 'Error in maximumStrict: ');\n    return $a.maximum($b);\n}\n/**\n * Returns (a - b) * (a - b) element-wise.\n * Supports broadcasting.\n *\n * We also expose `tf.squaredDifferenceStrict` which has the same signature as\n * this op and asserts that `a` and `b` are the same shape (does not\n * broadcast).\n *\n * ```js\n * const a = tf.tensor1d([1, 4, 3, 16]);\n * const b = tf.tensor1d([1, 2, 9, 4]);\n *\n * a.squaredDifference(b).print();  // or tf.squaredDifference(a, b)\n * ```\n *\n * ```js\n * // Broadcast squared difference  a with b.\n * const a = tf.tensor1d([2, 4, 6, 8]);\n * const b = tf.scalar(5);\n *\n * a.squaredDifference(b).print();  // or tf.squaredDifference(a, b)\n * ```\n *\n * @param a The first tensor.\n * @param b The second tensor. Must have the same type as `a`.\n */\n/** @doc {heading: 'Operations', subheading: 'Arithmetic'} */\nfunction squaredDifference_(a, b) {\n    var _a;\n    var $a = tensor_util_env_1.convertToTensor(a, 'a', 'squaredDifference');\n    var $b = tensor_util_env_1.convertToTensor(b, 'b', 'squaredDifference');\n    _a = tensor_util_1.makeTypesMatch($a, $b), $a = _a[0], $b = _a[1];\n    broadcast_util.assertAndGetBroadcastShape($a.shape, $b.shape);\n    var der = function (dy, saved) {\n        var $a = saved[0], $b = saved[1];\n        var two = tensor_ops_1.scalar(2);\n        var derA = function () { return dy.mul($a.sub($b).mul(two)); };\n        var derB = function () { return dy.mul($b.sub($a).mul(two)); };\n        return { $a: derA, $b: derB };\n    };\n    return engine_1.ENGINE.runKernel(function (backend, save) {\n        var res = backend.squaredDifference($a, $b);\n        save([$a, $b]);\n        return res;\n    }, { $a: $a, $b: $b }, der);\n}\n/**\n * Returns (a - b) * (a - b) element-wise.\n *\n * Inputs must be the same shape. For broadcasting support, use\n * `tf.squaredDifference` instead.\n *\n * @param a The first tensor.\n * @param b The second tensor. Must have the same type as `a`.\n */\nfunction squaredDifferenceStrict_(a, b) {\n    var $a = tensor_util_env_1.convertToTensor(a, 'a', 'squaredDifferenceStrict');\n    var $b = tensor_util_env_1.convertToTensor(b, 'b', 'squaredDifferenceStrict');\n    util.assertShapesMatch($a.shape, $b.shape, 'Error in squaredDifferenceStrict: ');\n    return $a.squaredDifference($b);\n}\n/**\n * Computes arctangent of `tf.Tensor`s a / b element-wise: `atan2(a, b)`.\n * Supports broadcasting.\n *\n * ```js\n * const a = tf.tensor1d([1.0, 1.0, -1.0, .7]);\n * const b = tf.tensor1d([2.0, 13.0, 3.5, .21]);\n *\n * tf.atan2(a, b).print()\n * ```\n *\n * @param a The first tensor.\n * @param b The second tensor. Must have the same dtype as `a`.\n *\n */\n/** @doc {heading: 'Operations', subheading: 'Basic math'} */\nfunction atan2_(a, b) {\n    var _a;\n    var $a = tensor_util_env_1.convertToTensor(a, 'a', 'atan2');\n    var $b = tensor_util_env_1.convertToTensor(b, 'b', 'atan2');\n    _a = tensor_util_1.makeTypesMatch($a, $b), $a = _a[0], $b = _a[1];\n    var outShape = broadcast_util.assertAndGetBroadcastShape($a.shape, $b.shape);\n    var der = function (dy, saved) {\n        var $a = saved[0], $b = saved[1];\n        var derA = function () {\n            var d = exports.add($a.square(), $b.square());\n            var res = dy.mul($b.div(d));\n            var reduceAxes = broadcast_util.getReductionAxes($a.shape, outShape);\n            if (reduceAxes.length > 0) {\n                res = res.sum(reduceAxes);\n            }\n            return res.reshape($a.shape);\n        };\n        var derB = function () {\n            var d = exports.add($a.square(), $b.square());\n            var res = unary_ops_1.neg(dy.mul($a.div(d)));\n            var reduceAxes = broadcast_util.getReductionAxes($b.shape, outShape);\n            if (reduceAxes.length > 0) {\n                res = res.sum(reduceAxes);\n            }\n            return res.reshape($b.shape);\n        };\n        return { $a: derA, $b: derB };\n    };\n    return engine_1.ENGINE.runKernel(function (backend, save) {\n        var res = backend.atan2($a, $b);\n        save([$a, $b]);\n        return res;\n    }, { $a: $a, $b: $b }, der);\n}\nexports.add = operation_1.op({ add_: add_ });\nexports.addN = operation_1.op({ addN_: addN_ });\nexports.addStrict = operation_1.op({ addStrict_: addStrict_ });\nexports.atan2 = operation_1.op({ atan2_: atan2_ });\nexports.div = operation_1.op({ div_: div_ });\nexports.divStrict = operation_1.op({ divStrict_: divStrict_ });\nexports.floorDiv = operation_1.op({ floorDiv_: floorDiv_ });\nexports.maximum = operation_1.op({ maximum_: maximum_ });\nexports.maximumStrict = operation_1.op({ maximumStrict_: maximumStrict_ });\nexports.minimum = operation_1.op({ minimum_: minimum_ });\nexports.minimumStrict = operation_1.op({ minimumStrict_: minimumStrict_ });\nexports.mod = operation_1.op({ mod_: mod_ });\nexports.modStrict = operation_1.op({ modStrict_: modStrict_ });\nexports.mul = operation_1.op({ mul_: mul_ });\nexports.mulStrict = operation_1.op({ mulStrict_: mulStrict_ });\nexports.pow = operation_1.op({ pow_: pow_ });\nexports.powStrict = operation_1.op({ powStrict_: powStrict_ });\nexports.squaredDifference = operation_1.op({ squaredDifference_: squaredDifference_ });\nexports.squaredDifferenceStrict = operation_1.op({ squaredDifferenceStrict_: squaredDifferenceStrict_ });\nexports.sub = operation_1.op({ sub_: sub_ });\nexports.subStrict = operation_1.op({ subStrict_: subStrict_ });\n//# sourceMappingURL=binary_ops.js.map","\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar engine_1 = require(\"../engine\");\nvar tensor_util_env_1 = require(\"../tensor_util_env\");\nvar binary_ops_1 = require(\"./binary_ops\");\nvar broadcast_util_1 = require(\"./broadcast_util\");\nvar logical_ops_1 = require(\"./logical_ops\");\nvar operation_1 = require(\"./operation\");\nvar selu_util_1 = require(\"./selu_util\");\nvar tensor_ops_1 = require(\"./tensor_ops\");\n/**\n * Computes rectified linear element-wise: `max(x, 0)`.\n *\n * ```js\n * const x = tf.tensor1d([-1, 2, -3, 4]);\n *\n * x.relu().print();  // or tf.relu(x)\n * ```\n * @param x The input tensor. If the dtype is `bool`, the output dtype will be\n *     `int32'.\n */\n/** @doc {heading: 'Operations', subheading: 'Basic math'} */\nfunction relu_(x) {\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'relu');\n    if ($x.dtype === 'bool') {\n        return $x.toInt();\n    }\n    var grad = function (dy, saved) {\n        var $x = saved[0];\n        return { $x: function () { return dy.mulStrict($x.step().toFloat()); } };\n    };\n    return engine_1.ENGINE.runKernel(function (backend, save) {\n        var res = backend.relu($x);\n        save([$x]);\n        return res;\n    }, { $x: $x }, grad);\n}\n/**\n * Computes exponential linear element-wise: `x > 0 ? e ^ x - 1 : 0`.\n *\n * ```js\n * const x = tf.tensor1d([-1, 1, -3, 2]);\n *\n * x.elu().print();  // or tf.elu(x)\n * ```\n * @param x The input tensor.\n */\n/** @doc {heading: 'Operations', subheading: 'Basic math'} */\nfunction elu_(x) {\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'elu');\n    var grad = function (dy, saved) {\n        var y = saved[0];\n        return {\n            $x: function () { return engine_1.ENGINE.runKernel(function (backend) { return backend.eluDer(dy, y); }, { dy: dy, y: y }); }\n        };\n    };\n    return engine_1.ENGINE.runKernel(function (backend, save) {\n        var y = backend.elu($x);\n        save([y]);\n        return y;\n    }, { $x: $x }, grad);\n}\n/**\n * Computes scaled exponential linear element-wise.\n *\n * `x < 0 ? scale * alpha * (exp(x) - 1) : x`\n *\n * ```js\n * const x = tf.tensor1d([-1, 2, -3, 4]);\n *\n * x.selu().print();  // or tf.selu(x)\n * ```\n * @param x The input tensor.\n */\n/** @doc {heading: 'Operations', subheading: 'Basic math'} */\nfunction selu_(x) {\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'selu');\n    var grad = function (dy, saved) {\n        var $x = saved[0];\n        return {\n            $x: function () {\n                var mask = $x.greater(tensor_ops_1.scalar(0));\n                var scaleAlpha = tensor_ops_1.scalar(selu_util_1.SELU_SCALEALPHA);\n                var scale = tensor_ops_1.scalar(selu_util_1.SELU_SCALE);\n                var greaterThanZeroDer = dy.mul(scale);\n                var lessEqualZeroDer = dy.mul(scaleAlpha).mul($x.toFloat().exp());\n                return logical_ops_1.where(mask, greaterThanZeroDer, lessEqualZeroDer);\n            }\n        };\n    };\n    return engine_1.ENGINE.runKernel(function (backend, save) {\n        var res = backend.selu($x);\n        save([$x]);\n        return res;\n    }, { $x: $x }, grad);\n}\n/**\n * Computes leaky rectified linear element-wise.\n *\n * See\n * [http://web.stanford.edu/~awni/papers/relu_hybrid_icml2013_final.pdf](\n *     http://web.stanford.edu/~awni/papers/relu_hybrid_icml2013_final.pdf)\n *\n * ```js\n * const x = tf.tensor1d([-1, 2, -3, 4]);\n *\n * x.leakyRelu(0.1).print();  // or tf.leakyRelu(x, 0.1)\n * ```\n * @param x The input tensor.\n * @param alpha The scaling factor for negative values, defaults to 0.2.\n */\n/** @doc {heading: 'Operations', subheading: 'Basic math'} */\nfunction leakyRelu_(x, alpha) {\n    if (alpha === void 0) { alpha = 0.2; }\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'leakyRelu');\n    return binary_ops_1.maximum(tensor_ops_1.scalar(alpha).mul($x), $x);\n}\n/**\n * Computes leaky rectified linear element-wise with parametric alphas.\n *\n * `x < 0 ? alpha * x : f(x) = x`\n *\n * ```js\n * const x = tf.tensor1d([-1, 2, -3, 4]);\n * const alpha = tf.scalar(0.1);\n *\n * x.prelu(alpha).print();  // or tf.prelu(x, alpha)\n * ```\n * @param x The input tensor.\n * @param alpha Scaling factor for negative values.\n */\n/** @doc {heading: 'Operations', subheading: 'Basic math'} */\nfunction prelu_(x, alpha) {\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'prelu');\n    var $alpha = tensor_util_env_1.convertToTensor(alpha, 'alpha', 'prelu');\n    var grad = function (dy, saved) {\n        var $x = saved[0], $alpha = saved[1];\n        var mask = $x.greater(0);\n        return {\n            $x: function () { return logical_ops_1.where(mask, dy, dy.mul($alpha)); },\n            $alpha: function () {\n                var res = logical_ops_1.where(mask, tensor_ops_1.zerosLike(dy), dy.mul($x));\n                var reduceAxes = broadcast_util_1.getReductionAxes($alpha.shape, dy.shape);\n                if (reduceAxes.length > 0) {\n                    res = res.sum(reduceAxes);\n                }\n                return res.reshape($alpha.shape);\n            }\n        };\n    };\n    return engine_1.ENGINE.runKernel(function (backend, save) {\n        var res = backend.prelu($x, $alpha);\n        save([$x, $alpha]);\n        return res;\n    }, { $x: $x, $alpha: $alpha }, grad);\n}\nexports.elu = operation_1.op({ elu_: elu_ });\nexports.leakyRelu = operation_1.op({ leakyRelu_: leakyRelu_ });\nexports.prelu = operation_1.op({ prelu_: prelu_ });\nexports.relu = operation_1.op({ relu_: relu_ });\nexports.selu = operation_1.op({ selu_: selu_ });\n//# sourceMappingURL=relu_ops.js.map","\n/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : new P(function (resolve) { resolve(result.value); }).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nvar __generator = (this && this.__generator) || function (thisArg, body) {\n    var _ = { label: 0, sent: function() { if (t[0] & 1) throw t[1]; return t[1]; }, trys: [], ops: [] }, f, y, t, g;\n    return g = { next: verb(0), \"throw\": verb(1), \"return\": verb(2) }, typeof Symbol === \"function\" && (g[Symbol.iterator] = function() { return this; }), g;\n    function verb(n) { return function (v) { return step([n, v]); }; }\n    function step(op) {\n        if (f) throw new TypeError(\"Generator is already executing.\");\n        while (_) try {\n            if (f = 1, y && (t = op[0] & 2 ? y[\"return\"] : op[0] ? y[\"throw\"] || ((t = y[\"return\"]) && t.call(y), 0) : y.next) && !(t = t.call(y, op[1])).done) return t;\n            if (y = 0, t) op = [op[0] & 2, t.value];\n            switch (op[0]) {\n                case 0: case 1: t = op; break;\n                case 4: _.label++; return { value: op[1], done: false };\n                case 5: _.label++; y = op[1]; op = [0]; continue;\n                case 7: op = _.ops.pop(); _.trys.pop(); continue;\n                default:\n                    if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) { _ = 0; continue; }\n                    if (op[0] === 3 && (!t || (op[1] > t[0] && op[1] < t[3]))) { _.label = op[1]; break; }\n                    if (op[0] === 6 && _.label < t[1]) { _.label = t[1]; t = op; break; }\n                    if (t && _.label < t[2]) { _.label = t[2]; _.ops.push(op); break; }\n                    if (t[2]) _.ops.pop();\n                    _.trys.pop(); continue;\n            }\n            op = body.call(thisArg, _);\n        } catch (e) { op = [6, e]; y = 0; } finally { f = t = 0; }\n        if (op[0] & 5) throw op[1]; return { value: op[0] ? op[1] : void 0, done: true };\n    }\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar where_impl_1 = require(\"../backends/where_impl\");\nvar engine_1 = require(\"../engine\");\nvar tensor_util_env_1 = require(\"../tensor_util_env\");\nvar util_1 = require(\"../util\");\nvar broadcast_util_1 = require(\"./broadcast_util\");\nvar operation_1 = require(\"./operation\");\nvar tensor_ops_1 = require(\"./tensor_ops\");\n/**\n * Returns the truth value of `NOT x` element-wise.\n *\n * ```js\n * const a = tf.tensor1d([false, true], 'bool');\n *\n * a.logicalNot().print();\n * ```\n *\n * @param x The input tensor. Must be of dtype 'bool'.\n */\n/** @doc {heading: 'Operations', subheading: 'Logical'} */\nfunction logicalNot_(x) {\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'logicalNot', 'bool');\n    return engine_1.ENGINE.runKernel(function (backend) { return backend.logicalNot($x); }, { $x: $x });\n}\n/**\n * Returns the truth value of `a AND b` element-wise. Supports broadcasting.\n *\n * ```js\n * const a = tf.tensor1d([false, false, true, true], 'bool');\n * const b = tf.tensor1d([false, true, false, true], 'bool');\n *\n * a.logicalAnd(b).print();\n * ```\n *\n * @param a The first input tensor. Must be of dtype bool.\n * @param b The second input tensor. Must be of dtype bool.\n */\n/** @doc {heading: 'Operations', subheading: 'Logical'} */\nfunction logicalAnd_(a, b) {\n    var $a = tensor_util_env_1.convertToTensor(a, 'a', 'logicalAnd', 'bool');\n    var $b = tensor_util_env_1.convertToTensor(b, 'b', 'logicalAnd', 'bool');\n    broadcast_util_1.assertAndGetBroadcastShape($a.shape, $b.shape);\n    return engine_1.ENGINE.runKernel(function (backend) { return backend.logicalAnd($a, $b); }, { $a: $a, $b: $b });\n}\n/**\n * Returns the truth value of `a OR b` element-wise. Supports broadcasting.\n *\n * ```js\n * const a = tf.tensor1d([false, false, true, true], 'bool');\n * const b = tf.tensor1d([false, true, false, true], 'bool');\n *\n * a.logicalOr(b).print();\n * ```\n * @param a The first input tensor. Must be of dtype bool.\n * @param b The second input tensor. Must be of dtype bool.\n */\n/** @doc {heading: 'Operations', subheading: 'Logical'} */\nfunction logicalOr_(a, b) {\n    var $a = tensor_util_env_1.convertToTensor(a, 'a', 'logicalOr', 'bool');\n    var $b = tensor_util_env_1.convertToTensor(b, 'b', 'logicalOr', 'bool');\n    broadcast_util_1.assertAndGetBroadcastShape($a.shape, $b.shape);\n    return engine_1.ENGINE.runKernel(function (backend) { return backend.logicalOr($a, $b); }, { $a: $a, $b: $b });\n}\n/**\n * Returns the truth value of `a XOR b` element-wise. Supports broadcasting.\n *\n * ```js\n * const a = tf.tensor1d([false, false, true, true], 'bool');\n * const b = tf.tensor1d([false, true, false, true], 'bool');\n *\n * a.logicalXor(b).print();\n * ```\n *\n * @param a The first input tensor. Must be of dtype bool.\n * @param b The second input tensor. Must be of dtype bool.\n */\n/** @doc {heading: 'Operations', subheading: 'Logical'} */\nfunction logicalXor_(a, b) {\n    var $a = tensor_util_env_1.convertToTensor(a, 'a', 'logicalXor', 'bool');\n    var $b = tensor_util_env_1.convertToTensor(b, 'b', 'logicalXor', 'bool');\n    broadcast_util_1.assertAndGetBroadcastShape($a.shape, $b.shape);\n    // x ^ y = (x | y) & ~(x & y)\n    return exports.logicalOr(a, b).logicalAnd(exports.logicalAnd(a, b).logicalNot());\n}\n/**\n * Returns the elements, either `a` or `b` depending on the `condition`.\n *\n * If the condition is true, select from `a`, otherwise select from `b`.\n *\n * ```js\n * const cond = tf.tensor1d([false, false, true], 'bool');\n * const a = tf.tensor1d([1 , 2, 3]);\n * const b = tf.tensor1d([-1, -2, -3]);\n *\n * a.where(cond, b).print();\n * ```\n *\n * @param condition The input condition. Must be of dtype bool.\n * @param a If `condition` is rank 1, `a` may have a higher rank but\n *     its first dimension must match the size of `condition`.\n * @param b A tensor with the same shape and type as `a`.\n */\n/** @doc {heading: 'Operations', subheading: 'Logical'} */\nfunction where_(condition, a, b) {\n    var $a = tensor_util_env_1.convertToTensor(a, 'a', 'where');\n    var $b = tensor_util_env_1.convertToTensor(b, 'b', 'where');\n    var $condition = tensor_util_env_1.convertToTensor(condition, 'condition', 'where', 'bool');\n    util_1.assertShapesMatch($a.shape, $b.shape, 'Error in where: ');\n    if ($condition.rank === 1) {\n        // If condition rank is 1, then the first dimension must match the size of\n        // condition.\n        util_1.assert($condition.shape[0] === $a.shape[0], function () { return 'The first dimension of `a` must match the size of `condition`.'; });\n    }\n    else {\n        // A must have the same shape as condition.\n        util_1.assertShapesMatch($condition.shape, $b.shape, 'Error in where: ');\n    }\n    // TODO(julianoks): Return null for condition gradient\n    // when backprop supports it.\n    var grad = function (dy, saved) {\n        var $condition = saved[0];\n        return {\n            $condition: function () { return tensor_ops_1.zerosLike($condition).toFloat(); },\n            $a: function () { return dy.mul($condition.cast(dy.dtype)); },\n            $b: function () { return dy.mul($condition.logicalNot().cast(dy.dtype)); }\n        };\n    };\n    return engine_1.ENGINE.runKernel(function (backend, save) {\n        var res = backend.select($condition, $a, $b);\n        save([$condition]);\n        return res;\n    }, { $condition: $condition, $a: $a, $b: $b }, grad);\n}\n/**\n * Returns the coordinates of true elements of condition.\n *\n * The coordinates are returned in a 2-D tensor where the first dimension (rows)\n * represents the number of true elements, and the second dimension (columns)\n * represents the coordinates of the true elements. Keep in mind, the shape of\n * the output tensor can vary depending on how many true values there are in\n * input. Indices are output in row-major order. The resulting tensor has the\n * shape `[numTrueElems, condition.rank]`.\n *\n * This is analogous to calling the python `tf.where(cond)` without an x or y.\n *\n * ```js\n * const cond = tf.tensor1d([false, false, true], 'bool');\n * const result = await tf.whereAsync(cond);\n * result.print();\n * ```\n */\n/** @doc {heading: 'Operations', subheading: 'Logical'} */\nfunction whereAsync_(condition) {\n    return __awaiter(this, void 0, void 0, function () {\n        var $condition, vals, res;\n        return __generator(this, function (_a) {\n            switch (_a.label) {\n                case 0:\n                    $condition = tensor_util_env_1.convertToTensor(condition, 'condition', 'whereAsync', 'bool');\n                    return [4 /*yield*/, $condition.data()];\n                case 1:\n                    vals = _a.sent();\n                    res = where_impl_1.whereImpl($condition.shape, vals);\n                    if (condition !== $condition) {\n                        $condition.dispose();\n                    }\n                    return [2 /*return*/, res];\n            }\n        });\n    });\n}\nexports.logicalAnd = operation_1.op({ logicalAnd_: logicalAnd_ });\nexports.logicalNot = operation_1.op({ logicalNot_: logicalNot_ });\nexports.logicalOr = operation_1.op({ logicalOr_: logicalOr_ });\nexports.logicalXor = operation_1.op({ logicalXor_: logicalXor_ });\nexports.where = operation_1.op({ where_: where_ });\nexports.whereAsync = whereAsync_;\n//# sourceMappingURL=logical_ops.js.map","\n/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar engine_1 = require(\"../engine\");\nvar tensor_util_env_1 = require(\"../tensor_util_env\");\nvar util = require(\"../util\");\nvar axis_util = require(\"./axis_util\");\nvar operation_1 = require(\"./operation\");\n/**\n * Transposes the `tf.Tensor`. Permutes the dimensions according to `perm`.\n *\n * The returned `tf.Tensor`'s dimension `i` will correspond to the input\n * dimension `perm[i]`. If `perm` is not given, it is set to `[n-1...0]`,\n * where `n` is the rank of the input `tf.Tensor`. Hence by default, this\n * operation performs a regular matrix transpose on 2-D input `tf.Tensor`s.\n *\n * ```js\n * const a = tf.tensor2d([1, 2, 3, 4, 5, 6], [2, 3]);\n *\n * a.transpose().print();  // or tf.transpose(a)\n * ```\n *\n * @param x The tensor to transpose.\n * @param perm The permutation of the dimensions of a.\n */\n/** @doc {heading: 'Operations', subheading: 'Matrices'} */\nfunction transpose_(x, perm) {\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'transpose');\n    if (perm == null) {\n        perm = $x.shape.map(function (s, i) { return i; }).reverse();\n    }\n    util.assert($x.rank === perm.length, function () { return \"Error in transpose: rank of input \" + $x.rank + \" \" +\n        (\"must match length of perm \" + perm + \".\"); });\n    perm.forEach(function (axis) {\n        util.assert(axis >= 0 && axis < $x.rank, function () { return \"All entries in 'perm' must be between 0 and \" + ($x.rank - 1) +\n            (\" but got \" + perm); });\n    });\n    if ($x.rank <= 1) {\n        return $x.clone();\n    }\n    var der = function (dy) {\n        var undoPerm = axis_util.getUndoAxesPermutation(perm);\n        return { $x: function () { return dy.transpose(undoPerm); } };\n    };\n    return engine_1.ENGINE.runKernel(function (backend) { return backend.transpose($x, perm); }, { $x: $x }, der);\n}\nexports.transpose = operation_1.op({ transpose_: transpose_ });\n//# sourceMappingURL=transpose.js.map","\n/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar engine_1 = require(\"../engine\");\nvar tensor_util_env_1 = require(\"../tensor_util_env\");\nvar util = require(\"../util\");\nvar operation_1 = require(\"./operation\");\n/**\n * Normalizes the activation of a local neighborhood across or within\n * channels.\n *\n * @param x The input tensor. The 4-D input tensor is treated as a 3-D array\n *     of 1D vectors (along the last dimension), and each vector is\n *     normalized independently.\n * @param depthRadius The number of adjacent channels in the 1D normalization\n *     window.\n * @param bias A constant bias term for the basis.\n * @param alpha A scale factor, usually positive.\n * @param beta An exponent.\n */\n/** @doc {heading: 'Operations', subheading: 'Normalization'} */\nfunction localResponseNormalization_(x, depthRadius, bias, alpha, beta) {\n    if (depthRadius === void 0) { depthRadius = 5; }\n    if (bias === void 0) { bias = 1; }\n    if (alpha === void 0) { alpha = 1; }\n    if (beta === void 0) { beta = 0.5; }\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'localResponseNormalization');\n    util.assert($x.rank === 4 || $x.rank === 3, function () { return \"Error in localResponseNormalization: x must be rank 3 or 4 but got\\n               rank \" + $x.rank + \".\"; });\n    util.assert(util.isInt(depthRadius), function () { return \"Error in localResponseNormalization: depthRadius must be an \" +\n        (\"integer but got depthRadius \" + depthRadius + \".\"); });\n    var x4D = $x;\n    var reshapedTo4D = false;\n    if ($x.rank === 3) {\n        reshapedTo4D = true;\n        x4D = $x.as4D(1, $x.shape[0], $x.shape[1], $x.shape[2]);\n    }\n    var backward = function (dy, saved) {\n        var x4D = saved[0], y = saved[1];\n        return {\n            x4D: function () { return engine_1.ENGINE.runKernel(function (backend) { return backend.LRNGrad(dy, x4D, y, depthRadius, bias, alpha, beta); }, {}); }\n        };\n    };\n    var res = engine_1.ENGINE.runKernel(function (backend, save) {\n        var y = backend.localResponseNormalization4D(x4D, depthRadius, bias, alpha, beta);\n        save([x4D, y]);\n        return y;\n    }, { x4D: x4D }, backward);\n    if (reshapedTo4D) {\n        return res.as3D(res.shape[1], res.shape[2], res.shape[3]);\n    }\n    else {\n        return res;\n    }\n}\nexports.localResponseNormalization = operation_1.op({ localResponseNormalization_: localResponseNormalization_ });\n//# sourceMappingURL=lrn.js.map","\n/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar tensor_util_env_1 = require(\"../tensor_util_env\");\nvar axis_util = require(\"./axis_util\");\nvar operation_1 = require(\"./operation\");\nvar tensor_ops_1 = require(\"./tensor_ops\");\nvar util_1 = require(\"../util\");\n/**\n * Computes the norm of scalar, vectors, and matrices.\n * This function can compute several different vector norms (the 1-norm, the\n * Euclidean or 2-norm, the inf-norm, and in general the p-norm for p > 0)\n * and matrix norms (Frobenius, 1-norm, and inf-norm).\n *\n * ```js\n * const x = tf.tensor1d([1, 2, 3, 4]);\n *\n * x.norm().print();  // or tf.norm(x)\n * ```\n *\n * @param x The input array.\n * @param ord Optional. Order of the norm. Supported norm types are\n * following:\n *\n *  | ord        | norm for matrices         | norm for vectors\n *  |------------|---------------------------|---------------------\n *  |'euclidean' |Frobenius norm             |2-norm\n *  |'fro'       |Frobenius norm\t           |\n *  |Infinity    |max(sum(abs(x), axis=1))   |max(abs(x))\n *  |-Infinity   |min(sum(abs(x), axis=1))   |min(abs(x))\n *  |1           |max(sum(abs(x), axis=0))   |sum(abs(x))\n *  |2           |                           |sum(abs(x)^2)^1/2*\n *\n * @param axis Optional. If axis is null (the default), the input is\n * considered a vector and a single vector norm is computed over the entire\n * set of values in the Tensor, i.e. norm(x, ord) is equivalent\n * to norm(x.reshape([-1]), ord). If axis is a integer, the input\n * is considered a batch of vectors, and axis determines the axis in x\n * over which to compute vector norms. If axis is a 2-tuple of integer it is\n * considered a batch of matrices and axis determines the axes in NDArray\n * over which to compute a matrix norm.\n * @param keepDims Optional. If true, the norm have the same dimensionality\n * as the input.\n */\n/** @doc {heading: 'Operations', subheading: 'Matrices'} */\nfunction norm_(x, ord, axis, keepDims) {\n    if (ord === void 0) { ord = 'euclidean'; }\n    if (axis === void 0) { axis = null; }\n    if (keepDims === void 0) { keepDims = false; }\n    x = tensor_util_env_1.convertToTensor(x, 'x', 'norm');\n    var norm = normImpl(x, ord, axis);\n    var keepDimsShape = norm.shape;\n    if (keepDims) {\n        var axes = util_1.parseAxisParam(axis, x.shape);\n        keepDimsShape = axis_util.expandShapeToKeepDim(norm.shape, axes);\n    }\n    return norm.reshape(keepDimsShape);\n}\nfunction normImpl(x, p, axis) {\n    if (axis === void 0) { axis = null; }\n    if (x.rank === 0) {\n        return x.abs();\n    }\n    // consider vector when no axis is specified\n    if (x.rank !== 1 && axis === null) {\n        return normImpl(x.reshape([-1]), p, axis);\n    }\n    // vector\n    if (x.rank === 1 || typeof axis === 'number' ||\n        Array.isArray(axis) && axis.length === 1) {\n        if (p === 1) {\n            return x.abs().sum(axis);\n        }\n        if (p === Infinity) {\n            return x.abs().max(axis);\n        }\n        if (p === -Infinity) {\n            return x.abs().min(axis);\n        }\n        if (p === 'euclidean' || p === 2) {\n            // norm(x, 2) = sum(abs(xi) ^ 2) ^ 1/2\n            return x.abs().pow(tensor_ops_1.scalar(2, 'int32')).sum(axis).sqrt();\n        }\n        throw new Error(\"Error in norm: invalid ord value: \" + p);\n    }\n    // matrix (assumption axis[0] < axis[1])\n    if (Array.isArray(axis) && axis.length === 2) {\n        if (p === 1) {\n            return x.abs().sum(axis[0]).max(axis[1] - 1);\n        }\n        if (p === Infinity) {\n            return x.abs().sum(axis[1]).max(axis[0]);\n        }\n        if (p === -Infinity) {\n            return x.abs().sum(axis[1]).min(axis[0]);\n        }\n        if (p === 'fro' || p === 'euclidean') {\n            // norm(x) = sqrt(sum(pow(x, 2)))\n            return x.square().sum(axis).sqrt();\n        }\n        throw new Error(\"Error in norm: invalid ord value: \" + p);\n    }\n    throw new Error(\"Error in norm: invalid axis: \" + axis);\n}\nexports.norm = operation_1.op({ norm_: norm_ });\n//# sourceMappingURL=norm.js.map","\n/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar engine_1 = require(\"../engine\");\nvar tensor_util_env_1 = require(\"../tensor_util_env\");\nvar util_1 = require(\"../util\");\nvar array_ops_1 = require(\"./array_ops\");\nvar axis_util_1 = require(\"./axis_util\");\nvar binary_ops_1 = require(\"./binary_ops\");\nvar compare_1 = require(\"./compare\");\nvar logical_ops_1 = require(\"./logical_ops\");\nvar operation_1 = require(\"./operation\");\nvar segment_util_1 = require(\"./segment_util\");\nvar tensor_ops_1 = require(\"./tensor_ops\");\n/**\n * Computes the sum along segments of a `tf.Tensor`.\n *\n * ```js\n * const x = tf.tensor1d([1, 2, 3, 4]);\n * const segmentIds = tf.tensor1d([1, 2, 0, 1], 'int32');\n * const numSegments = 3;\n *\n * x.unsortedSegmentSum(segmentIds, numSegments).print()\n * //or tf.unsortedSegmentSum(x, segmentIds, numSegments)\n * ```\n * @param x The `tf.Tensor` that will be summed along its segments.\n * @param segmentIds A `tf.Tensor1D` whose rank is equal to the rank of `x`'s\n * dimension along the `axis`.  Maps each element of `x` to a segment.\n * @param numSegments The number of distinct `segmentIds`.\n */\n/** @doc {heading: 'Operations', subheading: 'Segment'} */\nfunction unsortedSegmentSum_(x, segmentIds, numSegments) {\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'unsortedSegmentSum');\n    var $segmentIds = tensor_util_env_1.convertToTensor(segmentIds, 'segmentIds', 'unsortedSegmentSum', 'int32');\n    util_1.assert(util_1.isInt(numSegments), function () { return 'numSegments must be of dtype int'; });\n    var gradFunc = function (dy, saved) {\n        var $segmentIds = saved[0];\n        var derX = function () {\n            return gatherDropNegatives(dy, $segmentIds);\n        };\n        return { $x: derX };\n    };\n    return engine_1.ENGINE.runKernel(function (backend, save) {\n        var res = backend.unsortedSegmentSum($x, $segmentIds, numSegments);\n        save([$segmentIds]);\n        return res;\n    }, { $x: $x }, gradFunc);\n}\n/**\n * Gather slices from tensor `x`'s axis `axis` according to `indices`.\n *\n * ```js\n * const x = tf.tensor1d([1, 2, 3, 4]);\n * const indices = tf.tensor1d([1, 3, 3], 'int32');\n *\n * x.gather(indices).print();\n * ```\n *\n * ```js\n * const x = tf.tensor2d([1, 2, 3, 4], [2, 2]);\n * const indices = tf.tensor1d([1, 1, 0], 'int32');\n *\n * x.gather(indices).print();\n * ```\n * @param x The input tensor whose slices to be gathered.\n * @param indices The indices of the values to extract.\n * @param axis The axis over which to select values. Defaults to 0.\n */\n/** @doc {heading: 'Tensors', subheading: 'Slicing and Joining'} */\nfunction gather_(x, indices, axis) {\n    if (axis === void 0) { axis = 0; }\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'gather');\n    var $indices = tensor_util_env_1.convertToTensor(indices, 'indices', 'gather', 'int32');\n    axis = util_1.parseAxisParam(axis, $x.shape)[0];\n    var shapeInfo = segment_util_1.collectGatherOpShapeInfo($x, $indices, axis);\n    var grad = function (dy, saved) {\n        var $indices = saved[0];\n        var derX = function () {\n            var paramsShape = $x.shape;\n            var indicesSize = $indices.size;\n            var outerShape = paramsShape.slice(0, axis);\n            var outerDims = outerShape.length;\n            var innerShape = paramsShape.slice(axis, paramsShape.length).slice(1);\n            var innerDims = innerShape.length;\n            var outerAxesIndices = arrayRange(0, outerDims);\n            var innerAxesIndices = arrayRange(outerDims + 1, outerDims + 1 + innerDims);\n            var valuesShape = arrayConcat([outerShape, [indicesSize], innerShape]);\n            var values = dy.reshape(valuesShape);\n            var reshapedIndices = $indices.reshape([indicesSize]);\n            var transposeDims = arrayConcat([[outerDims], outerAxesIndices, innerAxesIndices]);\n            var valuesTranspose = values.transpose(transposeDims);\n            var paramsGrad = exports.unsortedSegmentSum(valuesTranspose, reshapedIndices, $x.shape[axis]);\n            var invertTransposeDims = axis_util_1.getUndoAxesPermutation(transposeDims);\n            paramsGrad = paramsGrad.transpose(invertTransposeDims);\n            return paramsGrad;\n        };\n        return { $x: derX };\n    };\n    return (engine_1.ENGINE.runKernel(function (backend, save) {\n        var res = backend.gather($x, $indices.flatten(), axis);\n        save([$indices]);\n        return res;\n    }, { $x: $x }, grad)).reshape(shapeInfo.outputShape);\n}\nfunction arrayRange(start, stop) {\n    var result = [];\n    for (var i = start; i < stop; ++i) {\n        result.push(i);\n    }\n    return result;\n}\nfunction arrayConcat(arrays) {\n    var result = [];\n    for (var i = 0; i < arrays.length; ++i) {\n        for (var j = 0; j < arrays[i].length; ++j) {\n            result.push(arrays[i][j]);\n        }\n    }\n    return result;\n}\nfunction gatherDropNegatives(x, indices) {\n    // Helper function for unsorted segment ops. Gathers params for\n    // positive segment ids and gathers 0 for inputs with negative segment id.\n    // Mirrors _GatherDropNegatives from tensorflow/python/ops/math_grad.py\n    var zeroClippedIndices = binary_ops_1.maximum(indices, tensor_ops_1.zerosLike(indices));\n    var gathered = exports.gather(x, zeroClippedIndices);\n    var isPositive = compare_1.greaterEqual(indices, tensor_ops_1.scalar(0, 'int32'));\n    var numIters = gathered.rank - isPositive.rank;\n    for (var i = 0; i < numIters; ++i) {\n        isPositive = array_ops_1.expandDims(isPositive, i + 1);\n    }\n    isPositive = logical_ops_1.logicalAnd(isPositive, tensor_ops_1.ones(gathered.shape, 'bool'));\n    var zeroSlice = tensor_ops_1.zerosLike(gathered);\n    return logical_ops_1.where(isPositive, gathered, zeroSlice);\n}\nexports.gather = operation_1.op({ gather_: gather_ });\nexports.unsortedSegmentSum = operation_1.op({ unsortedSegmentSum_: unsortedSegmentSum_ });\n//# sourceMappingURL=segment_ops.js.map","\n/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar tensor_util_env_1 = require(\"../tensor_util_env\");\nvar operation_1 = require(\"./operation\");\n/**\n * Computes the next states and outputs of a stack of LSTMCells.\n *\n * Each cell output is used as input to the next cell.\n *\n * Returns `[cellState, cellOutput]`.\n *\n * Derived from tf.contrib.rn.MultiRNNCell.\n *\n * @param lstmCells Array of LSTMCell functions.\n * @param data The input to the cell.\n * @param c Array of previous cell states.\n * @param h Array of previous cell outputs.\n */\n/** @doc {heading: 'Operations', subheading: 'RNN'} */\nfunction multiRNNCell_(lstmCells, data, c, h) {\n    var $data = tensor_util_env_1.convertToTensor(data, 'data', 'multiRNNCell');\n    var $c = tensor_util_env_1.convertToTensorArray(c, 'c', 'multiRNNCell');\n    var $h = tensor_util_env_1.convertToTensorArray(h, 'h', 'multiRNNCell');\n    var input = $data;\n    var newStates = [];\n    for (var i = 0; i < lstmCells.length; i++) {\n        var output = lstmCells[i](input, $c[i], $h[i]);\n        newStates.push(output[0]);\n        newStates.push(output[1]);\n        input = output[1];\n    }\n    var newC = [];\n    var newH = [];\n    for (var i = 0; i < newStates.length; i += 2) {\n        newC.push(newStates[i]);\n        newH.push(newStates[i + 1]);\n    }\n    return [newC, newH];\n}\n/**\n * Computes the next state and output of a BasicLSTMCell.\n *\n * Returns `[newC, newH]`.\n *\n * Derived from tf.contrib.rnn.BasicLSTMCell.\n *\n * @param forgetBias Forget bias for the cell.\n * @param lstmKernel The weights for the cell.\n * @param lstmBias The bias for the cell.\n * @param data The input to the cell.\n * @param c Previous cell state.\n * @param h Previous cell output.\n */\n/** @doc {heading: 'Operations', subheading: 'RNN'} */\nfunction basicLSTMCell_(forgetBias, lstmKernel, lstmBias, data, c, h) {\n    var $forgetBias = tensor_util_env_1.convertToTensor(forgetBias, 'forgetBias', 'basicLSTMCell');\n    var $lstmKernel = tensor_util_env_1.convertToTensor(lstmKernel, 'lstmKernel', 'basicLSTMCell');\n    var $lstmBias = tensor_util_env_1.convertToTensor(lstmBias, 'lstmBias', 'basicLSTMCell');\n    var $data = tensor_util_env_1.convertToTensor(data, 'data', 'basicLSTMCell');\n    var $c = tensor_util_env_1.convertToTensor(c, 'c', 'basicLSTMCell');\n    var $h = tensor_util_env_1.convertToTensor(h, 'h', 'basicLSTMCell');\n    var combined = $data.concat($h, 1);\n    var weighted = combined.matMul($lstmKernel);\n    var res = weighted.add($lstmBias);\n    // i = input_gate, j = new_input, f = forget_gate, o = output_gate\n    var batchSize = res.shape[0];\n    var sliceCols = res.shape[1] / 4;\n    var sliceSize = [batchSize, sliceCols];\n    var i = res.slice([0, 0], sliceSize);\n    var j = res.slice([0, sliceCols], sliceSize);\n    var f = res.slice([0, sliceCols * 2], sliceSize);\n    var o = res.slice([0, sliceCols * 3], sliceSize);\n    var newC = i.sigmoid().mulStrict(j.tanh()).addStrict($c.mulStrict($forgetBias.add(f).sigmoid()));\n    var newH = newC.tanh().mulStrict(o.sigmoid());\n    return [newC, newH];\n}\nexports.basicLSTMCell = operation_1.op({ basicLSTMCell_: basicLSTMCell_ });\nexports.multiRNNCell = operation_1.op({ multiRNNCell_: multiRNNCell_ });\n//# sourceMappingURL=lstm.js.map","\n/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar tensor_util_1 = require(\"../tensor_util\");\nvar tensor_util_env_1 = require(\"../tensor_util_env\");\nvar util = require(\"../util\");\nvar binary_ops_1 = require(\"./binary_ops\");\nvar operation_1 = require(\"./operation\");\nvar tensor_ops_1 = require(\"./tensor_ops\");\n/**\n * Compute the moving average of a variable.\n *\n * Without zeroDebias, the moving average operation is defined by:\n *   `v += delta`\n * where\n *   `delta = (1 - decay) * (x - v)`\n *\n * With zeroDebias (default), the `delta` term is scaled to debias the\n * effect of the (assumed) zero-initialization of `v`.\n *   `delta /= (1 - decay ^ step)`\n *\n * For more details on the zero-debiasing algorithm, see:\n *   https://arxiv.org/abs/1412.6980\n *\n * Note that this function is completely stateless and does not keep track of\n * step count. The step count needs to be maintained by the caller and passed\n * in as `step`.\n *\n * @param v The current moving average value.\n * @param x New input value, must have the same shape and dtype as `v`.\n * @param decay The decay factor. Typical values are 0.95 and 0.99.\n * @param step Step count.\n * @param zeroDebias: Whether zeroDebias is to be performed (default: `true`).\n * @returns The new moving average value.\n */\n/** @doc {heading: 'Operations', subheading: 'Moving Average'} */\nfunction movingAverage_(v, x, decay, step, zeroDebias) {\n    if (zeroDebias === void 0) { zeroDebias = true; }\n    var $v = tensor_util_env_1.convertToTensor(v, 'v', 'movingAverage');\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'movingAverage');\n    var $decay = tensor_util_env_1.convertToTensor(decay, 'decay', 'movingAverage');\n    tensor_util_1.assertTypesMatch($v, $x);\n    util.assert(util.arraysEqual($v.shape, $x.shape), function () { return 'Shape mismatch in v and x'; });\n    var one = tensor_ops_1.scalar(1);\n    var oneMinusDecay = one.sub($decay);\n    var update = $x.sub($v).mul(oneMinusDecay);\n    if (zeroDebias) {\n        util.assert(step != null, function () { return 'When using zeroDebias: true, step is required.'; });\n        var $step = tensor_util_env_1.convertToTensor(step, 'step', 'movingAverage');\n        update = update.div(one.sub(binary_ops_1.pow($decay, $step)));\n    }\n    return $v.add(update);\n}\nexports.movingAverage = operation_1.op({ movingAverage_: movingAverage_ });\n//# sourceMappingURL=moving_average.js.map","\n/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar engine_1 = require(\"../engine\");\nvar tensor_util_env_1 = require(\"../tensor_util_env\");\nvar operation_1 = require(\"./operation\");\nvar slice_1 = require(\"./slice\");\nvar slice_util_1 = require(\"./slice_util\");\n/**\n * Extracts a strided slice of a tensor.\n *\n * Roughly speaking, this op extracts a slice of size (end-begin)/stride from\n * the given input tensor (x). Starting at the location specified by begin the\n * slice continues by adding stride to the index until all dimensions are not\n * less than end. Note that a stride can be negative, which causes a reverse\n * slice.\n *\n * ```js\n * const t = tf.tensor3d([1, 1, 1 ,2, 2, 2, 3, 3, 3, 4, 4, 4, 5, 5, 5, 6, 6, 6],\n *    [3, 2, 3]);\n * t.stridedSlice([1, 0, 0], [2, 1, 3], [1, 1, 1]).print()  // [[[3, 3, 3]]]\n * t.stridedSlice([1, 0, 0], [2, 2, 3], [1, 1, 1]).print()  // [[[3, 3, 3],\n *                                                     // [4, 4, 4]]]\n * t.stridedSlice([1, -1, 0], [2, -3, 3], [1, -1, 1]).print() // [[[4, 4, 4],\n *                                                     // [3, 3, 3]]]\n * ```\n *\n * @param x The tensor to stride slice.\n * @param begin The coordinates to start the slice from.\n * @param end: The coordinates to end the slice at.\n * @param strides: The size of the slice.\n * @param beginMask: If the ith bit of beginMask is set, begin[i] is ignored\n *      and the fullest possible range in that dimension is used instead.\n * @param endMask: If the ith bit of endMask is set, end[i] is ignored\n *      and the fullest possible range in that dimension is used instead.\n * @param shrinkAxisMask: a bitmask where bit i implies that\n * the ith specification should shrink the dimensionality. begin and end must\n * imply a slice of size 1 in the dimension.\n */\n/** @doc {heading: 'Operations', subheading: 'Slicing and Joining'} */\nfunction stridedSlice_(x, begin, end, strides, beginMask, endMask, ellipsisMask, newAxisMask, shrinkAxisMask) {\n    if (beginMask === void 0) { beginMask = 0; }\n    if (endMask === void 0) { endMask = 0; }\n    if (ellipsisMask === void 0) { ellipsisMask = 0; }\n    if (newAxisMask === void 0) { newAxisMask = 0; }\n    if (shrinkAxisMask === void 0) { shrinkAxisMask = 0; }\n    if (ellipsisMask !== 0) {\n        throw new Error('ellipsis mask is not yet supported');\n    }\n    if (newAxisMask !== 0) {\n        throw new Error('new axis mask is not yet supported');\n    }\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'stridedSlice');\n    var nonStrided = strides.every(function (v) { return v === 1; });\n    if (nonStrided) {\n        var _a = slice_util_1.getStridedSlicedInfo($x.shape, begin, end, strides, beginMask, endMask, ellipsisMask, newAxisMask, shrinkAxisMask), beginIndex = _a[0], size = _a[1], shrinkAxis_1 = _a[2];\n        var outShape = size.filter(function (_, index) { return shrinkAxis_1.indexOf(index) === -1; });\n        return slice_1.slice($x, beginIndex, size).reshape(outShape);\n    }\n    return engine_1.ENGINE.runKernel(function (backend) { return backend.stridedSlice($x, begin, end, strides, beginMask, endMask, ellipsisMask, newAxisMask, shrinkAxisMask); }, { $x: $x });\n}\nexports.stridedSlice = operation_1.op({ stridedSlice_: stridedSlice_ });\n//# sourceMappingURL=strided_slice.js.map","\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar engine_1 = require(\"../engine\");\nvar tensor_util_env_1 = require(\"../tensor_util_env\");\nvar operation_1 = require(\"./operation\");\n/**\n * Finds the values and indices of the `k` largest entries along the last\n * dimension.\n *\n * If the input is a vector (rank=1), finds the k largest entries in the vector\n * and outputs their values and indices as vectors. Thus values[j] is the j-th\n * largest entry in input, and its index is indices[j].\n * For higher rank inputs, computes the top k entries along the last dimension.\n *\n * If two elements are equal, the lower-index element appears first.\n *\n * ```js\n * const a = tf.tensor2d([[1, 5], [4, 3]]);\n * const {values, indices} = tf.topk(a);\n * values.print();\n * indices.print();\n * ```\n * @param x 1-D or higher `tf.Tensor` with last dimension being at least `k`.\n * @param k Number of top elements to look for along the last dimension.\n * @param sorted If true, the resulting `k` elements will be sorted by the\n *     values in descending order.\n */\n/** @doc {heading: 'Operations', subheading: 'Evaluation'} */\nfunction topk_(x, k, sorted) {\n    if (k === void 0) { k = 1; }\n    if (sorted === void 0) { sorted = true; }\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'topk');\n    if ($x.rank === 0) {\n        throw new Error('topk() expects the input to be of rank 1 or higher');\n    }\n    var lastDim = $x.shape[$x.shape.length - 1];\n    if (k > lastDim) {\n        throw new Error(\"'k' passed to topk() must be <= the last dimension (\" + lastDim + \") \" +\n            (\"but got \" + k));\n    }\n    var _a = engine_1.ENGINE.runKernel(function (b) { return b.topk($x, k, sorted); }, { $x: $x }), values = _a[0], indices = _a[1];\n    return { values: values, indices: indices };\n}\nexports.topk = operation_1.op({ topk_: topk_ });\n//# sourceMappingURL=topk.js.map","\n/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar engine_1 = require(\"../engine\");\nvar tensor_util_env_1 = require(\"../tensor_util_env\");\nvar operation_1 = require(\"./operation\");\nvar scatter_nd_util = require(\"./scatter_nd_util\");\n/**\n * Creates a new tensor by applying sparse updates to individual\n * values or slices within a zero tensor of the given shape tensor according to\n * indices. This operator is the inverse of the `tf.gatherND` operator which\n * extracts values or slices from a given tensor.\n *\n * ```js\n * const indices = tf.tensor2d([4, 3, 1, 7], [4, 1], 'int32');\n * const updates = tf.tensor1d([9, 10, 11, 12]);\n * const shape = [8];\n * tf.scatterND(indices, updates, shape).print() //[0, 11, 0, 10, 9, 0, 0, 12]\n * ```\n *\n * @param indices The tensor contains the indices into the output tensor.\n * @param updates The tensor contains the value for the indices.\n * @param shape: The shape of the output tensor.\n */\n/** @doc {heading: 'Operations', subheading: 'Slicing and Joining'} */\nfunction scatterND_(indices, updates, shape) {\n    var $indices = tensor_util_env_1.convertToTensor(indices, 'indices', 'scatterND', 'int32');\n    var $updates = tensor_util_env_1.convertToTensor(updates, 'updates', 'scatterND');\n    scatter_nd_util.validateInput($updates, $indices, shape);\n    return engine_1.ENGINE.runKernel(function (backend) { return backend.scatterND($indices, $updates, shape); }, { $indices: $indices, $updates: $updates });\n}\nexports.scatterND = operation_1.op({ scatterND_: scatterND_ });\n//# sourceMappingURL=scatter_nd.js.map","\n/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar engine_1 = require(\"../engine\");\nvar complex_ops_1 = require(\"../ops/complex_ops\");\nvar operation_1 = require(\"../ops/operation\");\nvar util_1 = require(\"../util\");\nvar tensor_ops_1 = require(\"./tensor_ops\");\n/**\n * Fast Fourier transform.\n *\n * Computes the 1-dimensional discrete Fourier transform over the inner-most\n * dimension of input.\n *\n * ```js\n * const real = tf.tensor1d([1, 2, 3]);\n * const imag = tf.tensor1d([1, 2, 3]);\n * const x = tf.complex(real, imag);\n *\n * x.fft().print();  // tf.spectral.fft(x).print();\n * ```\n * @param input The complex input to compute an fft over.\n */\n/**\n * @doc {heading: 'Operations', subheading: 'Spectral', namespace: 'spectral'}\n */\nfunction fft_(input) {\n    util_1.assert(input.dtype === 'complex64', function () { return \"The dtype for tf.spectral.fft() must be complex64 \" +\n        (\"but got \" + input.dtype + \".\"); });\n    // Collapse all outer dimensions to a single batch dimension.\n    var innerDimensionSize = input.shape[input.shape.length - 1];\n    var batch = input.size / innerDimensionSize;\n    var input2D = input.as2D(batch, innerDimensionSize);\n    var ret = engine_1.ENGINE.runKernel(function (backend) { return backend.fft(input2D); }, { input: input });\n    return ret.reshape(input.shape);\n}\n/**\n * Inverse fast Fourier transform.\n *\n * Computes the inverse 1-dimensional discrete Fourier transform over the\n * inner-most dimension of input.\n *\n * ```js\n * const real = tf.tensor1d([1, 2, 3]);\n * const imag = tf.tensor1d([1, 2, 3]);\n * const x = tf.complex(real, imag);\n *\n * x.ifft().print();  // tf.spectral.ifft(x).print();\n * ```\n * @param input The complex input to compute an ifft over.\n */\n/**\n * @doc {heading: 'Operations', subheading: 'Spectral', namespace: 'spectral'}\n */\nfunction ifft_(input) {\n    util_1.assert(input.dtype === 'complex64', function () { return \"The dtype for tf.spectral.ifft() must be complex64 \" +\n        (\"but got \" + input.dtype + \".\"); });\n    // Collapse all outer dimensions to a single batch dimension.\n    var innerDimensionSize = input.shape[input.shape.length - 1];\n    var batch = input.size / innerDimensionSize;\n    var input2D = input.as2D(batch, innerDimensionSize);\n    var ret = engine_1.ENGINE.runKernel(function (backend) { return backend.ifft(input2D); }, { input: input });\n    return ret.reshape(input.shape);\n}\n/**\n * Real value input fast Fourier transform.\n *\n * Computes the 1-dimensional discrete Fourier transform over the\n * inner-most dimension of the real input.\n *\n * ```js\n * const real = tf.tensor1d([1, 2, 3]);\n *\n * real.rfft().print();\n * ```\n * @param input The real value input to compute an rfft over.\n */\n/**\n * @doc {heading: 'Operations', subheading: 'Spectral', namespace: 'spectral'}\n */\nfunction rfft_(input) {\n    util_1.assert(input.dtype === 'float32', function () { return \"The dtype for rfft() must be real value but got \" + input.dtype; });\n    var innerDimensionSize = input.shape[input.shape.length - 1];\n    var batch = input.size / innerDimensionSize;\n    // Complement the input with zero imaginary numbers.\n    var zeros = input.zerosLike();\n    var complexInput = complex_ops_1.complex(input, zeros).as2D(batch, innerDimensionSize);\n    var ret = exports.fft(complexInput);\n    // Exclude complex conjugations. These conjugations are put symmetrically.\n    var half = Math.floor(innerDimensionSize / 2) + 1;\n    var realValues = complex_ops_1.real(ret);\n    var imagValues = complex_ops_1.imag(ret);\n    var realComplexConjugate = realValues.split([half, innerDimensionSize - half], realValues.shape.length - 1);\n    var imagComplexConjugate = imagValues.split([half, innerDimensionSize - half], imagValues.shape.length - 1);\n    var outputShape = input.shape.slice();\n    outputShape[input.shape.length - 1] = half;\n    return complex_ops_1.complex(realComplexConjugate[0], imagComplexConjugate[0])\n        .reshape(outputShape);\n}\n/**\n * Inversed real value input fast Fourier transform.\n *\n * Computes the 1-dimensional inversed discrete Fourier transform over the\n * inner-most dimension of the real input.\n *\n * ```js\n * const real = tf.tensor1d([1, 2, 3]);\n * const imag = tf.tensor1d([0, 0, 0]);\n * const x = tf.complex(real, imag);\n *\n * x.irfft().print();\n * ```\n * @param input The real value input to compute an irfft over.\n */\n/**\n * @doc {heading: 'Operations', subheading: 'Spectral', namespace: 'spectral'}\n */\nfunction irfft_(input) {\n    var innerDimensionSize = input.shape[input.shape.length - 1];\n    var batch = input.size / innerDimensionSize;\n    if (innerDimensionSize <= 2) {\n        var complexInput = input.as2D(batch, innerDimensionSize);\n        var ret = exports.ifft(complexInput);\n        return complex_ops_1.real(ret);\n    }\n    else {\n        // The length of unique components of the DFT of a real-valued signal\n        // is 2 * (input_len - 1)\n        var outputShape = [batch, 2 * (innerDimensionSize - 1)];\n        var realInput = complex_ops_1.real(input).as2D(batch, innerDimensionSize);\n        var imagInput = complex_ops_1.imag(input).as2D(batch, innerDimensionSize);\n        var realConjugate = realInput.slice([0, 1], [batch, innerDimensionSize - 2]).reverse(1);\n        var imagConjugate = imagInput.slice([0, 1], [batch, innerDimensionSize - 2])\n            .reverse(1)\n            .mul(tensor_ops_1.scalar(-1));\n        var r = realInput.concat(realConjugate, 1);\n        var i = imagInput.concat(imagConjugate, 1);\n        var complexInput = complex_ops_1.complex(r, i).as2D(outputShape[0], outputShape[1]);\n        var ret = exports.ifft(complexInput);\n        return complex_ops_1.real(ret);\n    }\n}\nexports.fft = operation_1.op({ fft_: fft_ });\nexports.ifft = operation_1.op({ ifft_: ifft_ });\nexports.rfft = operation_1.op({ rfft_: rfft_ });\nexports.irfft = operation_1.op({ irfft_: irfft_ });\n//# sourceMappingURL=spectral_ops.js.map","\n/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar engine_1 = require(\"../engine\");\nvar sparse_to_dense = require(\"../ops/sparse_to_dense_util\");\nvar tensor_util_env_1 = require(\"../tensor_util_env\");\nvar operation_1 = require(\"./operation\");\n/**\n * Converts a sparse representation into a dense tensor.\n *\n * Builds an array dense with shape outputShape such that:\n *\n * // If sparseIndices is scalar\n * dense[i] = (i == sparseIndices ? sparseValues : defaultValue)\n *\n * // If sparseIndices is a vector, then for each i\n * dense[sparseIndices[i]] = sparseValues[i]\n *\n * // If sparseIndices is an n by d matrix, then for each i in [0, n)\n * dense[sparseIndices[i][0], ..., sparseIndices[i][d-1]] = sparseValues[i]\n * All other values in dense are set to defaultValue. If sparseValues is a\n * scalar, all sparse indices are set to this single value.\n *\n * If indices are repeated the final value is summed over all values for those\n * indices.\n *\n * ```js\n * const indices = tf.tensor1d([4, 5, 6, 1, 2, 3], 'int32');\n * const values = tf.tensor1d([10, 11, 12, 13, 14, 15], 'float32');\n * const shape = [8];\n * tf.sparseToDense(indices, values, shape).print();\n * ```\n *\n * @param sparseIndices A 0-D, 1-D, or 2-D Tensor of type int32.\n * sparseIndices[i] contains the complete index where sparseValues[i] will be\n * placed.\n * @param sparseValues A 0-D or 1-D Tensor. Values\n * corresponding to each row of sparseIndices, or a scalar value to be used for\n * all sparse indices.\n * @param outputShape Shape of the dense output tensor. the type is inferred.\n * @param defaultValue Scalar. Value to set for indices not specified in\n * sparseIndices. Defaults to zero.\n */\n/** @doc {heading: 'Operations', subheading: 'Normalization'} */\nfunction sparseToDense_(sparseIndices, sparseValues, outputShape, defaultValue) {\n    if (defaultValue === void 0) { defaultValue = 0; }\n    var $sparseIndices = tensor_util_env_1.convertToTensor(sparseIndices, 'sparseIndices', 'sparseToDense', 'int32');\n    var $sparseValues = tensor_util_env_1.convertToTensor(sparseValues, 'sparseValues', 'sparseToDense');\n    var $defaultValue = tensor_util_env_1.convertToTensor(defaultValue, 'defaultValue', 'sparseToDense', $sparseValues.dtype);\n    sparse_to_dense.validateInput($sparseIndices, $sparseValues, outputShape, $defaultValue);\n    return engine_1.ENGINE.runKernel(function (backend) { return backend.sparseToDense($sparseIndices, $sparseValues, outputShape, $defaultValue); }, { $sparseIndices: $sparseIndices, $sparseValues: $sparseValues, $defaultValue: $defaultValue });\n}\nexports.sparseToDense = operation_1.op({ sparseToDense_: sparseToDense_ });\n//# sourceMappingURL=sparse_to_dense.js.map","\nObject.defineProperty(exports, \"__esModule\", { value: true });\n/**\n * Validate sparseToDense inputs.\n *\n * @param sparseIndices A 0-D, 1-D, or 2-D Tensor of type int32.\n * sparseIndices[i] contains the complete index where sparseValues[i] will be\n * placed.\n * @param sparseValues A 0-D or 1-D Tensor. Values\n * corresponding to each row of sparseIndices, or a scalar value to be used for\n * all sparse indices.\n * @param outputShape number[]. Shape of the dense output tensor.\n * @param validateIndices boolean. indice validation is not supported, error\n * will be thrown if it is set.\n */\nfunction validateInput(sparseIndices, sparseValues, outputShape, defaultValues) {\n    if (sparseIndices.dtype !== 'int32') {\n        throw new Error('tf.sparseToDense() expects the indices to be int32 type,' +\n            (\" but the dtype was \" + sparseIndices.dtype + \".\"));\n    }\n    if (sparseIndices.rank > 2) {\n        throw new Error('sparseIndices should be a scalar, vector, or matrix,' +\n            (\" but got shape \" + sparseIndices.shape + \".\"));\n    }\n    var numElems = sparseIndices.rank > 0 ? sparseIndices.shape[0] : 1;\n    var numDims = sparseIndices.rank > 1 ? sparseIndices.shape[1] : 1;\n    if (outputShape.length !== numDims) {\n        throw new Error('outputShape has incorrect number of elements:,' +\n            (\" \" + outputShape.length + \", should be: \" + numDims + \".\"));\n    }\n    var numValues = sparseValues.size;\n    if (!(sparseValues.rank === 0 ||\n        sparseValues.rank === 1 && numValues === numElems)) {\n        throw new Error('sparseValues has incorrect shape ' +\n            (sparseValues.shape + \", should be [] or [\" + numElems + \"]\"));\n    }\n    if (sparseValues.dtype !== defaultValues.dtype) {\n        throw new Error('sparseValues.dtype must match defaultValues.dtype');\n    }\n}\nexports.validateInput = validateInput;\n//# sourceMappingURL=sparse_to_dense_util.js.map","\nObject.defineProperty(exports, \"__esModule\", { value: true });\n/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar engine_1 = require(\"../engine\");\nvar tensor_util_env_1 = require(\"../tensor_util_env\");\nvar operation_1 = require(\"./operation\");\n/**\n * Gather slices from input tensor into a Tensor with shape specified by\n * `indices`.\n *\n * `indices` is an K-dimensional integer tensor, best thought of as a\n * (K-1)-dimensional tensor of indices into input, where each element defines a\n * slice of input:\n * output[\\\\(i_0, ..., i_{K-2}\\\\)] = input[indices[\\\\(i_0, ..., i_{K-2}\\\\)]]\n *\n * Whereas in `tf.gather`, `indices` defines slices into the first dimension of\n * input, in `tf.gatherND`, `indices` defines slices into the first N dimensions\n * of input, where N = indices.shape[-1].\n *\n * The last dimension of indices can be at most the rank of input:\n * indices.shape[-1] <= input.rank\n *\n * The last dimension of `indices` corresponds to elements\n * (if indices.shape[-1] == input.rank) or slices\n * (if indices.shape[-1] < input.rank) along dimension indices.shape[-1] of\n * input.\n * The output tensor has shape\n * indices.shape[:-1] + input.shape[indices.shape[-1]:]\n *\n * Note that on CPU, if an out of bound index is found, an error is returned. On\n * GPU, if an out of bound index is found, a 0 is stored in the corresponding\n * output value.\n *\n * ```js\n * const indices = tf.tensor2d([0, 1, 1, 0], [2,2], 'int32');\n * const input = tf.tensor2d([9, 10, 11, 12], [2, 2]);\n * tf.gatherND(input, indices).print() // [10, 11]\n * ```\n *\n * @param x The tensor from which to gather values.\n * @param indices Index tensor, must be of type int32.\n */\n/** @doc {heading: 'Operations', subheading: 'Slicing and Joining'} */\nfunction gatherND_(x, indices) {\n    var $indices = tensor_util_env_1.convertToTensor(indices, 'indices', 'gatherND', 'int32');\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'gatherND');\n    return engine_1.ENGINE.runKernel(function (backend) { return backend.gatherND($x, $indices); }, { $x: $x, $indices: $indices });\n}\nexports.gatherND = operation_1.op({ gatherND_: gatherND_ });\n//# sourceMappingURL=gather_nd.js.map","\n/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar util_1 = require(\"../util\");\nvar array_ops_1 = require(\"./array_ops\");\nvar binary_ops_1 = require(\"./binary_ops\");\nvar operation_1 = require(\"./operation\");\n/**\n * Sets entries in `x` to zero at random, while scaling the entire tensor.\n * ```js\n * const x = tf.range(1, 21).reshape([10, 2]);\n * const rate = 0.5;\n * const seed = 23;\n * const noiseShape = null || x.shape;\n * const tensor = tf.dropout(x, rate, noiseShape, seed);\n * ```\n * @param x input tensor.\n * @param level fraction of the entries in the tensor that will be set to 0.\n * @param noiseShape shape of randomly generated keep/drop flags, must be\n *   broadcastable to the shape of `x`.\n * @param seed random seed to ensure determinism.\n * @returns Result of the dropout operation.\n */\nfunction dropout_(x, rate, noiseShape, seed) {\n    if (noiseShape != null && !util_1.arraysEqual(x.shape, noiseShape)) {\n        // TODO(VariableVasasMT): implement non default noise shape\n        throw new Error('Non-default noise shape is not implemented yet: ' +\n            JSON.stringify(noiseShape));\n    }\n    var multiplier = array_ops_1.randomUniform(x.shape, 0, 1, 'float32', seed).greater(rate);\n    // Scale the kept elements, so the expected sum is unchanged.\n    multiplier = multiplier.div(binary_ops_1.sub(1, rate));\n    return x.mul(multiplier);\n}\nexports.dropout = operation_1.op({ dropout_: dropout_ });\n//# sourceMappingURL=dropout.js.map","\n/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar operation_1 = require(\"../ops/operation\");\nvar concat_split_1 = require(\"./concat_split\");\nvar slice_1 = require(\"./slice\");\nvar tensor_ops_1 = require(\"./tensor_ops\");\n/**\n * Generate a Hann window.\n *\n * See: https://en.wikipedia.org/wiki/Window_function#Hann_and_Hamming_windows\n *\n * ```js\n * tf.signal.hannWindow(10).print();\n * ```\n * @param The length of window\n */\n/**\n * @doc {heading: 'Operations', subheading: 'Signal', namespace: 'signal'}\n */\nfunction hannWindow_(windowLength) {\n    return cosineWindow(windowLength, 0.5, 0.5);\n}\n/**\n * Generate a hamming window.\n *\n * See: https://en.wikipedia.org/wiki/Window_function#Hann_and_Hamming_windows\n *\n * ```js\n * tf.signal.hammingWindow(10).print();\n * ```\n * @param The length of window\n */\n/**\n * @doc {heading: 'Operations', subheading: 'Signal', namespace: 'signal'}\n */\nfunction hammingWindow_(windowLength) {\n    return cosineWindow(windowLength, 0.54, 0.46);\n}\n/**\n * Expands input into frames of frameLength.\n * Slides a window size with frameStep.\n *\n * ```js\n * tf.signal.frame([1, 2, 3], 2, 1).print();\n * ```\n * @param signal The input tensor to be expanded\n * @param frameLength Length of each frame\n * @param frameStep The frame hop size in samples.\n */\n/**\n * @doc {heading: 'Operations', subheading: 'Signal', namespace: 'signal'}\n */\nfunction frame_(signal, frameLength, frameStep, padEnd, padValue) {\n    if (padEnd === void 0) { padEnd = false; }\n    if (padValue === void 0) { padValue = 0; }\n    var start = 0;\n    var output = [];\n    while (start + frameLength <= signal.size) {\n        output.push(slice_1.slice(signal, start, frameLength));\n        start += frameStep;\n    }\n    if (padEnd) {\n        var padLen = (start + frameLength) - signal.size;\n        var pad = concat_split_1.concat([slice_1.slice(signal, start, frameLength - padLen), tensor_ops_1.fill([padLen], padValue)]);\n        output.push(pad);\n    }\n    if (output.length === 0) {\n        return tensor_ops_1.tensor2d([], [0, frameLength]);\n    }\n    return concat_split_1.concat(output).as2D(output.length, frameLength);\n}\nfunction cosineWindow(windowLength, a, b) {\n    var even = 1 - windowLength % 2;\n    var newValues = new Float32Array(windowLength);\n    for (var i = 0; i < windowLength; ++i) {\n        var cosArg = (2.0 * Math.PI * i) / (windowLength + even - 1);\n        newValues[i] = a - b * Math.cos(cosArg);\n    }\n    return tensor_ops_1.tensor1d(newValues, 'float32');\n}\nexports.hannWindow = operation_1.op({ hannWindow_: hannWindow_ });\nexports.hammingWindow = operation_1.op({ hammingWindow_: hammingWindow_ });\nexports.frame = operation_1.op({ frame_: frame_ });\n//# sourceMappingURL=signal_ops.js.map","\n/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar gradients_1 = require(\"../gradients\");\nvar tensor_util_env_1 = require(\"../tensor_util_env\");\nvar util_1 = require(\"../util\");\nvar axis_util_1 = require(\"./axis_util\");\nvar binary_ops_1 = require(\"./binary_ops\");\nvar operation_1 = require(\"./operation\");\nvar tensor_ops_1 = require(\"./tensor_ops\");\nvar Reduction;\n(function (Reduction) {\n    Reduction[Reduction[\"NONE\"] = 0] = \"NONE\";\n    Reduction[Reduction[\"MEAN\"] = 1] = \"MEAN\";\n    Reduction[Reduction[\"SUM\"] = 2] = \"SUM\";\n    Reduction[Reduction[\"SUM_BY_NONZERO_WEIGHTS\"] = 3] = \"SUM_BY_NONZERO_WEIGHTS\";\n})(Reduction = exports.Reduction || (exports.Reduction = {}));\n/**\n * Computes the weighted loss between two tensors.\n *\n * @param losses Tensor of shape `[batch_size, d1, ... dN]`.\n * @param weights Tensor whose rank is either 0, or the same rank as\n *    `losses`, and must be broadcastable to `losses` (i.e., all\n *    dimensions must be either `1`, or the same as the corresponding\n *    `losses` dimension).\n */\n/** @doc {heading: 'Training', subheading: 'Losses', namespace: 'losses'} */\nfunction computeWeightedLoss_(losses, weights, reduction) {\n    if (reduction === void 0) { reduction = Reduction.SUM_BY_NONZERO_WEIGHTS; }\n    var $losses = tensor_util_env_1.convertToTensor(losses, 'losses', 'computeWeightedLoss');\n    var $weights = null;\n    if (weights != null) {\n        $weights = tensor_util_env_1.convertToTensor(weights, 'weights', 'computeWeightedLoss');\n    }\n    var weightedLoss = ($weights == null) ? $losses : $losses.mul($weights);\n    if (reduction === Reduction.NONE) {\n        return weightedLoss;\n    }\n    if (reduction === Reduction.SUM) {\n        return weightedLoss.sum();\n    }\n    if (reduction === Reduction.MEAN) {\n        if ($weights == null) {\n            return weightedLoss.mean();\n        }\n        else {\n            var broadcastFactor = $losses.size / $weights.size;\n            var result = weightedLoss.sum().div($weights.sum());\n            return broadcastFactor > 1 ? result.div(tensor_ops_1.scalar(broadcastFactor)) :\n                result;\n        }\n    }\n    if (reduction === Reduction.SUM_BY_NONZERO_WEIGHTS) {\n        if ($weights == null) {\n            return weightedLoss.sum().div(tensor_ops_1.scalar($losses.size));\n        }\n        else {\n            var broadcastedWeights = $weights.mul(tensor_ops_1.ones($losses.shape));\n            var numNonZeros = broadcastedWeights.notEqual(tensor_ops_1.scalar(0)).sum().toFloat();\n            return weightedLoss.sum().div(numNonZeros);\n        }\n    }\n    throw Error(\"Unknown reduction: \" + reduction);\n}\n/**\n * Computes the absolute difference loss between two tensors.\n *\n * @param labels The ground truth output tensor, same dimensions as\n *    'predictions'.\n * @param predictions The predicted outputs.\n * @param weights Tensor whose rank is either 0, or the same rank as\n *    `labels`, and must be broadcastable to `labels` (i.e., all dimensions\n *    must be either `1`, or the same as the corresponding `losses`\n *    dimension).\n * @param reduction Type of reduction to apply to loss. Should be of type\n *    `Reduction`\n */\n/** @doc {heading: 'Training', subheading: 'Losses', namespace: 'losses'} */\nfunction absoluteDifference_(labels, predictions, weights, reduction) {\n    if (reduction === void 0) { reduction = Reduction.SUM_BY_NONZERO_WEIGHTS; }\n    var $labels = tensor_util_env_1.convertToTensor(labels, 'labels', 'absoluteDifference');\n    var $predictions = tensor_util_env_1.convertToTensor(predictions, 'predictions', 'absoluteDifference');\n    var $weights = null;\n    if (weights != null) {\n        $weights = tensor_util_env_1.convertToTensor(weights, 'weights', 'absoluteDifference');\n    }\n    util_1.assertShapesMatch($labels.shape, $predictions.shape, 'Error in absoluteDifference: ');\n    var losses = $labels.sub($predictions).abs();\n    return exports.computeWeightedLoss(losses, $weights, reduction);\n}\n/**\n * Computes the mean squared error between two tensors.\n *\n * @param labels The ground truth output tensor, same dimensions as\n *    'predictions'.\n * @param predictions The predicted outputs.\n * @param weights Tensor whose rank is either 0, or the same rank as\n *    `labels`, and must be broadcastable to `labels` (i.e., all dimensions\n *    must be either `1`, or the same as the corresponding `losses`\n *    dimension).\n * @param reduction Type of reduction to apply to loss. Should be of type\n *    `Reduction`\n */\n/** @doc {heading: 'Training', subheading: 'Losses', namespace: 'losses'} */\nfunction meanSquaredError_(labels, predictions, weights, reduction) {\n    if (reduction === void 0) { reduction = Reduction.SUM_BY_NONZERO_WEIGHTS; }\n    var $labels = tensor_util_env_1.convertToTensor(labels, 'labels', 'meanSquaredError');\n    var $predictions = tensor_util_env_1.convertToTensor(predictions, 'predictions', 'meanSquaredError');\n    var $weights = null;\n    if (weights != null) {\n        $weights = tensor_util_env_1.convertToTensor(weights, 'weights', 'meanSquaredError');\n    }\n    util_1.assertShapesMatch($labels.shape, $predictions.shape, 'Error in meanSquaredError: ');\n    var losses = $labels.squaredDifference($predictions);\n    return exports.computeWeightedLoss(losses, $weights, reduction);\n}\n/**\n * Computes the cosine distance loss between two tensors.\n *\n * @param labels The ground truth output tensor, same dimensions as\n *    'predictions'.\n * @param predictions The predicted outputs.\n * @param axis The dimension along which the cosine distance is computed.\n * @param weights Tensor whose rank is either 0, or the same rank as\n *    `labels`, and must be broadcastable to `labels` (i.e., all dimensions\n *    must be either `1`, or the same as the corresponding `losses`\n *    dimension).\n * @param reduction Type of reduction to apply to loss. Should be of type\n *    `Reduction`\n */\n/** @doc {heading: 'Training', subheading: 'Losses', namespace: 'losses'} */\nfunction cosineDistance_(labels, predictions, axis, weights, reduction) {\n    if (reduction === void 0) { reduction = Reduction.SUM_BY_NONZERO_WEIGHTS; }\n    var $labels = tensor_util_env_1.convertToTensor(labels, 'labels', 'cosineDistance');\n    var $predictions = tensor_util_env_1.convertToTensor(predictions, 'predictions', 'cosineDistance');\n    var $weights = null;\n    if (weights != null) {\n        $weights = tensor_util_env_1.convertToTensor(weights, 'weights', 'cosineDistance');\n    }\n    util_1.assertShapesMatch($labels.shape, $predictions.shape, 'Error in cosineDistance: ');\n    var one = tensor_ops_1.scalar(1);\n    var losses = one.sub($labels.mul($predictions).sum(axis, true));\n    return exports.computeWeightedLoss(losses, $weights, reduction);\n}\n/**\n * Computes the Hinge loss between two tensors.\n *\n * @param labels The ground truth output tensor, same dimensions as\n *    'predictions'.\n * @param predictions The predicted outputs.\n * @param weights Tensor whose rank is either 0, or the same rank as\n *    `labels`, and must be broadcastable to `labels` (i.e., all dimensions\n *    must be either `1`, or the same as the corresponding `losses`\n *    dimension).\n * @param reduction Type of reduction to apply to loss. Should be of type\n *    `Reduction`\n */\n/** @doc {heading: 'Training', subheading: 'Losses', namespace: 'losses'} */\nfunction hingeLoss_(labels, predictions, weights, reduction) {\n    if (reduction === void 0) { reduction = Reduction.SUM_BY_NONZERO_WEIGHTS; }\n    var $labels = tensor_util_env_1.convertToTensor(labels, 'labels', 'hingeLoss');\n    var $predictions = tensor_util_env_1.convertToTensor(predictions, 'predictions', 'hingeLoss');\n    var $weights = null;\n    if (weights != null) {\n        $weights = tensor_util_env_1.convertToTensor(weights, 'weights', 'hingeLoss');\n    }\n    util_1.assertShapesMatch($labels.shape, $predictions.shape, 'Error in hingeLoss: ');\n    var one = tensor_ops_1.scalar(1);\n    // Convert binary labels to (-1, 1)\n    $labels = tensor_ops_1.scalar(2).mul($labels).sub(one);\n    var losses = one.sub($labels.mul($predictions)).relu();\n    return exports.computeWeightedLoss(losses, $weights, reduction);\n}\n/**\n * Computes the log loss between two tensors.\n *\n * @param labels The ground truth output tensor, same dimensions as\n *    'predictions'.\n * @param predictions The predicted outputs.\n * @param weights Tensor whose rank is either 0, or the same rank as\n *    `labels`, and must be broadcastable to `labels` (i.e., all dimensions\n *    must be either `1`, or the same as the corresponding `losses`\n *    dimension).\n * @param epsilon A small increment to avoid taking log of zero\n * @param reduction Type of reduction to apply to loss. Should be of type\n *    `Reduction`\n */\n/** @doc {heading: 'Training', subheading: 'Losses', namespace: 'losses'} */\nfunction logLoss_(labels, predictions, weights, epsilon, reduction) {\n    if (epsilon === void 0) { epsilon = 1e-7; }\n    if (reduction === void 0) { reduction = Reduction.SUM_BY_NONZERO_WEIGHTS; }\n    var $labels = tensor_util_env_1.convertToTensor(labels, 'labels', 'logLoss');\n    var $predictions = tensor_util_env_1.convertToTensor(predictions, 'predictions', 'logLoss');\n    var $weights = null;\n    if (weights != null) {\n        $weights = tensor_util_env_1.convertToTensor(weights, 'weights', 'logLoss');\n    }\n    util_1.assertShapesMatch($labels.shape, $predictions.shape, 'Error in logLoss: ');\n    var one = tensor_ops_1.scalar(1);\n    var epsilonScalar = tensor_ops_1.scalar(epsilon);\n    var losses = $labels.mul($predictions.add(epsilonScalar).log())\n        .neg()\n        .sub(one.sub($labels).mul(one.sub($predictions).add(epsilonScalar).log()));\n    return exports.computeWeightedLoss(losses, $weights, reduction);\n}\nfunction sigmoidCrossEntropyWithLogits_(labels, logits) {\n    var $labels = tensor_util_env_1.convertToTensor(labels, 'labels', 'sigmoidCrossEntropyWithLogits');\n    var $logits = tensor_util_env_1.convertToTensor(logits, 'logits', 'sigmoidCrossEntropyWithLogits');\n    util_1.assertShapesMatch($labels.shape, $logits.shape, 'Error in sigmoidCrossEntropyWithLogits: ');\n    /**\n     * Implementation Details:\n     *\n     * For brevity, let `x = logits`, `z = labels`.  The logistic loss is\n     *     z * -log(sigmoid(x)) + (1 - z) * -log(1 - sigmoid(x))\n     *   = z * -log(1 / (1 + exp(-x))) + (1 - z) * -log(exp(-x) / (1 + exp(-x)))\n     *   = z * log(1 + exp(-x)) + (1 - z) * (-log(exp(-x)) + log(1 + exp(-x)))\n     *   = z * log(1 + exp(-x)) + (1 - z) * (x + log(1 + exp(-x))\n     *   = (1 - z) * x + log(1 + exp(-x))\n     *   = x - x * z + log(1 + exp(-x))\n     *\n     *   For x < 0, to avoid overflow in exp(-x), we reformulate the above\n     *     x - x * z + log(1 + exp(-x))\n     *   = log(exp(x)) - x * z + log(1 + exp(-x))\n     *   = - x * z + log(1 + exp(x))\n     *\n     * Hence, to ensure stability and avoid overflow, the implementation uses\n     * this equivalent formulation:\n     *     max(x, 0) - x * z + log(1 + exp(-abs(x)))\n     */\n    var maxOutput = $logits.relu();\n    var outputXTarget = $logits.mul($labels);\n    var sigmoidOutput = $logits.abs().neg().exp().log1p();\n    return maxOutput.sub(outputXTarget).add(sigmoidOutput);\n}\n/**\n * Computes the sigmoid cross entropy loss between two tensors.\n *\n * If labelSmoothing is nonzero, smooth the labels towards 1/2:\n *\n *   newMulticlassLabels = multiclassLabels * (1 - labelSmoothing)\n *                         + 0.5 * labelSmoothing\n *\n * @param multiClassLabels The ground truth output tensor of shape\n * [batch_size, num_classes], same dimensions as 'predictions'.\n * @param logits The predicted outputs.\n * @param weights Tensor whose rank is either 0, or the same rank as\n *    `labels`, and must be broadcastable to `labels` (i.e., all dimensions\n *    must be either `1`, or the same as the corresponding `losses`\n *    dimension).\n * @param labelSmoothing If greater than 0, then smooth the labels.\n * @param reduction Type of reduction to apply to loss. Should be of type\n *    `Reduction`\n */\n/** @doc { heading: 'Training', subheading: 'Losses', namespace: 'losses' } */\nfunction sigmoidCrossEntropy_(multiClassLabels, logits, weights, labelSmoothing, reduction) {\n    if (labelSmoothing === void 0) { labelSmoothing = 0; }\n    if (reduction === void 0) { reduction = Reduction.SUM_BY_NONZERO_WEIGHTS; }\n    var $multiClassLabels = tensor_util_env_1.convertToTensor(multiClassLabels, 'multiClassLabels', 'sigmoidCrossEntropy');\n    var $logits = tensor_util_env_1.convertToTensor(logits, 'logits', 'sigmoidCrossEntropy');\n    var $weights = null;\n    if (weights != null) {\n        $weights = tensor_util_env_1.convertToTensor(weights, 'weights', 'sigmoidCrossEntropy');\n    }\n    util_1.assertShapesMatch($multiClassLabels.shape, $logits.shape, 'Error in sigmoidCrossEntropy: ');\n    if (labelSmoothing > 0) {\n        var labelSmoothingScalar = tensor_ops_1.scalar(labelSmoothing);\n        var one = tensor_ops_1.scalar(1);\n        var half = tensor_ops_1.scalar(0.5);\n        $multiClassLabels = $multiClassLabels.mul(one.sub(labelSmoothingScalar))\n            .add(half.mul(labelSmoothingScalar));\n    }\n    var losses = sigmoidCrossEntropyWithLogits_($multiClassLabels, $logits);\n    return exports.computeWeightedLoss(losses, $weights, reduction);\n}\n/**\n * Computes the huber loss between two tensors.\n *\n * @param labels The ground truth output tensor, same dimensions as\n *    'predictions'.\n * @param predictions The predicted outputs.\n * @param weights Tensor whose rank is either 0, or the same rank as\n *    `labels`, and must be broadcastable to `labels` (i.e., all dimensions\n *    must be either `1`, or the same as the corresponding `losses`\n *    dimension).\n * @param delta Point where huber loss changes from quadratic to linear.\n * @param reduction Type of reduction to apply to loss. Should be of type\n *    `Reduction`.\n */\n/** @doc {heading: 'Training', subheading: 'Losses', namespace: 'losses'} */\nfunction huberLoss_(labels, predictions, weights, delta, reduction) {\n    if (delta === void 0) { delta = 1.0; }\n    if (reduction === void 0) { reduction = Reduction.SUM_BY_NONZERO_WEIGHTS; }\n    var $labels = tensor_util_env_1.convertToTensor(labels, 'labels', 'huberLoss');\n    var $predictions = tensor_util_env_1.convertToTensor(predictions, 'predictions', 'huberLoss');\n    var $weights = null;\n    if (weights != null) {\n        $weights = tensor_util_env_1.convertToTensor(weights, 'weights', 'huberLoss');\n    }\n    util_1.assertShapesMatch($labels.shape, $predictions.shape, 'Error in huberLoss: ');\n    var deltaScalar = tensor_ops_1.scalar(delta);\n    var error = $predictions.sub($labels).abs();\n    var quadratic = binary_ops_1.minimum(error, deltaScalar);\n    var linear = error.sub(quadratic);\n    var losses = tensor_ops_1.scalar(0.5).mul(quadratic.square()).add(deltaScalar.mul(linear));\n    return exports.computeWeightedLoss(losses, $weights, reduction);\n}\n/**\n * Computes softmax cross entropy between logits and labels.\n *\n * Measures the probability error in discrete classification tasks in which\n * the classes are mutually exclusive (each entry is in exactly one class).\n * For example, each CIFAR-10 image is labeled with one and only one label: an\n * image can be a dog or a truck, but not both.\n *\n * `NOTE`: While the classes are mutually exclusive, their probabilities need\n * not be. All that is required is that each row of labels is a valid\n * probability distribution. If they are not, the computation of the gradient\n * will be incorrect.\n *\n * `WARNING`: This op expects unscaled logits, since it performs a softmax on\n * logits internally for efficiency. Do not call this op with the output of\n * softmax, as it will produce incorrect results.\n *\n * logits and labels must have the same shape, e.g. [batch_size, num_classes]\n * and the same dtype.\n * @param labels The labels array.\n * @param logits The logits array.\n * @param dim The dimension softmax would be performed on. Defaults to `-1`\n *     which indicates the last dimension.\n */\nfunction softmaxCrossEntropyWithLogits_(labels, logits, dim) {\n    if (dim === void 0) { dim = -1; }\n    if (dim === -1) {\n        dim = logits.rank - 1;\n    }\n    if (dim !== logits.rank - 1) {\n        throw Error(\"Softmax cross entropy along a non-last dimension is not yet \" +\n            (\"supported. Labels / logits was rank \" + logits.rank + \" \") +\n            (\"and dim was \" + dim));\n    }\n    // Use a custom gradient for numerical stability.\n    var customOp = gradients_1.customGrad(function (labels, logits, save) {\n        // Reference:\n        //   1. http://cs231n.github.io/linear-classify/#softmax\n        //   2. https://blog.feedly.com/tricks-of-the-trade-logsumexp/\n        var keepDims = true;\n        var lse = logits.logSumExp([dim], keepDims);\n        var logResult = logits.toFloat().sub(lse);\n        save([labels, logResult]);\n        var costVector = logResult.mul(labels).neg();\n        var value = costVector.sum([dim]);\n        var gradFunc = function (dy, saved) {\n            var labels = saved[0], logResult = saved[1];\n            var dyShape = axis_util_1.expandShapeToKeepDim(dy.shape, [dim]);\n            return [\n                dy.reshape(dyShape).mul(labels.toFloat().sub(logResult.exp())),\n                dy.reshape(dyShape).mul(logResult.exp().sub(labels.toFloat())),\n            ];\n        };\n        return { value: value, gradFunc: gradFunc };\n    });\n    return customOp(labels, logits);\n}\n/**\n * Computes the softmax cross entropy loss between two tensors.\n *\n * If labelSmoothing is nonzero, smooth the labels towards 1/2:\n *\n *   newOnehotLabels = onehotLabels * (1 - labelSmoothing)\n *                         + labelSmoothing / numClasses\n *\n * @param onehotLabels One hot encoded labels\n *    [batch_size, num_classes], same dimensions as 'predictions'.\n * @param logits The predicted outputs.\n * @param weights Tensor whose rank is either 0, or 1, and must be\n *    broadcastable to `loss`  of shape [batch_size]\n * @param labelSmoothing If greater than 0, then smooth the labels.\n * @param reduction Type of reduction to apply to loss. Should be of type\n *    `Reduction`\n */\n/** @doc { heading: 'Training', subheading: 'Losses', namespace: 'losses' } */\nfunction softmaxCrossEntropy_(onehotLabels, logits, weights, labelSmoothing, reduction) {\n    if (labelSmoothing === void 0) { labelSmoothing = 0; }\n    if (reduction === void 0) { reduction = Reduction.SUM_BY_NONZERO_WEIGHTS; }\n    var $onehotLabels = tensor_util_env_1.convertToTensor(onehotLabels, 'onehotLabels', 'softmaxCrossEntropy');\n    var $logits = tensor_util_env_1.convertToTensor(logits, 'logits', 'softmaxCrossEntropy');\n    var $weights = null;\n    if (weights != null) {\n        $weights = tensor_util_env_1.convertToTensor(weights, 'weights', 'softmaxCrossEntropy');\n    }\n    util_1.assertShapesMatch($onehotLabels.shape, $logits.shape, 'Error in softmaxCrossEntropy: ');\n    if (labelSmoothing > 0) {\n        var labelSmoothingScalar = tensor_ops_1.scalar(labelSmoothing);\n        var one = tensor_ops_1.scalar(1);\n        var numClasses = tensor_ops_1.scalar($onehotLabels.shape[1]);\n        $onehotLabels = $onehotLabels.mul(one.sub(labelSmoothingScalar))\n            .add(labelSmoothingScalar.div(numClasses));\n    }\n    var losses = softmaxCrossEntropyWithLogits_($onehotLabels, $logits);\n    return exports.computeWeightedLoss(losses, $weights, reduction);\n}\nexports.absoluteDifference = operation_1.op({ absoluteDifference_: absoluteDifference_ });\nexports.computeWeightedLoss = operation_1.op({ computeWeightedLoss_: computeWeightedLoss_ });\nexports.cosineDistance = operation_1.op({ cosineDistance_: cosineDistance_ });\nexports.hingeLoss = operation_1.op({ hingeLoss_: hingeLoss_ });\nexports.huberLoss = operation_1.op({ huberLoss_: huberLoss_ });\nexports.logLoss = operation_1.op({ logLoss_: logLoss_ });\nexports.meanSquaredError = operation_1.op({ meanSquaredError_: meanSquaredError_ });\nexports.sigmoidCrossEntropy = operation_1.op({ sigmoidCrossEntropy_: sigmoidCrossEntropy_ });\nexports.softmaxCrossEntropy = operation_1.op({ softmaxCrossEntropy_: softmaxCrossEntropy_ });\n//# sourceMappingURL=loss_ops.js.map","\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\n/**\n * Linear algebra ops.\n */\nvar engine_1 = require(\"../engine\");\nvar globals_1 = require(\"../globals\");\nvar util_1 = require(\"../util\");\nvar array_ops_1 = require(\"./array_ops\");\nvar concat_split_1 = require(\"./concat_split\");\nvar norm_1 = require(\"./norm\");\nvar operation_1 = require(\"./operation\");\nvar reduction_ops_1 = require(\"./reduction_ops\");\nvar tensor_ops_1 = require(\"./tensor_ops\");\n/**\n * Gram-Schmidt orthogonalization.\n *\n * ```js\n * const x = tf.tensor2d([[1, 2], [3, 4]]);\n * let y = tf.linalg.gramSchmidt(x);\n * y.print();\n * console.log('Othogonalized:');\n * y.dot(y.transpose()).print();  // should be nearly the identity matrix.\n * console.log('First row direction maintained:');\n * const data = await y.array();\n * console.log(data[0][1] / data[0][0]);  // should be nearly 2.\n * ```\n *\n * @param xs The vectors to be orthogonalized, in one of the two following\n *   formats:\n *   - An Array of `tf.Tensor1D`.\n *   - A `tf.Tensor2D`, i.e., a matrix, in which case the vectors are the rows\n *     of `xs`.\n *   In each case, all the vectors must have the same length and the length\n *   must be greater than or equal to the number of vectors.\n * @returns The orthogonalized and normalized vectors or matrix.\n *   Orthogonalization means that the vectors or the rows of the matrix\n *   are orthogonal (zero inner products). Normalization means that each\n *   vector or each row of the matrix has an L2 norm that equals `1`.\n */\n/**\n * @doc {heading:'Operations',\n *       subheading:'Linear Algebra',\n *       namespace:'linalg'}\n */\nfunction gramSchmidt_(xs) {\n    var inputIsTensor2D;\n    if (Array.isArray(xs)) {\n        inputIsTensor2D = false;\n        util_1.assert(xs != null && xs.length > 0, function () { return 'Gram-Schmidt process: input must not be null, undefined, or ' +\n            'empty'; });\n        var dim_1 = xs[0].shape[0];\n        var _loop_1 = function (i) {\n            util_1.assert(xs[i].shape[0] === dim_1, function () {\n                return 'Gram-Schmidt: Non-unique lengths found in the input vectors: ' +\n                    (\"(\" + xs[i].shape[0] + \" vs. \" + dim_1 + \")\");\n            });\n        };\n        for (var i = 1; i < xs.length; ++i) {\n            _loop_1(i);\n        }\n    }\n    else {\n        inputIsTensor2D = true;\n        xs = concat_split_1.split(xs, xs.shape[0], 0).map(function (x) { return array_ops_1.squeeze(x, [0]); });\n    }\n    util_1.assert(xs.length <= xs[0].shape[0], function () { return \"Gram-Schmidt: Number of vectors (\" + xs.length + \") exceeds \" +\n        (\"number of dimensions (\" + xs[0].shape[0] + \").\"); });\n    var ys = [];\n    var xs1d = xs;\n    var _loop_2 = function (i) {\n        ys.push(engine_1.ENGINE.tidy(function () {\n            var x = xs1d[i];\n            if (i > 0) {\n                for (var j = 0; j < i; ++j) {\n                    var proj = reduction_ops_1.sum(ys[j].mulStrict(x)).mul(ys[j]);\n                    x = x.sub(proj);\n                }\n            }\n            return x.div(norm_1.norm(x, 'euclidean'));\n        }));\n    };\n    for (var i = 0; i < xs.length; ++i) {\n        _loop_2(i);\n    }\n    if (inputIsTensor2D) {\n        return array_ops_1.stack(ys, 0);\n    }\n    else {\n        return ys;\n    }\n}\n/**\n * Compute QR decomposition of m-by-n matrix using Householder transformation.\n *\n * Implementation based on\n *   [http://www.cs.cornell.edu/~bindel/class/cs6210-f09/lec18.pdf]\n * (http://www.cs.cornell.edu/~bindel/class/cs6210-f09/lec18.pdf)\n *\n * ```js\n * const a = tf.tensor2d([[1, 2], [3, 4]]);\n * let [q, r] = tf.linalg.qr(a);\n * console.log('Q');\n * q.print();\n * console.log('R');\n * r.print();\n * console.log('Orthogonalized');\n * q.dot(q.transpose()).print()  // should be nearly the identity matrix.\n * console.log('Reconstructed');\n * q.dot(r).print(); // should be nearly [[1, 2], [3, 4]];\n * ```\n *\n * @param x The `tf.Tensor` to be QR-decomposed. Must have rank >= 2. Suppose\n *   it has the shape `[..., M, N]`.\n * @param fullMatrices An optional boolean parameter. Defaults to `false`.\n *   If `true`, compute full-sized `Q`. If `false` (the default),\n *   compute only the leading N columns of `Q` and `R`.\n * @returns An `Array` of two `tf.Tensor`s: `[Q, R]`. `Q` is a unitary matrix,\n *   i.e., its columns all have unit norm and are mutually orthogonal.\n *   If `M >= N`,\n *     If `fullMatrices` is `false` (default),\n *       - `Q` has a shape of `[..., M, N]`,\n *       - `R` has a shape of `[..., N, N]`.\n *     If `fullMatrices` is `true` (default),\n *       - `Q` has a shape of `[..., M, M]`,\n *       - `R` has a shape of `[..., M, N]`.\n *   If `M < N`,\n *     - `Q` has a shape of `[..., M, M]`,\n *     - `R` has a shape of `[..., M, N]`.\n * @throws If the rank of `x` is less than 2.\n */\n/**\n * @doc {heading:'Operations',\n *       subheading:'Linear Algebra',\n *       namespace:'linalg'}\n */\nfunction qr_(x, fullMatrices) {\n    if (fullMatrices === void 0) { fullMatrices = false; }\n    if (x.rank < 2) {\n        throw new Error(\"qr() requires input tensor to have a rank >= 2, but got rank \" + x.rank);\n    }\n    else if (x.rank === 2) {\n        return qr2d(x, fullMatrices);\n    }\n    else {\n        // Rank > 2.\n        // TODO(cais): Below we split the input into individual 2D tensors,\n        //   perform QR decomposition on them and then stack the results back\n        //   together. We should explore whether this can be parallelized.\n        var outerDimsProd = x.shape.slice(0, x.shape.length - 2)\n            .reduce(function (value, prev) { return value * prev; });\n        var x2ds = array_ops_1.unstack(x.reshape([\n            outerDimsProd, x.shape[x.shape.length - 2],\n            x.shape[x.shape.length - 1]\n        ]), 0);\n        var q2ds_1 = [];\n        var r2ds_1 = [];\n        x2ds.forEach(function (x2d) {\n            var _a = qr2d(x2d, fullMatrices), q2d = _a[0], r2d = _a[1];\n            q2ds_1.push(q2d);\n            r2ds_1.push(r2d);\n        });\n        var q = array_ops_1.stack(q2ds_1, 0).reshape(x.shape);\n        var r = array_ops_1.stack(r2ds_1, 0).reshape(x.shape);\n        return [q, r];\n    }\n}\nfunction qr2d(x, fullMatrices) {\n    if (fullMatrices === void 0) { fullMatrices = false; }\n    return engine_1.ENGINE.tidy(function () {\n        if (x.shape.length !== 2) {\n            throw new Error(\"qr2d() requires a 2D Tensor, but got a \" + x.shape.length + \"D Tensor.\");\n        }\n        var m = x.shape[0];\n        var n = x.shape[1];\n        var q = array_ops_1.eye(m); // Orthogonal transform so far.\n        var r = x.clone(); // Transformed matrix so far.\n        var one2D = tensor_ops_1.tensor2d([[1]], [1, 1]);\n        var w = one2D.clone();\n        var iters = m >= n ? n : m;\n        var _loop_3 = function (j) {\n            var _a;\n            // This tidy within the for-loop ensures we clean up temporary\n            // tensors as soon as they are no longer needed.\n            var rTemp = r;\n            var wTemp = w;\n            var qTemp = q;\n            _a = engine_1.ENGINE.tidy(function () {\n                // Find H = I - tau * w * w', to put zeros below R(j, j).\n                var rjEnd1 = r.slice([j, j], [m - j, 1]);\n                var normX = rjEnd1.norm();\n                var rjj = r.slice([j, j], [1, 1]);\n                var s = rjj.sign().neg();\n                var u1 = rjj.sub(s.mul(normX));\n                var wPre = rjEnd1.div(u1);\n                if (wPre.shape[0] === 1) {\n                    w = one2D.clone();\n                }\n                else {\n                    w = one2D.concat(wPre.slice([1, 0], [wPre.shape[0] - 1, wPre.shape[1]]), 0);\n                }\n                var tau = s.matMul(u1).div(normX).neg();\n                // -- R := HR, Q := QH.\n                var rjEndAll = r.slice([j, 0], [m - j, n]);\n                var tauTimesW = tau.mul(w);\n                if (j === 0) {\n                    r = rjEndAll.sub(tauTimesW.matMul(w.transpose().matMul(rjEndAll)));\n                }\n                else {\n                    r = r.slice([0, 0], [j, n])\n                        .concat(rjEndAll.sub(tauTimesW.matMul(w.transpose().matMul(rjEndAll))), 0);\n                }\n                var qAllJEnd = q.slice([0, j], [m, q.shape[1] - j]);\n                if (j === 0) {\n                    q = qAllJEnd.sub(qAllJEnd.matMul(w).matMul(tauTimesW.transpose()));\n                }\n                else {\n                    q = q.slice([0, 0], [m, j])\n                        .concat(qAllJEnd.sub(qAllJEnd.matMul(w).matMul(tauTimesW.transpose())), 1);\n                }\n                return [w, r, q];\n            }), w = _a[0], r = _a[1], q = _a[2];\n            globals_1.dispose([rTemp, wTemp, qTemp]);\n        };\n        for (var j = 0; j < iters; ++j) {\n            _loop_3(j);\n        }\n        if (!fullMatrices && m > n) {\n            q = q.slice([0, 0], [m, n]);\n            r = r.slice([0, 0], [n, n]);\n        }\n        return [q, r];\n    });\n}\nexports.gramSchmidt = operation_1.op({ gramSchmidt_: gramSchmidt_ });\nexports.qr = operation_1.op({ qr_: qr_ });\n//# sourceMappingURL=linalg_ops.js.map","\n/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : new P(function (resolve) { resolve(result.value); }).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nvar __generator = (this && this.__generator) || function (thisArg, body) {\n    var _ = { label: 0, sent: function() { if (t[0] & 1) throw t[1]; return t[1]; }, trys: [], ops: [] }, f, y, t, g;\n    return g = { next: verb(0), \"throw\": verb(1), \"return\": verb(2) }, typeof Symbol === \"function\" && (g[Symbol.iterator] = function() { return this; }), g;\n    function verb(n) { return function (v) { return step([n, v]); }; }\n    function step(op) {\n        if (f) throw new TypeError(\"Generator is already executing.\");\n        while (_) try {\n            if (f = 1, y && (t = op[0] & 2 ? y[\"return\"] : op[0] ? y[\"throw\"] || ((t = y[\"return\"]) && t.call(y), 0) : y.next) && !(t = t.call(y, op[1])).done) return t;\n            if (y = 0, t) op = [op[0] & 2, t.value];\n            switch (op[0]) {\n                case 0: case 1: t = op; break;\n                case 4: _.label++; return { value: op[1], done: false };\n                case 5: _.label++; y = op[1]; op = [0]; continue;\n                case 7: op = _.ops.pop(); _.trys.pop(); continue;\n                default:\n                    if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) { _ = 0; continue; }\n                    if (op[0] === 3 && (!t || (op[1] > t[0] && op[1] < t[3]))) { _.label = op[1]; break; }\n                    if (op[0] === 6 && _.label < t[1]) { _.label = t[1]; t = op; break; }\n                    if (t && _.label < t[2]) { _.label = t[2]; _.ops.push(op); break; }\n                    if (t[2]) _.ops.pop();\n                    _.trys.pop(); continue;\n            }\n            op = body.call(thisArg, _);\n        } catch (e) { op = [6, e]; y = 0; } finally { f = t = 0; }\n        if (op[0] & 5) throw op[1]; return { value: op[0] ? op[1] : void 0, done: true };\n    }\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar non_max_suppression_impl_1 = require(\"../backends/non_max_suppression_impl\");\nvar engine_1 = require(\"../engine\");\nvar tensor_util_env_1 = require(\"../tensor_util_env\");\nvar util = require(\"../util\");\nvar operation_1 = require(\"./operation\");\n/**\n * Bilinear resize a batch of 3D images to a new shape.\n *\n * @param images The images, of rank 4 or rank 3, of shape\n *     `[batch, height, width, inChannels]`. If rank 3, batch of 1 is assumed.\n * @param size The new shape `[newHeight, newWidth]` to resize the\n *     images to. Each channel is resized individually.\n * @param alignCorners Defaults to False. If true, rescale\n *     input by `(new_height - 1) / (height - 1)`, which exactly aligns the 4\n *     corners of images and resized images. If false, rescale by\n *     `new_height / height`. Treat similarly the width dimension.\n */\n/** @doc {heading: 'Operations', subheading: 'Images', namespace: 'image'} */\nfunction resizeBilinear_(images, size, alignCorners) {\n    if (alignCorners === void 0) { alignCorners = false; }\n    var $images = tensor_util_env_1.convertToTensor(images, 'images', 'resizeBilinear');\n    util.assert($images.rank === 3 || $images.rank === 4, function () { return \"Error in resizeBilinear: x must be rank 3 or 4, but got \" +\n        (\"rank \" + $images.rank + \".\"); });\n    util.assert(size.length === 2, function () { return \"Error in resizeBilinear: new shape must 2D, but got shape \" +\n        (size + \".\"); });\n    var batchImages = $images;\n    var reshapedTo4D = false;\n    if ($images.rank === 3) {\n        reshapedTo4D = true;\n        batchImages =\n            $images.as4D(1, $images.shape[0], $images.shape[1], $images.shape[2]);\n    }\n    var newHeight = size[0], newWidth = size[1];\n    var forward = function (backend, save) {\n        save([batchImages]);\n        return backend.resizeBilinear(batchImages, newHeight, newWidth, alignCorners);\n    };\n    var backward = function (dy, saved) {\n        return {\n            batchImages: function () { return engine_1.ENGINE.runKernel(function (backend) { return backend.resizeBilinearBackprop(dy, saved[0], alignCorners); }, {}); }\n        };\n    };\n    var res = engine_1.ENGINE.runKernel(forward, { batchImages: batchImages }, backward);\n    if (reshapedTo4D) {\n        return res.as3D(res.shape[1], res.shape[2], res.shape[3]);\n    }\n    return res;\n}\n/**\n * NearestNeighbor resize a batch of 3D images to a new shape.\n *\n * @param images The images, of rank 4 or rank 3, of shape\n *     `[batch, height, width, inChannels]`. If rank 3, batch of 1 is assumed.\n * @param size The new shape `[newHeight, newWidth]` to resize the\n *     images to. Each channel is resized individually.\n * @param alignCorners Defaults to False. If true, rescale\n *     input by `(new_height - 1) / (height - 1)`, which exactly aligns the 4\n *     corners of images and resized images. If false, rescale by\n *     `new_height / height`. Treat similarly the width dimension.\n */\n/** @doc {heading: 'Operations', subheading: 'Images', namespace: 'image'} */\nfunction resizeNearestNeighbor_(images, size, alignCorners) {\n    if (alignCorners === void 0) { alignCorners = false; }\n    var $images = tensor_util_env_1.convertToTensor(images, 'images', 'resizeNearestNeighbor');\n    util.assert($images.rank === 3 || $images.rank === 4, function () { return \"Error in resizeNearestNeighbor: x must be rank 3 or 4, but got \" +\n        (\"rank \" + $images.rank + \".\"); });\n    util.assert(size.length === 2, function () {\n        return \"Error in resizeNearestNeighbor: new shape must 2D, but got shape \" +\n            (size + \".\");\n    });\n    util.assert($images.dtype === 'float32' || $images.dtype === 'int32', function () { return '`images` must have `int32` or `float32` as dtype'; });\n    var batchImages = $images;\n    var reshapedTo4D = false;\n    if ($images.rank === 3) {\n        reshapedTo4D = true;\n        batchImages =\n            $images.as4D(1, $images.shape[0], $images.shape[1], $images.shape[2]);\n    }\n    var newHeight = size[0], newWidth = size[1];\n    var forward = function (backend, save) {\n        save([batchImages]);\n        return backend.resizeNearestNeighbor(batchImages, newHeight, newWidth, alignCorners);\n    };\n    var backward = function (dy, saved) {\n        return {\n            batchImages: function () { return engine_1.ENGINE.runKernel(function (backend) { return backend.resizeNearestNeighborBackprop(dy, saved[0], alignCorners); }, {}); }\n        };\n    };\n    var res = engine_1.ENGINE.runKernel(forward, { batchImages: batchImages }, backward);\n    if (reshapedTo4D) {\n        return res.as3D(res.shape[1], res.shape[2], res.shape[3]);\n    }\n    return res;\n}\n/**\n * Performs non maximum suppression of bounding boxes based on\n * iou (intersection over union)\n *\n * @param boxes a 2d tensor of shape `[numBoxes, 4]`. Each entry is\n *     `[y1, x1, y2, x2]`, where `(y1, x1)` and `(y2, x2)` are the corners of\n *     the bounding box.\n * @param scores a 1d tensor providing the box scores of shape `[numBoxes]`.\n * @param maxOutputSize The maximum number of boxes to be selected.\n * @param iouThreshold A float representing the threshold for deciding whether\n *     boxes overlap too much with respect to IOU. Must be between [0, 1].\n *     Defaults to 0.5 (50% box overlap).\n * @param scoreThreshold A threshold for deciding when to remove boxes based\n *     on score. Defaults to -inf, which means any score is accepted.\n * @return A 1D tensor with the selected box indices.\n */\n/** @doc {heading: 'Operations', subheading: 'Images', namespace: 'image'} */\nfunction nonMaxSuppression_(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold) {\n    if (iouThreshold === void 0) { iouThreshold = 0.5; }\n    if (scoreThreshold === void 0) { scoreThreshold = Number.NEGATIVE_INFINITY; }\n    var $boxes = tensor_util_env_1.convertToTensor(boxes, 'boxes', 'nonMaxSuppression');\n    var $scores = tensor_util_env_1.convertToTensor(scores, 'scores', 'nonMaxSuppression');\n    var inputs = nonMaxSuppSanityCheck($boxes, $scores, maxOutputSize, iouThreshold, scoreThreshold);\n    maxOutputSize = inputs.maxOutputSize;\n    iouThreshold = inputs.iouThreshold;\n    scoreThreshold = inputs.scoreThreshold;\n    return engine_1.ENGINE.runKernel(function (b) { return b.nonMaxSuppression($boxes, $scores, maxOutputSize, iouThreshold, scoreThreshold); }, { $boxes: $boxes });\n}\n/** This is the async version of `nonMaxSuppression` */\nfunction nonMaxSuppressionAsync_(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold) {\n    if (iouThreshold === void 0) { iouThreshold = 0.5; }\n    if (scoreThreshold === void 0) { scoreThreshold = Number.NEGATIVE_INFINITY; }\n    return __awaiter(this, void 0, void 0, function () {\n        var $boxes, $scores, inputs, boxesVals, scoresVals, res;\n        return __generator(this, function (_a) {\n            switch (_a.label) {\n                case 0:\n                    $boxes = tensor_util_env_1.convertToTensor(boxes, 'boxes', 'nonMaxSuppressionAsync');\n                    $scores = tensor_util_env_1.convertToTensor(scores, 'scores', 'nonMaxSuppressionAsync');\n                    inputs = nonMaxSuppSanityCheck($boxes, $scores, maxOutputSize, iouThreshold, scoreThreshold);\n                    maxOutputSize = inputs.maxOutputSize;\n                    iouThreshold = inputs.iouThreshold;\n                    scoreThreshold = inputs.scoreThreshold;\n                    return [4 /*yield*/, $boxes.data()];\n                case 1:\n                    boxesVals = _a.sent();\n                    return [4 /*yield*/, $scores.data()];\n                case 2:\n                    scoresVals = _a.sent();\n                    res = non_max_suppression_impl_1.nonMaxSuppressionImpl(boxesVals, scoresVals, maxOutputSize, iouThreshold, scoreThreshold);\n                    if ($boxes !== boxes) {\n                        $boxes.dispose();\n                    }\n                    if ($scores !== scores) {\n                        $scores.dispose();\n                    }\n                    return [2 /*return*/, res];\n            }\n        });\n    });\n}\nfunction nonMaxSuppSanityCheck(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold) {\n    if (iouThreshold == null) {\n        iouThreshold = 0.5;\n    }\n    if (scoreThreshold == null) {\n        scoreThreshold = Number.NEGATIVE_INFINITY;\n    }\n    var numBoxes = boxes.shape[0];\n    maxOutputSize = Math.min(maxOutputSize, numBoxes);\n    util.assert(0 <= iouThreshold && iouThreshold <= 1, function () { return \"iouThreshold must be in [0, 1], but was '\" + iouThreshold + \"'\"; });\n    util.assert(boxes.rank === 2, function () { return \"boxes must be a 2D tensor, but was of rank '\" + boxes.rank + \"'\"; });\n    util.assert(boxes.shape[1] === 4, function () {\n        return \"boxes must have 4 columns, but 2nd dimension was \" + boxes.shape[1];\n    });\n    util.assert(scores.rank === 1, function () { return 'scores must be a 1D tensor'; });\n    util.assert(scores.shape[0] === numBoxes, function () { return \"scores has incompatible shape with boxes. Expected \" + numBoxes + \", \" +\n        (\"but was \" + scores.shape[0]); });\n    return { maxOutputSize: maxOutputSize, iouThreshold: iouThreshold, scoreThreshold: scoreThreshold };\n}\n/**\n * Extracts crops from the input image tensor and resizes them using bilinear\n * sampling or nearest neighbor sampling (possibly with aspect ratio change)\n * to a common output size specified by crop_size.\n *\n * @param image 4d tensor of shape `[batch,imageHeight,imageWidth, depth]`,\n *     where imageHeight and imageWidth must be positive, specifying the\n *     batch of images from which to take crops\n * @param boxes 2d float32 tensor of shape `[numBoxes, 4]`. Each entry is\n *     `[y1, x1, y2, x2]`, where `(y1, x1)` and `(y2, x2)` are the normalized\n *     coordinates of the box in the boxInd[i]'th image in the batch\n * @param boxInd 1d int32 tensor of shape `[numBoxes]` with values in range\n *     `[0, batch)` that specifies the image that the `i`-th box refers to.\n * @param cropSize 1d int32 tensor of 2 elements `[cropHeigh, cropWidth]`\n *     specifying the size to which all crops are resized to.\n * @param method Optional string from `'bilinear' | 'nearest'`,\n *     defaults to bilinear, which specifies the sampling method for resizing\n * @param extrapolationValue A threshold for deciding when to remove boxes based\n *     on score. Defaults to 0.\n * @return A 4D tensor of the shape `[numBoxes,cropHeight,cropWidth,depth]`\n */\n/** @doc {heading: 'Operations', subheading: 'Images', namespace: 'image'} */\nfunction cropAndResize_(image, boxes, boxInd, cropSize, method, extrapolationValue) {\n    var $image = tensor_util_env_1.convertToTensor(image, 'image', 'cropAndResize', 'float32');\n    var $boxes = tensor_util_env_1.convertToTensor(boxes, 'boxes', 'cropAndResize', 'float32');\n    var $boxInd = tensor_util_env_1.convertToTensor(boxInd, 'boxInd', 'cropAndResize', 'int32');\n    method = method || 'bilinear';\n    extrapolationValue = extrapolationValue || 0;\n    var numBoxes = $boxes.shape[0];\n    util.assert($image.rank === 4, function () { return 'Error in cropAndResize: image must be rank 4,' +\n        (\"but got rank \" + $image.rank + \".\"); });\n    util.assert($boxes.rank === 2 && $boxes.shape[1] === 4, function () { return \"Error in cropAndResize: boxes must be have size [\" + numBoxes + \",4] \" +\n        (\"but had shape \" + $boxes.shape + \".\"); });\n    util.assert($boxInd.rank === 1 && $boxInd.shape[0] === numBoxes, function () { return \"Error in cropAndResize: boxInd must be have size [\" + numBoxes + \"] \" +\n        (\"but had shape \" + $boxes.shape + \".\"); });\n    util.assert(cropSize.length === 2, function () { return \"Error in cropAndResize: cropSize must be of length 2, but got \" +\n        (\"length \" + cropSize.length + \".\"); });\n    util.assert(cropSize[0] >= 1 && cropSize[1] >= 1, function () { return \"cropSize must be atleast [1,1], but was \" + cropSize; });\n    util.assert(method === 'bilinear' || method === 'nearest', function () { return \"method must be bilinear or nearest, but was \" + method; });\n    var forward = function (backend, save) {\n        return backend.cropAndResize($image, $boxes, $boxInd, cropSize, method, extrapolationValue);\n    };\n    var res = engine_1.ENGINE.runKernel(forward, { $image: $image, $boxes: $boxes });\n    return res;\n}\nexports.resizeBilinear = operation_1.op({ resizeBilinear_: resizeBilinear_ });\nexports.resizeNearestNeighbor = operation_1.op({ resizeNearestNeighbor_: resizeNearestNeighbor_ });\nexports.nonMaxSuppression = operation_1.op({ nonMaxSuppression_: nonMaxSuppression_ });\nexports.nonMaxSuppressionAsync = nonMaxSuppressionAsync_;\nexports.cropAndResize = operation_1.op({ cropAndResize_: cropAndResize_ });\n//# sourceMappingURL=image_ops.js.map","\n/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar engine_1 = require(\"../engine\");\nvar operation_1 = require(\"../ops/operation\");\nvar tensor_util_1 = require(\"../tensor_util\");\nvar tensor_util_env_1 = require(\"../tensor_util_env\");\nvar util = require(\"../util\");\nvar broadcast_util = require(\"./broadcast_util\");\n/**\n * Computes the dot product of two matrices with optional activation and bias.\n *\n * ```js\n * const a = tf.tensor2d([-1, -2], [1, 2]);\n * const b = tf.tensor2d([1, 2, 3, 4], [2, 2]);\n * const bias = tf.tensor2d([1, 2], [1, 2]);\n *\n * tf.fused.matMul(a, b, false, false, bias, 'relu').print();\n * ```\n *\n * @param a First matrix in dot product operation.\n * @param b Second matrix in dot product operation.\n * @param transposeA If true, `a` is transposed before multiplication.\n * @param transposeB If true, `b` is transposed before multiplication.\n * @param bias Matrix to be added to the result.\n * @param activation Name of activation kernel (defaults to `linear`).\n */\n/** @doc {heading: 'Operations', subheading: 'Matrices', namespace: 'fused'} */\nfunction matMul_(a, b, transposeA, transposeB, bias, activation) {\n    if (transposeA === void 0) { transposeA = false; }\n    if (transposeB === void 0) { transposeB = false; }\n    if (activation === void 0) { activation = 'linear'; }\n    var _a;\n    var $a = tensor_util_env_1.convertToTensor(a, 'a', 'fused matMul');\n    var $b = tensor_util_env_1.convertToTensor(b, 'b', 'fused matMul');\n    _a = tensor_util_1.makeTypesMatch($a, $b), $a = _a[0], $b = _a[1];\n    var innerShapeA = transposeA ? $a.shape[$a.rank - 2] : $a.shape[$a.rank - 1];\n    var innerShapeB = transposeB ? $b.shape[$b.rank - 1] : $b.shape[$b.rank - 2];\n    var outerShapeA = transposeA ? $a.shape[$a.rank - 1] : $a.shape[$a.rank - 2];\n    var outerShapeB = transposeB ? $b.shape[$b.rank - 2] : $b.shape[$b.rank - 1];\n    var outerDimsA = $a.shape.slice(0, -2);\n    var outerDimsB = $b.shape.slice(0, -2);\n    var batchDimA = util.sizeFromShape(outerDimsA);\n    var batchDimB = util.sizeFromShape(outerDimsB);\n    util.assert($a.rank >= 2 && $b.rank >= 2 && $a.rank === $b.rank, function () {\n        return \"Error in fused matMul: inputs must have the same rank of at least \" +\n            (\"2, got ranks \" + $a.rank + \" and \" + $b.rank + \".\");\n    });\n    util.assert(util.arraysEqual(outerDimsA, outerDimsB), function () { return \"Error in fused matMul: outer dimensions (\" + outerDimsA + \") and (\" +\n        (outerDimsB + \") of Tensors with shapes \" + $a.shape + \" and \") +\n        ($b.shape + \" must match.\"); });\n    util.assert(innerShapeA === innerShapeB, function () { return \"Error in fused matMul: inner shapes (\" + innerShapeA + \") and (\" +\n        (innerShapeB + \") of Tensors with shapes \" + $a.shape + \" and \") +\n        ($b.shape + \" and transposeA=\" + transposeA) +\n        (\" and transposeB=\" + transposeB + \" must match.\"); });\n    var outShape = $a.shape.slice(0, -2).concat([outerShapeA, outerShapeB]);\n    var a3D = transposeA ? $a.as3D(batchDimA, innerShapeA, outerShapeA) :\n        $a.as3D(batchDimA, outerShapeA, innerShapeA);\n    var b3D = transposeB ? $b.as3D(batchDimB, outerShapeB, innerShapeB) :\n        $b.as3D(batchDimB, innerShapeB, outerShapeB);\n    var $bias;\n    if (bias != null) {\n        $bias = tensor_util_env_1.convertToTensor(bias, 'bias', 'fused matMul');\n        $bias = tensor_util_1.makeTypesMatch($bias, $a)[0];\n        broadcast_util.assertAndGetBroadcastShape(outShape, $bias.shape);\n    }\n    var grad = function (dy, saved) {\n        var a3D = saved[0], b3D = saved[1], y = saved[2];\n        var dyActivation;\n        if (activation == null || activation === 'linear') {\n            dyActivation = dy;\n        }\n        else if (activation === 'relu') {\n            dyActivation = dy.mul(y.step());\n        }\n        else {\n            throw new Error(\"Gradient for activation \" + activation + \" has not been \" +\n                \"implemented yet.\");\n        }\n        var biasGradient = {};\n        if (bias != null) {\n            biasGradient = {\n                $bias: function () {\n                    var res = dyActivation;\n                    // Using dyActivation as reference shape because outputShape does not\n                    // account for the fact that we temporarily reshape inputs to 3D as\n                    // part of batched matMul.\n                    var reduceAxes = broadcast_util.getReductionAxes($bias.shape, dyActivation.shape);\n                    if (reduceAxes.length > 0) {\n                        res = res.sum(reduceAxes);\n                    }\n                    return res.reshape($bias.shape);\n                }\n            };\n        }\n        if (!transposeA && !transposeB) {\n            return Object.assign({\n                $a: function () { return dyActivation.matMul(b3D, false, true); },\n                $b: function () { return a3D.matMul(dyActivation, true, false); }\n            }, biasGradient);\n        }\n        else if (!transposeA && transposeB) {\n            return Object.assign({\n                $a: function () { return dyActivation.matMul(b3D, false, false); },\n                $b: function () { return dyActivation.matMul(a3D, true, false); }\n            }, biasGradient);\n        }\n        else if (transposeA && !transposeB) {\n            return Object.assign({\n                $a: function () { return b3D.matMul(dyActivation, false, true); },\n                $b: function () { return a3D.matMul(dyActivation, false, false); }\n            }, biasGradient);\n        }\n        else {\n            return Object.assign({\n                $a: function () { return b3D.matMul(dyActivation, true, true); },\n                $b: function () { return dyActivation.matMul(a3D, true, true); }\n            }, biasGradient);\n        }\n    };\n    var inputs = { $a: a3D, $b: b3D };\n    if (bias != null) {\n        inputs.$bias = $bias;\n    }\n    var res = engine_1.ENGINE.runKernel(function (backend, save) {\n        var y = backend.fusedBatchMatMul(a3D, b3D, transposeA, transposeB, $bias, activation);\n        save([a3D, b3D, y]);\n        return y;\n    }, inputs, grad);\n    return res.reshape(outShape);\n}\nexports.matMul = operation_1.op({ matMul_: matMul_ });\n//# sourceMappingURL=fused_ops.js.map","\nObject.defineProperty(exports, \"__esModule\", { value: true });\n/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar environment_1 = require(\"../environment\");\nvar PlatformBrowser = /** @class */ (function () {\n    function PlatformBrowser() {\n    }\n    PlatformBrowser.prototype.fetch = function (path, init) {\n        return fetch(path, init);\n    };\n    return PlatformBrowser;\n}());\nexports.PlatformBrowser = PlatformBrowser;\nif (environment_1.ENV.get('IS_BROWSER')) {\n    environment_1.ENV.setPlatform('browser', new PlatformBrowser());\n}\n//# sourceMappingURL=platform_browser.js.map","\nObject.defineProperty(exports, \"__esModule\", { value: true });\n/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar environment_1 = require(\"../environment\");\n// We are wrapping this within an object so it can be stubbed by Jasmine.\nexports.getNodeFetch = {\n    // tslint:disable-next-line:no-require-imports\n    importFetch: function () { return require('node-fetch'); }\n};\nvar PlatformNode = /** @class */ (function () {\n    function PlatformNode() {\n    }\n    PlatformNode.prototype.fetch = function (path, requestInits) {\n        if (environment_1.ENV.global.fetch != null) {\n            return environment_1.ENV.global.fetch(path, requestInits);\n        }\n        if (exports.systemFetch == null) {\n            exports.systemFetch = exports.getNodeFetch.importFetch();\n        }\n        return exports.systemFetch(path, requestInits);\n    };\n    return PlatformNode;\n}());\nexports.PlatformNode = PlatformNode;\nif (environment_1.ENV.get('IS_NODE')) {\n    environment_1.ENV.setPlatform('node', new PlatformNode());\n}\n//# sourceMappingURL=platform_node.js.map","\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\n// Importing local_storage and indexed_db is necessary for the routers to be\n// registered.\nrequire(\"./indexed_db\");\nrequire(\"./local_storage\");\nvar browser_files_1 = require(\"./browser_files\");\nexports.browserFiles = browser_files_1.browserFiles;\nvar http_1 = require(\"./http\");\nexports.browserHTTPRequest = http_1.browserHTTPRequest;\nexports.http = http_1.http;\nexports.isHTTPScheme = http_1.isHTTPScheme;\nvar io_utils_1 = require(\"./io_utils\");\nexports.concatenateArrayBuffers = io_utils_1.concatenateArrayBuffers;\nexports.decodeWeights = io_utils_1.decodeWeights;\nexports.encodeWeights = io_utils_1.encodeWeights;\nexports.getModelArtifactsInfoForJSON = io_utils_1.getModelArtifactsInfoForJSON;\nvar passthrough_1 = require(\"./passthrough\");\nexports.fromMemory = passthrough_1.fromMemory;\nexports.withSaveHandler = passthrough_1.withSaveHandler;\nvar router_registry_1 = require(\"./router_registry\");\nexports.getLoadHandlers = router_registry_1.getLoadHandlers;\nexports.getSaveHandlers = router_registry_1.getSaveHandlers;\nexports.registerLoadRouter = router_registry_1.registerLoadRouter;\nexports.registerSaveRouter = router_registry_1.registerSaveRouter;\nvar weights_loader_1 = require(\"./weights_loader\");\nexports.loadWeights = weights_loader_1.loadWeights;\nexports.weightsLoaderFactory = weights_loader_1.weightsLoaderFactory;\nvar model_management_1 = require(\"./model_management\");\nexports.copyModel = model_management_1.copyModel;\nexports.listModels = model_management_1.listModels;\nexports.moveModel = model_management_1.moveModel;\nexports.removeModel = model_management_1.removeModel;\n//# sourceMappingURL=io.js.map","\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : new P(function (resolve) { resolve(result.value); }).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nvar __generator = (this && this.__generator) || function (thisArg, body) {\n    var _ = { label: 0, sent: function() { if (t[0] & 1) throw t[1]; return t[1]; }, trys: [], ops: [] }, f, y, t, g;\n    return g = { next: verb(0), \"throw\": verb(1), \"return\": verb(2) }, typeof Symbol === \"function\" && (g[Symbol.iterator] = function() { return this; }), g;\n    function verb(n) { return function (v) { return step([n, v]); }; }\n    function step(op) {\n        if (f) throw new TypeError(\"Generator is already executing.\");\n        while (_) try {\n            if (f = 1, y && (t = op[0] & 2 ? y[\"return\"] : op[0] ? y[\"throw\"] || ((t = y[\"return\"]) && t.call(y), 0) : y.next) && !(t = t.call(y, op[1])).done) return t;\n            if (y = 0, t) op = [op[0] & 2, t.value];\n            switch (op[0]) {\n                case 0: case 1: t = op; break;\n                case 4: _.label++; return { value: op[1], done: false };\n                case 5: _.label++; y = op[1]; op = [0]; continue;\n                case 7: op = _.ops.pop(); _.trys.pop(); continue;\n                default:\n                    if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) { _ = 0; continue; }\n                    if (op[0] === 3 && (!t || (op[1] > t[0] && op[1] < t[3]))) { _.label = op[1]; break; }\n                    if (op[0] === 6 && _.label < t[1]) { _.label = t[1]; t = op; break; }\n                    if (t && _.label < t[2]) { _.label = t[2]; _.ops.push(op); break; }\n                    if (t[2]) _.ops.pop();\n                    _.trys.pop(); continue;\n            }\n            op = body.call(thisArg, _);\n        } catch (e) { op = [6, e]; y = 0; } finally { f = t = 0; }\n        if (op[0] & 5) throw op[1]; return { value: op[0] ? op[1] : void 0, done: true };\n    }\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar environment_1 = require(\"../environment\");\nvar io_utils_1 = require(\"./io_utils\");\nvar model_management_1 = require(\"./model_management\");\nvar router_registry_1 = require(\"./router_registry\");\nvar DATABASE_NAME = 'tensorflowjs';\nvar DATABASE_VERSION = 1;\n// Model data and ModelArtifactsInfo (metadata) are stored in two separate\n// stores for efficient access of the list of stored models and their metadata.\n// 1. The object store for model data: topology, weights and weight manifests.\nvar MODEL_STORE_NAME = 'models_store';\n// 2. The object store for ModelArtifactsInfo, including meta-information such\n//    as the type of topology (JSON vs binary), byte size of the topology, byte\n//    size of the weights, etc.\nvar INFO_STORE_NAME = 'model_info_store';\n/**\n * Delete the entire database for tensorflow.js, including the models store.\n */\nfunction deleteDatabase() {\n    return __awaiter(this, void 0, void 0, function () {\n        var idbFactory;\n        return __generator(this, function (_a) {\n            idbFactory = getIndexedDBFactory();\n            return [2 /*return*/, new Promise(function (resolve, reject) {\n                    var deleteRequest = idbFactory.deleteDatabase(DATABASE_NAME);\n                    deleteRequest.onsuccess = function () { return resolve(); };\n                    deleteRequest.onerror = function (error) { return reject(error); };\n                })];\n        });\n    });\n}\nexports.deleteDatabase = deleteDatabase;\nfunction getIndexedDBFactory() {\n    if (!environment_1.ENV.getBool('IS_BROWSER')) {\n        // TODO(cais): Add more info about what IOHandler subtypes are available.\n        //   Maybe point to a doc page on the web and/or automatically determine\n        //   the available IOHandlers and print them in the error message.\n        throw new Error('Failed to obtain IndexedDB factory because the current environment' +\n            'is not a web browser.');\n    }\n    // tslint:disable-next-line:no-any\n    var theWindow = window;\n    var factory = theWindow.indexedDB || theWindow.mozIndexedDB ||\n        theWindow.webkitIndexedDB || theWindow.msIndexedDB ||\n        theWindow.shimIndexedDB;\n    if (factory == null) {\n        throw new Error('The current browser does not appear to support IndexedDB.');\n    }\n    return factory;\n}\nfunction setUpDatabase(openRequest) {\n    var db = openRequest.result;\n    db.createObjectStore(MODEL_STORE_NAME, { keyPath: 'modelPath' });\n    db.createObjectStore(INFO_STORE_NAME, { keyPath: 'modelPath' });\n}\n/**\n * IOHandler subclass: Browser IndexedDB.\n *\n * See the doc string of `browserIndexedDB` for more details.\n */\nvar BrowserIndexedDB = /** @class */ (function () {\n    function BrowserIndexedDB(modelPath) {\n        this.indexedDB = getIndexedDBFactory();\n        if (modelPath == null || !modelPath) {\n            throw new Error('For IndexedDB, modelPath must not be null, undefined or empty.');\n        }\n        this.modelPath = modelPath;\n    }\n    BrowserIndexedDB.prototype.save = function (modelArtifacts) {\n        return __awaiter(this, void 0, void 0, function () {\n            return __generator(this, function (_a) {\n                // TODO(cais): Support saving GraphDef models.\n                if (modelArtifacts.modelTopology instanceof ArrayBuffer) {\n                    throw new Error('BrowserLocalStorage.save() does not support saving model topology ' +\n                        'in binary formats yet.');\n                }\n                return [2 /*return*/, this.databaseAction(this.modelPath, modelArtifacts)];\n            });\n        });\n    };\n    BrowserIndexedDB.prototype.load = function () {\n        return __awaiter(this, void 0, void 0, function () {\n            return __generator(this, function (_a) {\n                return [2 /*return*/, this.databaseAction(this.modelPath)];\n            });\n        });\n    };\n    /**\n     * Perform database action to put model artifacts into or read model artifacts\n     * from IndexedDB object store.\n     *\n     * Whether the action is put or get depends on whether `modelArtifacts` is\n     * specified. If it is specified, the action will be put; otherwise the action\n     * will be get.\n     *\n     * @param modelPath A unique string path for the model.\n     * @param modelArtifacts If specified, it will be the model artifacts to be\n     *   stored in IndexedDB.\n     * @returns A `Promise` of `SaveResult`, if the action is put, or a `Promise`\n     *   of `ModelArtifacts`, if the action is get.\n     */\n    BrowserIndexedDB.prototype.databaseAction = function (modelPath, modelArtifacts) {\n        var _this = this;\n        return new Promise(function (resolve, reject) {\n            var openRequest = _this.indexedDB.open(DATABASE_NAME, DATABASE_VERSION);\n            openRequest.onupgradeneeded = function () { return setUpDatabase(openRequest); };\n            openRequest.onsuccess = function () {\n                var db = openRequest.result;\n                if (modelArtifacts == null) {\n                    // Read model out from object store.\n                    var modelTx = db.transaction(MODEL_STORE_NAME, 'readonly');\n                    var modelStore = modelTx.objectStore(MODEL_STORE_NAME);\n                    var getRequest_1 = modelStore.get(_this.modelPath);\n                    getRequest_1.onsuccess = function () {\n                        if (getRequest_1.result == null) {\n                            db.close();\n                            return reject(new Error(\"Cannot find model with path '\" + _this.modelPath + \"' \" +\n                                \"in IndexedDB.\"));\n                        }\n                        else {\n                            resolve(getRequest_1.result.modelArtifacts);\n                        }\n                    };\n                    getRequest_1.onerror = function (error) {\n                        db.close();\n                        return reject(getRequest_1.error);\n                    };\n                    modelTx.oncomplete = function () { return db.close(); };\n                }\n                else {\n                    // Put model into object store.\n                    var modelArtifactsInfo_1 = io_utils_1.getModelArtifactsInfoForJSON(modelArtifacts);\n                    // First, put ModelArtifactsInfo into info store.\n                    var infoTx_1 = db.transaction(INFO_STORE_NAME, 'readwrite');\n                    var infoStore_1 = infoTx_1.objectStore(INFO_STORE_NAME);\n                    var putInfoRequest_1 = infoStore_1.put({ modelPath: _this.modelPath, modelArtifactsInfo: modelArtifactsInfo_1 });\n                    var modelTx_1;\n                    putInfoRequest_1.onsuccess = function () {\n                        // Second, put model data into model store.\n                        modelTx_1 = db.transaction(MODEL_STORE_NAME, 'readwrite');\n                        var modelStore = modelTx_1.objectStore(MODEL_STORE_NAME);\n                        var putModelRequest = modelStore.put({\n                            modelPath: _this.modelPath,\n                            modelArtifacts: modelArtifacts,\n                            modelArtifactsInfo: modelArtifactsInfo_1\n                        });\n                        putModelRequest.onsuccess = function () { return resolve({ modelArtifactsInfo: modelArtifactsInfo_1 }); };\n                        putModelRequest.onerror = function (error) {\n                            // If the put-model request fails, roll back the info entry as\n                            // well.\n                            infoStore_1 = infoTx_1.objectStore(INFO_STORE_NAME);\n                            var deleteInfoRequest = infoStore_1.delete(_this.modelPath);\n                            deleteInfoRequest.onsuccess = function () {\n                                db.close();\n                                return reject(putModelRequest.error);\n                            };\n                            deleteInfoRequest.onerror = function (error) {\n                                db.close();\n                                return reject(putModelRequest.error);\n                            };\n                        };\n                    };\n                    putInfoRequest_1.onerror = function (error) {\n                        db.close();\n                        return reject(putInfoRequest_1.error);\n                    };\n                    infoTx_1.oncomplete = function () {\n                        if (modelTx_1 == null) {\n                            db.close();\n                        }\n                        else {\n                            modelTx_1.oncomplete = function () { return db.close(); };\n                        }\n                    };\n                }\n            };\n            openRequest.onerror = function (error) { return reject(openRequest.error); };\n        });\n    };\n    BrowserIndexedDB.URL_SCHEME = 'indexeddb://';\n    return BrowserIndexedDB;\n}());\nexports.BrowserIndexedDB = BrowserIndexedDB;\nexports.indexedDBRouter = function (url) {\n    if (!environment_1.ENV.getBool('IS_BROWSER')) {\n        return null;\n    }\n    else {\n        if (!Array.isArray(url) && url.startsWith(BrowserIndexedDB.URL_SCHEME)) {\n            return browserIndexedDB(url.slice(BrowserIndexedDB.URL_SCHEME.length));\n        }\n        else {\n            return null;\n        }\n    }\n};\nrouter_registry_1.IORouterRegistry.registerSaveRouter(exports.indexedDBRouter);\nrouter_registry_1.IORouterRegistry.registerLoadRouter(exports.indexedDBRouter);\n/**\n * Creates a browser IndexedDB IOHandler for saving and loading models.\n *\n * ```js\n * const model = tf.sequential();\n * model.add(\n *     tf.layers.dense({units: 1, inputShape: [100], activation: 'sigmoid'}));\n *\n * const saveResult = await model.save('indexeddb://MyModel'));\n * console.log(saveResult);\n * ```\n *\n * @param modelPath A unique identifier for the model to be saved. Must be a\n *   non-empty string.\n * @returns An instance of `BrowserIndexedDB` (sublcass of `IOHandler`),\n *   which can be used with, e.g., `tf.Model.save`.\n */\nfunction browserIndexedDB(modelPath) {\n    return new BrowserIndexedDB(modelPath);\n}\nexports.browserIndexedDB = browserIndexedDB;\nfunction maybeStripScheme(key) {\n    return key.startsWith(BrowserIndexedDB.URL_SCHEME) ?\n        key.slice(BrowserIndexedDB.URL_SCHEME.length) :\n        key;\n}\nvar BrowserIndexedDBManager = /** @class */ (function () {\n    function BrowserIndexedDBManager() {\n        this.indexedDB = getIndexedDBFactory();\n    }\n    BrowserIndexedDBManager.prototype.listModels = function () {\n        return __awaiter(this, void 0, void 0, function () {\n            var _this = this;\n            return __generator(this, function (_a) {\n                return [2 /*return*/, new Promise(function (resolve, reject) {\n                        var openRequest = _this.indexedDB.open(DATABASE_NAME, DATABASE_VERSION);\n                        openRequest.onupgradeneeded = function () { return setUpDatabase(openRequest); };\n                        openRequest.onsuccess = function () {\n                            var db = openRequest.result;\n                            var tx = db.transaction(INFO_STORE_NAME, 'readonly');\n                            var store = tx.objectStore(INFO_STORE_NAME);\n                            // tslint:disable:max-line-length\n                            // Need to cast `store` as `any` here because TypeScript's DOM\n                            // library does not have the `getAll()` method even though the\n                            // method is supported in the latest version of most mainstream\n                            // browsers:\n                            // https://developer.mozilla.org/en-US/docs/Web/API/IDBObjectStore/getAll\n                            // tslint:enable:max-line-length\n                            // tslint:disable-next-line:no-any\n                            var getAllInfoRequest = store.getAll();\n                            getAllInfoRequest.onsuccess = function () {\n                                var out = {};\n                                for (var _i = 0, _a = getAllInfoRequest.result; _i < _a.length; _i++) {\n                                    var item = _a[_i];\n                                    out[item.modelPath] = item.modelArtifactsInfo;\n                                }\n                                resolve(out);\n                            };\n                            getAllInfoRequest.onerror = function (error) {\n                                db.close();\n                                return reject(getAllInfoRequest.error);\n                            };\n                            tx.oncomplete = function () { return db.close(); };\n                        };\n                        openRequest.onerror = function (error) { return reject(openRequest.error); };\n                    })];\n            });\n        });\n    };\n    BrowserIndexedDBManager.prototype.removeModel = function (path) {\n        return __awaiter(this, void 0, void 0, function () {\n            var _this = this;\n            return __generator(this, function (_a) {\n                path = maybeStripScheme(path);\n                return [2 /*return*/, new Promise(function (resolve, reject) {\n                        var openRequest = _this.indexedDB.open(DATABASE_NAME, DATABASE_VERSION);\n                        openRequest.onupgradeneeded = function () { return setUpDatabase(openRequest); };\n                        openRequest.onsuccess = function () {\n                            var db = openRequest.result;\n                            var infoTx = db.transaction(INFO_STORE_NAME, 'readwrite');\n                            var infoStore = infoTx.objectStore(INFO_STORE_NAME);\n                            var getInfoRequest = infoStore.get(path);\n                            var modelTx;\n                            getInfoRequest.onsuccess = function () {\n                                if (getInfoRequest.result == null) {\n                                    db.close();\n                                    return reject(new Error(\"Cannot find model with path '\" + path + \"' \" +\n                                        \"in IndexedDB.\"));\n                                }\n                                else {\n                                    // First, delete the entry in the info store.\n                                    var deleteInfoRequest = infoStore.delete(path);\n                                    var deleteModelData_1 = function () {\n                                        // Second, delete the entry in the model store.\n                                        modelTx = db.transaction(MODEL_STORE_NAME, 'readwrite');\n                                        var modelStore = modelTx.objectStore(MODEL_STORE_NAME);\n                                        var deleteModelRequest = modelStore.delete(path);\n                                        deleteModelRequest.onsuccess = function () {\n                                            return resolve(getInfoRequest.result.modelArtifactsInfo);\n                                        };\n                                        deleteModelRequest.onerror = function (error) {\n                                            return reject(getInfoRequest.error);\n                                        };\n                                    };\n                                    // Proceed with deleting model data regardless of whether deletion\n                                    // of info data succeeds or not.\n                                    deleteInfoRequest.onsuccess = deleteModelData_1;\n                                    deleteInfoRequest.onerror = function (error) {\n                                        deleteModelData_1();\n                                        db.close();\n                                        return reject(getInfoRequest.error);\n                                    };\n                                }\n                            };\n                            getInfoRequest.onerror = function (error) {\n                                db.close();\n                                return reject(getInfoRequest.error);\n                            };\n                            infoTx.oncomplete = function () {\n                                if (modelTx == null) {\n                                    db.close();\n                                }\n                                else {\n                                    modelTx.oncomplete = function () { return db.close(); };\n                                }\n                            };\n                        };\n                        openRequest.onerror = function (error) { return reject(openRequest.error); };\n                    })];\n            });\n        });\n    };\n    return BrowserIndexedDBManager;\n}());\nexports.BrowserIndexedDBManager = BrowserIndexedDBManager;\nif (environment_1.ENV.getBool('IS_BROWSER')) {\n    // Wrap the construction and registration, to guard against browsers that\n    // don't support Local Storage.\n    try {\n        model_management_1.ModelStoreManagerRegistry.registerManager(BrowserIndexedDB.URL_SCHEME, new BrowserIndexedDBManager());\n    }\n    catch (err) {\n    }\n}\n//# sourceMappingURL=indexed_db.js.map","\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : new P(function (resolve) { resolve(result.value); }).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nvar __generator = (this && this.__generator) || function (thisArg, body) {\n    var _ = { label: 0, sent: function() { if (t[0] & 1) throw t[1]; return t[1]; }, trys: [], ops: [] }, f, y, t, g;\n    return g = { next: verb(0), \"throw\": verb(1), \"return\": verb(2) }, typeof Symbol === \"function\" && (g[Symbol.iterator] = function() { return this; }), g;\n    function verb(n) { return function (v) { return step([n, v]); }; }\n    function step(op) {\n        if (f) throw new TypeError(\"Generator is already executing.\");\n        while (_) try {\n            if (f = 1, y && (t = op[0] & 2 ? y[\"return\"] : op[0] ? y[\"throw\"] || ((t = y[\"return\"]) && t.call(y), 0) : y.next) && !(t = t.call(y, op[1])).done) return t;\n            if (y = 0, t) op = [op[0] & 2, t.value];\n            switch (op[0]) {\n                case 0: case 1: t = op; break;\n                case 4: _.label++; return { value: op[1], done: false };\n                case 5: _.label++; y = op[1]; op = [0]; continue;\n                case 7: op = _.ops.pop(); _.trys.pop(); continue;\n                default:\n                    if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) { _ = 0; continue; }\n                    if (op[0] === 3 && (!t || (op[1] > t[0] && op[1] < t[3]))) { _.label = op[1]; break; }\n                    if (op[0] === 6 && _.label < t[1]) { _.label = t[1]; t = op; break; }\n                    if (t && _.label < t[2]) { _.label = t[2]; _.ops.push(op); break; }\n                    if (t[2]) _.ops.pop();\n                    _.trys.pop(); continue;\n            }\n            op = body.call(thisArg, _);\n        } catch (e) { op = [6, e]; y = 0; } finally { f = t = 0; }\n        if (op[0] & 5) throw op[1]; return { value: op[0] ? op[1] : void 0, done: true };\n    }\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar tensor_ops_1 = require(\"../ops/tensor_ops\");\nvar util_1 = require(\"../util\");\nvar types_1 = require(\"./types\");\n/**\n * Encode a map from names to weight values as an ArrayBuffer, along with an\n * `Array` of `WeightsManifestEntry` as specification of the encoded weights.\n *\n * This function does not perform sharding.\n *\n * This function is the reverse of `decodeWeights`.\n *\n * @param tensors A map (\"dict\") from names to tensors.\n * @param group Group to which the weights belong (optional).\n * @returns A `Promise` of\n *   - A flat `ArrayBuffer` with all the binary values of the `Tensor`s\n *     concatenated.\n *   - An `Array` of `WeightManifestEntry`s, carrying information including\n *     tensor names, `dtype`s and shapes.\n * @throws Error: on unsupported tensor `dtype`.\n */\nfunction encodeWeights(tensors, group) {\n    return __awaiter(this, void 0, void 0, function () {\n        var specs, dataPromises, names, i, name_1, t, spec, tensorValues;\n        return __generator(this, function (_a) {\n            switch (_a.label) {\n                case 0:\n                    specs = [];\n                    dataPromises = [];\n                    names = Array.isArray(tensors) ?\n                        tensors.map(function (tensor) { return tensor.name; }) :\n                        Object.keys(tensors);\n                    for (i = 0; i < names.length; ++i) {\n                        name_1 = names[i];\n                        t = Array.isArray(tensors) ? tensors[i].tensor : tensors[name_1];\n                        if (t.dtype !== 'float32' && t.dtype !== 'int32' && t.dtype !== 'bool') {\n                            throw new Error(\"Unsupported dtype in weight '\" + name_1 + \"': \" + t.dtype);\n                        }\n                        spec = { name: name_1, shape: t.shape, dtype: t.dtype };\n                        if (group != null) {\n                            spec.group = group;\n                        }\n                        specs.push(spec);\n                        dataPromises.push(t.data());\n                    }\n                    return [4 /*yield*/, Promise.all(dataPromises)];\n                case 1:\n                    tensorValues = _a.sent();\n                    return [2 /*return*/, { data: concatenateTypedArrays(tensorValues), specs: specs }];\n            }\n        });\n    });\n}\nexports.encodeWeights = encodeWeights;\n/**\n * Decode flat ArrayBuffer as weights.\n *\n * This function does not handle sharding.\n *\n * This function is the reverse of `encodeWeights`.\n *\n * @param buffer A flat ArrayBuffer carrying the binary values of the tensors\n *   concatenated in the order specified in `specs`.\n * @param specs Specifications of the names, dtypes and shapes of the tensors\n *   whose value are encoded by `buffer`.\n * @return A map from tensor name to tensor value, with the names corresponding\n *   to names in `specs`.\n * @throws Error, if any of the tensors has unsupported dtype.\n */\nfunction decodeWeights(buffer, specs) {\n    // TODO(adarob, cais): Support quantization.\n    var out = {};\n    var offset = 0;\n    var _loop_1 = function (spec) {\n        var name_2 = spec.name;\n        var dtype = spec.dtype;\n        var shape = spec.shape;\n        var size = util_1.sizeFromShape(shape);\n        var typedArray = void 0;\n        if ('quantization' in spec) {\n            var quantization_1 = spec.quantization;\n            if (quantization_1.dtype !== 'uint8' && quantization_1.dtype !== 'uint16') {\n                throw new Error(\"Weight \" + spec.name + \" has unknown \" +\n                    (\"quantization dtype \" + quantization_1.dtype + \". \") +\n                    \"Supported quantization dtypes are: 'uint8' and 'uint16'.\");\n            }\n            var quantizationSizeFactor = types_1.DTYPE_VALUE_SIZE_MAP[quantization_1.dtype];\n            var byteBuffer = buffer.slice(offset, offset + size * quantizationSizeFactor);\n            var quantizedArray = (quantization_1.dtype === 'uint8') ?\n                new Uint8Array(byteBuffer) :\n                new Uint16Array(byteBuffer);\n            if (dtype === 'float32') {\n                typedArray = Float32Array.from(quantizedArray, function (v) { return v * quantization_1.scale + quantization_1.min; });\n            }\n            else if (dtype === 'int32') {\n                typedArray = Int32Array.from(quantizedArray, function (v) { return Math.round(v * quantization_1.scale + quantization_1.min); });\n            }\n            else {\n                throw new Error(\"Unsupported dtype in weight '\" + name_2 + \"': \" + dtype);\n            }\n            offset += size * quantizationSizeFactor;\n        }\n        else {\n            var dtypeFactor = types_1.DTYPE_VALUE_SIZE_MAP[dtype];\n            var byteBuffer = buffer.slice(offset, offset + size * dtypeFactor);\n            if (dtype === 'float32') {\n                typedArray = new Float32Array(byteBuffer);\n            }\n            else if (dtype === 'int32') {\n                typedArray = new Int32Array(byteBuffer);\n            }\n            else if (dtype === 'bool') {\n                typedArray = new Uint8Array(byteBuffer);\n            }\n            else {\n                throw new Error(\"Unsupported dtype in weight '\" + name_2 + \"': \" + dtype);\n            }\n            offset += size * dtypeFactor;\n        }\n        var value = void 0;\n        if (dtype === 'float32') {\n            value = tensor_ops_1.tensor(typedArray, shape, 'float32');\n        }\n        else if (dtype === 'int32') {\n            value = tensor_ops_1.tensor(typedArray, shape, 'int32');\n        }\n        else if (dtype === 'bool') {\n            value = tensor_ops_1.tensor(typedArray, shape, 'bool');\n        }\n        else {\n            throw new Error(\"Unsupported dtype in weight '\" + name_2 + \"': \" + dtype);\n        }\n        out[name_2] = value;\n    };\n    for (var _i = 0, specs_1 = specs; _i < specs_1.length; _i++) {\n        var spec = specs_1[_i];\n        _loop_1(spec);\n    }\n    return out;\n}\nexports.decodeWeights = decodeWeights;\n/**\n * Concatenate TypedArrays into an ArrayBuffer.\n */\nfunction concatenateTypedArrays(xs) {\n    // TODO(adarob, cais): Support quantization.\n    if (xs === null) {\n        throw new Error(\"Invalid input value: \" + JSON.stringify(xs));\n    }\n    var totalByteLength = 0;\n    // `normalizedXs` is here for this reason: a `TypedArray`'s `buffer'\n    // can have a different byte length from that of the `TypedArray` itself,\n    // for example, when the `TypedArray` is created from an offset in an\n    // `ArrayBuffer`. `normliazedXs` holds `TypedArray`s whose `buffer`s match\n    // the `TypedArray` in byte length. If an element of `xs` does not show\n    // this property, a new `TypedArray` that satisfy this property will be\n    // constructed and pushed into `normalizedXs`.\n    var normalizedXs = [];\n    xs.forEach(function (x) {\n        totalByteLength += x.byteLength;\n        // tslint:disable:no-any\n        normalizedXs.push(x.byteLength === x.buffer.byteLength ? x :\n            new x.constructor(x));\n        if (!(x instanceof Float32Array || x instanceof Int32Array ||\n            x instanceof Uint8Array)) {\n            throw new Error(\"Unsupported TypedArray subtype: \" + x.constructor.name);\n        }\n        // tslint:enable:no-any\n    });\n    var y = new Uint8Array(totalByteLength);\n    var offset = 0;\n    normalizedXs.forEach(function (x) {\n        y.set(new Uint8Array(x.buffer), offset);\n        offset += x.byteLength;\n    });\n    return y.buffer;\n}\nexports.concatenateTypedArrays = concatenateTypedArrays;\n// Use Buffer on Node.js instead of Blob/atob/btoa\nvar useNodeBuffer = typeof Buffer !== 'undefined' &&\n    (typeof Blob === 'undefined' || typeof atob === 'undefined' ||\n        typeof btoa === 'undefined');\n/**\n * Calculate the byte length of a JavaScript string.\n *\n * Note that a JavaScript string can contain wide characters, therefore the\n * length of the string is not necessarily equal to the byte length.\n *\n * @param str Input string.\n * @returns Byte length.\n */\nfunction stringByteLength(str) {\n    if (useNodeBuffer) {\n        return Buffer.byteLength(str);\n    }\n    return new Blob([str]).size;\n}\nexports.stringByteLength = stringByteLength;\n/**\n * Encode an ArrayBuffer as a base64 encoded string.\n *\n * @param buffer `ArrayBuffer` to be converted.\n * @returns A string that base64-encodes `buffer`.\n */\nfunction arrayBufferToBase64String(buffer) {\n    if (useNodeBuffer) {\n        return Buffer.from(buffer).toString('base64');\n    }\n    return btoa(String.fromCharCode.apply(null, new Uint8Array(buffer)));\n}\nexports.arrayBufferToBase64String = arrayBufferToBase64String;\n/**\n * Decode a base64 string as an ArrayBuffer.\n *\n * @param str Base64 string.\n * @returns Decoded `ArrayBuffer`.\n */\nfunction base64StringToArrayBuffer(str) {\n    if (useNodeBuffer) {\n        var buf = Buffer.from(str, 'base64');\n        return buf.buffer.slice(buf.byteOffset, buf.byteOffset + buf.byteLength);\n    }\n    var s = atob(str);\n    var buffer = new Uint8Array(s.length);\n    for (var i = 0; i < s.length; ++i) {\n        buffer.set([s.charCodeAt(i)], i);\n    }\n    return buffer.buffer;\n}\nexports.base64StringToArrayBuffer = base64StringToArrayBuffer;\n/**\n * Concatenate a number of ArrayBuffers into one.\n *\n * @param buffers A number of array buffers to concatenate.\n * @returns Result of concatenating `buffers` in order.\n */\nfunction concatenateArrayBuffers(buffers) {\n    var totalByteLength = 0;\n    buffers.forEach(function (buffer) {\n        totalByteLength += buffer.byteLength;\n    });\n    var temp = new Uint8Array(totalByteLength);\n    var offset = 0;\n    buffers.forEach(function (buffer) {\n        temp.set(new Uint8Array(buffer), offset);\n        offset += buffer.byteLength;\n    });\n    return temp.buffer;\n}\nexports.concatenateArrayBuffers = concatenateArrayBuffers;\n/**\n * Get the basename of a path.\n *\n * Behaves in a way analogous to Linux's basename command.\n *\n * @param path\n */\nfunction basename(path) {\n    var SEPARATOR = '/';\n    path = path.trim();\n    while (path.endsWith(SEPARATOR)) {\n        path = path.slice(0, path.length - 1);\n    }\n    var items = path.split(SEPARATOR);\n    return items[items.length - 1];\n}\nexports.basename = basename;\n/**\n * Populate ModelArtifactsInfo fields for a model with JSON topology.\n * @param modelArtifacts\n * @returns A ModelArtifactsInfo object.\n */\nfunction getModelArtifactsInfoForJSON(modelArtifacts) {\n    if (modelArtifacts.modelTopology instanceof ArrayBuffer) {\n        throw new Error('Expected JSON model topology, received ArrayBuffer.');\n    }\n    return {\n        dateSaved: new Date(),\n        modelTopologyType: 'JSON',\n        modelTopologyBytes: modelArtifacts.modelTopology == null ?\n            0 :\n            stringByteLength(JSON.stringify(modelArtifacts.modelTopology)),\n        weightSpecsBytes: modelArtifacts.weightSpecs == null ?\n            0 :\n            stringByteLength(JSON.stringify(modelArtifacts.weightSpecs)),\n        weightDataBytes: modelArtifacts.weightData == null ?\n            0 :\n            modelArtifacts.weightData.byteLength,\n    };\n}\nexports.getModelArtifactsInfoForJSON = getModelArtifactsInfoForJSON;\n//# sourceMappingURL=io_utils.js.map","\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\n/* Type definitions for exporting and importing of models. */\n/**\n * A map from Tensor dtype to number of bytes per element of the Tensor.\n */\nexports.DTYPE_VALUE_SIZE_MAP = {\n    'float32': 4,\n    'int32': 4,\n    'uint16': 2,\n    'uint8': 1,\n    'bool': 1,\n};\n//# sourceMappingURL=types.js.map","\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : new P(function (resolve) { resolve(result.value); }).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nvar __generator = (this && this.__generator) || function (thisArg, body) {\n    var _ = { label: 0, sent: function() { if (t[0] & 1) throw t[1]; return t[1]; }, trys: [], ops: [] }, f, y, t, g;\n    return g = { next: verb(0), \"throw\": verb(1), \"return\": verb(2) }, typeof Symbol === \"function\" && (g[Symbol.iterator] = function() { return this; }), g;\n    function verb(n) { return function (v) { return step([n, v]); }; }\n    function step(op) {\n        if (f) throw new TypeError(\"Generator is already executing.\");\n        while (_) try {\n            if (f = 1, y && (t = op[0] & 2 ? y[\"return\"] : op[0] ? y[\"throw\"] || ((t = y[\"return\"]) && t.call(y), 0) : y.next) && !(t = t.call(y, op[1])).done) return t;\n            if (y = 0, t) op = [op[0] & 2, t.value];\n            switch (op[0]) {\n                case 0: case 1: t = op; break;\n                case 4: _.label++; return { value: op[1], done: false };\n                case 5: _.label++; y = op[1]; op = [0]; continue;\n                case 7: op = _.ops.pop(); _.trys.pop(); continue;\n                default:\n                    if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) { _ = 0; continue; }\n                    if (op[0] === 3 && (!t || (op[1] > t[0] && op[1] < t[3]))) { _.label = op[1]; break; }\n                    if (op[0] === 6 && _.label < t[1]) { _.label = t[1]; t = op; break; }\n                    if (t && _.label < t[2]) { _.label = t[2]; _.ops.push(op); break; }\n                    if (t[2]) _.ops.pop();\n                    _.trys.pop(); continue;\n            }\n            op = body.call(thisArg, _);\n        } catch (e) { op = [6, e]; y = 0; } finally { f = t = 0; }\n        if (op[0] & 5) throw op[1]; return { value: op[0] ? op[1] : void 0, done: true };\n    }\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\n/**\n * Classes and functions for model management across multiple storage mediums.\n *\n * Supported client actions:\n * - Listing models on all registered storage mediums.\n * - Remove model by URL from any registered storage mediums, by using URL\n *   string.\n * - Moving or copying model from one path to another in the same medium or from\n *   one medium to another, by using URL strings.\n */\nvar util_1 = require(\"../util\");\nvar router_registry_1 = require(\"./router_registry\");\nvar URL_SCHEME_SUFFIX = '://';\nvar ModelStoreManagerRegistry = /** @class */ (function () {\n    function ModelStoreManagerRegistry() {\n        this.managers = {};\n    }\n    ModelStoreManagerRegistry.getInstance = function () {\n        if (ModelStoreManagerRegistry.instance == null) {\n            ModelStoreManagerRegistry.instance = new ModelStoreManagerRegistry();\n        }\n        return ModelStoreManagerRegistry.instance;\n    };\n    /**\n     * Register a save-handler router.\n     *\n     * @param saveRouter A function that maps a URL-like string onto an instance\n     * of `IOHandler` with the `save` method defined or `null`.\n     */\n    ModelStoreManagerRegistry.registerManager = function (scheme, manager) {\n        util_1.assert(scheme != null, function () { return 'scheme must not be undefined or null.'; });\n        if (scheme.endsWith(URL_SCHEME_SUFFIX)) {\n            scheme = scheme.slice(0, scheme.indexOf(URL_SCHEME_SUFFIX));\n        }\n        util_1.assert(scheme.length > 0, function () { return 'scheme must not be an empty string.'; });\n        var registry = ModelStoreManagerRegistry.getInstance();\n        util_1.assert(registry.managers[scheme] == null, function () { return \"A model store manager is already registered for scheme '\" + scheme + \"'.\"; });\n        registry.managers[scheme] = manager;\n    };\n    ModelStoreManagerRegistry.getManager = function (scheme) {\n        var manager = this.getInstance().managers[scheme];\n        if (manager == null) {\n            throw new Error(\"Cannot find model manager for scheme '\" + scheme + \"'\");\n        }\n        return manager;\n    };\n    ModelStoreManagerRegistry.getSchemes = function () {\n        return Object.keys(this.getInstance().managers);\n    };\n    return ModelStoreManagerRegistry;\n}());\nexports.ModelStoreManagerRegistry = ModelStoreManagerRegistry;\n/**\n * Helper method for parsing a URL string into a scheme and a path.\n *\n * @param url E.g., 'localstorage://my-model'\n * @returns A dictionary with two fields: scheme and path.\n *   Scheme: e.g., 'localstorage' in the example above.\n *   Path: e.g., 'my-model' in the example above.\n */\nfunction parseURL(url) {\n    if (url.indexOf(URL_SCHEME_SUFFIX) === -1) {\n        throw new Error(\"The url string provided does not contain a scheme. \" +\n            \"Supported schemes are: \" +\n            (\"\" + ModelStoreManagerRegistry.getSchemes().join(',')));\n    }\n    return {\n        scheme: url.split(URL_SCHEME_SUFFIX)[0],\n        path: url.split(URL_SCHEME_SUFFIX)[1],\n    };\n}\nfunction cloneModelInternal(sourceURL, destURL, deleteSource) {\n    if (deleteSource === void 0) { deleteSource = false; }\n    return __awaiter(this, void 0, void 0, function () {\n        var loadHandlers, loadHandler, saveHandlers, saveHandler, sourceScheme, sourcePath, sameMedium, modelArtifacts, saveResult;\n        return __generator(this, function (_a) {\n            switch (_a.label) {\n                case 0:\n                    util_1.assert(sourceURL !== destURL, function () { return \"Old path and new path are the same: '\" + sourceURL + \"'\"; });\n                    loadHandlers = router_registry_1.IORouterRegistry.getLoadHandlers(sourceURL);\n                    util_1.assert(loadHandlers.length > 0, function () { return \"Copying failed because no load handler is found for source URL \" + sourceURL + \".\"; });\n                    util_1.assert(loadHandlers.length < 2, function () { return \"Copying failed because more than one (\" + loadHandlers.length + \") \" +\n                        (\"load handlers for source URL \" + sourceURL + \".\"); });\n                    loadHandler = loadHandlers[0];\n                    saveHandlers = router_registry_1.IORouterRegistry.getSaveHandlers(destURL);\n                    util_1.assert(saveHandlers.length > 0, function () { return \"Copying failed because no save handler is found for destination \" +\n                        (\"URL \" + destURL + \".\"); });\n                    util_1.assert(saveHandlers.length < 2, function () { return \"Copying failed because more than one (\" + loadHandlers.length + \") \" +\n                        (\"save handlers for destination URL \" + destURL + \".\"); });\n                    saveHandler = saveHandlers[0];\n                    sourceScheme = parseURL(sourceURL).scheme;\n                    sourcePath = parseURL(sourceURL).path;\n                    sameMedium = sourceScheme === parseURL(sourceURL).scheme;\n                    return [4 /*yield*/, loadHandler.load()];\n                case 1:\n                    modelArtifacts = _a.sent();\n                    if (!(deleteSource && sameMedium)) return [3 /*break*/, 3];\n                    return [4 /*yield*/, ModelStoreManagerRegistry.getManager(sourceScheme)\n                            .removeModel(sourcePath)];\n                case 2:\n                    _a.sent();\n                    _a.label = 3;\n                case 3: return [4 /*yield*/, saveHandler.save(modelArtifacts)];\n                case 4:\n                    saveResult = _a.sent();\n                    if (!(deleteSource && !sameMedium)) return [3 /*break*/, 6];\n                    return [4 /*yield*/, ModelStoreManagerRegistry.getManager(sourceScheme)\n                            .removeModel(sourcePath)];\n                case 5:\n                    _a.sent();\n                    _a.label = 6;\n                case 6: return [2 /*return*/, saveResult.modelArtifactsInfo];\n            }\n        });\n    });\n}\n/**\n * List all models stored in registered storage mediums.\n *\n * For a web browser environment, the registered mediums are Local Storage and\n * IndexedDB.\n *\n * ```js\n * // First create and save a model.\n * const model = tf.sequential();\n * model.add(tf.layers.dense(\n *     {units: 1, inputShape: [10], activation: 'sigmoid'}));\n * await model.save('localstorage://demo/management/model1');\n *\n * // Then list existing models.\n * console.log(JSON.stringify(await tf.io.listModels()));\n *\n * // Delete the model.\n * await tf.io.removeModel('localstorage://demo/management/model1');\n *\n * // List models again.\n * console.log(JSON.stringify(await tf.io.listModels()));\n * ```\n *\n * @returns A `Promise` of a dictionary mapping URLs of existing models to\n * their model artifacts info. URLs include medium-specific schemes, e.g.,\n *   'indexeddb://my/model/1'. Model artifacts info include type of the\n * model's topology, byte sizes of the topology, weights, etc.\n */\n/**\n * @doc {\n *   heading: 'Models',\n *   subheading: 'Management',\n *   namespace: 'io',\n *   ignoreCI: true\n * }\n */\nfunction listModels() {\n    return __awaiter(this, void 0, void 0, function () {\n        var schemes, out, _i, schemes_1, scheme, schemeOut, path, url;\n        return __generator(this, function (_a) {\n            switch (_a.label) {\n                case 0:\n                    schemes = ModelStoreManagerRegistry.getSchemes();\n                    out = {};\n                    _i = 0, schemes_1 = schemes;\n                    _a.label = 1;\n                case 1:\n                    if (!(_i < schemes_1.length)) return [3 /*break*/, 4];\n                    scheme = schemes_1[_i];\n                    return [4 /*yield*/, ModelStoreManagerRegistry.getManager(scheme).listModels()];\n                case 2:\n                    schemeOut = _a.sent();\n                    for (path in schemeOut) {\n                        url = scheme + URL_SCHEME_SUFFIX + path;\n                        out[url] = schemeOut[path];\n                    }\n                    _a.label = 3;\n                case 3:\n                    _i++;\n                    return [3 /*break*/, 1];\n                case 4: return [2 /*return*/, out];\n            }\n        });\n    });\n}\nexports.listModels = listModels;\n/**\n * Remove a model specified by URL from a reigstered storage medium.\n *\n * ```js\n * // First create and save a model.\n * const model = tf.sequential();\n * model.add(tf.layers.dense(\n *     {units: 1, inputShape: [10], activation: 'sigmoid'}));\n * await model.save('localstorage://demo/management/model1');\n *\n * // Then list existing models.\n * console.log(JSON.stringify(await tf.io.listModels()));\n *\n * // Delete the model.\n * await tf.io.removeModel('localstorage://demo/management/model1');\n *\n * // List models again.\n * console.log(JSON.stringify(await tf.io.listModels()));\n * ```\n *\n * @param url A URL to a stored model, with a scheme prefix, e.g.,\n *   'localstorage://my-model-1', 'indexeddb://my/model/2'.\n * @returns ModelArtifactsInfo of the deleted model (if and only if deletion\n *   is successful).\n * @throws Error if deletion fails, e.g., if no model exists at `path`.\n */\n/**\n * @doc {\n *   heading: 'Models',\n *   subheading: 'Management',\n *   namespace: 'io',\n *   ignoreCI: true\n * }\n */\nfunction removeModel(url) {\n    return __awaiter(this, void 0, void 0, function () {\n        var schemeAndPath, manager;\n        return __generator(this, function (_a) {\n            schemeAndPath = parseURL(url);\n            manager = ModelStoreManagerRegistry.getManager(schemeAndPath.scheme);\n            return [2 /*return*/, manager.removeModel(schemeAndPath.path)];\n        });\n    });\n}\nexports.removeModel = removeModel;\n/**\n * Copy a model from one URL to another.\n *\n * This function supports:\n *\n * 1. Copying within a storage medium, e.g.,\n *    `tf.io.copyModel('localstorage://model-1', 'localstorage://model-2')`\n * 2. Copying between two storage mediums, e.g.,\n *    `tf.io.copyModel('localstorage://model-1', 'indexeddb://model-1')`\n *\n * ```js\n * // First create and save a model.\n * const model = tf.sequential();\n * model.add(tf.layers.dense(\n *     {units: 1, inputShape: [10], activation: 'sigmoid'}));\n * await model.save('localstorage://demo/management/model1');\n *\n * // Then list existing models.\n * console.log(JSON.stringify(await tf.io.listModels()));\n *\n * // Copy the model, from Local Storage to IndexedDB.\n * await tf.io.copyModel(\n *     'localstorage://demo/management/model1',\n *     'indexeddb://demo/management/model1');\n *\n * // List models again.\n * console.log(JSON.stringify(await tf.io.listModels()));\n *\n * // Remove both models.\n * await tf.io.removeModel('localstorage://demo/management/model1');\n * await tf.io.removeModel('indexeddb://demo/management/model1');\n * ```\n *\n * @param sourceURL Source URL of copying.\n * @param destURL Destination URL of copying.\n * @returns ModelArtifactsInfo of the copied model (if and only if copying\n *   is successful).\n * @throws Error if copying fails, e.g., if no model exists at `sourceURL`, or\n *   if `oldPath` and `newPath` are identical.\n */\n/**\n * @doc {\n *   heading: 'Models',\n *   subheading: 'Management',\n *   namespace: 'io',\n *   ignoreCI: true\n * }\n */\nfunction copyModel(sourceURL, destURL) {\n    return __awaiter(this, void 0, void 0, function () {\n        var deleteSource;\n        return __generator(this, function (_a) {\n            deleteSource = false;\n            return [2 /*return*/, cloneModelInternal(sourceURL, destURL, deleteSource)];\n        });\n    });\n}\nexports.copyModel = copyModel;\n/**\n * Move a model from one URL to another.\n *\n * This function supports:\n *\n * 1. Moving within a storage medium, e.g.,\n *    `tf.io.moveModel('localstorage://model-1', 'localstorage://model-2')`\n * 2. Moving between two storage mediums, e.g.,\n *    `tf.io.moveModel('localstorage://model-1', 'indexeddb://model-1')`\n *\n * ```js\n * // First create and save a model.\n * const model = tf.sequential();\n * model.add(tf.layers.dense(\n *     {units: 1, inputShape: [10], activation: 'sigmoid'}));\n * await model.save('localstorage://demo/management/model1');\n *\n * // Then list existing models.\n * console.log(JSON.stringify(await tf.io.listModels()));\n *\n * // Move the model, from Local Storage to IndexedDB.\n * await tf.io.moveModel(\n *     'localstorage://demo/management/model1',\n *     'indexeddb://demo/management/model1');\n *\n * // List models again.\n * console.log(JSON.stringify(await tf.io.listModels()));\n *\n * // Remove the moved model.\n * await tf.io.removeModel('indexeddb://demo/management/model1');\n * ```\n *\n * @param sourceURL Source URL of moving.\n * @param destURL Destination URL of moving.\n * @returns ModelArtifactsInfo of the copied model (if and only if copying\n *   is successful).\n * @throws Error if moving fails, e.g., if no model exists at `sourceURL`, or\n *   if `oldPath` and `newPath` are identical.\n */\n/**\n * @doc {\n *   heading: 'Models',\n *   subheading: 'Management',\n *   namespace: 'io',\n *   ignoreCI: true\n * }\n */\nfunction moveModel(sourceURL, destURL) {\n    return __awaiter(this, void 0, void 0, function () {\n        var deleteSource;\n        return __generator(this, function (_a) {\n            deleteSource = true;\n            return [2 /*return*/, cloneModelInternal(sourceURL, destURL, deleteSource)];\n        });\n    });\n}\nexports.moveModel = moveModel;\n//# sourceMappingURL=model_management.js.map","\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar IORouterRegistry = /** @class */ (function () {\n    function IORouterRegistry() {\n        this.saveRouters = [];\n        this.loadRouters = [];\n    }\n    IORouterRegistry.getInstance = function () {\n        if (IORouterRegistry.instance == null) {\n            IORouterRegistry.instance = new IORouterRegistry();\n        }\n        return IORouterRegistry.instance;\n    };\n    /**\n     * Register a save-handler router.\n     *\n     * @param saveRouter A function that maps a URL-like string onto an instance\n     * of `IOHandler` with the `save` method defined or `null`.\n     */\n    IORouterRegistry.registerSaveRouter = function (saveRouter) {\n        IORouterRegistry.getInstance().saveRouters.push(saveRouter);\n    };\n    /**\n     * Register a load-handler router.\n     *\n     * @param loadRouter A function that maps a URL-like string onto an instance\n     * of `IOHandler` with the `load` method defined or `null`.\n     */\n    IORouterRegistry.registerLoadRouter = function (loadRouter) {\n        IORouterRegistry.getInstance().loadRouters.push(loadRouter);\n    };\n    /**\n     * Look up IOHandler for saving, given a URL-like string.\n     *\n     * @param url\n     * @returns If only one match is found, an instance of IOHandler with the\n     * `save` method defined. If no match is found, `null`.\n     * @throws Error, if more than one match is found.\n     */\n    IORouterRegistry.getSaveHandlers = function (url) {\n        return IORouterRegistry.getHandlers(url, 'save');\n    };\n    /**\n     * Look up IOHandler for loading, given a URL-like string.\n     *\n     * @param url\n     * @param onProgress Optional, progress callback function, fired periodically\n     *   before the load is completed.\n     * @returns All valid handlers for `url`, given the currently registered\n     *   handler routers.\n     */\n    IORouterRegistry.getLoadHandlers = function (url, onProgress) {\n        return IORouterRegistry.getHandlers(url, 'load', onProgress);\n    };\n    IORouterRegistry.getHandlers = function (url, handlerType, onProgress) {\n        var validHandlers = [];\n        var routers = handlerType === 'load' ?\n            IORouterRegistry.getInstance().loadRouters :\n            IORouterRegistry.getInstance().saveRouters;\n        routers.forEach(function (router) {\n            var handler = router(url, onProgress);\n            if (handler !== null) {\n                validHandlers.push(handler);\n            }\n        });\n        return validHandlers;\n    };\n    return IORouterRegistry;\n}());\nexports.IORouterRegistry = IORouterRegistry;\nexports.registerSaveRouter = function (loudRouter) {\n    return IORouterRegistry.registerSaveRouter(loudRouter);\n};\nexports.registerLoadRouter = function (loudRouter) {\n    return IORouterRegistry.registerLoadRouter(loudRouter);\n};\nexports.getSaveHandlers = function (url) {\n    return IORouterRegistry.getSaveHandlers(url);\n};\nexports.getLoadHandlers = function (url, onProgress) {\n    return IORouterRegistry.getLoadHandlers(url, onProgress);\n};\n//# sourceMappingURL=router_registry.js.map","\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : new P(function (resolve) { resolve(result.value); }).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nvar __generator = (this && this.__generator) || function (thisArg, body) {\n    var _ = { label: 0, sent: function() { if (t[0] & 1) throw t[1]; return t[1]; }, trys: [], ops: [] }, f, y, t, g;\n    return g = { next: verb(0), \"throw\": verb(1), \"return\": verb(2) }, typeof Symbol === \"function\" && (g[Symbol.iterator] = function() { return this; }), g;\n    function verb(n) { return function (v) { return step([n, v]); }; }\n    function step(op) {\n        if (f) throw new TypeError(\"Generator is already executing.\");\n        while (_) try {\n            if (f = 1, y && (t = op[0] & 2 ? y[\"return\"] : op[0] ? y[\"throw\"] || ((t = y[\"return\"]) && t.call(y), 0) : y.next) && !(t = t.call(y, op[1])).done) return t;\n            if (y = 0, t) op = [op[0] & 2, t.value];\n            switch (op[0]) {\n                case 0: case 1: t = op; break;\n                case 4: _.label++; return { value: op[1], done: false };\n                case 5: _.label++; y = op[1]; op = [0]; continue;\n                case 7: op = _.ops.pop(); _.trys.pop(); continue;\n                default:\n                    if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) { _ = 0; continue; }\n                    if (op[0] === 3 && (!t || (op[1] > t[0] && op[1] < t[3]))) { _.label = op[1]; break; }\n                    if (op[0] === 6 && _.label < t[1]) { _.label = t[1]; t = op; break; }\n                    if (t && _.label < t[2]) { _.label = t[2]; _.ops.push(op); break; }\n                    if (t[2]) _.ops.pop();\n                    _.trys.pop(); continue;\n            }\n            op = body.call(thisArg, _);\n        } catch (e) { op = [6, e]; y = 0; } finally { f = t = 0; }\n        if (op[0] & 5) throw op[1]; return { value: op[0] ? op[1] : void 0, done: true };\n    }\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar environment_1 = require(\"../environment\");\nvar util_1 = require(\"../util\");\nvar io_utils_1 = require(\"./io_utils\");\nvar model_management_1 = require(\"./model_management\");\nvar router_registry_1 = require(\"./router_registry\");\nvar PATH_SEPARATOR = '/';\nvar PATH_PREFIX = 'tensorflowjs_models';\nvar INFO_SUFFIX = 'info';\nvar MODEL_TOPOLOGY_SUFFIX = 'model_topology';\nvar WEIGHT_SPECS_SUFFIX = 'weight_specs';\nvar WEIGHT_DATA_SUFFIX = 'weight_data';\nvar MODEL_METADATA_SUFFIX = 'model_metadata';\n/**\n * Purge all tensorflow.js-saved model artifacts from local storage.\n *\n * @returns Paths of the models purged.\n */\nfunction purgeLocalStorageArtifacts() {\n    if (!environment_1.ENV.getBool('IS_BROWSER') ||\n        typeof window.localStorage === 'undefined') {\n        throw new Error('purgeLocalStorageModels() cannot proceed because local storage is ' +\n            'unavailable in the current environment.');\n    }\n    var LS = window.localStorage;\n    var purgedModelPaths = [];\n    for (var i = 0; i < LS.length; ++i) {\n        var key = LS.key(i);\n        var prefix = PATH_PREFIX + PATH_SEPARATOR;\n        if (key.startsWith(prefix) && key.length > prefix.length) {\n            LS.removeItem(key);\n            var modelName = getModelPathFromKey(key);\n            if (purgedModelPaths.indexOf(modelName) === -1) {\n                purgedModelPaths.push(modelName);\n            }\n        }\n    }\n    return purgedModelPaths;\n}\nexports.purgeLocalStorageArtifacts = purgeLocalStorageArtifacts;\nfunction getModelKeys(path) {\n    return {\n        info: [PATH_PREFIX, path, INFO_SUFFIX].join(PATH_SEPARATOR),\n        topology: [PATH_PREFIX, path, MODEL_TOPOLOGY_SUFFIX].join(PATH_SEPARATOR),\n        weightSpecs: [PATH_PREFIX, path, WEIGHT_SPECS_SUFFIX].join(PATH_SEPARATOR),\n        weightData: [PATH_PREFIX, path, WEIGHT_DATA_SUFFIX].join(PATH_SEPARATOR),\n        modelMetadata: [PATH_PREFIX, path, MODEL_METADATA_SUFFIX].join(PATH_SEPARATOR)\n    };\n}\n/**\n * Get model path from a local-storage key.\n *\n * E.g., 'tensorflowjs_models/my/model/1/info' --> 'my/model/1'\n *\n * @param key\n */\nfunction getModelPathFromKey(key) {\n    var items = key.split(PATH_SEPARATOR);\n    if (items.length < 3) {\n        throw new Error(\"Invalid key format: \" + key);\n    }\n    return items.slice(1, items.length - 1).join(PATH_SEPARATOR);\n}\nfunction maybeStripScheme(key) {\n    return key.startsWith(BrowserLocalStorage.URL_SCHEME) ?\n        key.slice(BrowserLocalStorage.URL_SCHEME.length) :\n        key;\n}\n/**\n * IOHandler subclass: Browser Local Storage.\n *\n * See the doc string to `browserLocalStorage` for more details.\n */\nvar BrowserLocalStorage = /** @class */ (function () {\n    function BrowserLocalStorage(modelPath) {\n        if (!environment_1.ENV.getBool('IS_BROWSER') ||\n            typeof window.localStorage === 'undefined') {\n            // TODO(cais): Add more info about what IOHandler subtypes are\n            // available.\n            //   Maybe point to a doc page on the web and/or automatically determine\n            //   the available IOHandlers and print them in the error message.\n            throw new Error('The current environment does not support local storage.');\n        }\n        this.LS = window.localStorage;\n        if (modelPath == null || !modelPath) {\n            throw new Error('For local storage, modelPath must not be null, undefined or empty.');\n        }\n        this.modelPath = modelPath;\n        this.keys = getModelKeys(this.modelPath);\n    }\n    /**\n     * Save model artifacts to browser local storage.\n     *\n     * See the documentation to `browserLocalStorage` for details on the saved\n     * artifacts.\n     *\n     * @param modelArtifacts The model artifacts to be stored.\n     * @returns An instance of SaveResult.\n     */\n    BrowserLocalStorage.prototype.save = function (modelArtifacts) {\n        return __awaiter(this, void 0, void 0, function () {\n            var topology, weightSpecs, modelArtifactsInfo;\n            return __generator(this, function (_a) {\n                if (modelArtifacts.modelTopology instanceof ArrayBuffer) {\n                    throw new Error('BrowserLocalStorage.save() does not support saving model topology ' +\n                        'in binary formats yet.');\n                }\n                else {\n                    topology = JSON.stringify(modelArtifacts.modelTopology);\n                    weightSpecs = JSON.stringify(modelArtifacts.weightSpecs);\n                    modelArtifactsInfo = io_utils_1.getModelArtifactsInfoForJSON(modelArtifacts);\n                    try {\n                        this.LS.setItem(this.keys.info, JSON.stringify(modelArtifactsInfo));\n                        this.LS.setItem(this.keys.topology, topology);\n                        this.LS.setItem(this.keys.weightSpecs, weightSpecs);\n                        this.LS.setItem(this.keys.weightData, io_utils_1.arrayBufferToBase64String(modelArtifacts.weightData));\n                        this.LS.setItem(this.keys.modelMetadata, JSON.stringify({\n                            format: modelArtifacts.format,\n                            generatedBy: modelArtifacts.generatedBy,\n                            convertedBy: modelArtifacts.convertedBy\n                        }));\n                        return [2 /*return*/, { modelArtifactsInfo: modelArtifactsInfo }];\n                    }\n                    catch (err) {\n                        // If saving failed, clean up all items saved so far.\n                        this.LS.removeItem(this.keys.info);\n                        this.LS.removeItem(this.keys.topology);\n                        this.LS.removeItem(this.keys.weightSpecs);\n                        this.LS.removeItem(this.keys.weightData);\n                        this.LS.removeItem(this.keys.modelMetadata);\n                        throw new Error(\"Failed to save model '\" + this.modelPath + \"' to local storage: \" +\n                            \"size quota being exceeded is a possible cause of this failure: \" +\n                            (\"modelTopologyBytes=\" + modelArtifactsInfo.modelTopologyBytes + \", \") +\n                            (\"weightSpecsBytes=\" + modelArtifactsInfo.weightSpecsBytes + \", \") +\n                            (\"weightDataBytes=\" + modelArtifactsInfo.weightDataBytes + \".\"));\n                    }\n                }\n                return [2 /*return*/];\n            });\n        });\n    };\n    /**\n     * Load a model from local storage.\n     *\n     * See the documentation to `browserLocalStorage` for details on the saved\n     * artifacts.\n     *\n     * @returns The loaded model (if loading succeeds).\n     */\n    BrowserLocalStorage.prototype.load = function () {\n        return __awaiter(this, void 0, void 0, function () {\n            var info, out, topology, weightSpecs, metadataString, metadata, weightDataBase64;\n            return __generator(this, function (_a) {\n                info = JSON.parse(this.LS.getItem(this.keys.info));\n                if (info == null) {\n                    throw new Error(\"In local storage, there is no model with name '\" + this.modelPath + \"'\");\n                }\n                if (info.modelTopologyType !== 'JSON') {\n                    throw new Error('BrowserLocalStorage does not support loading non-JSON model ' +\n                        'topology yet.');\n                }\n                out = {};\n                topology = JSON.parse(this.LS.getItem(this.keys.topology));\n                if (topology == null) {\n                    throw new Error(\"In local storage, the topology of model '\" + this.modelPath + \"' \" +\n                        \"is missing.\");\n                }\n                out.modelTopology = topology;\n                weightSpecs = JSON.parse(this.LS.getItem(this.keys.weightSpecs));\n                if (weightSpecs == null) {\n                    throw new Error(\"In local storage, the weight specs of model '\" + this.modelPath + \"' \" +\n                        \"are missing.\");\n                }\n                out.weightSpecs = weightSpecs;\n                metadataString = this.LS.getItem(this.keys.modelMetadata);\n                if (metadataString != null) {\n                    metadata = JSON.parse(metadataString);\n                    out.format = metadata['format'];\n                    out.generatedBy = metadata['generatedBy'];\n                    out.convertedBy = metadata['convertedBy'];\n                }\n                weightDataBase64 = this.LS.getItem(this.keys.weightData);\n                if (weightDataBase64 == null) {\n                    throw new Error(\"In local storage, the binary weight values of model \" +\n                        (\"'\" + this.modelPath + \"' are missing.\"));\n                }\n                out.weightData = io_utils_1.base64StringToArrayBuffer(weightDataBase64);\n                return [2 /*return*/, out];\n            });\n        });\n    };\n    BrowserLocalStorage.URL_SCHEME = 'localstorage://';\n    return BrowserLocalStorage;\n}());\nexports.BrowserLocalStorage = BrowserLocalStorage;\nexports.localStorageRouter = function (url) {\n    if (!environment_1.ENV.getBool('IS_BROWSER')) {\n        return null;\n    }\n    else {\n        if (!Array.isArray(url) && url.startsWith(BrowserLocalStorage.URL_SCHEME)) {\n            return browserLocalStorage(url.slice(BrowserLocalStorage.URL_SCHEME.length));\n        }\n        else {\n            return null;\n        }\n    }\n};\nrouter_registry_1.IORouterRegistry.registerSaveRouter(exports.localStorageRouter);\nrouter_registry_1.IORouterRegistry.registerLoadRouter(exports.localStorageRouter);\n/**\n * Factory function for local storage IOHandler.\n *\n * This `IOHandler` supports both `save` and `load`.\n *\n * For each model's saved artifacts, four items are saved to local storage.\n *   - `${PATH_SEPARATOR}/${modelPath}/info`: Contains meta-info about the\n *     model, such as date saved, type of the topology, size in bytes, etc.\n *   - `${PATH_SEPARATOR}/${modelPath}/topology`: Model topology. For Keras-\n *     style models, this is a stringized JSON.\n *   - `${PATH_SEPARATOR}/${modelPath}/weight_specs`: Weight specs of the\n *     model, can be used to decode the saved binary weight values (see\n *     item below).\n *   - `${PATH_SEPARATOR}/${modelPath}/weight_data`: Concatenated binary\n *     weight values, stored as a base64-encoded string.\n *\n * Saving may throw an `Error` if the total size of the artifacts exceed the\n * browser-specific quota.\n *\n * @param modelPath A unique identifier for the model to be saved. Must be a\n *   non-empty string.\n * @returns An instance of `IOHandler`, which can be used with, e.g.,\n *   `tf.Model.save`.\n */\nfunction browserLocalStorage(modelPath) {\n    return new BrowserLocalStorage(modelPath);\n}\nexports.browserLocalStorage = browserLocalStorage;\nvar BrowserLocalStorageManager = /** @class */ (function () {\n    function BrowserLocalStorageManager() {\n        util_1.assert(environment_1.ENV.getBool('IS_BROWSER'), function () { return 'Current environment is not a web browser'; });\n        util_1.assert(typeof window.localStorage !== 'undefined', function () { return 'Current browser does not appear to support localStorage'; });\n        this.LS = window.localStorage;\n    }\n    BrowserLocalStorageManager.prototype.listModels = function () {\n        return __awaiter(this, void 0, void 0, function () {\n            var out, prefix, suffix, i, key, modelPath;\n            return __generator(this, function (_a) {\n                out = {};\n                prefix = PATH_PREFIX + PATH_SEPARATOR;\n                suffix = PATH_SEPARATOR + INFO_SUFFIX;\n                for (i = 0; i < this.LS.length; ++i) {\n                    key = this.LS.key(i);\n                    if (key.startsWith(prefix) && key.endsWith(suffix)) {\n                        modelPath = getModelPathFromKey(key);\n                        out[modelPath] = JSON.parse(this.LS.getItem(key));\n                    }\n                }\n                return [2 /*return*/, out];\n            });\n        });\n    };\n    BrowserLocalStorageManager.prototype.removeModel = function (path) {\n        return __awaiter(this, void 0, void 0, function () {\n            var keys, info;\n            return __generator(this, function (_a) {\n                path = maybeStripScheme(path);\n                keys = getModelKeys(path);\n                if (this.LS.getItem(keys.info) == null) {\n                    throw new Error(\"Cannot find model at path '\" + path + \"'\");\n                }\n                info = JSON.parse(this.LS.getItem(keys.info));\n                this.LS.removeItem(keys.info);\n                this.LS.removeItem(keys.topology);\n                this.LS.removeItem(keys.weightSpecs);\n                this.LS.removeItem(keys.weightData);\n                return [2 /*return*/, info];\n            });\n        });\n    };\n    return BrowserLocalStorageManager;\n}());\nexports.BrowserLocalStorageManager = BrowserLocalStorageManager;\nif (environment_1.ENV.getBool('IS_BROWSER')) {\n    // Wrap the construction and registration, to guard against browsers that\n    // don't support Local Storage.\n    try {\n        model_management_1.ModelStoreManagerRegistry.registerManager(BrowserLocalStorage.URL_SCHEME, new BrowserLocalStorageManager());\n    }\n    catch (err) {\n    }\n}\n//# sourceMappingURL=local_storage.js.map","\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : new P(function (resolve) { resolve(result.value); }).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nvar __generator = (this && this.__generator) || function (thisArg, body) {\n    var _ = { label: 0, sent: function() { if (t[0] & 1) throw t[1]; return t[1]; }, trys: [], ops: [] }, f, y, t, g;\n    return g = { next: verb(0), \"throw\": verb(1), \"return\": verb(2) }, typeof Symbol === \"function\" && (g[Symbol.iterator] = function() { return this; }), g;\n    function verb(n) { return function (v) { return step([n, v]); }; }\n    function step(op) {\n        if (f) throw new TypeError(\"Generator is already executing.\");\n        while (_) try {\n            if (f = 1, y && (t = op[0] & 2 ? y[\"return\"] : op[0] ? y[\"throw\"] || ((t = y[\"return\"]) && t.call(y), 0) : y.next) && !(t = t.call(y, op[1])).done) return t;\n            if (y = 0, t) op = [op[0] & 2, t.value];\n            switch (op[0]) {\n                case 0: case 1: t = op; break;\n                case 4: _.label++; return { value: op[1], done: false };\n                case 5: _.label++; y = op[1]; op = [0]; continue;\n                case 7: op = _.ops.pop(); _.trys.pop(); continue;\n                default:\n                    if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) { _ = 0; continue; }\n                    if (op[0] === 3 && (!t || (op[1] > t[0] && op[1] < t[3]))) { _.label = op[1]; break; }\n                    if (op[0] === 6 && _.label < t[1]) { _.label = t[1]; t = op; break; }\n                    if (t && _.label < t[2]) { _.label = t[2]; _.ops.push(op); break; }\n                    if (t[2]) _.ops.pop();\n                    _.trys.pop(); continue;\n            }\n            op = body.call(thisArg, _);\n        } catch (e) { op = [6, e]; y = 0; } finally { f = t = 0; }\n        if (op[0] & 5) throw op[1]; return { value: op[0] ? op[1] : void 0, done: true };\n    }\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\n/**\n * IOHandlers related to files, such as browser-triggered file downloads,\n * user-selected files in browser.\n */\nvar environment_1 = require(\"../environment\");\nvar io_utils_1 = require(\"./io_utils\");\nvar router_registry_1 = require(\"./router_registry\");\nvar DEFAULT_FILE_NAME_PREFIX = 'model';\nvar DEFAULT_JSON_EXTENSION_NAME = '.json';\nvar DEFAULT_WEIGHT_DATA_EXTENSION_NAME = '.weights.bin';\nfunction defer(f) {\n    return new Promise(function (resolve) { return setTimeout(resolve); }).then(f);\n}\nvar BrowserDownloads = /** @class */ (function () {\n    function BrowserDownloads(fileNamePrefix) {\n        if (!environment_1.ENV.getBool('IS_BROWSER')) {\n            // TODO(cais): Provide info on what IOHandlers are available under the\n            //   current environment.\n            throw new Error('browserDownloads() cannot proceed because the current environment ' +\n                'is not a browser.');\n        }\n        if (fileNamePrefix.startsWith(BrowserDownloads.URL_SCHEME)) {\n            fileNamePrefix = fileNamePrefix.slice(BrowserDownloads.URL_SCHEME.length);\n        }\n        if (fileNamePrefix == null || fileNamePrefix.length === 0) {\n            fileNamePrefix = DEFAULT_FILE_NAME_PREFIX;\n        }\n        this.modelTopologyFileName = fileNamePrefix + DEFAULT_JSON_EXTENSION_NAME;\n        this.weightDataFileName =\n            fileNamePrefix + DEFAULT_WEIGHT_DATA_EXTENSION_NAME;\n    }\n    BrowserDownloads.prototype.save = function (modelArtifacts) {\n        return __awaiter(this, void 0, void 0, function () {\n            var weightsURL, weightsManifest, modelTopologyAndWeightManifest, modelTopologyAndWeightManifestURL, jsonAnchor_1, weightDataAnchor_1;\n            return __generator(this, function (_a) {\n                switch (_a.label) {\n                    case 0:\n                        weightsURL = window.URL.createObjectURL(new Blob([modelArtifacts.weightData], { type: 'application/octet-stream' }));\n                        if (!(modelArtifacts.modelTopology instanceof ArrayBuffer)) return [3 /*break*/, 1];\n                        throw new Error('BrowserDownloads.save() does not support saving model topology ' +\n                            'in binary formats yet.');\n                    case 1:\n                        weightsManifest = [{\n                                paths: ['./' + this.weightDataFileName],\n                                weights: modelArtifacts.weightSpecs\n                            }];\n                        modelTopologyAndWeightManifest = {\n                            modelTopology: modelArtifacts.modelTopology,\n                            format: modelArtifacts.format,\n                            generatedBy: modelArtifacts.generatedBy,\n                            convertedBy: modelArtifacts.convertedBy,\n                            weightsManifest: weightsManifest\n                        };\n                        modelTopologyAndWeightManifestURL = window.URL.createObjectURL(new Blob([JSON.stringify(modelTopologyAndWeightManifest)], { type: 'application/json' }));\n                        jsonAnchor_1 = this.jsonAnchor == null ? document.createElement('a') :\n                            this.jsonAnchor;\n                        jsonAnchor_1.download = this.modelTopologyFileName;\n                        jsonAnchor_1.href = modelTopologyAndWeightManifestURL;\n                        // Trigger downloads by evoking a click event on the download anchors.\n                        // When multiple downloads are started synchronously, Firefox will only\n                        // save the last one.\n                        return [4 /*yield*/, defer(function () { return jsonAnchor_1.dispatchEvent(new MouseEvent('click')); })];\n                    case 2:\n                        // Trigger downloads by evoking a click event on the download anchors.\n                        // When multiple downloads are started synchronously, Firefox will only\n                        // save the last one.\n                        _a.sent();\n                        if (!(modelArtifacts.weightData != null)) return [3 /*break*/, 4];\n                        weightDataAnchor_1 = this.weightDataAnchor == null ?\n                            document.createElement('a') :\n                            this.weightDataAnchor;\n                        weightDataAnchor_1.download = this.weightDataFileName;\n                        weightDataAnchor_1.href = weightsURL;\n                        return [4 /*yield*/, defer(function () { return weightDataAnchor_1.dispatchEvent(new MouseEvent('click')); })];\n                    case 3:\n                        _a.sent();\n                        _a.label = 4;\n                    case 4: return [2 /*return*/, { modelArtifactsInfo: io_utils_1.getModelArtifactsInfoForJSON(modelArtifacts) }];\n                }\n            });\n        });\n    };\n    BrowserDownloads.URL_SCHEME = 'downloads://';\n    return BrowserDownloads;\n}());\nexports.BrowserDownloads = BrowserDownloads;\nvar BrowserFiles = /** @class */ (function () {\n    function BrowserFiles(files) {\n        if (files == null || files.length < 1) {\n            throw new Error(\"When calling browserFiles, at least 1 file is required, \" +\n                (\"but received \" + files));\n        }\n        this.files = files;\n    }\n    BrowserFiles.prototype.load = function () {\n        return __awaiter(this, void 0, void 0, function () {\n            var jsonFile, weightFiles;\n            var _this = this;\n            return __generator(this, function (_a) {\n                jsonFile = this.files[0];\n                weightFiles = this.files.slice(1);\n                return [2 /*return*/, new Promise(function (resolve, reject) {\n                        var jsonReader = new FileReader();\n                        jsonReader.onload = function (event) {\n                            // tslint:disable-next-line:no-any\n                            var modelJSON = JSON.parse(event.target.result);\n                            var modelTopology = modelJSON.modelTopology;\n                            if (modelTopology == null) {\n                                reject(new Error(\"modelTopology field is missing from file \" + jsonFile.name));\n                                return;\n                            }\n                            if (weightFiles.length === 0) {\n                                resolve({ modelTopology: modelTopology });\n                            }\n                            var weightsManifest = modelJSON.weightsManifest;\n                            if (weightsManifest == null) {\n                                reject(new Error(\"weightManifest field is missing from file \" + jsonFile.name));\n                                return;\n                            }\n                            var pathToFile;\n                            try {\n                                pathToFile =\n                                    _this.checkManifestAndWeightFiles(weightsManifest, weightFiles);\n                            }\n                            catch (err) {\n                                reject(err);\n                                return;\n                            }\n                            var weightSpecs = [];\n                            var paths = [];\n                            var perFileBuffers = [];\n                            weightsManifest.forEach(function (weightsGroup) {\n                                weightsGroup.paths.forEach(function (path) {\n                                    paths.push(path);\n                                    perFileBuffers.push(null);\n                                });\n                                weightSpecs.push.apply(weightSpecs, weightsGroup.weights);\n                            });\n                            weightsManifest.forEach(function (weightsGroup) {\n                                weightsGroup.paths.forEach(function (path) {\n                                    var weightFileReader = new FileReader();\n                                    weightFileReader.onload = function (event) {\n                                        // tslint:disable-next-line:no-any\n                                        var weightData = event.target.result;\n                                        var index = paths.indexOf(path);\n                                        perFileBuffers[index] = weightData;\n                                        if (perFileBuffers.indexOf(null) === -1) {\n                                            resolve({\n                                                modelTopology: modelTopology,\n                                                weightSpecs: weightSpecs,\n                                                weightData: io_utils_1.concatenateArrayBuffers(perFileBuffers),\n                                            });\n                                        }\n                                    };\n                                    weightFileReader.onerror = function (error) {\n                                        return reject(\"Failed to weights data from file of path '\" + path + \"'.\");\n                                    };\n                                    weightFileReader.readAsArrayBuffer(pathToFile[path]);\n                                });\n                            });\n                        };\n                        jsonReader.onerror = function (error) { return reject(\"Failed to read model topology and weights manifest JSON \" +\n                            (\"from file '\" + jsonFile.name + \"'. BrowserFiles supports loading \") +\n                            \"Keras-style tf.Model artifacts only.\"); };\n                        jsonReader.readAsText(jsonFile);\n                    })];\n            });\n        });\n    };\n    /**\n     * Check the compatibility between weights manifest and weight files.\n     */\n    BrowserFiles.prototype.checkManifestAndWeightFiles = function (manifest, files) {\n        var basenames = [];\n        var fileNames = files.map(function (file) { return io_utils_1.basename(file.name); });\n        var pathToFile = {};\n        for (var _i = 0, manifest_1 = manifest; _i < manifest_1.length; _i++) {\n            var group = manifest_1[_i];\n            group.paths.forEach(function (path) {\n                var pathBasename = io_utils_1.basename(path);\n                if (basenames.indexOf(pathBasename) !== -1) {\n                    throw new Error(\"Duplicate file basename found in weights manifest: \" +\n                        (\"'\" + pathBasename + \"'\"));\n                }\n                basenames.push(pathBasename);\n                if (fileNames.indexOf(pathBasename) === -1) {\n                    throw new Error(\"Weight file with basename '\" + pathBasename + \"' is not provided.\");\n                }\n                else {\n                    pathToFile[path] = files[fileNames.indexOf(pathBasename)];\n                }\n            });\n        }\n        if (basenames.length !== files.length) {\n            throw new Error(\"Mismatch in the number of files in weights manifest \" +\n                (\"(\" + basenames.length + \") and the number of weight files provided \") +\n                (\"(\" + files.length + \").\"));\n        }\n        return pathToFile;\n    };\n    return BrowserFiles;\n}());\nexports.browserDownloadsRouter = function (url) {\n    if (!environment_1.ENV.getBool('IS_BROWSER')) {\n        return null;\n    }\n    else {\n        if (!Array.isArray(url) && url.startsWith(BrowserDownloads.URL_SCHEME)) {\n            return browserDownloads(url.slice(BrowserDownloads.URL_SCHEME.length));\n        }\n        else {\n            return null;\n        }\n    }\n};\nrouter_registry_1.IORouterRegistry.registerSaveRouter(exports.browserDownloadsRouter);\n/**\n * Creates an IOHandler that triggers file downloads from the browser.\n *\n * The returned `IOHandler` instance can be used as model exporting methods such\n * as `tf.Model.save` and supports only saving.\n *\n * ```js\n * const model = tf.sequential();\n * model.add(tf.layers.dense(\n *     {units: 1, inputShape: [10], activation: 'sigmoid'}));\n * const saveResult = await model.save('downloads://mymodel');\n * // This will trigger downloading of two files:\n * //   'mymodel.json' and 'mymodel.weights.bin'.\n * console.log(saveResult);\n * ```\n *\n * @param fileNamePrefix Prefix name of the files to be downloaded. For use with\n *   `tf.Model`, `fileNamePrefix` should follow either of the following two\n *   formats:\n *   1. `null` or `undefined`, in which case the default file\n *      names will be used:\n *      - 'model.json' for the JSON file containing the model topology and\n *        weights manifest.\n *      - 'model.weights.bin' for the binary file containing the binary weight\n *        values.\n *   2. A single string or an Array of a single string, as the file name prefix.\n *      For example, if `'foo'` is provided, the downloaded JSON\n *      file and binary weights file will be named 'foo.json' and\n *      'foo.weights.bin', respectively.\n * @param config Additional configuration for triggering downloads.\n * @returns An instance of `BrowserDownloads` `IOHandler`.\n */\n/**\n * @doc {\n *   heading: 'Models',\n *   subheading: 'Loading',\n *   namespace: 'io',\n *   ignoreCI: true\n * }\n */\nfunction browserDownloads(fileNamePrefix) {\n    if (fileNamePrefix === void 0) { fileNamePrefix = 'model'; }\n    return new BrowserDownloads(fileNamePrefix);\n}\nexports.browserDownloads = browserDownloads;\n/**\n * Creates an IOHandler that loads model artifacts from user-selected files.\n *\n * This method can be used for loading from files such as user-selected files\n * in the browser.\n * When used in conjunction with `tf.loadLayersModel`, an instance of\n * `tf.LayersModel` (Keras-style) can be constructed from the loaded artifacts.\n *\n * ```js\n * // Note: This code snippet won't run properly without the actual file input\n * //   elements in the HTML DOM.\n *\n * // Suppose there are two HTML file input (`<input type=\"file\" ...>`)\n * // elements.\n * const uploadJSONInput = document.getElementById('upload-json');\n * const uploadWeightsInput = document.getElementById('upload-weights');\n * const model = await tf.loadLayersModel(tf.io.browserFiles(\n *     [uploadJSONInput.files[0], uploadWeightsInput.files[0]]));\n * ```\n *\n * @param files `File`s to load from. Currently, this function supports only\n *   loading from files that contain Keras-style models (i.e., `tf.Model`s), for\n *   which an `Array` of `File`s is expected (in that order):\n *   - A JSON file containing the model topology and weight manifest.\n *   - Optionally, One or more binary files containing the binary weights.\n *     These files must have names that match the paths in the `weightsManifest`\n *     contained by the aforementioned JSON file, or errors will be thrown\n *     during loading. These weights files have the same format as the ones\n *     generated by `tensorflowjs_converter` that comes with the `tensorflowjs`\n *     Python PIP package. If no weights files are provided, only the model\n *     topology will be loaded from the JSON file above.\n * @returns An instance of `Files` `IOHandler`.\n */\n/**\n * @doc {\n *   heading: 'Models',\n *   subheading: 'Loading',\n *   namespace: 'io',\n *   ignoreCI: true\n * }\n */\nfunction browserFiles(files) {\n    return new BrowserFiles(files);\n}\nexports.browserFiles = browserFiles;\n//# sourceMappingURL=browser_files.js.map","\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : new P(function (resolve) { resolve(result.value); }).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nvar __generator = (this && this.__generator) || function (thisArg, body) {\n    var _ = { label: 0, sent: function() { if (t[0] & 1) throw t[1]; return t[1]; }, trys: [], ops: [] }, f, y, t, g;\n    return g = { next: verb(0), \"throw\": verb(1), \"return\": verb(2) }, typeof Symbol === \"function\" && (g[Symbol.iterator] = function() { return this; }), g;\n    function verb(n) { return function (v) { return step([n, v]); }; }\n    function step(op) {\n        if (f) throw new TypeError(\"Generator is already executing.\");\n        while (_) try {\n            if (f = 1, y && (t = op[0] & 2 ? y[\"return\"] : op[0] ? y[\"throw\"] || ((t = y[\"return\"]) && t.call(y), 0) : y.next) && !(t = t.call(y, op[1])).done) return t;\n            if (y = 0, t) op = [op[0] & 2, t.value];\n            switch (op[0]) {\n                case 0: case 1: t = op; break;\n                case 4: _.label++; return { value: op[1], done: false };\n                case 5: _.label++; y = op[1]; op = [0]; continue;\n                case 7: op = _.ops.pop(); _.trys.pop(); continue;\n                default:\n                    if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) { _ = 0; continue; }\n                    if (op[0] === 3 && (!t || (op[1] > t[0] && op[1] < t[3]))) { _.label = op[1]; break; }\n                    if (op[0] === 6 && _.label < t[1]) { _.label = t[1]; t = op; break; }\n                    if (t && _.label < t[2]) { _.label = t[2]; _.ops.push(op); break; }\n                    if (t[2]) _.ops.pop();\n                    _.trys.pop(); continue;\n            }\n            op = body.call(thisArg, _);\n        } catch (e) { op = [6, e]; y = 0; } finally { f = t = 0; }\n        if (op[0] & 5) throw op[1]; return { value: op[0] ? op[1] : void 0, done: true };\n    }\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\n/**\n * IOHandler implementations based on HTTP requests in the web browser.\n *\n * Uses [`fetch`](https://developer.mozilla.org/en-US/docs/Web/API/Fetch_API).\n */\nvar util_1 = require(\"../util\");\nvar io_utils_1 = require(\"./io_utils\");\nvar router_registry_1 = require(\"./router_registry\");\nvar weights_loader_1 = require(\"./weights_loader\");\nvar OCTET_STREAM_MIME_TYPE = 'application/octet-stream';\nvar JSON_TYPE = 'application/json';\nvar HTTPRequest = /** @class */ (function () {\n    function HTTPRequest(path, loadOptions) {\n        this.DEFAULT_METHOD = 'POST';\n        if (loadOptions == null) {\n            loadOptions = {};\n        }\n        this.weightPathPrefix = loadOptions.weightPathPrefix;\n        this.onProgress = loadOptions.onProgress;\n        if (loadOptions.fetchFunc != null) {\n            util_1.assert(typeof loadOptions.fetchFunc === 'function', function () { return 'Must pass a function that matches the signature of ' +\n                '`fetch` (see ' +\n                'https://developer.mozilla.org/en-US/docs/Web/API/Fetch_API)'; });\n            this.fetch = loadOptions.fetchFunc;\n        }\n        else {\n            this.fetch = util_1.fetch;\n        }\n        util_1.assert(path != null && path.length > 0, function () { return 'URL path for http must not be null, undefined or ' +\n            'empty.'; });\n        if (Array.isArray(path)) {\n            util_1.assert(path.length === 2, function () { return 'URL paths for http must have a length of 2, ' +\n                (\"(actual length is \" + path.length + \").\"); });\n        }\n        this.path = path;\n        if (loadOptions.requestInit != null &&\n            loadOptions.requestInit.body != null) {\n            throw new Error('requestInit is expected to have no pre-existing body, but has one.');\n        }\n        this.requestInit = loadOptions.requestInit || {};\n    }\n    HTTPRequest.prototype.save = function (modelArtifacts) {\n        return __awaiter(this, void 0, void 0, function () {\n            var init, weightsManifest, modelTopologyAndWeightManifest, response;\n            return __generator(this, function (_a) {\n                switch (_a.label) {\n                    case 0:\n                        if (modelArtifacts.modelTopology instanceof ArrayBuffer) {\n                            throw new Error('BrowserHTTPRequest.save() does not support saving model topology ' +\n                                'in binary formats yet.');\n                        }\n                        init = Object.assign({ method: this.DEFAULT_METHOD }, this.requestInit);\n                        init.body = new FormData();\n                        weightsManifest = [{\n                                paths: ['./model.weights.bin'],\n                                weights: modelArtifacts.weightSpecs,\n                            }];\n                        modelTopologyAndWeightManifest = {\n                            modelTopology: modelArtifacts.modelTopology,\n                            format: modelArtifacts.format,\n                            generatedBy: modelArtifacts.generatedBy,\n                            convertedBy: modelArtifacts.convertedBy,\n                            weightsManifest: weightsManifest\n                        };\n                        init.body.append('model.json', new Blob([JSON.stringify(modelTopologyAndWeightManifest)], { type: JSON_TYPE }), 'model.json');\n                        if (modelArtifacts.weightData != null) {\n                            init.body.append('model.weights.bin', new Blob([modelArtifacts.weightData], { type: OCTET_STREAM_MIME_TYPE }), 'model.weights.bin');\n                        }\n                        return [4 /*yield*/, this.fetch(this.path, init)];\n                    case 1:\n                        response = _a.sent();\n                        if (response.ok) {\n                            return [2 /*return*/, {\n                                    modelArtifactsInfo: io_utils_1.getModelArtifactsInfoForJSON(modelArtifacts),\n                                    responses: [response],\n                                }];\n                        }\n                        else {\n                            throw new Error(\"BrowserHTTPRequest.save() failed due to HTTP response status \" +\n                                (response.status + \".\"));\n                        }\n                        return [2 /*return*/];\n                }\n            });\n        });\n    };\n    /**\n     * Load model artifacts via HTTP request(s).\n     *\n     * See the documentation to `tf.io.http` for details on the saved\n     * artifacts.\n     *\n     * @returns The loaded model artifacts (if loading succeeds).\n     */\n    HTTPRequest.prototype.load = function () {\n        return __awaiter(this, void 0, void 0, function () {\n            var modelConfigRequest, modelConfig, e_1, message, modelTopology, weightsManifest, weightSpecs, weightData, results;\n            return __generator(this, function (_a) {\n                switch (_a.label) {\n                    case 0: return [4 /*yield*/, this.fetch(this.path, this.requestInit)];\n                    case 1:\n                        modelConfigRequest = _a.sent();\n                        if (!modelConfigRequest.ok) {\n                            throw new Error(\"Request to \" + this.path + \" failed with status code \" +\n                                (modelConfigRequest.status + \". Please verify this URL points to \") +\n                                \"the model JSON of the model to load.\");\n                        }\n                        _a.label = 2;\n                    case 2:\n                        _a.trys.push([2, 4, , 5]);\n                        return [4 /*yield*/, modelConfigRequest.json()];\n                    case 3:\n                        modelConfig = _a.sent();\n                        return [3 /*break*/, 5];\n                    case 4:\n                        e_1 = _a.sent();\n                        message = \"Failed to parse model JSON of response from \" + this.path + \".\";\n                        // TODO(nsthorat): Remove this after some time when we're comfortable that\n                        // .pb files are mostly gone.\n                        if (this.path.endsWith('.pb')) {\n                            message += ' Your path contains a .pb file extension. ' +\n                                'Support for .pb models have been removed in TensorFlow.js 1.0 ' +\n                                'in favor of .json models. You can re-convert your Python ' +\n                                'TensorFlow model using the TensorFlow.js 1.0 conversion scripts ' +\n                                'or you can convert your.pb models with the \\'pb2json\\'' +\n                                'NPM script in the tensorflow/tfjs-converter repository.';\n                        }\n                        else {\n                            message += ' Please make sure the server is serving valid ' +\n                                'JSON for this request.';\n                        }\n                        throw new Error(message);\n                    case 5:\n                        modelTopology = modelConfig.modelTopology;\n                        weightsManifest = modelConfig.weightsManifest;\n                        // We do not allow both modelTopology and weightsManifest to be missing.\n                        if (modelTopology == null && weightsManifest == null) {\n                            throw new Error(\"The JSON from HTTP path \" + this.path + \" contains neither model \" +\n                                \"topology or manifest for weights.\");\n                        }\n                        if (!(weightsManifest != null)) return [3 /*break*/, 7];\n                        return [4 /*yield*/, this.loadWeights(weightsManifest)];\n                    case 6:\n                        results = _a.sent();\n                        weightSpecs = results[0], weightData = results[1];\n                        _a.label = 7;\n                    case 7: return [2 /*return*/, { modelTopology: modelTopology, weightSpecs: weightSpecs, weightData: weightData }];\n                }\n            });\n        });\n    };\n    HTTPRequest.prototype.loadWeights = function (weightsManifest) {\n        return __awaiter(this, void 0, void 0, function () {\n            var weightPath, _a, prefix, suffix, pathPrefix, weightSpecs, _i, weightsManifest_1, entry, fetchURLs, buffers;\n            return __generator(this, function (_b) {\n                switch (_b.label) {\n                    case 0:\n                        weightPath = Array.isArray(this.path) ? this.path[1] : this.path;\n                        _a = parseUrl(weightPath), prefix = _a[0], suffix = _a[1];\n                        pathPrefix = this.weightPathPrefix || prefix;\n                        weightSpecs = [];\n                        for (_i = 0, weightsManifest_1 = weightsManifest; _i < weightsManifest_1.length; _i++) {\n                            entry = weightsManifest_1[_i];\n                            weightSpecs.push.apply(weightSpecs, entry.weights);\n                        }\n                        fetchURLs = [];\n                        weightsManifest.forEach(function (weightsGroup) {\n                            weightsGroup.paths.forEach(function (path) {\n                                fetchURLs.push(pathPrefix + path + suffix);\n                            });\n                        });\n                        return [4 /*yield*/, weights_loader_1.loadWeightsAsArrayBuffer(fetchURLs, {\n                                requestInit: this.requestInit,\n                                fetchFunc: this.fetch,\n                                onProgress: this.onProgress\n                            })];\n                    case 1:\n                        buffers = _b.sent();\n                        return [2 /*return*/, [weightSpecs, io_utils_1.concatenateArrayBuffers(buffers)]];\n                }\n            });\n        });\n    };\n    HTTPRequest.URL_SCHEME_REGEX = /^https?:\\/\\//;\n    return HTTPRequest;\n}());\nexports.HTTPRequest = HTTPRequest;\n/**\n * Extract the prefix and suffix of the url, where the prefix is the path before\n * the last file, and suffix is the search params after the last file.\n * ```\n * const url = 'http://tfhub.dev/model/1/tensorflowjs_model.pb?tfjs-format=file'\n * [prefix, suffix] = parseUrl(url)\n * // prefix = 'http://tfhub.dev/model/1/'\n * // suffix = '?tfjs-format=file'\n * ```\n * @param url the model url to be parsed.\n */\nfunction parseUrl(url) {\n    var lastSlash = url.lastIndexOf('/');\n    var lastSearchParam = url.lastIndexOf('?');\n    var prefix = url.substring(0, lastSlash);\n    var suffix = lastSearchParam > lastSlash ? url.substring(lastSearchParam) : '';\n    return [prefix + '/', suffix];\n}\nexports.parseUrl = parseUrl;\nfunction isHTTPScheme(url) {\n    return url.match(HTTPRequest.URL_SCHEME_REGEX) != null;\n}\nexports.isHTTPScheme = isHTTPScheme;\nexports.httpRouter = function (url, onProgress) {\n    if (typeof util_1.fetch === 'undefined') {\n        // `http` uses `fetch` or `node-fetch`, if one wants to use it in\n        // an environment that is not the browser or node they have to setup a\n        // global fetch polyfill.\n        return null;\n    }\n    else {\n        var isHTTP = true;\n        if (Array.isArray(url)) {\n            isHTTP = url.every(function (urlItem) { return isHTTPScheme(urlItem); });\n        }\n        else {\n            isHTTP = isHTTPScheme(url);\n        }\n        if (isHTTP) {\n            return http(url, { onProgress: onProgress });\n        }\n    }\n    return null;\n};\nrouter_registry_1.IORouterRegistry.registerSaveRouter(exports.httpRouter);\nrouter_registry_1.IORouterRegistry.registerLoadRouter(exports.httpRouter);\n/**\n * Creates an IOHandler subtype that sends model artifacts to HTTP server.\n *\n * An HTTP request of the `multipart/form-data` mime type will be sent to the\n * `path` URL. The form data includes artifacts that represent the topology\n * and/or weights of the model. In the case of Keras-style `tf.Model`, two\n * blobs (files) exist in form-data:\n *   - A JSON file consisting of `modelTopology` and `weightsManifest`.\n *   - A binary weights file consisting of the concatenated weight values.\n * These files are in the same format as the one generated by\n * [tfjs_converter](https://js.tensorflow.org/tutorials/import-keras.html).\n *\n * The following code snippet exemplifies the client-side code that uses this\n * function:\n *\n * ```js\n * const model = tf.sequential();\n * model.add(\n *     tf.layers.dense({units: 1, inputShape: [100], activation: 'sigmoid'}));\n *\n * const saveResult = await model.save(tf.io.http(\n *     'http://model-server:5000/upload', {method: 'PUT'}));\n * console.log(saveResult);\n * ```\n *\n * If the default `POST` method is to be used, without any custom parameters\n * such as headers, you can simply pass an HTTP or HTTPS URL to `model.save`:\n *\n * ```js\n * const saveResult = await model.save('http://model-server:5000/upload');\n * ```\n *\n * The following GitHub Gist\n * https://gist.github.com/dsmilkov/1b6046fd6132d7408d5257b0976f7864\n * implements a server based on [flask](https://github.com/pallets/flask) that\n * can receive the request. Upon receiving the model artifacts via the requst,\n * this particular server reconsistutes instances of [Keras\n * Models](https://keras.io/models/model/) in memory.\n *\n *\n * @param path A URL path to the model.\n *   Can be an absolute HTTP path (e.g.,\n *   'http://localhost:8000/model-upload)') or a relative path (e.g.,\n *   './model-upload').\n * @param requestInit Request configurations to be used when sending\n *    HTTP request to server using `fetch`. It can contain fields such as\n *    `method`, `credentials`, `headers`, `mode`, etc. See\n *    https://developer.mozilla.org/en-US/docs/Web/API/Request/Request\n *    for more information. `requestInit` must not have a body, because the\n * body will be set by TensorFlow.js. File blobs representing the model\n * topology (filename: 'model.json') and the weights of the model (filename:\n * 'model.weights.bin') will be appended to the body. If `requestInit` has a\n * `body`, an Error will be thrown.\n * @param loadOptions Optional configuration for the loading. It includes the\n *   following fields:\n *   - weightPathPrefix Optional, this specifies the path prefix for weight\n *     files, by default this is calculated from the path param.\n *   - fetchFunc Optional, custom `fetch` function. E.g., in Node.js,\n *     the `fetch` from node-fetch can be used here.\n *   - onProgress Optional, progress callback function, fired periodically\n *     before the load is completed.\n * @returns An instance of `IOHandler`.\n */\n/**\n * @doc {\n *   heading: 'Models',\n *   subheading: 'Loading',\n *   namespace: 'io',\n *   ignoreCI: true\n * }\n */\nfunction http(path, loadOptions) {\n    return new HTTPRequest(path, loadOptions);\n}\nexports.http = http;\n/**\n * Deprecated. Use `tf.io.http`.\n * @param path\n * @param loadOptions\n */\nfunction browserHTTPRequest(path, loadOptions) {\n    return http(path, loadOptions);\n}\nexports.browserHTTPRequest = browserHTTPRequest;\n//# sourceMappingURL=http.js.map","\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : new P(function (resolve) { resolve(result.value); }).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nvar __generator = (this && this.__generator) || function (thisArg, body) {\n    var _ = { label: 0, sent: function() { if (t[0] & 1) throw t[1]; return t[1]; }, trys: [], ops: [] }, f, y, t, g;\n    return g = { next: verb(0), \"throw\": verb(1), \"return\": verb(2) }, typeof Symbol === \"function\" && (g[Symbol.iterator] = function() { return this; }), g;\n    function verb(n) { return function (v) { return step([n, v]); }; }\n    function step(op) {\n        if (f) throw new TypeError(\"Generator is already executing.\");\n        while (_) try {\n            if (f = 1, y && (t = op[0] & 2 ? y[\"return\"] : op[0] ? y[\"throw\"] || ((t = y[\"return\"]) && t.call(y), 0) : y.next) && !(t = t.call(y, op[1])).done) return t;\n            if (y = 0, t) op = [op[0] & 2, t.value];\n            switch (op[0]) {\n                case 0: case 1: t = op; break;\n                case 4: _.label++; return { value: op[1], done: false };\n                case 5: _.label++; y = op[1]; op = [0]; continue;\n                case 7: op = _.ops.pop(); _.trys.pop(); continue;\n                default:\n                    if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) { _ = 0; continue; }\n                    if (op[0] === 3 && (!t || (op[1] > t[0] && op[1] < t[3]))) { _.label = op[1]; break; }\n                    if (op[0] === 6 && _.label < t[1]) { _.label = t[1]; t = op; break; }\n                    if (t && _.label < t[2]) { _.label = t[2]; _.ops.push(op); break; }\n                    if (t[2]) _.ops.pop();\n                    _.trys.pop(); continue;\n            }\n            op = body.call(thisArg, _);\n        } catch (e) { op = [6, e]; y = 0; } finally { f = t = 0; }\n        if (op[0] & 5) throw op[1]; return { value: op[0] ? op[1] : void 0, done: true };\n    }\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar util = require(\"../util\");\nvar io_utils_1 = require(\"./io_utils\");\nvar progress_1 = require(\"./progress\");\nvar types_1 = require(\"./types\");\n/**\n * Reads binary weights data from a number of URLs.\n *\n * @param fetchURLs URLs to send the HTTP requests at, using `fetch` calls.\n * @param requestOptions RequestInit (options) for the HTTP requests.\n * @param fetchFunc Optional overriding value for the `window.fetch` function.\n * @param onProgress Optional, progress callback function, fired periodically\n *   before the load is completed.\n * @returns A `Promise` of an Array of `ArrayBuffer`. The Array has the same\n *   length as `fetchURLs`.\n */\nfunction loadWeightsAsArrayBuffer(fetchURLs, loadOptions) {\n    return __awaiter(this, void 0, void 0, function () {\n        var fetchFunc, requests, fetchStartFraction, fetchEndFraction, responses, _a, bufferPromises, bufferStartFraction, bufferEndFraction, buffers, _b;\n        return __generator(this, function (_c) {\n            switch (_c.label) {\n                case 0:\n                    if (loadOptions == null) {\n                        loadOptions = {};\n                    }\n                    fetchFunc = loadOptions.fetchFunc == null ? util.fetch : loadOptions.fetchFunc;\n                    requests = fetchURLs.map(function (fetchURL) { return fetchFunc(fetchURL, loadOptions.requestInit); });\n                    fetchStartFraction = 0;\n                    fetchEndFraction = 0.5;\n                    if (!(loadOptions.onProgress == null)) return [3 /*break*/, 2];\n                    return [4 /*yield*/, Promise.all(requests)];\n                case 1:\n                    _a = _c.sent();\n                    return [3 /*break*/, 4];\n                case 2: return [4 /*yield*/, progress_1.monitorPromisesProgress(requests, loadOptions.onProgress, fetchStartFraction, fetchEndFraction)];\n                case 3:\n                    _a = _c.sent();\n                    _c.label = 4;\n                case 4:\n                    responses = _a;\n                    bufferPromises = responses.map(function (response) { return response.arrayBuffer(); });\n                    bufferStartFraction = 0.5;\n                    bufferEndFraction = 1;\n                    if (!(loadOptions.onProgress == null)) return [3 /*break*/, 6];\n                    return [4 /*yield*/, Promise.all(bufferPromises)];\n                case 5:\n                    _b = _c.sent();\n                    return [3 /*break*/, 8];\n                case 6: return [4 /*yield*/, progress_1.monitorPromisesProgress(bufferPromises, loadOptions.onProgress, bufferStartFraction, bufferEndFraction)];\n                case 7:\n                    _b = _c.sent();\n                    _c.label = 8;\n                case 8:\n                    buffers = _b;\n                    return [2 /*return*/, buffers];\n            }\n        });\n    });\n}\nexports.loadWeightsAsArrayBuffer = loadWeightsAsArrayBuffer;\n/**\n * Reads a weights manifest JSON configuration, fetches the weights and\n * returns them as `Tensor`s.\n *\n * @param manifest The weights manifest JSON.\n * @param filePathPrefix The path prefix for filenames given in the manifest.\n *     Defaults to the empty string.\n * @param weightNames The names of the weights to be fetched.\n */\nfunction loadWeights(manifest, filePathPrefix, weightNames, requestInit) {\n    if (filePathPrefix === void 0) { filePathPrefix = ''; }\n    return __awaiter(this, void 0, void 0, function () {\n        var fetchWeights, loadWeights;\n        return __generator(this, function (_a) {\n            fetchWeights = function (fetchUrls) {\n                return loadWeightsAsArrayBuffer(fetchUrls, { requestInit: requestInit });\n            };\n            loadWeights = weightsLoaderFactory(fetchWeights);\n            return [2 /*return*/, loadWeights(manifest, filePathPrefix, weightNames)];\n        });\n    });\n}\nexports.loadWeights = loadWeights;\n/**\n * Creates a function, which reads a weights manifest JSON configuration,\n * fetches the weight files using the specified function and returns them as\n * `Tensor`s.\n *\n * ```js\n * // example for creating a nodejs weight loader, which reads the weight files\n * // from disk using fs.readFileSync\n *\n * import * as fs from 'fs'\n *\n * const fetchWeightsFromDisk = (filePaths: string[]) =>\n *   filePaths.map(filePath => fs.readFileSync(filePath).buffer)\n *\n * const loadWeights = tf.io.weightsLoaderFactory(fetchWeightsFromDisk)\n *\n * const manifest = JSON.parse(\n *   fs.readFileSync('./my_model-weights_manifest').toString()\n * )\n * const weightMap = await loadWeights(manifest, './')\n * ```\n * @param fetchWeightsFunction The function used for fetching the weight files.\n * @returns Weight loading function.\n */\nfunction weightsLoaderFactory(fetchWeightsFunction) {\n    var _this = this;\n    return function (manifest, filePathPrefix, weightNames) {\n        if (filePathPrefix === void 0) { filePathPrefix = ''; }\n        return __awaiter(_this, void 0, void 0, function () {\n            var groupIndicesToFetchMap, groupWeightsToFetch, weightsFound, allManifestWeightNames, weightsNotFound, groupIndicesToFetch, fetchUrls, buffers, weightsTensorMap, bufferIndexOffset;\n            return __generator(this, function (_a) {\n                switch (_a.label) {\n                    case 0:\n                        groupIndicesToFetchMap = manifest.map(function () { return false; });\n                        groupWeightsToFetch = {};\n                        weightsFound = weightNames != null ? weightNames.map(function () { return false; }) : [];\n                        allManifestWeightNames = [];\n                        manifest.forEach(function (manifestGroupConfig, groupIndex) {\n                            var groupOffset = 0;\n                            manifestGroupConfig.weights.forEach(function (weightsEntry) {\n                                var rawDtype = ('quantization' in weightsEntry) ?\n                                    weightsEntry.quantization.dtype :\n                                    weightsEntry.dtype;\n                                var weightsBytes = types_1.DTYPE_VALUE_SIZE_MAP[rawDtype] *\n                                    util.sizeFromShape(weightsEntry.shape);\n                                var enqueueWeightsForFetchingFn = function () {\n                                    groupIndicesToFetchMap[groupIndex] = true;\n                                    if (groupWeightsToFetch[groupIndex] == null) {\n                                        groupWeightsToFetch[groupIndex] = [];\n                                    }\n                                    groupWeightsToFetch[groupIndex].push({\n                                        manifestEntry: weightsEntry,\n                                        groupOffset: groupOffset,\n                                        sizeBytes: weightsBytes\n                                    });\n                                };\n                                if (weightNames != null) {\n                                    weightNames.forEach(function (weightName, weightIndex) {\n                                        if (weightName === weightsEntry.name) {\n                                            enqueueWeightsForFetchingFn();\n                                            weightsFound[weightIndex] = true;\n                                        }\n                                    });\n                                }\n                                else {\n                                    enqueueWeightsForFetchingFn();\n                                }\n                                allManifestWeightNames.push(weightsEntry.name);\n                                groupOffset += weightsBytes;\n                            });\n                        });\n                        if (!weightsFound.every(function (found) { return found; })) {\n                            weightsNotFound = weightNames.filter(function (_, i) { return !weightsFound[i]; });\n                            throw new Error(\"Could not find weights in manifest with names: \" +\n                                (weightsNotFound.join(', ') + \". \\n\") +\n                                \"Manifest JSON has weights with names: \" +\n                                (allManifestWeightNames.join(', ') + \".\"));\n                        }\n                        groupIndicesToFetch = groupIndicesToFetchMap.reduce(function (accumulator, shouldFetch, i) {\n                            if (shouldFetch) {\n                                accumulator.push(i);\n                            }\n                            return accumulator;\n                        }, []);\n                        fetchUrls = [];\n                        groupIndicesToFetch.forEach(function (i) {\n                            manifest[i].paths.forEach(function (filepath) {\n                                var fetchUrl = filePathPrefix +\n                                    (!filePathPrefix.endsWith('/') ? '/' : '') + filepath;\n                                fetchUrls.push(fetchUrl);\n                            });\n                        });\n                        return [4 /*yield*/, fetchWeightsFunction(fetchUrls)];\n                    case 1:\n                        buffers = _a.sent();\n                        weightsTensorMap = {};\n                        bufferIndexOffset = 0;\n                        groupIndicesToFetch.forEach(function (i) {\n                            var numBuffers = manifest[i].paths.length;\n                            var groupBytes = 0;\n                            for (var i_1 = 0; i_1 < numBuffers; i_1++) {\n                                groupBytes += buffers[bufferIndexOffset + i_1].byteLength;\n                            }\n                            // Create a buffer for the whole group.\n                            var groupBuffer = new ArrayBuffer(groupBytes);\n                            var groupByteBuffer = new Uint8Array(groupBuffer);\n                            var groupBufferOffset = 0;\n                            for (var i_2 = 0; i_2 < numBuffers; i_2++) {\n                                var buffer = new Uint8Array(buffers[bufferIndexOffset + i_2]);\n                                groupByteBuffer.set(buffer, groupBufferOffset);\n                                groupBufferOffset += buffer.byteLength;\n                            }\n                            var weightsEntries = groupWeightsToFetch[i];\n                            weightsEntries.forEach(function (weightsEntry) {\n                                var byteBuffer = groupBuffer.slice(weightsEntry.groupOffset, weightsEntry.groupOffset + weightsEntry.sizeBytes);\n                                var nameToTensorMap = io_utils_1.decodeWeights(byteBuffer, [weightsEntry.manifestEntry]);\n                                for (var name_1 in nameToTensorMap) {\n                                    weightsTensorMap[name_1] = nameToTensorMap[name_1];\n                                }\n                            });\n                            bufferIndexOffset += numBuffers;\n                        });\n                        return [2 /*return*/, weightsTensorMap];\n                }\n            });\n        });\n    };\n}\nexports.weightsLoaderFactory = weightsLoaderFactory;\n//# sourceMappingURL=weights_loader.js.map","\n/**\n * @license\n * Copyright 2019 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar util_1 = require(\"../util\");\n/**\n * Monitor Promise.all progress, fire onProgress callback function.\n *\n * @param promises Promise list going to be monitored\n * @param onProgress Callback function. Fired when a promise resolved.\n * @param startFraction Optional fraction start. Default to 0.\n * @param endFraction Optional fraction end. Default to 1.\n */\nfunction monitorPromisesProgress(promises, onProgress, startFraction, endFraction) {\n    checkPromises(promises);\n    startFraction = startFraction == null ? 0 : startFraction;\n    endFraction = endFraction == null ? 1 : endFraction;\n    checkFraction(startFraction, endFraction);\n    var resolvedPromise = 0;\n    var registerMonitor = function (promise) {\n        promise.then(function (value) {\n            var fraction = startFraction +\n                ++resolvedPromise / promises.length * (endFraction - startFraction);\n            // pass fraction as parameter to callback function.\n            onProgress(fraction);\n            return value;\n        });\n        return promise;\n    };\n    function checkPromises(promises) {\n        util_1.assert(promises != null && Array.isArray(promises) && promises.length > 0, function () { return 'promises must be a none empty array'; });\n    }\n    function checkFraction(startFraction, endFraction) {\n        util_1.assert(startFraction >= 0 && startFraction <= 1, function () { return \"Progress fraction must be in range [0, 1], but \" +\n            (\"got startFraction \" + startFraction); });\n        util_1.assert(endFraction >= 0 && endFraction <= 1, function () { return \"Progress fraction must be in range [0, 1], but \" +\n            (\"got endFraction \" + endFraction); });\n        util_1.assert(endFraction >= startFraction, function () { return \"startFraction must be no more than endFraction, but \" +\n            (\"got startFraction \" + startFraction + \" and endFraction \") +\n            (\"\" + endFraction); });\n    }\n    return Promise.all(promises.map(registerMonitor));\n}\nexports.monitorPromisesProgress = monitorPromisesProgress;\n//# sourceMappingURL=progress.js.map","\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar __assign = (this && this.__assign) || function () {\n    __assign = Object.assign || function(t) {\n        for (var s, i = 1, n = arguments.length; i < n; i++) {\n            s = arguments[i];\n            for (var p in s) if (Object.prototype.hasOwnProperty.call(s, p))\n                t[p] = s[p];\n        }\n        return t;\n    };\n    return __assign.apply(this, arguments);\n};\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : new P(function (resolve) { resolve(result.value); }).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nvar __generator = (this && this.__generator) || function (thisArg, body) {\n    var _ = { label: 0, sent: function() { if (t[0] & 1) throw t[1]; return t[1]; }, trys: [], ops: [] }, f, y, t, g;\n    return g = { next: verb(0), \"throw\": verb(1), \"return\": verb(2) }, typeof Symbol === \"function\" && (g[Symbol.iterator] = function() { return this; }), g;\n    function verb(n) { return function (v) { return step([n, v]); }; }\n    function step(op) {\n        if (f) throw new TypeError(\"Generator is already executing.\");\n        while (_) try {\n            if (f = 1, y && (t = op[0] & 2 ? y[\"return\"] : op[0] ? y[\"throw\"] || ((t = y[\"return\"]) && t.call(y), 0) : y.next) && !(t = t.call(y, op[1])).done) return t;\n            if (y = 0, t) op = [op[0] & 2, t.value];\n            switch (op[0]) {\n                case 0: case 1: t = op; break;\n                case 4: _.label++; return { value: op[1], done: false };\n                case 5: _.label++; y = op[1]; op = [0]; continue;\n                case 7: op = _.ops.pop(); _.trys.pop(); continue;\n                default:\n                    if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) { _ = 0; continue; }\n                    if (op[0] === 3 && (!t || (op[1] > t[0] && op[1] < t[3]))) { _.label = op[1]; break; }\n                    if (op[0] === 6 && _.label < t[1]) { _.label = t[1]; t = op; break; }\n                    if (t && _.label < t[2]) { _.label = t[2]; _.ops.push(op); break; }\n                    if (t[2]) _.ops.pop();\n                    _.trys.pop(); continue;\n            }\n            op = body.call(thisArg, _);\n        } catch (e) { op = [6, e]; y = 0; } finally { f = t = 0; }\n        if (op[0] & 5) throw op[1]; return { value: op[0] ? op[1] : void 0, done: true };\n    }\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar PassthroughLoader = /** @class */ (function () {\n    function PassthroughLoader(modelTopology, weightSpecs, weightData) {\n        this.modelTopology = modelTopology;\n        this.weightSpecs = weightSpecs;\n        this.weightData = weightData;\n    }\n    PassthroughLoader.prototype.load = function () {\n        return __awaiter(this, void 0, void 0, function () {\n            var result;\n            return __generator(this, function (_a) {\n                result = {};\n                if (this.modelTopology != null) {\n                    result = __assign({ modelTopology: this.modelTopology }, result);\n                }\n                if (this.weightSpecs != null && this.weightSpecs.length > 0) {\n                    result = __assign({ weightSpecs: this.weightSpecs }, result);\n                }\n                if (this.weightData != null && this.weightData.byteLength > 0) {\n                    result = __assign({ weightData: this.weightData }, result);\n                }\n                return [2 /*return*/, result];\n            });\n        });\n    };\n    return PassthroughLoader;\n}());\nvar PassthroughSaver = /** @class */ (function () {\n    function PassthroughSaver(saveHandler) {\n        this.saveHandler = saveHandler;\n    }\n    PassthroughSaver.prototype.save = function (modelArtifacts) {\n        return __awaiter(this, void 0, void 0, function () {\n            return __generator(this, function (_a) {\n                return [2 /*return*/, this.saveHandler(modelArtifacts)];\n            });\n        });\n    };\n    return PassthroughSaver;\n}());\n/**\n * Creates an IOHandler that loads model artifacts from memory.\n *\n * When used in conjunction with `tf.loadLayersModel`, an instance of\n * `tf.LayersModel` (Keras-style) can be constructed from the loaded artifacts.\n *\n * ```js\n * const model = await tf.loadLayersModel(tf.io.fromMemory(\n *     modelTopology, weightSpecs, weightData));\n * ```\n *\n * @param modelTopology a object containing model topology (i.e., parsed from\n *   the JSON format).\n * @param weightSpecs An array of `WeightsManifestEntry` objects describing the\n *   names, shapes, types, and quantization of the weight data.\n * @param weightData A single `ArrayBuffer` containing the weight data,\n *   concatenated in the order described by the weightSpecs.\n *\n * @returns A passthrough `IOHandler` that simply loads the provided data.\n */\nfunction fromMemory(modelTopology, weightSpecs, weightData) {\n    return new PassthroughLoader(modelTopology, weightSpecs, weightData);\n}\nexports.fromMemory = fromMemory;\n/**\n * Creates an IOHandler that passes saved model artifacts to a callback.\n *\n * ```js\n * function handleSave(artifacts) {\n *   // ... do something with the artifacts ...\n *   return {modelArtifactsInfo: {...}, ...};\n * }\n *\n * const saveResult = model.save(tf.io.withSaveHandler(handleSave));\n * ```\n *\n * @param saveHandler A function that accepts a `ModelArtifacts` and returns a\n *     `SaveResult`.\n */\nfunction withSaveHandler(saveHandler) {\n    return new PassthroughSaver(saveHandler);\n}\nexports.withSaveHandler = withSaveHandler;\n//# sourceMappingURL=passthrough.js.map","\n/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\n/**\n * Exports under the tf.math.* namespace.\n */\nvar confusion_matrix_1 = require(\"./ops/confusion_matrix\");\nexports.confusionMatrix = confusion_matrix_1.confusionMatrix;\n//# sourceMappingURL=math.js.map","\n/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar tensor_util_env_1 = require(\"../tensor_util_env\");\nvar util = require(\"../util\");\nvar array_ops_1 = require(\"./array_ops\");\nvar operation_1 = require(\"./operation\");\n/**\n * Computes the confusion matrix from true labels and predicted labels.\n *\n * ```js\n * const labels = tf.tensor1d([0, 1, 2, 1, 0], 'int32');\n * const predictions = tf.tensor1d([0, 2, 2, 1, 0], 'int32');\n * const numClasses = 3;\n * const out = tf.math.confusionMatrix(labels, predictions, numClasses);\n * out.print();\n * // Expected output matrix:\n * // [[2, 0, 0],\n * //  [0, 1, 1],\n * //  [0, 0, 1]]\n * ```\n *\n * @param labels The target labels, assumed to be 0-based integers\n *   for the classes. The shape is `[numExamples]`, where\n *   `numExamples` is the number of examples included.\n * @param predictions The predicted classes, assumed to be\n *   0-based integers for the classes. Must have the same shape as `labels`.\n * @param numClasses Number of all classes, as an integer.\n *   Its value must be larger than the largest element in `labels` and\n *   `predictions`.\n * @returns The confusion matrix as a int32-type 2D tensor. The value at\n *   row `r` and column `c` is the number of times examples of actual class\n *   `r` were predicted as class `c`.\n */\n/** @doc {heading: 'Operations', subheading: 'Evaluation'} */\nfunction confusionMatrix_(labels, predictions, numClasses) {\n    var $labels = tensor_util_env_1.convertToTensor(labels, 'labels', 'confusionMatrix');\n    var $predictions = tensor_util_env_1.convertToTensor(predictions, 'predictions', 'confusionMatrix');\n    util.assert(numClasses == null || numClasses > 0 && Number.isInteger(numClasses), function () { return \"If provided, numClasses must be a positive integer, \" +\n        (\"but got \" + numClasses); });\n    util.assert($labels.rank === 1, function () { return \"Expected the rank of labels to be 1, but got \" + $labels.rank; });\n    util.assert($predictions.rank === 1, function () { return \"Expected the rank of predictions to be 1, \" +\n        (\"but got \" + $predictions.rank); });\n    util.assert($labels.shape[0] === $predictions.shape[0], function () { return \"Mismatch in the number of examples: \" +\n        ($labels.shape[0] + \" vs. \" + $predictions.shape[0] + \". \") +\n        \"Labels and predictions should have the same number of elements.\"; });\n    util.assert(numClasses > 0 && Number.isInteger(numClasses), function () { return \"numClasses is required to be a positive integer, but got \" +\n        (\"\" + numClasses); });\n    // TODO(cais): In the future, if oneHot supports tensors inputs for\n    //   `numClasses`, `confusionMatrix` can make `numClasses` optional.\n    var oneHotLabels = array_ops_1.oneHot($labels.asType('int32'), numClasses);\n    var oneHotPredictions = array_ops_1.oneHot($predictions.asType('int32'), numClasses);\n    return oneHotLabels.transpose().matMul(oneHotPredictions).asType('int32');\n}\nexports.confusionMatrix_ = confusionMatrix_;\nexports.confusionMatrix = operation_1.op({ confusionMatrix_: confusionMatrix_ });\n//# sourceMappingURL=confusion_matrix.js.map","\n/**\n * @license\n * Copyright 2019 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : new P(function (resolve) { resolve(result.value); }).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nvar __generator = (this && this.__generator) || function (thisArg, body) {\n    var _ = { label: 0, sent: function() { if (t[0] & 1) throw t[1]; return t[1]; }, trys: [], ops: [] }, f, y, t, g;\n    return g = { next: verb(0), \"throw\": verb(1), \"return\": verb(2) }, typeof Symbol === \"function\" && (g[Symbol.iterator] = function() { return this; }), g;\n    function verb(n) { return function (v) { return step([n, v]); }; }\n    function step(op) {\n        if (f) throw new TypeError(\"Generator is already executing.\");\n        while (_) try {\n            if (f = 1, y && (t = op[0] & 2 ? y[\"return\"] : op[0] ? y[\"throw\"] || ((t = y[\"return\"]) && t.call(y), 0) : y.next) && !(t = t.call(y, op[1])).done) return t;\n            if (y = 0, t) op = [op[0] & 2, t.value];\n            switch (op[0]) {\n                case 0: case 1: t = op; break;\n                case 4: _.label++; return { value: op[1], done: false };\n                case 5: _.label++; y = op[1]; op = [0]; continue;\n                case 7: op = _.ops.pop(); _.trys.pop(); continue;\n                default:\n                    if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) { _ = 0; continue; }\n                    if (op[0] === 3 && (!t || (op[1] > t[0] && op[1] < t[3]))) { _.label = op[1]; break; }\n                    if (op[0] === 6 && _.label < t[1]) { _.label = t[1]; t = op; break; }\n                    if (t && _.label < t[2]) { _.label = t[2]; _.ops.push(op); break; }\n                    if (t[2]) _.ops.pop();\n                    _.trys.pop(); continue;\n            }\n            op = body.call(thisArg, _);\n        } catch (e) { op = [6, e]; y = 0; } finally { f = t = 0; }\n        if (op[0] & 5) throw op[1]; return { value: op[0] ? op[1] : void 0, done: true };\n    }\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar engine_1 = require(\"../engine\");\nvar tensor_1 = require(\"../tensor\");\nvar tensor_util_env_1 = require(\"../tensor_util_env\");\nvar operation_1 = require(\"./operation\");\n/**\n * Creates a `tf.Tensor` from an image.\n *\n * ```js\n * const image = new ImageData(1, 1);\n * image.data[0] = 100;\n * image.data[1] = 150;\n * image.data[2] = 200;\n * image.data[3] = 255;\n *\n * tf.browser.fromPixels(image).print();\n * ```\n *\n * @param pixels The input image to construct the tensor from. The\n * supported image types are all 4-channel. You can also pass in an image\n * object with following attributes:\n * `{data: Uint8Array; width: number; height: number}`\n * @param numChannels The number of channels of the output tensor. A\n * numChannels value less than 4 allows you to ignore channels. Defaults to\n * 3 (ignores alpha channel of input image).\n */\n/** @doc {heading: 'Browser', namespace: 'browser', ignoreCI: true} */\nfunction fromPixels_(pixels, numChannels) {\n    if (numChannels === void 0) { numChannels = 3; }\n    if (numChannels > 4) {\n        throw new Error('Cannot construct Tensor with more than 4 channels from pixels.');\n    }\n    return engine_1.ENGINE.fromPixels(pixels, numChannels);\n}\n/**\n * Draws a `tf.Tensor` of pixel values to a byte array or optionally a\n * canvas.\n *\n * When the dtype of the input is 'float32', we assume values in the range\n * [0-1]. Otherwise, when input is 'int32', we assume values in the range\n * [0-255].\n *\n * Returns a promise that resolves when the canvas has been drawn to.\n *\n * @param img A rank-2 or rank-3 tensor. If rank-2, draws grayscale. If\n *     rank-3, must have depth of 1, 3 or 4. When depth of 1, draws\n * grayscale. When depth of 3, we draw with the first three components of\n * the depth dimension corresponding to r, g, b and alpha = 1. When depth of\n * 4, all four components of the depth dimension correspond to r, g, b, a.\n * @param canvas The canvas to draw to.\n */\n/** @doc {heading: 'Browser', namespace: 'browser'} */\nfunction toPixels(img, canvas) {\n    return __awaiter(this, void 0, void 0, function () {\n        var $img, _a, height, width, depth, data, minTensor, maxTensor, _b, minVals, maxVals, min, max, multiplier, bytes, i, r, g, b, a, j, ctx, imageData;\n        return __generator(this, function (_c) {\n            switch (_c.label) {\n                case 0:\n                    $img = tensor_util_env_1.convertToTensor(img, 'img', 'toPixels');\n                    if (!(img instanceof tensor_1.Tensor)) {\n                        // Assume int32 if user passed a native array.\n                        $img = $img.toInt();\n                    }\n                    if ($img.rank !== 2 && $img.rank !== 3) {\n                        throw new Error(\"toPixels only supports rank 2 or 3 tensors, got rank \" + $img.rank + \".\");\n                    }\n                    _a = $img.shape.slice(0, 2), height = _a[0], width = _a[1];\n                    depth = $img.rank === 2 ? 1 : $img.shape[2];\n                    if (depth > 4 || depth === 2) {\n                        throw new Error(\"toPixels only supports depth of size \" +\n                            (\"1, 3 or 4 but got \" + depth));\n                    }\n                    return [4 /*yield*/, $img.data()];\n                case 1:\n                    data = _c.sent();\n                    minTensor = $img.min();\n                    maxTensor = $img.max();\n                    return [4 /*yield*/, Promise.all([minTensor.data(), maxTensor.data()])];\n                case 2:\n                    _b = _c.sent(), minVals = _b[0], maxVals = _b[1];\n                    min = minVals[0];\n                    max = maxVals[0];\n                    minTensor.dispose();\n                    maxTensor.dispose();\n                    if ($img.dtype === 'float32') {\n                        if (min < 0 || max > 1) {\n                            throw new Error(\"Tensor values for a float32 Tensor must be in the \" +\n                                (\"range [0 - 1] but got range [\" + min + \" - \" + max + \"].\"));\n                        }\n                    }\n                    else if ($img.dtype === 'int32') {\n                        if (min < 0 || max > 255) {\n                            throw new Error(\"Tensor values for a int32 Tensor must be in the \" +\n                                (\"range [0 - 255] but got range [\" + min + \" - \" + max + \"].\"));\n                        }\n                    }\n                    else {\n                        throw new Error(\"Unsupported type for toPixels: \" + $img.dtype + \".\" +\n                            \" Please use float32 or int32 tensors.\");\n                    }\n                    multiplier = $img.dtype === 'float32' ? 255 : 1;\n                    bytes = new Uint8ClampedArray(width * height * 4);\n                    for (i = 0; i < height * width; ++i) {\n                        r = void 0, g = void 0, b = void 0, a = void 0;\n                        if (depth === 1) {\n                            r = data[i] * multiplier;\n                            g = data[i] * multiplier;\n                            b = data[i] * multiplier;\n                            a = 255;\n                        }\n                        else if (depth === 3) {\n                            r = data[i * 3] * multiplier;\n                            g = data[i * 3 + 1] * multiplier;\n                            b = data[i * 3 + 2] * multiplier;\n                            a = 255;\n                        }\n                        else if (depth === 4) {\n                            r = data[i * 4] * multiplier;\n                            g = data[i * 4 + 1] * multiplier;\n                            b = data[i * 4 + 2] * multiplier;\n                            a = data[i * 4 + 3] * multiplier;\n                        }\n                        j = i * 4;\n                        bytes[j + 0] = Math.round(r);\n                        bytes[j + 1] = Math.round(g);\n                        bytes[j + 2] = Math.round(b);\n                        bytes[j + 3] = Math.round(a);\n                    }\n                    if (canvas != null) {\n                        canvas.width = width;\n                        canvas.height = height;\n                        ctx = canvas.getContext('2d');\n                        imageData = new ImageData(bytes, width, height);\n                        ctx.putImageData(imageData, 0, 0);\n                    }\n                    if ($img !== img) {\n                        $img.dispose();\n                    }\n                    return [2 /*return*/, bytes];\n            }\n        });\n    });\n}\nexports.toPixels = toPixels;\nexports.fromPixels = operation_1.op({ fromPixels_: fromPixels_ });\n//# sourceMappingURL=browser.js.map","\n/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar util_1 = require(\"./util\");\n/**\n * Serializable defines the serialization contract.\n *\n * TFJS requires serializable classes to return their className when asked\n * to avoid issues with minification.\n */\nvar Serializable = /** @class */ (function () {\n    function Serializable() {\n    }\n    /**\n     * Return the class name for this class to use in serialization contexts.\n     *\n     * Generally speaking this will be the same thing that constructor.name\n     * would have returned.  However, the class name needs to be robust\n     * against minification for serialization/deserialization to work properly.\n     *\n     * There's also places such as initializers.VarianceScaling, where\n     * implementation details between different languages led to different\n     * class hierarchies and a non-leaf node is used for serialization purposes.\n     */\n    Serializable.prototype.getClassName = function () {\n        return this.constructor\n            .className;\n    };\n    /**\n     * Creates an instance of T from a ConfigDict.\n     *\n     * This works for most descendants of serializable.  A few need to\n     * provide special handling.\n     * @param cls A Constructor for the class to instantiate.\n     * @param config The Configuration for the object.\n     */\n    /** @nocollapse */\n    Serializable.fromConfig = function (cls, config) {\n        return new cls(config);\n    };\n    return Serializable;\n}());\nexports.Serializable = Serializable;\n/**\n * Maps string keys to class constructors.\n *\n * Used during (de)serialization from the cross-language JSON format, which\n * requires the class name in the serialization format matches the class\n * names as used in Python, should it exist.\n */\nvar SerializationMap = /** @class */ (function () {\n    function SerializationMap() {\n        this.classNameMap = {};\n    }\n    /**\n     * Returns the singleton instance of the map.\n     */\n    SerializationMap.getMap = function () {\n        if (SerializationMap.instance == null) {\n            SerializationMap.instance = new SerializationMap();\n        }\n        return SerializationMap.instance;\n    };\n    /**\n     * Registers the class as serializable.\n     */\n    SerializationMap.register = function (cls) {\n        SerializationMap.getMap().classNameMap[cls.className] =\n            [cls, cls.fromConfig];\n    };\n    return SerializationMap;\n}());\nexports.SerializationMap = SerializationMap;\n/**\n * Register a class with the serialization map of TensorFlow.js.\n *\n * This is often used for registering custom Layers, so they can be\n * serialized and deserialized.\n *\n * Example:\n *\n * ```js\n * class MyCustomLayer extends tf.layers.Layer {\n *   static className = 'MyCustomLayer';\n *\n *   constructor(config) {\n *     super(config);\n *   }\n * }\n * tf.serialization.registerClass(MyCustomLayer);\n * ```\n *\n * @param cls The class to be registered. It must have a public static member\n *   called `className` defined and the value must be a non-empty string.\n */\n/** @doc {heading: 'Models', subheading: 'Serialization', ignoreCI: true} */\nfunction registerClass(cls) {\n    util_1.assert(cls.className != null, function () { return \"Class being registered does not have the static className \" +\n        \"property defined.\"; });\n    util_1.assert(typeof cls.className === 'string', function () { return \"className is required to be a string, but got type \" +\n        typeof cls.className; });\n    util_1.assert(cls.className.length > 0, function () { return \"Class being registered has an empty-string as its className, \" +\n        \"which is disallowed.\"; });\n    SerializationMap.register(cls);\n}\nexports.registerClass = registerClass;\n//# sourceMappingURL=serialization.js.map","\n/**\n * @license\n * Copyright 2017 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar engine_1 = require(\"./engine\");\nvar tensor_util_env_1 = require(\"./tensor_util_env\");\nvar util_1 = require(\"./util\");\nvar TEST_EPSILON_FLOAT32 = 1e-3;\nexports.TEST_EPSILON_FLOAT16 = 1e-1;\nfunction expectArraysClose(actual, expected, epsilon) {\n    if (epsilon == null) {\n        epsilon = testEpsilon();\n    }\n    return expectArraysPredicate(actual, expected, function (a, b) { return areClose(a, b, epsilon); });\n}\nexports.expectArraysClose = expectArraysClose;\nfunction testEpsilon() {\n    return engine_1.ENGINE.backend.floatPrecision() === 32 ? TEST_EPSILON_FLOAT32 :\n        exports.TEST_EPSILON_FLOAT16;\n}\nexports.testEpsilon = testEpsilon;\nfunction expectArraysPredicate(actual, expected, predicate) {\n    var checkClassType = true;\n    if (util_1.isTypedArray(actual) || util_1.isTypedArray(expected)) {\n        checkClassType = false;\n    }\n    if (util_1.isTypedArray(actual) && util_1.isTypedArray(expected)) {\n        checkClassType = true;\n    }\n    if (checkClassType) {\n        var aType = actual.constructor.name;\n        var bType = expected.constructor.name;\n        if (aType !== bType) {\n            throw new Error(\"Arrays are of different type. Actual: \" + aType + \". \" +\n                (\"Expected: \" + bType));\n        }\n    }\n    if (Array.isArray(actual) && Array.isArray(expected)) {\n        var actualShape = tensor_util_env_1.inferShape(actual);\n        var expectedShape = tensor_util_env_1.inferShape(expected);\n        if (!util_1.arraysEqual(actualShape, expectedShape)) {\n            throw new Error(\"Arrays have different shapes. \" +\n                (\"Actual: [\" + actualShape + \"]. Expected: [\" + expectedShape + \"]\"));\n        }\n    }\n    var actualFlat = util_1.isTypedArray(actual) ? actual : util_1.flatten(actual);\n    var expectedFlat = util_1.isTypedArray(expected) ? expected : util_1.flatten(expected);\n    if (actualFlat.length !== expectedFlat.length) {\n        throw new Error(\"Arrays have different lengths actual: \" + actualFlat.length + \" vs \" +\n            (\"expected: \" + expectedFlat.length + \".\\n\") +\n            (\"Actual:   \" + actualFlat + \".\\n\") +\n            (\"Expected: \" + expectedFlat + \".\"));\n    }\n    for (var i = 0; i < expectedFlat.length; ++i) {\n        var a = actualFlat[i];\n        var e = expectedFlat[i];\n        if (!predicate(a, e)) {\n            throw new Error(\"Arrays differ: actual[\" + i + \"] = \" + a + \", expected[\" + i + \"] = \" + e + \".\\n\" +\n                (\"Actual:   \" + actualFlat + \".\\n\") +\n                (\"Expected: \" + expectedFlat + \".\"));\n        }\n    }\n}\nfunction expectPromiseToFail(fn, done) {\n    fn().then(function () { return done.fail(); }, function () { return done(); });\n}\nexports.expectPromiseToFail = expectPromiseToFail;\nfunction expectArraysEqual(actual, expected) {\n    var exp = typeof expected === 'string' || typeof expected === 'number' ||\n        typeof expected === 'boolean' ?\n        [expected] :\n        expected;\n    if (util_1.isString(actual) || util_1.isString(actual[0]) ||\n        util_1.isString(expected) || util_1.isString(expected[0])) {\n        // tslint:disable-next-line: triple-equals\n        return expectArraysPredicate(actual, exp, function (a, b) { return a == b; });\n    }\n    return expectArraysPredicate(actual, expected, function (a, b) { return areClose(a, b, 0); });\n}\nexports.expectArraysEqual = expectArraysEqual;\nfunction expectNumbersClose(a, e, epsilon) {\n    if (epsilon == null) {\n        epsilon = testEpsilon();\n    }\n    if (!areClose(a, e, epsilon)) {\n        throw new Error(\"Numbers differ: actual === \" + a + \", expected === \" + e);\n    }\n}\nexports.expectNumbersClose = expectNumbersClose;\nfunction areClose(a, e, epsilon) {\n    if (!isFinite(a) && !isFinite(e)) {\n        return true;\n    }\n    if (isNaN(a) || isNaN(e) || Math.abs(a - e) > epsilon) {\n        return false;\n    }\n    return true;\n}\nfunction expectValuesInRange(actual, low, high) {\n    for (var i = 0; i < actual.length; i++) {\n        if (actual[i] < low || actual[i] > high) {\n            throw new Error(\"Value out of range:\" + actual[i] + \" low: \" + low + \", high: \" + high);\n        }\n    }\n}\nexports.expectValuesInRange = expectValuesInRange;\nfunction expectArrayBuffersEqual(actual, expected) {\n    // Safari & Jasmine don't like comparing ArrayBuffers directly. Wrapping in\n    // a Float32Array solves this issue.\n    expect(new Float32Array(actual)).toEqual(new Float32Array(expected));\n}\nexports.expectArrayBuffersEqual = expectArrayBuffersEqual;\n//# sourceMappingURL=test_util.js.map","\n/** @license See the LICENSE file. */\nObject.defineProperty(exports, \"__esModule\", { value: true });\n// This code is auto-generated, do not modify this file!\nvar version = '1.2.0';\nexports.version = version;\n//# sourceMappingURL=version.js.map","\n/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar gpgpu_util = require(\"./backends/webgl/gpgpu_util\");\nexports.gpgpu_util = gpgpu_util;\nvar webgl_util = require(\"./backends/webgl/webgl_util\");\nexports.webgl_util = webgl_util;\nvar backend_webgl_1 = require(\"./backends/webgl/backend_webgl\");\nexports.MathBackendWebGL = backend_webgl_1.MathBackendWebGL;\nvar gpgpu_context_1 = require(\"./backends/webgl/gpgpu_context\");\nexports.GPGPUContext = gpgpu_context_1.GPGPUContext;\n//# sourceMappingURL=webgl.js.map","\n/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar __extends = (this && this.__extends) || (function () {\n    var extendStatics = function (d, b) {\n        extendStatics = Object.setPrototypeOf ||\n            ({ __proto__: [] } instanceof Array && function (d, b) { d.__proto__ = b; }) ||\n            function (d, b) { for (var p in b) if (b.hasOwnProperty(p)) d[p] = b[p]; };\n        return extendStatics(d, b);\n    };\n    return function (d, b) {\n        extendStatics(d, b);\n        function __() { this.constructor = d; }\n        d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());\n    };\n})();\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : new P(function (resolve) { resolve(result.value); }).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nvar __generator = (this && this.__generator) || function (thisArg, body) {\n    var _ = { label: 0, sent: function() { if (t[0] & 1) throw t[1]; return t[1]; }, trys: [], ops: [] }, f, y, t, g;\n    return g = { next: verb(0), \"throw\": verb(1), \"return\": verb(2) }, typeof Symbol === \"function\" && (g[Symbol.iterator] = function() { return this; }), g;\n    function verb(n) { return function (v) { return step([n, v]); }; }\n    function step(op) {\n        if (f) throw new TypeError(\"Generator is already executing.\");\n        while (_) try {\n            if (f = 1, y && (t = op[0] & 2 ? y[\"return\"] : op[0] ? y[\"throw\"] || ((t = y[\"return\"]) && t.call(y), 0) : y.next) && !(t = t.call(y, op[1])).done) return t;\n            if (y = 0, t) op = [op[0] & 2, t.value];\n            switch (op[0]) {\n                case 0: case 1: t = op; break;\n                case 4: _.label++; return { value: op[1], done: false };\n                case 5: _.label++; y = op[1]; op = [0]; continue;\n                case 7: op = _.ops.pop(); _.trys.pop(); continue;\n                default:\n                    if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) { _ = 0; continue; }\n                    if (op[0] === 3 && (!t || (op[1] > t[0] && op[1] < t[3]))) { _.label = op[1]; break; }\n                    if (op[0] === 6 && _.label < t[1]) { _.label = t[1]; t = op; break; }\n                    if (t && _.label < t[2]) { _.label = t[2]; _.ops.push(op); break; }\n                    if (t[2]) _.ops.pop();\n                    _.trys.pop(); continue;\n            }\n            op = body.call(thisArg, _);\n        } catch (e) { op = [6, e]; y = 0; } finally { f = t = 0; }\n        if (op[0] & 5) throw op[1]; return { value: op[0] ? op[1] : void 0, done: true };\n    }\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar engine_1 = require(\"../engine\");\nvar globals_1 = require(\"../globals\");\nvar ops_1 = require(\"../ops/ops\");\nvar serialization_1 = require(\"../serialization\");\nvar optimizer_1 = require(\"./optimizer\");\n/** @doclink Optimizer */\nvar AdadeltaOptimizer = /** @class */ (function (_super) {\n    __extends(AdadeltaOptimizer, _super);\n    function AdadeltaOptimizer(learningRate, rho, epsilon) {\n        if (epsilon === void 0) { epsilon = null; }\n        var _this = _super.call(this) || this;\n        _this.learningRate = learningRate;\n        _this.rho = rho;\n        _this.epsilon = epsilon;\n        _this.accumulatedGrads = [];\n        _this.accumulatedUpdates = [];\n        if (epsilon == null) {\n            _this.epsilon = engine_1.ENGINE.backend.epsilon();\n        }\n        return _this;\n    }\n    AdadeltaOptimizer.prototype.applyGradients = function (variableGradients) {\n        var _this = this;\n        var variableNames = Array.isArray(variableGradients) ?\n            variableGradients.map(function (item) { return item.name; }) :\n            Object.keys(variableGradients);\n        variableNames.forEach(function (name, i) {\n            var value = engine_1.ENGINE.registeredVariables[name];\n            var trainable = false;\n            if (_this.accumulatedGrads[i] == null) {\n                _this.accumulatedGrads[i] = {\n                    originalName: name + \"/accum_grad\",\n                    variable: globals_1.tidy(function () { return ops_1.zerosLike(value).variable(trainable); })\n                };\n            }\n            if (_this.accumulatedUpdates[i] == null) {\n                _this.accumulatedUpdates[i] = {\n                    originalName: name + \"/accum_var\",\n                    variable: globals_1.tidy(function () { return ops_1.zerosLike(value).variable(trainable); })\n                };\n            }\n            var gradient = Array.isArray(variableGradients) ?\n                variableGradients[i].tensor :\n                variableGradients[name];\n            if (gradient == null) {\n                return;\n            }\n            var accumulatedGrad = _this.accumulatedGrads[i].variable;\n            var accumulatedUpdate = _this.accumulatedUpdates[i].variable;\n            globals_1.tidy(function () {\n                var newAccumulatedGrad = accumulatedGrad.mul(_this.rho).add(gradient.square().mul(1 - _this.rho));\n                var updates = accumulatedUpdate.add(_this.epsilon)\n                    .sqrt()\n                    .div(accumulatedGrad.add(_this.epsilon).sqrt())\n                    .mul(gradient);\n                var newAccumulatedUpdate = accumulatedUpdate.mul(_this.rho).add(updates.square().mul(1 - _this.rho));\n                accumulatedGrad.assign(newAccumulatedGrad);\n                accumulatedUpdate.assign(newAccumulatedUpdate);\n                var newValue = updates.mul(-_this.learningRate).add(value);\n                value.assign(newValue);\n            });\n        });\n        this.incrementIterations();\n    };\n    AdadeltaOptimizer.prototype.dispose = function () {\n        if (this.accumulatedUpdates != null) {\n            globals_1.dispose(this.accumulatedGrads.map(function (v) { return v.variable; }));\n            globals_1.dispose(this.accumulatedUpdates.map(function (v) { return v.variable; }));\n        }\n    };\n    AdadeltaOptimizer.prototype.getWeights = function () {\n        return __awaiter(this, void 0, void 0, function () {\n            var variables;\n            return __generator(this, function (_a) {\n                switch (_a.label) {\n                    case 0:\n                        variables = this.accumulatedGrads.concat(this.accumulatedUpdates);\n                        return [4 /*yield*/, this.saveIterations()];\n                    case 1: return [2 /*return*/, [_a.sent()].concat(variables.map(function (v) { return ({ name: v.originalName, tensor: v.variable }); }))];\n                }\n            });\n        });\n    };\n    AdadeltaOptimizer.prototype.setWeights = function (weightValues) {\n        return __awaiter(this, void 0, void 0, function () {\n            var variableCount, trainable;\n            return __generator(this, function (_a) {\n                switch (_a.label) {\n                    case 0: return [4 /*yield*/, this.extractIterations(weightValues)];\n                    case 1:\n                        weightValues = _a.sent();\n                        variableCount = weightValues.length / 2;\n                        trainable = false;\n                        this.accumulatedGrads =\n                            weightValues.slice(0, variableCount).map(function (v) { return ({\n                                originalName: v.name,\n                                variable: v.tensor.variable(trainable)\n                            }); });\n                        this.accumulatedUpdates =\n                            weightValues.slice(variableCount, variableCount * 2)\n                                .map(function (v) { return ({\n                                originalName: v.name,\n                                variable: v.tensor.variable(trainable)\n                            }); });\n                        return [2 /*return*/];\n                }\n            });\n        });\n    };\n    AdadeltaOptimizer.prototype.getConfig = function () {\n        return {\n            'learningRate': this.learningRate,\n            'rho': this.rho,\n            'epsilon': this.epsilon\n        };\n    };\n    /** @nocollapse */\n    AdadeltaOptimizer.fromConfig = function (cls, config) {\n        return new cls(config['learningRate'], config['rho'], config['epsilon']);\n    };\n    /** @nocollapse */\n    AdadeltaOptimizer.className = 'AdadeltaOptimizer';\n    return AdadeltaOptimizer;\n}(optimizer_1.Optimizer));\nexports.AdadeltaOptimizer = AdadeltaOptimizer;\nserialization_1.registerClass(AdadeltaOptimizer);\n//# sourceMappingURL=adadelta_optimizer.js.map","\n/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar __extends = (this && this.__extends) || (function () {\n    var extendStatics = function (d, b) {\n        extendStatics = Object.setPrototypeOf ||\n            ({ __proto__: [] } instanceof Array && function (d, b) { d.__proto__ = b; }) ||\n            function (d, b) { for (var p in b) if (b.hasOwnProperty(p)) d[p] = b[p]; };\n        return extendStatics(d, b);\n    };\n    return function (d, b) {\n        extendStatics(d, b);\n        function __() { this.constructor = d; }\n        d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());\n    };\n})();\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : new P(function (resolve) { resolve(result.value); }).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nvar __generator = (this && this.__generator) || function (thisArg, body) {\n    var _ = { label: 0, sent: function() { if (t[0] & 1) throw t[1]; return t[1]; }, trys: [], ops: [] }, f, y, t, g;\n    return g = { next: verb(0), \"throw\": verb(1), \"return\": verb(2) }, typeof Symbol === \"function\" && (g[Symbol.iterator] = function() { return this; }), g;\n    function verb(n) { return function (v) { return step([n, v]); }; }\n    function step(op) {\n        if (f) throw new TypeError(\"Generator is already executing.\");\n        while (_) try {\n            if (f = 1, y && (t = op[0] & 2 ? y[\"return\"] : op[0] ? y[\"throw\"] || ((t = y[\"return\"]) && t.call(y), 0) : y.next) && !(t = t.call(y, op[1])).done) return t;\n            if (y = 0, t) op = [op[0] & 2, t.value];\n            switch (op[0]) {\n                case 0: case 1: t = op; break;\n                case 4: _.label++; return { value: op[1], done: false };\n                case 5: _.label++; y = op[1]; op = [0]; continue;\n                case 7: op = _.ops.pop(); _.trys.pop(); continue;\n                default:\n                    if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) { _ = 0; continue; }\n                    if (op[0] === 3 && (!t || (op[1] > t[0] && op[1] < t[3]))) { _.label = op[1]; break; }\n                    if (op[0] === 6 && _.label < t[1]) { _.label = t[1]; t = op; break; }\n                    if (t && _.label < t[2]) { _.label = t[2]; _.ops.push(op); break; }\n                    if (t[2]) _.ops.pop();\n                    _.trys.pop(); continue;\n            }\n            op = body.call(thisArg, _);\n        } catch (e) { op = [6, e]; y = 0; } finally { f = t = 0; }\n        if (op[0] & 5) throw op[1]; return { value: op[0] ? op[1] : void 0, done: true };\n    }\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar globals_1 = require(\"../globals\");\nvar gradients_1 = require(\"../gradients\");\nvar ops_1 = require(\"../ops/ops\");\nvar serialization_1 = require(\"../serialization\");\n/** @doc {heading: 'Training', subheading: 'Classes', namespace: 'train'} */\nvar Optimizer = /** @class */ (function (_super) {\n    __extends(Optimizer, _super);\n    function Optimizer() {\n        return _super !== null && _super.apply(this, arguments) || this;\n    }\n    /**\n     * Executes `f()` and minimizes the scalar output of `f()` by computing\n     * gradients of y with respect to the list of trainable variables provided by\n     * `varList`. If no list is provided, it defaults to all trainable variables.\n     *\n     * @param f The function to execute and whose output to minimize.\n     * @param returnCost Whether to return the scalar cost value produced by\n     * executing `f()`.\n     * @param varList An optional list of variables to update. If specified, only\n     * the trainable variables in varList will be updated by minimize. Defaults to\n     * all trainable variables.\n     */\n    /** @doc {heading: 'Training', subheading: 'Optimizers'} */\n    Optimizer.prototype.minimize = function (f, returnCost, varList) {\n        if (returnCost === void 0) { returnCost = false; }\n        var _a = this.computeGradients(f, varList), value = _a.value, grads = _a.grads;\n        if (varList != null) {\n            var gradArray = varList.map(function (v) { return ({ name: v.name, tensor: grads[v.name] }); });\n            this.applyGradients(gradArray);\n        }\n        else {\n            this.applyGradients(grads);\n        }\n        // Dispose gradients.\n        globals_1.dispose(grads);\n        if (returnCost) {\n            return value;\n        }\n        else {\n            value.dispose();\n            return null;\n        }\n    };\n    Object.defineProperty(Optimizer.prototype, \"iterations\", {\n        /**\n         * The number of iterations that this optimizer instance has been invoked for.\n         */\n        get: function () {\n            if (this.iterations_ == null) {\n                this.iterations_ = 0;\n            }\n            return this.iterations_;\n        },\n        enumerable: true,\n        configurable: true\n    });\n    Optimizer.prototype.incrementIterations = function () {\n        this.iterations_ = this.iterations + 1;\n    };\n    /**\n     * Executes f() and computes the gradient of the scalar output of f() with\n     * respect to the list of trainable variables provided by `varList`. If no\n     * list is provided, it defaults to all trainable variables.\n     *\n     * @param f The function to execute and whose output to use for computing\n     * gradients with respect to variables.\n     * @param varList An optional list of variables to compute gradients with\n     * respect to. If specified, only the trainable variables in varList will have\n     * gradients computed with respect to. Defaults to all trainable variables.\n     */\n    Optimizer.prototype.computeGradients = function (f, varList) {\n        return gradients_1.variableGrads(f, varList);\n    };\n    /**\n     * Dispose the variables (if any) owned by this optimizer instance.\n     */\n    Optimizer.prototype.dispose = function () {\n        if (this.iterations_ != null) {\n            globals_1.dispose(this.iterations_);\n        }\n    };\n    Optimizer.prototype.saveIterations = function () {\n        return __awaiter(this, void 0, void 0, function () {\n            return __generator(this, function (_a) {\n                if (this.iterations_ == null) {\n                    this.iterations_ = 0;\n                }\n                return [2 /*return*/, {\n                        name: 'iter',\n                        // TODO(cais): Use 'int64' type when available.\n                        tensor: ops_1.scalar(this.iterations_, 'int32')\n                    }];\n            });\n        });\n    };\n    Optimizer.prototype.getWeights = function () {\n        return __awaiter(this, void 0, void 0, function () {\n            return __generator(this, function (_a) {\n                throw new Error('getWeights() is not implemented for this optimizer yet.');\n            });\n        });\n    };\n    Optimizer.prototype.setWeights = function (weightValues) {\n        return __awaiter(this, void 0, void 0, function () {\n            return __generator(this, function (_a) {\n                throw new Error(\"setWeights() is not implemented for this optimizer class \" +\n                    (\"\" + this.getClassName()));\n            });\n        });\n    };\n    /**\n     * Extract the first element of the weight values and set it\n     * as the iterations counter variable of this instance of optimizer.\n     *\n     * @param weightValues\n     * @returns Weight values with the first element consumed and excluded.\n     */\n    Optimizer.prototype.extractIterations = function (weightValues) {\n        return __awaiter(this, void 0, void 0, function () {\n            var _a;\n            return __generator(this, function (_b) {\n                switch (_b.label) {\n                    case 0:\n                        _a = this;\n                        return [4 /*yield*/, weightValues[0].tensor.data()];\n                    case 1:\n                        _a.iterations_ = (_b.sent())[0];\n                        return [2 /*return*/, weightValues.slice(1)];\n                }\n            });\n        });\n    };\n    return Optimizer;\n}(serialization_1.Serializable));\nexports.Optimizer = Optimizer;\nObject.defineProperty(Optimizer, Symbol.hasInstance, {\n    value: function (instance) {\n        return instance.minimize != null && instance.computeGradients != null &&\n            instance.applyGradients != null;\n    }\n});\n//# sourceMappingURL=optimizer.js.map","\n/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar __extends = (this && this.__extends) || (function () {\n    var extendStatics = function (d, b) {\n        extendStatics = Object.setPrototypeOf ||\n            ({ __proto__: [] } instanceof Array && function (d, b) { d.__proto__ = b; }) ||\n            function (d, b) { for (var p in b) if (b.hasOwnProperty(p)) d[p] = b[p]; };\n        return extendStatics(d, b);\n    };\n    return function (d, b) {\n        extendStatics(d, b);\n        function __() { this.constructor = d; }\n        d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());\n    };\n})();\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : new P(function (resolve) { resolve(result.value); }).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nvar __generator = (this && this.__generator) || function (thisArg, body) {\n    var _ = { label: 0, sent: function() { if (t[0] & 1) throw t[1]; return t[1]; }, trys: [], ops: [] }, f, y, t, g;\n    return g = { next: verb(0), \"throw\": verb(1), \"return\": verb(2) }, typeof Symbol === \"function\" && (g[Symbol.iterator] = function() { return this; }), g;\n    function verb(n) { return function (v) { return step([n, v]); }; }\n    function step(op) {\n        if (f) throw new TypeError(\"Generator is already executing.\");\n        while (_) try {\n            if (f = 1, y && (t = op[0] & 2 ? y[\"return\"] : op[0] ? y[\"throw\"] || ((t = y[\"return\"]) && t.call(y), 0) : y.next) && !(t = t.call(y, op[1])).done) return t;\n            if (y = 0, t) op = [op[0] & 2, t.value];\n            switch (op[0]) {\n                case 0: case 1: t = op; break;\n                case 4: _.label++; return { value: op[1], done: false };\n                case 5: _.label++; y = op[1]; op = [0]; continue;\n                case 7: op = _.ops.pop(); _.trys.pop(); continue;\n                default:\n                    if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) { _ = 0; continue; }\n                    if (op[0] === 3 && (!t || (op[1] > t[0] && op[1] < t[3]))) { _.label = op[1]; break; }\n                    if (op[0] === 6 && _.label < t[1]) { _.label = t[1]; t = op; break; }\n                    if (t && _.label < t[2]) { _.label = t[2]; _.ops.push(op); break; }\n                    if (t[2]) _.ops.pop();\n                    _.trys.pop(); continue;\n            }\n            op = body.call(thisArg, _);\n        } catch (e) { op = [6, e]; y = 0; } finally { f = t = 0; }\n        if (op[0] & 5) throw op[1]; return { value: op[0] ? op[1] : void 0, done: true };\n    }\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar engine_1 = require(\"../engine\");\nvar globals_1 = require(\"../globals\");\nvar ops_1 = require(\"../ops/ops\");\nvar serialization_1 = require(\"../serialization\");\nvar optimizer_1 = require(\"./optimizer\");\n/** @doclink Optimizer */\nvar AdagradOptimizer = /** @class */ (function (_super) {\n    __extends(AdagradOptimizer, _super);\n    function AdagradOptimizer(learningRate, initialAccumulatorValue) {\n        if (initialAccumulatorValue === void 0) { initialAccumulatorValue = 0.1; }\n        var _this = _super.call(this) || this;\n        _this.learningRate = learningRate;\n        _this.initialAccumulatorValue = initialAccumulatorValue;\n        _this.accumulatedGrads = [];\n        return _this;\n    }\n    AdagradOptimizer.prototype.applyGradients = function (variableGradients) {\n        var _this = this;\n        var variableNames = Array.isArray(variableGradients) ?\n            variableGradients.map(function (item) { return item.name; }) :\n            Object.keys(variableGradients);\n        variableNames.forEach(function (name, i) {\n            var value = engine_1.ENGINE.registeredVariables[name];\n            if (_this.accumulatedGrads[i] == null) {\n                var trainable_1 = false;\n                _this.accumulatedGrads[i] = {\n                    originalName: name + \"/accumulator\",\n                    variable: globals_1.tidy(function () { return ops_1.fill(value.shape, _this.initialAccumulatorValue)\n                        .variable(trainable_1); })\n                };\n            }\n            var gradient = Array.isArray(variableGradients) ?\n                variableGradients[i].tensor :\n                variableGradients[name];\n            if (gradient == null) {\n                return;\n            }\n            var accumulatedGrad = _this.accumulatedGrads[i].variable;\n            globals_1.tidy(function () {\n                var newAccumulatedGrad = accumulatedGrad.add(gradient.square());\n                accumulatedGrad.assign(newAccumulatedGrad);\n                var newValue = gradient\n                    .div(newAccumulatedGrad.add(engine_1.ENGINE.backend.epsilon()).sqrt())\n                    .mul(-_this.learningRate)\n                    .add(value);\n                value.assign(newValue);\n            });\n        });\n        this.incrementIterations();\n    };\n    AdagradOptimizer.prototype.dispose = function () {\n        if (this.accumulatedGrads != null) {\n            globals_1.dispose(this.accumulatedGrads.map(function (v) { return v.variable; }));\n        }\n    };\n    AdagradOptimizer.prototype.getWeights = function () {\n        return __awaiter(this, void 0, void 0, function () {\n            return __generator(this, function (_a) {\n                switch (_a.label) {\n                    case 0: return [4 /*yield*/, this.saveIterations()];\n                    case 1: \n                    // Order matters for Python compatibility.\n                    return [2 /*return*/, [_a.sent()].concat(this.accumulatedGrads.map(function (v) { return ({ name: v.originalName, tensor: v.variable }); }))];\n                }\n            });\n        });\n    };\n    AdagradOptimizer.prototype.setWeights = function (weightValues) {\n        return __awaiter(this, void 0, void 0, function () {\n            var trainable;\n            return __generator(this, function (_a) {\n                switch (_a.label) {\n                    case 0: return [4 /*yield*/, this.extractIterations(weightValues)];\n                    case 1:\n                        weightValues = _a.sent();\n                        trainable = false;\n                        this.accumulatedGrads = weightValues.map(function (v) { return ({ originalName: v.name, variable: v.tensor.variable(trainable) }); });\n                        return [2 /*return*/];\n                }\n            });\n        });\n    };\n    AdagradOptimizer.prototype.getConfig = function () {\n        return {\n            'learningRate': this.learningRate,\n            'initialAccumulatorValue': this.initialAccumulatorValue,\n        };\n    };\n    /** @nocollapse */\n    AdagradOptimizer.fromConfig = function (cls, config) {\n        return new cls(config['learningRate'], config['initialAccumulatorValue']);\n    };\n    /** @nocollapse */\n    AdagradOptimizer.className = 'Adagrad'; // Note: Name matters for Python compatibility.\n    return AdagradOptimizer;\n}(optimizer_1.Optimizer));\nexports.AdagradOptimizer = AdagradOptimizer;\nserialization_1.registerClass(AdagradOptimizer);\n//# sourceMappingURL=adagrad_optimizer.js.map","\n/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar __extends = (this && this.__extends) || (function () {\n    var extendStatics = function (d, b) {\n        extendStatics = Object.setPrototypeOf ||\n            ({ __proto__: [] } instanceof Array && function (d, b) { d.__proto__ = b; }) ||\n            function (d, b) { for (var p in b) if (b.hasOwnProperty(p)) d[p] = b[p]; };\n        return extendStatics(d, b);\n    };\n    return function (d, b) {\n        extendStatics(d, b);\n        function __() { this.constructor = d; }\n        d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());\n    };\n})();\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : new P(function (resolve) { resolve(result.value); }).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nvar __generator = (this && this.__generator) || function (thisArg, body) {\n    var _ = { label: 0, sent: function() { if (t[0] & 1) throw t[1]; return t[1]; }, trys: [], ops: [] }, f, y, t, g;\n    return g = { next: verb(0), \"throw\": verb(1), \"return\": verb(2) }, typeof Symbol === \"function\" && (g[Symbol.iterator] = function() { return this; }), g;\n    function verb(n) { return function (v) { return step([n, v]); }; }\n    function step(op) {\n        if (f) throw new TypeError(\"Generator is already executing.\");\n        while (_) try {\n            if (f = 1, y && (t = op[0] & 2 ? y[\"return\"] : op[0] ? y[\"throw\"] || ((t = y[\"return\"]) && t.call(y), 0) : y.next) && !(t = t.call(y, op[1])).done) return t;\n            if (y = 0, t) op = [op[0] & 2, t.value];\n            switch (op[0]) {\n                case 0: case 1: t = op; break;\n                case 4: _.label++; return { value: op[1], done: false };\n                case 5: _.label++; y = op[1]; op = [0]; continue;\n                case 7: op = _.ops.pop(); _.trys.pop(); continue;\n                default:\n                    if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) { _ = 0; continue; }\n                    if (op[0] === 3 && (!t || (op[1] > t[0] && op[1] < t[3]))) { _.label = op[1]; break; }\n                    if (op[0] === 6 && _.label < t[1]) { _.label = t[1]; t = op; break; }\n                    if (t && _.label < t[2]) { _.label = t[2]; _.ops.push(op); break; }\n                    if (t[2]) _.ops.pop();\n                    _.trys.pop(); continue;\n            }\n            op = body.call(thisArg, _);\n        } catch (e) { op = [6, e]; y = 0; } finally { f = t = 0; }\n        if (op[0] & 5) throw op[1]; return { value: op[0] ? op[1] : void 0, done: true };\n    }\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar engine_1 = require(\"../engine\");\nvar globals_1 = require(\"../globals\");\nvar ops_1 = require(\"../ops/ops\");\nvar serialization_1 = require(\"../serialization\");\nvar optimizer_1 = require(\"./optimizer\");\nvar AdamOptimizer = /** @class */ (function (_super) {\n    __extends(AdamOptimizer, _super);\n    function AdamOptimizer(learningRate, beta1, beta2, epsilon) {\n        if (epsilon === void 0) { epsilon = null; }\n        var _this = _super.call(this) || this;\n        _this.learningRate = learningRate;\n        _this.beta1 = beta1;\n        _this.beta2 = beta2;\n        _this.epsilon = epsilon;\n        _this.accumulatedFirstMoment = [];\n        _this.accumulatedSecondMoment = [];\n        globals_1.tidy(function () {\n            // accB* will be updated by batch.\n            _this.accBeta1 = ops_1.scalar(beta1).variable();\n            _this.accBeta2 = ops_1.scalar(beta2).variable();\n        });\n        if (epsilon == null) {\n            _this.epsilon = engine_1.ENGINE.backend.epsilon();\n        }\n        return _this;\n    }\n    AdamOptimizer.prototype.applyGradients = function (variableGradients) {\n        var _this = this;\n        var varNames = Array.isArray(variableGradients) ?\n            variableGradients.map(function (v) { return v.name; }) :\n            Object.keys(variableGradients);\n        globals_1.tidy(function () {\n            var oneMinusAccBeta1 = ops_1.sub(1, _this.accBeta1);\n            var oneMinusAccBeta2 = ops_1.sub(1, _this.accBeta2);\n            varNames.forEach(function (name, i) {\n                var value = engine_1.ENGINE.registeredVariables[name];\n                var trainable = false;\n                if (_this.accumulatedFirstMoment[i] == null) {\n                    _this.accumulatedFirstMoment[i] = {\n                        originalName: name + \"/m\",\n                        variable: globals_1.tidy(function () { return ops_1.zerosLike(value).variable(trainable); })\n                    };\n                }\n                if (_this.accumulatedSecondMoment[i] == null) {\n                    _this.accumulatedSecondMoment[i] = {\n                        originalName: name + \"/v\",\n                        variable: globals_1.tidy(function () { return ops_1.zerosLike(value).variable(trainable); })\n                    };\n                }\n                var gradient = Array.isArray(variableGradients) ?\n                    variableGradients[i].tensor :\n                    variableGradients[name];\n                if (gradient == null) {\n                    return;\n                }\n                var firstMoment = _this.accumulatedFirstMoment[i].variable;\n                var secondMoment = _this.accumulatedSecondMoment[i].variable;\n                var newFirstMoment = firstMoment.mul(_this.beta1).add(gradient.mul(1 - _this.beta1));\n                var newSecondMoment = secondMoment.mul(_this.beta2)\n                    .add(gradient.square().mul(1 - _this.beta2));\n                var biasCorrectedFirstMoment = newFirstMoment.div(oneMinusAccBeta1);\n                var biasCorrectedSecondMoment = newSecondMoment.div(oneMinusAccBeta2);\n                firstMoment.assign(newFirstMoment);\n                secondMoment.assign(newSecondMoment);\n                var newValue = biasCorrectedFirstMoment\n                    .div(biasCorrectedSecondMoment.sqrt().add(_this.epsilon))\n                    .mul(-_this.learningRate)\n                    .add(value);\n                value.assign(newValue);\n            });\n            _this.accBeta1.assign(_this.accBeta1.mul(_this.beta1));\n            _this.accBeta2.assign(_this.accBeta2.mul(_this.beta2));\n        });\n        this.incrementIterations();\n    };\n    AdamOptimizer.prototype.dispose = function () {\n        this.accBeta1.dispose();\n        this.accBeta2.dispose();\n        if (this.accumulatedFirstMoment != null) {\n            globals_1.dispose(this.accumulatedFirstMoment.map(function (v) { return v.variable; }));\n        }\n        if (this.accumulatedSecondMoment != null) {\n            globals_1.dispose(this.accumulatedSecondMoment.map(function (v) { return v.variable; }));\n        }\n    };\n    AdamOptimizer.prototype.getWeights = function () {\n        return __awaiter(this, void 0, void 0, function () {\n            var variables;\n            return __generator(this, function (_a) {\n                switch (_a.label) {\n                    case 0:\n                        variables = this.accumulatedFirstMoment.concat(this.accumulatedSecondMoment);\n                        return [4 /*yield*/, this.saveIterations()];\n                    case 1: return [2 /*return*/, [_a.sent()].concat(variables.map(function (v) { return ({ name: v.originalName, tensor: v.variable }); }))];\n                }\n            });\n        });\n    };\n    AdamOptimizer.prototype.setWeights = function (weightValues) {\n        return __awaiter(this, void 0, void 0, function () {\n            var variableCount, trainable;\n            var _this = this;\n            return __generator(this, function (_a) {\n                switch (_a.label) {\n                    case 0: return [4 /*yield*/, this.extractIterations(weightValues)];\n                    case 1:\n                        weightValues = _a.sent();\n                        globals_1.tidy(function () {\n                            _this.accBeta1.assign(ops_1.pow(_this.beta1, _this.iterations_ + 1));\n                            _this.accBeta2.assign(ops_1.pow(_this.beta2, _this.iterations_ + 1));\n                        });\n                        variableCount = weightValues.length / 2;\n                        trainable = false;\n                        this.accumulatedFirstMoment =\n                            weightValues.slice(0, variableCount).map(function (v) { return ({\n                                originalName: v.name,\n                                variable: v.tensor.variable(trainable)\n                            }); });\n                        this.accumulatedSecondMoment =\n                            weightValues.slice(variableCount, variableCount * 2)\n                                .map(function (v) { return ({\n                                originalName: v.name,\n                                variable: v.tensor.variable(trainable)\n                            }); });\n                        return [2 /*return*/];\n                }\n            });\n        });\n    };\n    AdamOptimizer.prototype.getConfig = function () {\n        return {\n            'learningRate': this.learningRate,\n            'beta1': this.beta1,\n            'beta2': this.beta2,\n            'epsilon': this.epsilon,\n        };\n    };\n    /** @nocollapse */\n    AdamOptimizer.fromConfig = function (cls, config) {\n        return new cls(config['learningRate'], config['beta1'], config['beta2'], config['epsilon']);\n    };\n    /** @nocollapse */\n    AdamOptimizer.className = 'Adam'; // Note: Name matters for Python compatibility.\n    return AdamOptimizer;\n}(optimizer_1.Optimizer));\nexports.AdamOptimizer = AdamOptimizer;\nserialization_1.registerClass(AdamOptimizer);\n//# sourceMappingURL=adam_optimizer.js.map","\n/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar __extends = (this && this.__extends) || (function () {\n    var extendStatics = function (d, b) {\n        extendStatics = Object.setPrototypeOf ||\n            ({ __proto__: [] } instanceof Array && function (d, b) { d.__proto__ = b; }) ||\n            function (d, b) { for (var p in b) if (b.hasOwnProperty(p)) d[p] = b[p]; };\n        return extendStatics(d, b);\n    };\n    return function (d, b) {\n        extendStatics(d, b);\n        function __() { this.constructor = d; }\n        d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());\n    };\n})();\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : new P(function (resolve) { resolve(result.value); }).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nvar __generator = (this && this.__generator) || function (thisArg, body) {\n    var _ = { label: 0, sent: function() { if (t[0] & 1) throw t[1]; return t[1]; }, trys: [], ops: [] }, f, y, t, g;\n    return g = { next: verb(0), \"throw\": verb(1), \"return\": verb(2) }, typeof Symbol === \"function\" && (g[Symbol.iterator] = function() { return this; }), g;\n    function verb(n) { return function (v) { return step([n, v]); }; }\n    function step(op) {\n        if (f) throw new TypeError(\"Generator is already executing.\");\n        while (_) try {\n            if (f = 1, y && (t = op[0] & 2 ? y[\"return\"] : op[0] ? y[\"throw\"] || ((t = y[\"return\"]) && t.call(y), 0) : y.next) && !(t = t.call(y, op[1])).done) return t;\n            if (y = 0, t) op = [op[0] & 2, t.value];\n            switch (op[0]) {\n                case 0: case 1: t = op; break;\n                case 4: _.label++; return { value: op[1], done: false };\n                case 5: _.label++; y = op[1]; op = [0]; continue;\n                case 7: op = _.ops.pop(); _.trys.pop(); continue;\n                default:\n                    if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) { _ = 0; continue; }\n                    if (op[0] === 3 && (!t || (op[1] > t[0] && op[1] < t[3]))) { _.label = op[1]; break; }\n                    if (op[0] === 6 && _.label < t[1]) { _.label = t[1]; t = op; break; }\n                    if (t && _.label < t[2]) { _.label = t[2]; _.ops.push(op); break; }\n                    if (t[2]) _.ops.pop();\n                    _.trys.pop(); continue;\n            }\n            op = body.call(thisArg, _);\n        } catch (e) { op = [6, e]; y = 0; } finally { f = t = 0; }\n        if (op[0] & 5) throw op[1]; return { value: op[0] ? op[1] : void 0, done: true };\n    }\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar engine_1 = require(\"../engine\");\nvar globals_1 = require(\"../globals\");\nvar ops_1 = require(\"../ops/ops\");\nvar serialization_1 = require(\"../serialization\");\nvar optimizer_1 = require(\"./optimizer\");\nvar AdamaxOptimizer = /** @class */ (function (_super) {\n    __extends(AdamaxOptimizer, _super);\n    function AdamaxOptimizer(learningRate, beta1, beta2, epsilon, decay) {\n        if (epsilon === void 0) { epsilon = null; }\n        if (decay === void 0) { decay = 0.0; }\n        var _this = _super.call(this) || this;\n        _this.learningRate = learningRate;\n        _this.beta1 = beta1;\n        _this.beta2 = beta2;\n        _this.epsilon = epsilon;\n        _this.decay = decay;\n        _this.accumulatedFirstMoment = [];\n        _this.accumulatedWeightedInfNorm = [];\n        globals_1.tidy(function () {\n            _this.iteration = ops_1.scalar(0).variable();\n            _this.accBeta1 = ops_1.scalar(beta1).variable();\n        });\n        if (epsilon == null) {\n            _this.epsilon = engine_1.ENGINE.backend.epsilon();\n        }\n        return _this;\n    }\n    AdamaxOptimizer.prototype.applyGradients = function (variableGradients) {\n        var _this = this;\n        var variableNames = Array.isArray(variableGradients) ?\n            variableGradients.map(function (item) { return item.name; }) :\n            Object.keys(variableGradients);\n        globals_1.tidy(function () {\n            var oneMinusAccBeta1 = ops_1.sub(1, _this.accBeta1);\n            var lr = ops_1.div(-_this.learningRate, _this.iteration.mul(_this.decay).add(1));\n            variableNames.forEach(function (name, i) {\n                var value = engine_1.ENGINE.registeredVariables[name];\n                var trainable = false;\n                if (_this.accumulatedFirstMoment[i] == null) {\n                    _this.accumulatedFirstMoment[i] = {\n                        originalName: name + \"/m\",\n                        variable: ops_1.zerosLike(value).variable(trainable)\n                    };\n                }\n                if (_this.accumulatedWeightedInfNorm[i] == null) {\n                    _this.accumulatedWeightedInfNorm[i] = {\n                        originalName: name + \"/v\",\n                        variable: ops_1.zerosLike(value).variable(trainable)\n                    };\n                }\n                var gradient = Array.isArray(variableGradients) ?\n                    variableGradients[i].tensor :\n                    variableGradients[name];\n                if (gradient == null) {\n                    return;\n                }\n                var firstMoment = _this.accumulatedFirstMoment[i].variable;\n                var weightedInfNorm = _this.accumulatedWeightedInfNorm[i].variable;\n                var newFirstMoment = firstMoment.mul(_this.beta1).add(gradient.mul(1 - _this.beta1));\n                var ut0 = weightedInfNorm.mul(_this.beta2);\n                var ut1 = gradient.abs();\n                var newWeightedInfNorm = ut0.maximum(ut1);\n                firstMoment.assign(newFirstMoment);\n                weightedInfNorm.assign(newWeightedInfNorm);\n                var newValue = lr.div(oneMinusAccBeta1)\n                    .mul(newFirstMoment.div(newWeightedInfNorm.add(_this.epsilon)))\n                    .add(value);\n                value.assign(newValue);\n            });\n            _this.iteration.assign(_this.iteration.add(1));\n            _this.accBeta1.assign(_this.accBeta1.mul(_this.beta1));\n        });\n        this.incrementIterations();\n    };\n    AdamaxOptimizer.prototype.dispose = function () {\n        this.accBeta1.dispose();\n        this.iteration.dispose();\n        if (this.accumulatedFirstMoment != null) {\n            globals_1.dispose(this.accumulatedFirstMoment.map(function (v) { return v.variable; }));\n        }\n        if (this.accumulatedWeightedInfNorm != null) {\n            globals_1.dispose(this.accumulatedWeightedInfNorm.map(function (v) { return v.variable; }));\n        }\n    };\n    AdamaxOptimizer.prototype.getWeights = function () {\n        return __awaiter(this, void 0, void 0, function () {\n            return __generator(this, function (_a) {\n                throw new Error('getWeights() is not implemented for Adamax yet.');\n            });\n        });\n    };\n    AdamaxOptimizer.prototype.setWeights = function (weightValues) {\n        return __awaiter(this, void 0, void 0, function () {\n            return __generator(this, function (_a) {\n                throw new Error('setWeights() is not implemented for Adamax yet.');\n            });\n        });\n    };\n    AdamaxOptimizer.prototype.getConfig = function () {\n        return {\n            'learningRate': this.learningRate,\n            'beta1': this.beta1,\n            'beta2': this.beta2,\n            'epsilon': this.epsilon,\n            'decay': this.decay\n        };\n    };\n    /** @nocollapse */\n    AdamaxOptimizer.fromConfig = function (cls, config) {\n        return new cls(config['learningRate'], config['beta1'], config['beta2'], config['epsilon'], config['decay']);\n    };\n    /** @nocollapse */\n    AdamaxOptimizer.className = 'Adamax'; // Note: Name matters for Python compatbility.\n    return AdamaxOptimizer;\n}(optimizer_1.Optimizer));\nexports.AdamaxOptimizer = AdamaxOptimizer;\nserialization_1.registerClass(AdamaxOptimizer);\n//# sourceMappingURL=adamax_optimizer.js.map","\n/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar __extends = (this && this.__extends) || (function () {\n    var extendStatics = function (d, b) {\n        extendStatics = Object.setPrototypeOf ||\n            ({ __proto__: [] } instanceof Array && function (d, b) { d.__proto__ = b; }) ||\n            function (d, b) { for (var p in b) if (b.hasOwnProperty(p)) d[p] = b[p]; };\n        return extendStatics(d, b);\n    };\n    return function (d, b) {\n        extendStatics(d, b);\n        function __() { this.constructor = d; }\n        d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());\n    };\n})();\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : new P(function (resolve) { resolve(result.value); }).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nvar __generator = (this && this.__generator) || function (thisArg, body) {\n    var _ = { label: 0, sent: function() { if (t[0] & 1) throw t[1]; return t[1]; }, trys: [], ops: [] }, f, y, t, g;\n    return g = { next: verb(0), \"throw\": verb(1), \"return\": verb(2) }, typeof Symbol === \"function\" && (g[Symbol.iterator] = function() { return this; }), g;\n    function verb(n) { return function (v) { return step([n, v]); }; }\n    function step(op) {\n        if (f) throw new TypeError(\"Generator is already executing.\");\n        while (_) try {\n            if (f = 1, y && (t = op[0] & 2 ? y[\"return\"] : op[0] ? y[\"throw\"] || ((t = y[\"return\"]) && t.call(y), 0) : y.next) && !(t = t.call(y, op[1])).done) return t;\n            if (y = 0, t) op = [op[0] & 2, t.value];\n            switch (op[0]) {\n                case 0: case 1: t = op; break;\n                case 4: _.label++; return { value: op[1], done: false };\n                case 5: _.label++; y = op[1]; op = [0]; continue;\n                case 7: op = _.ops.pop(); _.trys.pop(); continue;\n                default:\n                    if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) { _ = 0; continue; }\n                    if (op[0] === 3 && (!t || (op[1] > t[0] && op[1] < t[3]))) { _.label = op[1]; break; }\n                    if (op[0] === 6 && _.label < t[1]) { _.label = t[1]; t = op; break; }\n                    if (t && _.label < t[2]) { _.label = t[2]; _.ops.push(op); break; }\n                    if (t[2]) _.ops.pop();\n                    _.trys.pop(); continue;\n            }\n            op = body.call(thisArg, _);\n        } catch (e) { op = [6, e]; y = 0; } finally { f = t = 0; }\n        if (op[0] & 5) throw op[1]; return { value: op[0] ? op[1] : void 0, done: true };\n    }\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar engine_1 = require(\"../engine\");\nvar globals_1 = require(\"../globals\");\nvar ops_1 = require(\"../ops/ops\");\nvar serialization_1 = require(\"../serialization\");\nvar sgd_optimizer_1 = require(\"./sgd_optimizer\");\n/** @doclink Optimizer */\nvar MomentumOptimizer = /** @class */ (function (_super) {\n    __extends(MomentumOptimizer, _super);\n    function MomentumOptimizer(learningRate, momentum, useNesterov) {\n        if (useNesterov === void 0) { useNesterov = false; }\n        var _this = _super.call(this, learningRate) || this;\n        _this.learningRate = learningRate;\n        _this.momentum = momentum;\n        _this.useNesterov = useNesterov;\n        _this.accumulations = [];\n        _this.m = ops_1.scalar(_this.momentum);\n        return _this;\n    }\n    MomentumOptimizer.prototype.applyGradients = function (variableGradients) {\n        var _this = this;\n        var variableNames = Array.isArray(variableGradients) ?\n            variableGradients.map(function (item) { return item.name; }) :\n            Object.keys(variableGradients);\n        variableNames.forEach(function (name, i) {\n            var value = engine_1.ENGINE.registeredVariables[name];\n            if (_this.accumulations[i] == null) {\n                var trainable_1 = false;\n                _this.accumulations[i] = {\n                    originalName: name + \"/momentum\",\n                    variable: globals_1.tidy(function () { return ops_1.zerosLike(value).variable(trainable_1); })\n                };\n            }\n            var accumulation = _this.accumulations[i].variable;\n            var gradient = Array.isArray(variableGradients) ?\n                variableGradients[i].tensor :\n                variableGradients[name];\n            if (gradient == null) {\n                return;\n            }\n            globals_1.tidy(function () {\n                var newValue;\n                var newAccumulation = _this.m.mul(accumulation).add(gradient);\n                if (_this.useNesterov) {\n                    newValue =\n                        _this.c.mul(gradient.add(newAccumulation.mul(_this.m))).add(value);\n                }\n                else {\n                    newValue = _this.c.mul(newAccumulation).add(value);\n                }\n                accumulation.assign(newAccumulation);\n                value.assign(newValue);\n            });\n        });\n        this.incrementIterations();\n    };\n    MomentumOptimizer.prototype.dispose = function () {\n        this.m.dispose();\n        if (this.accumulations != null) {\n            globals_1.dispose(this.accumulations.map(function (v) { return v.variable; }));\n        }\n    };\n    /**\n     * Sets the momentum of the optimizer.\n     *\n     * @param momentum\n     */\n    MomentumOptimizer.prototype.setMomentum = function (momentum) {\n        this.momentum = momentum;\n    };\n    MomentumOptimizer.prototype.getWeights = function () {\n        return __awaiter(this, void 0, void 0, function () {\n            return __generator(this, function (_a) {\n                switch (_a.label) {\n                    case 0: return [4 /*yield*/, this.saveIterations()];\n                    case 1: \n                    // Order matters for Python compatibility.\n                    return [2 /*return*/, [_a.sent()].concat(this.accumulations.map(function (v) { return ({ name: v.originalName, tensor: v.variable }); }))];\n                }\n            });\n        });\n    };\n    MomentumOptimizer.prototype.setWeights = function (weightValues) {\n        return __awaiter(this, void 0, void 0, function () {\n            var trainable;\n            return __generator(this, function (_a) {\n                switch (_a.label) {\n                    case 0: return [4 /*yield*/, this.extractIterations(weightValues)];\n                    case 1:\n                        weightValues = _a.sent();\n                        trainable = false;\n                        this.accumulations = weightValues.map(function (v) { return ({ originalName: v.name, variable: v.tensor.variable(trainable) }); });\n                        return [2 /*return*/];\n                }\n            });\n        });\n    };\n    MomentumOptimizer.prototype.getConfig = function () {\n        return {\n            'learningRate': this.learningRate,\n            'momentum': this.momentum,\n            'useNesterov': this.useNesterov\n        };\n    };\n    /** @nocollapse */\n    MomentumOptimizer.fromConfig = function (cls, config) {\n        return new cls(config['learningRate'], config['momentum'], config['useNesterov']);\n    };\n    /** @nocollapse */\n    MomentumOptimizer.className = 'MomentumOptimizer';\n    return MomentumOptimizer;\n}(sgd_optimizer_1.SGDOptimizer));\nexports.MomentumOptimizer = MomentumOptimizer;\nserialization_1.registerClass(MomentumOptimizer);\n//# sourceMappingURL=momentum_optimizer.js.map","\n/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar __extends = (this && this.__extends) || (function () {\n    var extendStatics = function (d, b) {\n        extendStatics = Object.setPrototypeOf ||\n            ({ __proto__: [] } instanceof Array && function (d, b) { d.__proto__ = b; }) ||\n            function (d, b) { for (var p in b) if (b.hasOwnProperty(p)) d[p] = b[p]; };\n        return extendStatics(d, b);\n    };\n    return function (d, b) {\n        extendStatics(d, b);\n        function __() { this.constructor = d; }\n        d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());\n    };\n})();\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : new P(function (resolve) { resolve(result.value); }).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nvar __generator = (this && this.__generator) || function (thisArg, body) {\n    var _ = { label: 0, sent: function() { if (t[0] & 1) throw t[1]; return t[1]; }, trys: [], ops: [] }, f, y, t, g;\n    return g = { next: verb(0), \"throw\": verb(1), \"return\": verb(2) }, typeof Symbol === \"function\" && (g[Symbol.iterator] = function() { return this; }), g;\n    function verb(n) { return function (v) { return step([n, v]); }; }\n    function step(op) {\n        if (f) throw new TypeError(\"Generator is already executing.\");\n        while (_) try {\n            if (f = 1, y && (t = op[0] & 2 ? y[\"return\"] : op[0] ? y[\"throw\"] || ((t = y[\"return\"]) && t.call(y), 0) : y.next) && !(t = t.call(y, op[1])).done) return t;\n            if (y = 0, t) op = [op[0] & 2, t.value];\n            switch (op[0]) {\n                case 0: case 1: t = op; break;\n                case 4: _.label++; return { value: op[1], done: false };\n                case 5: _.label++; y = op[1]; op = [0]; continue;\n                case 7: op = _.ops.pop(); _.trys.pop(); continue;\n                default:\n                    if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) { _ = 0; continue; }\n                    if (op[0] === 3 && (!t || (op[1] > t[0] && op[1] < t[3]))) { _.label = op[1]; break; }\n                    if (op[0] === 6 && _.label < t[1]) { _.label = t[1]; t = op; break; }\n                    if (t && _.label < t[2]) { _.label = t[2]; _.ops.push(op); break; }\n                    if (t[2]) _.ops.pop();\n                    _.trys.pop(); continue;\n            }\n            op = body.call(thisArg, _);\n        } catch (e) { op = [6, e]; y = 0; } finally { f = t = 0; }\n        if (op[0] & 5) throw op[1]; return { value: op[0] ? op[1] : void 0, done: true };\n    }\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar engine_1 = require(\"../engine\");\nvar globals_1 = require(\"../globals\");\nvar ops_1 = require(\"../ops/ops\");\nvar serialization_1 = require(\"../serialization\");\nvar optimizer_1 = require(\"./optimizer\");\n/** @doclink Optimizer */\nvar SGDOptimizer = /** @class */ (function (_super) {\n    __extends(SGDOptimizer, _super);\n    function SGDOptimizer(learningRate) {\n        var _this = _super.call(this) || this;\n        _this.learningRate = learningRate;\n        _this.setLearningRate(learningRate);\n        return _this;\n    }\n    SGDOptimizer.prototype.applyGradients = function (variableGradients) {\n        var _this = this;\n        var varNames = Array.isArray(variableGradients) ?\n            variableGradients.map(function (v) { return v.name; }) :\n            Object.keys(variableGradients);\n        varNames.forEach(function (name, i) {\n            var gradient = Array.isArray(variableGradients) ?\n                variableGradients[i].tensor :\n                variableGradients[name];\n            if (gradient == null) {\n                return;\n            }\n            var value = engine_1.ENGINE.registeredVariables[name];\n            globals_1.tidy(function () {\n                var newValue = _this.c.mul(gradient).add(value);\n                value.assign(newValue);\n            });\n        });\n        this.incrementIterations();\n    };\n    /**\n     * Sets the learning rate of the optimizer.\n     */\n    SGDOptimizer.prototype.setLearningRate = function (learningRate) {\n        this.learningRate = learningRate;\n        if (this.c != null) {\n            this.c.dispose();\n        }\n        this.c = globals_1.keep(ops_1.scalar(-learningRate));\n    };\n    SGDOptimizer.prototype.dispose = function () {\n        this.c.dispose();\n    };\n    SGDOptimizer.prototype.getWeights = function () {\n        return __awaiter(this, void 0, void 0, function () {\n            return __generator(this, function (_a) {\n                switch (_a.label) {\n                    case 0: return [4 /*yield*/, this.saveIterations()];\n                    case 1: return [2 /*return*/, [_a.sent()]];\n                }\n            });\n        });\n    };\n    SGDOptimizer.prototype.setWeights = function (weightValues) {\n        return __awaiter(this, void 0, void 0, function () {\n            return __generator(this, function (_a) {\n                switch (_a.label) {\n                    case 0: return [4 /*yield*/, this.extractIterations(weightValues)];\n                    case 1:\n                        weightValues = _a.sent();\n                        if (weightValues.length !== 0) {\n                            throw new Error('SGD optimizer does not have settable weights.');\n                        }\n                        return [2 /*return*/];\n                }\n            });\n        });\n    };\n    SGDOptimizer.prototype.getConfig = function () {\n        return { 'learningRate': this.learningRate };\n    };\n    /** @nocollapse */\n    SGDOptimizer.fromConfig = function (cls, config) {\n        return new cls(config['learningRate']);\n    };\n    /** @nocollapse */\n    SGDOptimizer.className = 'SGD'; // Name matters for Python compatibility.\n    return SGDOptimizer;\n}(optimizer_1.Optimizer));\nexports.SGDOptimizer = SGDOptimizer;\nserialization_1.registerClass(SGDOptimizer);\n//# sourceMappingURL=sgd_optimizer.js.map","\n/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar __extends = (this && this.__extends) || (function () {\n    var extendStatics = function (d, b) {\n        extendStatics = Object.setPrototypeOf ||\n            ({ __proto__: [] } instanceof Array && function (d, b) { d.__proto__ = b; }) ||\n            function (d, b) { for (var p in b) if (b.hasOwnProperty(p)) d[p] = b[p]; };\n        return extendStatics(d, b);\n    };\n    return function (d, b) {\n        extendStatics(d, b);\n        function __() { this.constructor = d; }\n        d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());\n    };\n})();\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : new P(function (resolve) { resolve(result.value); }).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nvar __generator = (this && this.__generator) || function (thisArg, body) {\n    var _ = { label: 0, sent: function() { if (t[0] & 1) throw t[1]; return t[1]; }, trys: [], ops: [] }, f, y, t, g;\n    return g = { next: verb(0), \"throw\": verb(1), \"return\": verb(2) }, typeof Symbol === \"function\" && (g[Symbol.iterator] = function() { return this; }), g;\n    function verb(n) { return function (v) { return step([n, v]); }; }\n    function step(op) {\n        if (f) throw new TypeError(\"Generator is already executing.\");\n        while (_) try {\n            if (f = 1, y && (t = op[0] & 2 ? y[\"return\"] : op[0] ? y[\"throw\"] || ((t = y[\"return\"]) && t.call(y), 0) : y.next) && !(t = t.call(y, op[1])).done) return t;\n            if (y = 0, t) op = [op[0] & 2, t.value];\n            switch (op[0]) {\n                case 0: case 1: t = op; break;\n                case 4: _.label++; return { value: op[1], done: false };\n                case 5: _.label++; y = op[1]; op = [0]; continue;\n                case 7: op = _.ops.pop(); _.trys.pop(); continue;\n                default:\n                    if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) { _ = 0; continue; }\n                    if (op[0] === 3 && (!t || (op[1] > t[0] && op[1] < t[3]))) { _.label = op[1]; break; }\n                    if (op[0] === 6 && _.label < t[1]) { _.label = t[1]; t = op; break; }\n                    if (t && _.label < t[2]) { _.label = t[2]; _.ops.push(op); break; }\n                    if (t[2]) _.ops.pop();\n                    _.trys.pop(); continue;\n            }\n            op = body.call(thisArg, _);\n        } catch (e) { op = [6, e]; y = 0; } finally { f = t = 0; }\n        if (op[0] & 5) throw op[1]; return { value: op[0] ? op[1] : void 0, done: true };\n    }\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar engine_1 = require(\"../engine\");\nvar globals_1 = require(\"../globals\");\nvar ops_1 = require(\"../ops/ops\");\nvar serialization_1 = require(\"../serialization\");\nvar optimizer_1 = require(\"./optimizer\");\n/** @doclink Optimizer */\nvar RMSPropOptimizer = /** @class */ (function (_super) {\n    __extends(RMSPropOptimizer, _super);\n    function RMSPropOptimizer(learningRate, decay, momentum, epsilon, centered) {\n        if (decay === void 0) { decay = 0.9; }\n        if (momentum === void 0) { momentum = 0.0; }\n        if (epsilon === void 0) { epsilon = null; }\n        if (centered === void 0) { centered = false; }\n        var _this = _super.call(this) || this;\n        _this.learningRate = learningRate;\n        _this.decay = decay;\n        _this.momentum = momentum;\n        _this.epsilon = epsilon;\n        _this.accumulatedMeanSquares = [];\n        _this.accumulatedMoments = [];\n        _this.accumulatedMeanGrads = [];\n        _this.centered = centered;\n        if (epsilon == null) {\n            _this.epsilon = engine_1.ENGINE.backend.epsilon();\n        }\n        return _this;\n    }\n    RMSPropOptimizer.prototype.applyGradients = function (variableGradients) {\n        var _this = this;\n        var variableNames = Array.isArray(variableGradients) ?\n            variableGradients.map(function (item) { return item.name; }) :\n            Object.keys(variableGradients);\n        variableNames.forEach(function (name, i) {\n            var value = engine_1.ENGINE.registeredVariables[name];\n            var trainable = false;\n            if (_this.accumulatedMeanSquares[i] == null) {\n                _this.accumulatedMeanSquares[i] = {\n                    originalName: name + \"/rms\",\n                    variable: globals_1.tidy(function () { return ops_1.zerosLike(value).variable(trainable); })\n                };\n            }\n            if (_this.accumulatedMoments[i] == null) {\n                _this.accumulatedMoments[i] = {\n                    originalName: name + \"/momentum\",\n                    variable: globals_1.tidy(function () { return ops_1.zerosLike(value).variable(trainable); })\n                };\n            }\n            if (_this.accumulatedMeanGrads[i] == null && _this.centered) {\n                _this.accumulatedMeanGrads[i] = {\n                    originalName: name + \"/mg\",\n                    variable: globals_1.tidy(function () { return ops_1.zerosLike(value).variable(trainable); })\n                };\n            }\n            var gradient = Array.isArray(variableGradients) ?\n                variableGradients[i].tensor :\n                variableGradients[name];\n            if (gradient == null) {\n                return;\n            }\n            var accumulatedMeanSquare = _this.accumulatedMeanSquares[i].variable;\n            var accumulatedMoments = _this.accumulatedMoments[i].variable;\n            globals_1.tidy(function () {\n                var newAccumulatedMeanSquare = accumulatedMeanSquare.mul(_this.decay)\n                    .add(gradient.square().mul(1 - _this.decay));\n                if (_this.centered) {\n                    var accumulatedMeanGrad = _this.accumulatedMeanGrads[i].variable;\n                    // Centered gradient\n                    var newAccumulatedMeanGrad = accumulatedMeanGrad.mul(_this.decay)\n                        .add(gradient.mul(1 - _this.decay));\n                    var newAccumulatedMoments = accumulatedMoments.mul(_this.momentum)\n                        .add(gradient.mul(_this.learningRate)\n                        .div(newAccumulatedMeanSquare\n                        .sub(newAccumulatedMeanGrad.square().add(_this.epsilon))\n                        .sqrt()));\n                    accumulatedMeanSquare.assign(newAccumulatedMeanSquare);\n                    accumulatedMeanGrad.assign(newAccumulatedMeanGrad);\n                    accumulatedMoments.assign(newAccumulatedMoments);\n                    var newValue = value.sub(newAccumulatedMoments);\n                    value.assign(newValue);\n                }\n                else {\n                    // Plain gradient\n                    var newAccumulatedMeanSquare_1 = accumulatedMeanSquare.mul(_this.decay)\n                        .add(gradient.square().mul(1 - _this.decay));\n                    var newAccumulatedMoments = accumulatedMoments.mul(_this.momentum)\n                        .add(gradient.mul(_this.learningRate)\n                        .div(newAccumulatedMeanSquare_1.add(_this.epsilon)\n                        .sqrt()));\n                    accumulatedMeanSquare.assign(newAccumulatedMeanSquare_1);\n                    accumulatedMoments.assign(newAccumulatedMoments);\n                    var newValue = value.sub(newAccumulatedMoments);\n                    value.assign(newValue);\n                }\n            });\n        });\n        this.incrementIterations();\n    };\n    RMSPropOptimizer.prototype.dispose = function () {\n        if (this.accumulatedMeanSquares != null) {\n            globals_1.dispose(this.accumulatedMeanSquares.map(function (v) { return v.variable; }));\n        }\n        if (this.accumulatedMeanGrads != null && this.centered) {\n            globals_1.dispose(this.accumulatedMeanGrads.map(function (v) { return v.variable; }));\n        }\n        if (this.accumulatedMoments != null) {\n            globals_1.dispose(this.accumulatedMoments.map(function (v) { return v.variable; }));\n        }\n    };\n    RMSPropOptimizer.prototype.getWeights = function () {\n        return __awaiter(this, void 0, void 0, function () {\n            var variables;\n            return __generator(this, function (_a) {\n                switch (_a.label) {\n                    case 0:\n                        variables = this.accumulatedMeanSquares.concat(this.accumulatedMoments);\n                        if (this.centered) {\n                            variables.push.apply(variables, this.accumulatedMeanGrads);\n                        }\n                        return [4 /*yield*/, this.saveIterations()];\n                    case 1: return [2 /*return*/, [_a.sent()].concat(variables.map(function (v) { return ({ name: v.originalName, tensor: v.variable }); }))];\n                }\n            });\n        });\n    };\n    RMSPropOptimizer.prototype.setWeights = function (weightValues) {\n        return __awaiter(this, void 0, void 0, function () {\n            var variableCount, trainable;\n            return __generator(this, function (_a) {\n                switch (_a.label) {\n                    case 0: return [4 /*yield*/, this.extractIterations(weightValues)];\n                    case 1:\n                        weightValues = _a.sent();\n                        variableCount = this.centered ? weightValues.length / 3 : weightValues.length / 2;\n                        trainable = false;\n                        this.accumulatedMeanSquares =\n                            weightValues.slice(0, variableCount).map(function (v) { return ({\n                                originalName: v.name,\n                                variable: v.tensor.variable(trainable)\n                            }); });\n                        this.accumulatedMoments =\n                            weightValues.slice(variableCount, variableCount * 2)\n                                .map(function (v) { return ({\n                                originalName: v.name,\n                                variable: v.tensor.variable(trainable)\n                            }); });\n                        if (this.centered) {\n                            this.accumulatedMeanGrads =\n                                weightValues.slice(variableCount * 2, variableCount * 3)\n                                    .map(function (v) { return ({\n                                    originalName: v.name,\n                                    variable: v.tensor.variable(trainable)\n                                }); });\n                        }\n                        return [2 /*return*/];\n                }\n            });\n        });\n    };\n    RMSPropOptimizer.prototype.getConfig = function () {\n        return {\n            'learningRate': this.learningRate,\n            'decay': this.decay,\n            'momentum': this.momentum,\n            'epsilon': this.epsilon,\n            'centered': this.centered\n        };\n    };\n    /** @nocollapse */\n    RMSPropOptimizer.fromConfig = function (cls, config) {\n        return new cls(config['learningRate'], config['decay'], config['momentum'], config['epsilon'], config['centered']);\n    };\n    /** @nocollapse */\n    RMSPropOptimizer.className = 'RMSProp';\n    return RMSPropOptimizer;\n}(optimizer_1.Optimizer));\nexports.RMSPropOptimizer = RMSPropOptimizer;\nserialization_1.registerClass(RMSPropOptimizer);\n//# sourceMappingURL=rmsprop_optimizer.js.map","\n/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\n// So typings can propagate.\nvar adadelta_optimizer_1 = require(\"./optimizers/adadelta_optimizer\");\nvar adagrad_optimizer_1 = require(\"./optimizers/adagrad_optimizer\");\nvar adam_optimizer_1 = require(\"./optimizers/adam_optimizer\");\nvar adamax_optimizer_1 = require(\"./optimizers/adamax_optimizer\");\nvar momentum_optimizer_1 = require(\"./optimizers/momentum_optimizer\");\nvar optimizer_constructors_1 = require(\"./optimizers/optimizer_constructors\");\nvar rmsprop_optimizer_1 = require(\"./optimizers/rmsprop_optimizer\");\nvar sgd_optimizer_1 = require(\"./optimizers/sgd_optimizer\");\n// tslint:disable-next-line:no-unused-expression\n[momentum_optimizer_1.MomentumOptimizer, sgd_optimizer_1.SGDOptimizer, adadelta_optimizer_1.AdadeltaOptimizer, adagrad_optimizer_1.AdagradOptimizer,\n    rmsprop_optimizer_1.RMSPropOptimizer, adamax_optimizer_1.AdamaxOptimizer, adam_optimizer_1.AdamOptimizer];\nexports.train = {\n    sgd: optimizer_constructors_1.OptimizerConstructors.sgd,\n    momentum: optimizer_constructors_1.OptimizerConstructors.momentum,\n    adadelta: optimizer_constructors_1.OptimizerConstructors.adadelta,\n    adagrad: optimizer_constructors_1.OptimizerConstructors.adagrad,\n    rmsprop: optimizer_constructors_1.OptimizerConstructors.rmsprop,\n    adamax: optimizer_constructors_1.OptimizerConstructors.adamax,\n    adam: optimizer_constructors_1.OptimizerConstructors.adam\n};\n//# sourceMappingURL=train.js.map","\n/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar adadelta_optimizer_1 = require(\"./adadelta_optimizer\");\nvar adagrad_optimizer_1 = require(\"./adagrad_optimizer\");\nvar adam_optimizer_1 = require(\"./adam_optimizer\");\nvar adamax_optimizer_1 = require(\"./adamax_optimizer\");\nvar momentum_optimizer_1 = require(\"./momentum_optimizer\");\nvar rmsprop_optimizer_1 = require(\"./rmsprop_optimizer\");\nvar sgd_optimizer_1 = require(\"./sgd_optimizer\");\nvar OptimizerConstructors = /** @class */ (function () {\n    function OptimizerConstructors() {\n    }\n    /**\n     * Constructs a `tf.SGDOptimizer` that uses stochastic gradient descent.\n     *\n     * ```js\n     * // Fit a quadratic function by learning the coefficients a, b, c.\n     * const xs = tf.tensor1d([0, 1, 2, 3]);\n     * const ys = tf.tensor1d([1.1, 5.9, 16.8, 33.9]);\n     *\n     * const a = tf.scalar(Math.random()).variable();\n     * const b = tf.scalar(Math.random()).variable();\n     * const c = tf.scalar(Math.random()).variable();\n     *\n     * // y = a * x^2 + b * x + c.\n     * const f = x => a.mul(x.square()).add(b.mul(x)).add(c);\n     * const loss = (pred, label) => pred.sub(label).square().mean();\n     *\n     * const learningRate = 0.01;\n     * const optimizer = tf.train.sgd(learningRate);\n     *\n     * // Train the model.\n     * for (let i = 0; i < 10; i++) {\n     *   optimizer.minimize(() => loss(f(xs), ys));\n     * }\n     *\n     * // Make predictions.\n     * console.log(\n     *     `a: ${a.dataSync()}, b: ${b.dataSync()}, c: ${c.dataSync()}`);\n     * const preds = f(xs).dataSync();\n     * preds.forEach((pred, i) => {\n     *   console.log(`x: ${i}, pred: ${pred}`);\n     * });\n     * ```\n     *\n     * @param learningRate The learning rate to use for the SGD algorithm.\n     */\n    /**\n     * @doc {heading: 'Training', subheading: 'Optimizers', namespace: 'train'}\n     */\n    OptimizerConstructors.sgd = function (learningRate) {\n        return new sgd_optimizer_1.SGDOptimizer(learningRate);\n    };\n    /**\n     * Constructs a `tf.MomentumOptimizer` that uses momentum gradient\n     * descent.\n     *\n     * See\n     * [http://proceedings.mlr.press/v28/sutskever13.pdf](\n     * http://proceedings.mlr.press/v28/sutskever13.pdf)\n     *\n     * @param learningRate The learning rate to use for the Momentum gradient\n     * descent algorithm.\n     * @param momentum The momentum to use for the momentum gradient descent\n     * algorithm.\n     */\n    /**\n     * @doc {heading: 'Training', subheading: 'Optimizers', namespace: 'train'}\n     */\n    OptimizerConstructors.momentum = function (learningRate, momentum, useNesterov) {\n        if (useNesterov === void 0) { useNesterov = false; }\n        return new momentum_optimizer_1.MomentumOptimizer(learningRate, momentum, useNesterov);\n    };\n    /**\n     * Constructs a `tf.RMSPropOptimizer` that uses RMSProp gradient\n     * descent. This implementation uses plain momentum and is not centered\n     * version of RMSProp.\n     *\n     * See\n     * [http://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf](\n     * http://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf)\n     *\n     * @param learningRate The learning rate to use for the RMSProp gradient\n     * descent algorithm.\n     * @param decay The discounting factor for the history/coming gradient.\n     * @param momentum The momentum to use for the RMSProp gradient descent\n     * algorithm.\n     * @param epsilon Small value to avoid zero denominator.\n     * @param centered If true, gradients are normalized by the estimated\n     * variance of the gradient.\n     */\n    /**\n     * @doc {heading: 'Training', subheading: 'Optimizers', namespace: 'train'}\n     */\n    OptimizerConstructors.rmsprop = function (learningRate, decay, momentum, epsilon, centered) {\n        if (decay === void 0) { decay = .9; }\n        if (momentum === void 0) { momentum = 0.0; }\n        if (epsilon === void 0) { epsilon = null; }\n        if (centered === void 0) { centered = false; }\n        return new rmsprop_optimizer_1.RMSPropOptimizer(learningRate, decay, momentum, epsilon, centered);\n    };\n    /**\n     * Constructs a `tf.AdamOptimizer` that uses the Adam algorithm.\n     * See [https://arxiv.org/abs/1412.6980](https://arxiv.org/abs/1412.6980)\n     *\n     * @param learningRate The learning rate to use for the Adam gradient\n     * descent algorithm.\n     * @param beta1 The exponential decay rate for the 1st moment estimates.\n     * @param beta2 The exponential decay rate for the 2nd moment estimates.\n     * @param epsilon A small constant for numerical stability.\n     */\n    /**\n     * @doc {heading: 'Training', subheading: 'Optimizers', namespace: 'train'}\n     */\n    OptimizerConstructors.adam = function (learningRate, beta1, beta2, epsilon) {\n        if (learningRate === void 0) { learningRate = 0.001; }\n        if (beta1 === void 0) { beta1 = 0.9; }\n        if (beta2 === void 0) { beta2 = 0.999; }\n        if (epsilon === void 0) { epsilon = null; }\n        return new adam_optimizer_1.AdamOptimizer(learningRate, beta1, beta2, epsilon);\n    };\n    /**\n     * Constructs a `tf.AdadeltaOptimizer` that uses the Adadelta algorithm.\n     * See [https://arxiv.org/abs/1212.5701](https://arxiv.org/abs/1212.5701)\n     *\n     * @param learningRate The learning rate to use for the Adadelta gradient\n     * descent algorithm.\n     * @param rho The learning rate decay over each update.\n     * @param epsilon A constant epsilon used to better condition the grad\n     * update.\n     */\n    /**\n     * @doc {heading: 'Training', subheading: 'Optimizers', namespace: 'train'}\n     */\n    OptimizerConstructors.adadelta = function (learningRate, rho, epsilon) {\n        if (learningRate === void 0) { learningRate = .001; }\n        if (rho === void 0) { rho = .95; }\n        if (epsilon === void 0) { epsilon = null; }\n        return new adadelta_optimizer_1.AdadeltaOptimizer(learningRate, rho, epsilon);\n    };\n    /**\n     * Constructs a `tf.AdamaxOptimizer` that uses the Adamax algorithm.\n     * See [https://arxiv.org/abs/1412.6980](https://arxiv.org/abs/1412.6980)\n     *\n     * @param learningRate The learning rate to use for the Adamax gradient\n     * descent algorithm.\n     * @param beta1 The exponential decay rate for the 1st moment estimates.\n     * @param beta2 The exponential decay rate for the 2nd moment estimates.\n     * @param epsilon A small constant for numerical stability.\n     * @param decay The learning rate decay over each update.\n     */\n    /**\n     * @doc {heading: 'Training', subheading: 'Optimizers', namespace: 'train'}\n     */\n    OptimizerConstructors.adamax = function (learningRate, beta1, beta2, epsilon, decay) {\n        if (learningRate === void 0) { learningRate = 0.002; }\n        if (beta1 === void 0) { beta1 = 0.9; }\n        if (beta2 === void 0) { beta2 = 0.999; }\n        if (epsilon === void 0) { epsilon = null; }\n        if (decay === void 0) { decay = 0.0; }\n        return new adamax_optimizer_1.AdamaxOptimizer(learningRate, beta1, beta2, epsilon, decay);\n    };\n    /**\n     * Constructs a `tf.AdagradOptimizer` that uses the Adagrad algorithm.\n     * See\n     * [http://www.jmlr.org/papers/volume12/duchi11a/duchi11a.pdf](\n     * http://www.jmlr.org/papers/volume12/duchi11a/duchi11a.pdf)\n     * or\n     * [http://ruder.io/optimizing-gradient-descent/index.html#adagrad](\n     * http://ruder.io/optimizing-gradient-descent/index.html#adagrad)\n     *\n     * @param learningRate The learning rate to use for the Adagrad gradient\n     * descent algorithm.\n     * @param initialAccumulatorValue Starting value for the accumulators, must be\n     * positive.\n     */\n    /**\n     * @doc {heading: 'Training', subheading: 'Optimizers', namespace: 'train'}\n     */\n    OptimizerConstructors.adagrad = function (learningRate, initialAccumulatorValue) {\n        if (initialAccumulatorValue === void 0) { initialAccumulatorValue = 0.1; }\n        return new adagrad_optimizer_1.AdagradOptimizer(learningRate, initialAccumulatorValue);\n    };\n    return OptimizerConstructors;\n}());\nexports.OptimizerConstructors = OptimizerConstructors;\n//# sourceMappingURL=optimizer_constructors.js.map","\n/**\n * @license\n * Copyright 2017 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar delayCallback = (function () {\n    if (typeof requestAnimationFrame !== 'undefined') {\n        return requestAnimationFrame;\n    }\n    else if (typeof setImmediate !== 'undefined') {\n        return setImmediate;\n    }\n    return function (f) { return f(); }; // no delays\n})();\n/**\n * Returns a promise that resolve when a requestAnimationFrame has completed.\n *\n * On Node.js this uses setImmediate instead of requestAnimationFrame.\n *\n * This is simply a sugar method so that users can do the following:\n * `await tf.nextFrame();`\n */\n/** @doc {heading: 'Performance', subheading: 'Timing'} */\nfunction nextFrame() {\n    return new Promise(function (resolve) { return delayCallback(function () { return resolve(); }); });\n}\nexports.nextFrame = nextFrame;\n//# sourceMappingURL=browser_util.js.map"]}